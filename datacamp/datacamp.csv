,title,time_in_hours,no_of_videos,Exercises,no_of_Learners,XP,course-description,what-you-will-learn-lesson-1,what-you-will-learn-lesson-2,what-you-will-learn-lesson-3,what-you-will-learn-lesson-4,collaborators,prerequisities,what-you-will-learn-lesson-5,what-you-will-learn-lesson-6
0,Data Science for Business,2,14,51,"67,677",3350,"What is data science and how can you use it to strengthen your organization? This course will teach you about the skills you need on your data team, and how you can structure that team to meet your organization's needs. Data is everywhere! This course will provide you with an understanding of data sources your company can use and how to store that data. You'll also discover ways to analyze and visualize your data through dashboards and A/B tests. To wrap up the course, we'll discuss exciting topics in machine learning, including clustering, time series prediction, natural language processing (NLP), deep learning, and explainable AI! Along the way, you'll learn about a variety of real-world applications of data science and gain a better understanding of these concepts through practical exercises.","What is Data Science?,Customer Segmentation Workflow,Building a customer service chatbot,Improving OKRs,Applications of Data Science,Assigning data science projects,Investment research,Building a data science team,Interpreting a team sprint,Editing a job posting,Matching skills to jobs,Classifying data tasks","Dashboards,Classifying dashboard elements,Improving a dashboard,Choosing the right dashboard,Ad hoc analysis,Filling out an ad hoc request,Classifying requests,A/B Testing,Creating an A/B testing workflow,Sample size,Intermediate results","Data sources and risks,Classifying data for security,Creating web data events,Protecting PII,Solicited data,Identifying question purpose,Validating focus group feedback,Net Promoter Score,Collecting additional data,Sorting data sources,Asthma frequency,Data storage and retrieval,Cloud platforms,Querying a database,Which type of database?","Supervised machine learning,When to use Supervised Learning,Features and labels,Model evaluation,Clustering,Supervised vs. unsupervised,Cluster size selection,Special topics in Machine Learning,Classifying machine learning tasks,Sentiment Analysis,Deep Learning and Explainable AI,Finding the correct solution,Should I use Deep Learning?","Amy Peterson,Hillary Green-Lerman",Data Skills for Business,,
1,Data Communication Concepts,3,16,50,"3,047",3750,"You’ve analyzed your data, run your model, and made your predictions. Now, it's time to bring your data to life! Presenting findings to stakeholders so they can make data-driven decisions is an essential skill for all data scientists. In this course, you’ll learn how to use storytelling to connect with your audience and help them understand the content of your presentation—so they can make the right decisions. Through hands-on exercises, you’ll learn the advantages and disadvantages of oral and written formats. You’ll also improve how you translate technical results into compelling stories, using the correct data, visualizations, and in-person presentation techniques. Start learning and improve your data storytelling today.","Fundamentals of storytelling,The story begins,Building a story,Translating technical results,A non-tech story,Be aware,Impacting the decision-making process,Is it a true story?,Structured to impact,A story to compare","Types of reports,Something to report,In summary,Reproducibility and references,Replicate me,Same results,Write precise and clear reports,Half-empty glass,Strong words,Case study: report on credit risk,Credit me,Report my credit","Selecting the right data,The truth about salaries,Earning interests,Showing relevant statistics,Salary variation,On a payroll,It's not significant,Visualizations for different audiences,Salary development,Salary on demand,Choosing the appropriate format,A communication problem,Should we meet?,When in doubt","Planning an oral presentation,Is this the plan?,An effective plan!,Building presentation slides,A color building,Too much text,The right building,Delivering the presentation,Put it into practice,Best practice,Avoiding common errors,The true mistake,Do's and don'ts,Congratulations!",Maria Eugenia Inzaugarat,"Data Analyst,Data Science for Everyone,Data Visualization for Everyone",,
2,Intermediate Data Visualization with ggplot2,4,14,52,"29,130",4350,"This ggplot2 course builds on your knowledge from the introductory course to produce meaningful explanatory plots. Statistics will be calculated on the fly and you’ll see how Coordinates and Facets aid in communication. You’ll also explore details of data visualization best practices with ggplot2 to help make sure you have a sound understanding of what works and why. By the end of the course, you’ll have all the tools needed to make a custom plotting function to explore a large data set, combining statistics and excellent visuals.","Stats with geoms,Smoothing,Grouping variables,Modifying stat_smooth,Modifying stat_smooth (2),Stats: sum and quantile,Quantiles,Using stat_sum,Stats outside geoms,Preparations,Using position objects,Plotting variations","The facets layer,Facet layer basics,Many variables,Formula notation,Facet labels and order,Labeling facets,Setting order,Facet plotting spaces,Variable plotting spaces I: continuous variables,Variable plotting spaces II: categorical variables,Facet wrap & margins,Wrapping for many levels,Margin plots","Coordinates,Zooming In,Aspect ratio I: 1:1 ratios,Aspect ratio II: setting ratios,Expand and clip,Coordinates vs. scales,Log-transforming scales,Adding stats to transformed scales,Double and flipped axes,Useful double axes,Flipping axes I,Flipping axes II,Polar coordinates,Pie charts,Wind rose plots","Best practices: bar plots,Bar plots: dynamite plots,Bar plots: position dodging,Bar plots: Using aggregated data,Heatmaps use case scenario,Heat maps,Useful heat maps,Heat map alternatives,When good data makes bad plots,Suppression of the origin,Color blindness,Typical problems",Richie Cotton,"Data Scientist,Data Visualization,Introduction to Data Visualization with ggplot2",,
3,Customer Segmentation in Python,4,17,55,"14,698",4400,"The most successful companies today are the ones that know their customers so well that they can anticipate their needs. Data analysts play a key role in unlocking these in-depth insights, and segmenting the customers to better serve them. In this course, you will learn real-world techniques on customer segmentation and behavioral analytics, using a real dataset containing anonymized customer transactions from an online retailer. You will first run cohort analysis to understand customer trends. You will then learn how to build easy to interpret customer segments. On top of that, you will prepare the segments you created, making them ready for machine learning. Finally, you will make your segments more powerful with k-means clustering, in just few lines of code! By the end of this course, you will be able to apply practical customer behavioral analytics and segmentation techniques.","Introduction to cohort analysis,How many customers acquired?,Cohort analysis,Assign daily acquisition cohort,Calculate time offset in days - part 1,Calculate time offset in days - part 2,Cohort metrics,Customer retention,Calculate retention rate from scratch,Calculate average price,Visualizing cohort analysis,Visualize average quantity metric","Data pre-processing,Assumptions of k-means,Calculate statistics of variables,Managing skewed variables,Detect skewed variables,Manage skewness,Centering and scaling data,Center and scale manually,Center and scale with StandardScaler(),Pre-processing pipeline,Visualize RFM distributions,Pre-process RFM data,Visualize the normalized variables","Recency, frequency, monetary (RFM) segmentation,Calculate spend quartiles (q=4),Calculate recency deciles (q=4),Calculating RFM metrics,Largest frequency value,Calculate RFM values,Building RFM segments,Calculate 3 groups for recency and frequency,Calculate RFM Score,Analyzing RFM table,Find average value for RFM score segment,Creating custom segments,Analyzing custom segments","Practical implementation of k-means clustering,Run k-means,Assign labels to raw data,Choosing the number of clusters,Calculate sum of squared errors,Plot sum of squared errors,Profile and interpret segments,Prepare data for the snake plot,Visualize snake plot,Calculate relative importance of each attribute,Plot relative importance heatmap,End-to-end segmentation solution,Pre-process data,Calculate and plot sum of squared errors,Build 4-cluster solution,Analyze the segments,Final thoughts","Hadrien Lacroix,Mari Nazary","Marketing Analytics,Chapter 1 datasets,Chapter 2 datasets,Chapter 3 datasets,Chapter 4 datasets,Data Manipulation with pandas,Supervised Learning with scikit-learn",,
4,Sampling in Python,4,15,51,,4000,"Sampling in Python is the cornerstone of inference statistics and hypothesis testing. It's a powerful skill used in survey analysis and experimental design to draw conclusions without surveying an entire population. In this Sampling in Python course, you’ll discover when to use sampling and how to perform common types of sampling—from simple random sampling to more complex methods like stratified and cluster sampling. Using real-world datasets, including coffee ratings, Spotify songs, and employee attrition, you’ll learn to estimate population statistics and quantify uncertainty in your estimates by generating sampling distributions and bootstrap distributions.","Living the sample life,Reasons for sampling,Simple sampling with pandas,Simple sampling and calculating with NumPy,A little too convenient,Are the findings from this sample generalizable?,Are these findings generalizable?,How does Sue do sampling?,Generating random numbers,Understanding random seeds","An ample sample,Calculating relative errors,Relative error vs. sample size,Baby back dist-rib-ution,Replicating samples,Replication parameters,Be our guess, put our samples to the test,Exact sampling distribution,Approximate sampling distribution,Exact vs. approximate,Err on the side of Gaussian,Population & sampling distribution means,Population & sampling distribution variation","Simple is as simple does,Simple random sampling,Systematic sampling,Is systematic sampling OK?,Can't get no stratisfaction,Which sampling method?,Proportional stratified sampling,Equal counts stratified sampling,Weighted sampling,What a cluster...,Benefits of clustering,Cluster sampling,Straight to the point (estimate),3 kinds of sampling,Comparing point estimates","This bears a striking resample-lance,Principles of bootstrapping,With or without replacement?,Generating a bootstrap distribution,A breath of fresh error,Bootstrap statistics and population statistics,Sampling distribution vs. bootstrap distribution,Compare sampling and bootstrap means,Compare sampling and bootstrap standard deviations,Venus infers,Confidence interval interpretation,Calculating confidence intervals,Congratulations","Dr. Chester Ismay,Amy Peterson","Data Scientist,Statistics Fundamentals,Coffee ratings,Spotify song attributes,Employee attrition,Introduction to Statistics in Python",,
5,Advanced Dimensionality Reduction in R,4,16,51,"3,796",4300,"Dimensionality reduction techniques are based on unsupervised machine learning algorithms and their application offers several advantages. In this course you will learn how to apply dimensionality reduction techniques to exploit these advantages, using interesting datasets like the MNIST database of handwritten digits, the fashion version of MNIST released by Zalando, and a credit card fraud detection dataset. Firstly, you will have a look at t-SNE, an algorithm that performs non-linear dimensionality reduction. Then, you will also explore some useful characteristics of dimensionality reduction to apply in predictive models. Finally, you will see the application of GLRM to compress big data (with numerical and categorical values) and impute missing values. Are you ready to start compressing high dimensional data?","Exploring the MNIST dataset,Exploring MNIST dataset,Digits features,Distance metrics,Euclidean distance,Minkowski distance,KL divergence,PCA and t-SNE,Generating PCA from MNIST sample,t-SNE output from MNIST sample","Credit card fraud detection,Exploring credit card fraud dataset,Generating training and test sets,Training random forests models,Training a random forest with original features,Computing and visualising the t-SNE embedding,Training a random forest with embedding features,Predicting data,Predicting data using original features,Predicting data using embedding random forest,Visualizing neural networks layers,Exploring neural network layer output,Using t-SNE to visualise a neural network layer","Building a t-SNE embedding,Computing t-SNE,Understanding t-SNE output,Optimal number of t-SNE iterations,Reproducing results,Optimal number of iterations,Effect of perplexity parameter,Perplexity of MNIST sample,Perplexity of bigger MNIST dataset,Classifying digits with t-SNE,Plotting spatial distribution of true classes,Computing the centroids of each class,Computing similarities of digits 1 and 0,Plotting similarities of digits 1 and 0","Exploring fashion MNIST dataset,Exploring fashion MNIST,Visualizing fashion MNIST,Generalized Low Rank Models (GLRM),Reducing data with GLRM,Improving model convergence,Visualizing a GLRM model,Visualizing the output of GLRM,Visualizing the prototypes,Dealing with missing data and speeding-up models,Imputing missing data,Training a random forest with original data,Training a random forest with compressed data,Summary of the course","Chester Ismay,Sara Billen","MNIST sample,Credit card fraud,Fashion MNIST sample,Unsupervised Learning in R",,
6,Introduction to NumPy,4,13,49,"6,066",4250,"NumPy is an essential Python library. TensorFlow and scikit-learn use NumPy arrays as inputs, and pandas and Matplotlib are built on top of NumPy. In this Introduction to NumPy course, you'll become a master wrangler of NumPy's core object: arrays! Using data from New York City's tree census, you'll create, sort, filter, and update arrays. You'll discover why NumPy is so efficient and use broadcasting and vectorization to make your NumPy code even faster. By the end of the course, you'll be using 3D arrays to alter a Claude Monet painting, and you'll understand why such array alterations are essential tools for machine learning.","Introducing arrays,Your first NumPy array,Creating arrays from scratch,A range array,Array dimensionality,3D array creation,The fourth dimension,Flattening and reshaping,NumPy data types,The dtype argument,Anticipating data types,A smaller sudoku game","Summarizing data,Sales totals,Plotting averages,Cumulative sales,Vectorized operations,Tax calculations,Projecting sales,Vectorizing .upper(),Broadcasting,Broadcastable or not?,Broadcasting across columns,Broadcasting across rows","Indexing and slicing arrays,Slicing and indexing trees,Stepping into 2D,Sorting trees,Filtering arrays,Filtering with masks,Fancy indexing vs. np.where(),Creating arrays from conditions,Adding and removing data,Compatible or not?,Adding rows,Adding columns,Deleting with np.delete()","Saving and loading arrays,Loading .npy files,Getting help,Update and save,Array acrobatics,Augmenting Monet,Transposing your masterpiece,Stacking and splitting,2D split and stack,Splitting RGB data,Stacking RGB data,Congratulations!","James Chapman,Amy Peterson","Data Scientist,Monet RGB Array,Tree Census Array,Monthly Sales Array,Sudoku Game Array,Sudoku Solution Array,Intermediate Python",,
7,Survival Analysis in Python,4,16,48,"2,444",3850,"How long does it take for flu symptoms to show after exposure? And what if you don't know when people caught the virus? Do salary and work-life balance influence the speed of employee turnover? Lots of real-life challenges require survival analysis to robustly estimate the time until an event to help us draw insights from time-to-event distributions. This course introduces you to the basic concepts of survival analysis. Through hands-on practice, you’ll learn how to compute, visualize, interpret, and compare survival curves using Kaplan-Meier, Weibull, and Cox PH models. By the end of this course, you’ll be able to model survival distributions, build pretty plots of survival curves, and even predict survival durations.","What is survival analysis?,What problems does survival analysis solve?,Choose the right data for survival analysis,Why use survival analysis?,Identify the censorship type,Preprocess censored data,First look at censored data,Your first survival curve!,Draw a survival curve,Long live democracy!","Fitting the Weibull model,Model prison data with Weibull,Compare Weibull model parameters,Weibull model with covariates,Analyze heart patients characteristics,Explore gender-LVDD interaction,Visualization and prediction with Weibull model,How do prior arrests impact re-arrest rate?,Predict re-arrest rate,Other distributions and model selection,How good is the fit?,Choose a parametric model","Fitting a Kaplan-Meier estimator,How to fit a Kaplan-Meier estimator?,Heart disease patient survival,Visualizing your Kaplan-Meier model,Plotting the survival curve,Patient soreness treatment,Applying survival analysis to groups,Senators' terms in office,Comparing patient soreness treatments,The log-rank test,Appropriate data for log-rank test,Plotting and comparing survival curves,Log-rank test","Fitting the Cox Proportional Hazards model,Model prison data with Cox PH,Custom Cox PH model,Interpreting the Cox PH model,Cox PH model survival time,Plot covariate effects on survival,The proportional hazards assumption,Test the PH assumption with KM curves,Test the PH assumption automatically,Predicting with the Cox PH model,Employee churn study,Predict before they leave!,Congratulations!","Maggie Matsui,Hadrien Lacroix","Echocardiogram data,Employee attrition data,Regimes data,Prison recidivism data,Introduction to Regression with statsmodels in Python,Hypothesis Testing in Python",,
8,Modeling with tidymodels in R,4,16,59,"4,166",4950,"Tidymodels is a powerful suite of R packages designed to streamline machine learning workflows. Learn to split datasets for cross-validation, preprocess data with tidymodels' recipe package, and fine-tune machine learning algorithms. You'll learn key concepts such as defining model objects and creating modeling workflows. Then, you'll apply your skills to predict home prices and classify employees by their risk of leaving a company.","The tidymodels ecosystem,Tidymodels packages,Creating training and test datasets,Distribution of outcome variable values,Linear regression with tidymodels,Fitting a linear regression model,Exploring estimated model parameters,Predicting home selling prices,Evaluating model performance,Model performance metrics,R squared plot,Complete model fitting process with last_fit()","Feature engineering,Exploring recipe objects,Creating recipe objects,Training a recipe object,Numeric predictors,Discovering correlated predictors,Removing correlated predictors with recipes,Multiple feature engineering steps,Nominal predictors,Applying step_dummy() to predictors,Ordering of step_*() functions,Complete feature engineering pipeline,Complete modeling workflow,Feature engineering process,Model training and prediction,Model performance metrics","Classification models,Data resampling,Fitting a logistic regression model,Combining test dataset results,Assessing model fit,Calculating metrics from the confusion matrix,Evaluating performance with yardstick,Creating custom metric sets,Visualizing model performance,Plotting the confusion matrix,ROC curves and area under the ROC curve,Automating the modeling workflow,Streamlining the modeling process,Collecting predictions and creating custom metrics,Complete modeling workflow","Machine learning workflows,Exploring the loans dataset,Specifying a model and recipe,Creating workflows,Estimating performance with cross validation,Measuring performance with cross validation,Cross validation with logistic regression,Comparing model performance profiles,Hyperparameter tuning,Setting model hyperparameters,Random grid search,Exploring tuning results,Selecting the best model,Finalizing a workflow,Training a finalized workflow,Congratulations!",Maggie Matsui,"Machine Learning Fundamentals,Machine Learning Scientist,Supervised Machine Learning,Home sales,Loans,Telecom data,Employee data,Purchase leads,Modeling with Data in the Tidyverse",,
9,Developing Python Packages,4,14,47,"5,323",3900,"Do you find yourself copying and pasting the same code between files, wishing it was easier to reuse and share your awesome snippets? Wrapping your code into Python packages can help! In this course, you’ll learn about package structure and the extra files needed to turn loose code into convenient packages. You'll also learn about import structure, documentation, and how to maintain code style using flake8. You’ll then speed up your package development by building templates, using cookiecutter to create package skeletons. Finally, you'll learn how to use setuptools and twine to build and publish your packages to PyPI—the world stage for Python packages.","Starting a package,Modules, packages and subpackages,From script to package,Putting your package to work,Documentation,Writing function documentation with pyment,Writing function documentation with pyment II,Package and module documentation,Structuring imports,Sibling imports,Importing from parents,Exposing functions to users","Testing your package,Creating the test directory,Writing some basic tests,Running your tests,Testing your package with different environments,Setting up tox,Running tox,Keeping your package stylish,Appropriate style filtering,Using flake8 to tidy up a file,Ignoring specific errors,Configuring flake8","Installing your own package,Adding the setup script,Installing your package locally,Utilizing editable installs,Dealing with dependencies,User dependencies,Development dependencies,Including licences and writing READMEs,Writing a README,MANIFEST - Including extra files with your package,Publishing your package,Building a distribution,Uploading distributions","Faster package development with templates,Using package templates,Version numbers and history,CONTRIBUTING.md,History file,Tracking version number with bumpversion,Makefiles and classifiers,PyPI classifiers,Using makefiles,Wrap-up","Maggie Matsui,Amy Peterson","Python Programmer,Introduction to Shell,Writing Functions in Python",,
10,Introduction to Data Visualization with Plotly in Python,4,14,45,"7,142",3550,"Producing high-quality, interactive visualizations historically required complex code, extensive time, and effort. Not anymore. In this course, you’ll learn how to create publication-quality graphs harnessing the power of JavaScript, without leaving the comfort of the Python programming language we all love. You’ll create, style, and customize a variety of stunning, interactive graphs—using datasets ranging from stock prices to basketball team stats, and even penguin beak sizes! Using the Plotly charting library, you’ll also learn to customize interactivity such as hover information, range sliders, custom buttons, and even drop-downs that reactively change the visualization. Are you ready to level-up your data visualization skills?","Plotly and the Plotly Figure,Playing with a Plotly Figure,Fixing a Plotly figure,Univariate visualizations,Student scores bar graph,Box plot of company revenues,Histogram of company revenues,Customizing color,What color did we use?,Coloring student scores bar graph,Side-by-side revenue box plots with color,Revenue histogram with stacked bars","Subplots,Revenue box subplots,Revenue histogram subplots,Layering multiple plots,Species on different islands,Monthly temperatures layered,Time buttons,A time button dictionary,Time buttons on our rainfall graph,Finance line chart with custom time buttons","Bivariate visualizations,Building a scatterplot with specific colors,Bird feature correlations,Customizing hover information and legends,GDP vs. life expectancy legend,Enhancing our GDP plot,Adding annotations,Annotating your savings,A happier histogram plot,Editing plot axes,The log-scale parameter,Analyzing basketball stats,Styling scientific research","Custom buttons,Rainfall plot type buttons,Changing annotations with buttons,Dropdowns,Growth locations dropdown,Housing prices dropdown,Sliders,Hiding a slider trace,Rainfall by season slider,What you learned",Amy Peterson,"Penguins data,Revenue data,AAPL data,World Bank population data,Sydney temperature data,Rainfall data,Monthly sales,Revenue Data Extended,Intermediate Python",,
11,Bayesian Data Analysis in Python,4,14,49,"5,488",4000,"Bayesian data analysis is an increasingly popular method of statistical inference, used to determine conditional probability without having to rely on fixed constants such as confidence levels or p-values. In this course, you’ll learn how Bayesian data analysis works, how it differs from the classical approach, and why it’s an indispensable part of your data science toolbox. You’ll get to grips with A/B testing, decision analysis, and linear regression modeling using a Bayesian approach as you analyze real-world advertising, sales, and bike rental data. Finally, you’ll get hands-on with the PyMC3 library, which will make it easier for you to design, fit, and interpret Bayesian models.","Who is Bayes? What is Bayes?,Bayesians vs. Frequentists,Probability distributions,Probability and Bayes' Theorem,Let's play cards,Bayesian spam filter,What does the test say?,Tasting the Bayes,Tossing a coin,The more you toss, the more you learn,Hey, is this coin fair?","A/B testing,Simulate beta posterior,Posterior click rates,A or B, and how sure are we?,How bad can it be?,Decision analysis,Decision analysis: cost,Decision analysis: profit,Regression and forecasting,Defining a Bayesian regression model,Analyzing regression parameters,Predictive distribution","Under the Bayesian hood,Towards grid approximation,Grid approximation without prior knowledge,Updating posterior belief,Prior belief,The truth of the prior,Picking the right prior,Simulating posterior draws,Reporting Bayesian results,Point estimates,Highest Posterior Density credible intervals,The meaning of credibility","Markov Chain Monte Carlo and model fitting,Markov Chain Monte Carlo,Sampling posterior draws,Interpreting results and comparing models,Inspecting posterior draws,Comparing models with WAIC,Making predictions,Sample from predictive density,Estimating test error,How much is an avocado?,Fitting the model,Inspecting the model,Optimizing the price,Final remarks","Amy Peterson,Justin Saddlemyer","Ads Data,Bikes Data,Intermediate Python,Introduction to Statistics in Python",,
12,Reshaping Data with tidyr,4,15,54,"6,522",4650,"Data in the wild can be scary—when confronted with a complicated and messy dataset you may find yourself wondering, where do I even start? The tidyr package allows you to wrangle such beasts into nice and tidy datasets. Inaccessible values stored in column names will be put into rows, JSON files will become data frames, and missing values will never go missing again. You'll practice these techniques on a wide range of messy datasets, learning along the way how many dogs the Soviet Union sent into space and what bird is most popular in New Zealand. With the tidyr package in your tidyverse toolkit, you'll be able to transform almost any dataset in a tidy format which will pay-off during the rest of your analysis.","What is tidy data?,Tidy data structure,Multiple variables per column,Columns with multiple values,International phone numbers,Extracting observations from values,Separating into columns and rows,Missing values,And the Oscar for best director goes to ... <NA>,Imputing sales data,Nuclear bombs per continent","Creating unique combinations of vectors,Letters of the genetic code,When did humans replace dogs in space?,Finding missing observations,Completing data with all value combinations,Completing the Solar System,Zero Olympic medals,Creating a sequence with full_seq(),The Cold War's hottest year,Advanced completions,Olympic medals per continent,Tracking a virus outbreak,Counting office occupants","From wide to long data,Nuclear bombs per country,WHO obesity per country,Bond... James Bond,Deriving variables from column headers,New-Zealand's bird of the year,Big tech stock prices,Deriving variables from complex column headers,Soviet space dogs, the dog perspective,WHO obesity vs. life expectancy,Uncounting observations,From long to wide data,Soviet space dogs, the flight perspective,Planet temperature & distance to the Sun,Transposing planet data","Intro to non-rectangular data,Rectangular vs non-rectangular files,Rectangling Star Wars movies,From nested values to observations,Unnesting wide or long,Rectangling Star Wars planets,The Solar System's biggest moons,Selecting nested variables,Hoisting Star Wars films,Hoisting movie ratings,Nesting data for modeling,Tidy model outputs with broom,Nesting tibbles,Modeling on nested data frames,Congratulations!","Maggie Matsui,Amy Peterson","Importing & Cleaning Data,Tidyverse Fundamentals,Nuclear explosions data,Planet data,Star Wars data,Netflix data,ANSUR II data,Olympic medals data,Data Manipulation with dplyr",,
13,Cloud Computing for Everyone,2,11,33,"25,103",2250,"Every day we interact with the cloud—whether it’s using Google Drive, apps like Salesforce, or accessing our favorite websites. Cloud computing has become the norm for many companies, but what exactly is the cloud and why is everyone rushing to adopt it? Designed for absolute novices, this course breaks down what the cloud is and explains terminology such as scalability, latency, and high-availability. You'll learn about the many advantages including ease of remote collaboration, how there are no hardware limitations, and reliable disaster recovery. You'll also discover the range of tools provided by major cloud providers such as Amazon Web Services (AWS), Microsoft Azure, and Google Cloud. By the end of this course, you'll be able to confidently explain how cloud tools can increase productivity and save money, as well as ask the right questions about how to optimize your use of cloud tools.","What is cloud computing?,Understanding the cloud,Cloud vs. on-premise,Cloud computing services,The power of the cloud,Primary cloud services,Key characteristics,Cloud service models,Outsourcing IT services,IaaS, PaaS, or SaaS?,Level of abstraction","Amazon Web Services,AWS,NerdWallet,Microsoft Azure,The Ottawa hospital,That doesn't seem right,Google Cloud,Lush migration,True or false?,Other actors and final thoughts,State of the competition,Cloud providers and their services,Congratulations!","Cloud deployment models,Private or public?,Pick the best model,Regulations on the cloud,Time limits on storing data,Personal data,Cloud computing roles,Microsoft cloud skills report,Cloud roles",,,Data Literacy Fundamentals,,
14,Introduction to Statistics in Python,4,15,54,"14,614",4250,"Statistics is the study of how to collect, analyze, and draw conclusions from data. It’s a hugely valuable tool that you can use to bring the future into focus and infer the answer to tons of questions. For example, what is the likelihood of someone purchasing your product, how many calls will your support team receive, and how many jeans sizes should you manufacture to fit 95% of the population? In this course, you'll discover how to answer questions like these as you grow your statistical skills and learn how to calculate averages, use scatterplots to show the relationship between numeric values, and calculate correlation. You'll also tackle probability, the backbone of statistical reasoning, and learn how to use Python to conduct a well-designed study to draw your own conclusions from data.","What is statistics?,Descriptive and inferential statistics,Data type classification,Measures of center,Mean and median,Mean vs. median,Measures of spread,Quartiles, quantiles, and quintiles,Variance and standard deviation,Finding outliers using IQR","The normal distribution,Distribution of Amir's sales,Probabilities from the normal distribution,Simulating sales under new market conditions,Which market is better?,The central limit theorem,Visualizing sampling distributions,The CLT in action,The mean of means,The Poisson distribution,Identifying lambda,Tracking lead responses,More probability distributions,Distribution dragging and dropping,Modeling time between leads,The t-distribution","What are the chances?,With or without replacement?,Calculating probabilities,Sampling deals,Discrete distributions,Creating a probability distribution,Identifying distributions,Expected value vs. sample mean,Continuous distributions,Which distribution?,Data back-ups,Simulating wait times,The binomial distribution,Simulating sales deals,Calculating binomial probabilities,How many sales will be won?","Correlation,Guess the correlation,Relationships between variables,Correlation caveats,What can't correlation measure?,Transforming variables,Does sugar improve happiness?,Confounders,Design of experiments,Study types,Longitudinal vs. cross-sectional studies,Congratulations!",Adel Nehme,"Data Analyst,Data Scientist,Statistics Fundamentals,Food Consumption,2019 World Happiness Report,Amir's sales deals,Data Manipulation with pandas",,
15,Cleaning Data in PostgreSQL Databases,4,15,49,"2,625",4050,"If you surveyed a large number of data scientists and data analysts about which tasks are most common in their workday, cleaning data would likely be in almost all responses. This is the case because real-world data is messy. To help you tame messy data, this course teaches you how to clean data stored in a PostgreSQL database. You’ll learn how to solve common problems such as how to clean messy strings, deal with empty values, compare the similarity between strings, and much more. You’ll get hands-on practice with these tasks using interesting (but messy) datasets made available by New York City's Open Data program. Are you ready to whip that messy data into shape?","Introduction to data cleaning,Developing a data cleaning mindset,Applying functions for string cleaning,Pattern matching,Classifying parking violations by time of day,Masking identifying information with regular expressions,Matching similar strings,Matching inconsistent color names,Standardizing color names,Standardizing multiple colors,Formatting text for colleagues","Data type conversions,Type conversion with a CASE clause,Applying aggregate functions to converted values,Date parsing and formatting,Cleaning invalid dates,Converting and displaying dates,Timestamp parsing and formatting,Extracting hours from a time value,A parking violation report by day of the month,Risky parking behavior","Handling missing data,Quantifying completeness,Using a fill-in value,Analyzing incomplete records,Handling duplicated data,Duplicate parking violations,Resolving impartial duplicates,Detecting invalid values,Detecting invalid values with regular expressions,Identifying out-of-range vehicle model years,Detecting inconsistent data,Identifying invalid parking violations,Invalid violations with overnight parking restrictions,Recovering deleted data","Combining columns,Tallying corner parking violations,Creating a TIMESTAMP with concatenation,Splitting column data,Extracting time units with SUBSTRING(),Extracting house numbers from a string,Splitting data with delimiters,Splitting house numbers with a delimiter,Mapping parking restrictions,Creating pivot tables,Selecting data for a pivot table,Using FILTER to create a pivot table,Aggregating film categories,Course wrap-up","Maggie Matsui,Amy Peterson","Parking violations in NYC,Restaurant inspections in NYC,Film permits in NYC,Intermediate SQL",,
16,Reshaping Data with pandas,4,15,52,"6,080",4450,"Often data is in a human-readable format, but it’s not suitable for data analysis. This is where pandas can help—it’s a powerful tool for reshaping DataFrames into different formats. In this course, you’ll grow your data scientist and analyst skills as you learn how to wrangle string columns and nested data contained in a DataFrame. You’ll work with real-world data, including FIFA player ratings, book reviews, and churn analysis data, as you learn how to reshape a DataFrame from wide to long format, stack and unstack rows and columns, and get descriptive statistics of a multi-index DataFrame.","Wide and long data formats,The long and the wide,Flipping players,Reshaping using pivot method,Dribbling the pivot method,Offensive or defensive player?,Replay that last move!,Pivot tables,Reviewing the moves,Exploring the big match,The tallest and the heaviest","Stacking DataFrames,Stack the calls!,Phone directory index,Text me!,Unstacking DataFrames,International caller,Call another time,Organizing your voicemail,Working with multiple levels,Swap your SIM card,Two many calls,Handling missing data,A missed phone call,Don't drop the stack","Reshaping with melt,Gothic times,Rating is not everything,How is Frankenstein, Dorian Gray?,Wide to long function,The golden age,Decrypting the code,Time to read, Katniss!,Working with string columns,Did you say dystopia?,What's your rating, Harry?,Elementary, dear Watson!","Reshaping and combining data,Less fast food, please!,Only going up,A group analysis,Transforming a list-like column,Merge it all,Explode the bounds,The good old split,Reading nested data into a DataFrame,Nested movies,A complex film,Dealing with nested data columns,Un-nesting birds,Don't dump the bird,The final reshape","Maggie Matsui,Amy Peterson","Importing & Cleaning Data,Customer churn data,Books data,FIFA players data,Obesity data,Data Manipulation with pandas",,
17,SQL Foundations,2,7,24,,1700,"Much of the world's raw data—from electronic medical records to customer transaction histories—lives in organized collections of tables called relational databases. Being able to wrangle and extract data from these databases using SQL is an essential skill within the data industry and in increasing demand. This course will teach you:

✓ How relational databases are structured
✓ Simple SQL commands to start your analysis
✓ The differences between SQL databases such as PostgreSQL and SQL Server

In just a few hours, you'll get to know the theory and the practice through bite-sized videos and interactive exercises where you can put your new-found SQL skills to the test.","Databases,Data organization,Database advantages,Tables,Picking a unique ID,Setting the table in style,Our very own table,Data,At your service,Finding data types,Choice of type","Introducing queries,SQL strengths,Developing SQL style,Querying the books table,Writing queries,Making queries DISTINCT,Aliasing,VIEWing your query,SQL flavors,Comparing flavors,Limiting results,Translating between flavors,Congratulations!",,,"James Chapman,Amy Peterson",,,
18,Supervised Learning with scikit-learn,4,15,49,"5,645",4050,"Grow your machine learning skills with scikit-learn and discover how to use this popular Python library to train models using labeled data. In this course, you'll learn how to make powerful predictions, such as whether a customer is will churn from your business, whether an individual has diabetes, and even how to tell classify the genre of a song. Using real-world datasets, you'll find out how to build predictive models, tune their parameters, and determine how well they will perform with unseen data.","Machine learning with scikit-learn,Binary classification,The supervised learning workflow,The classification challenge,k-Nearest Neighbors: Fit,k-Nearest Neighbors: Predict,Measuring model performance,Train/test split + computing accuracy,Overfitting and underfitting,Visualizing model complexity","How good is your model?,Deciding on a primary metric,Assessing a diabetes prediction classifier,Logistic regression and the ROC curve,Building a logistic regression model,The ROC curve,ROC AUC,Hyperparameter tuning,Hyperparameter tuning with GridSearchCV,Hyperparameter tuning with RandomizedSearchCV","Introduction to regression,Creating features,Building a linear regression model,Visualizing a linear regression model,The basics of linear regression,Fit and predict for regression,Regression performance,Cross-validation,Cross-validation for R-squared,Analyzing cross-validation metrics,Regularized regression,Regularized regression: Ridge,Lasso regression for feature importance","Preprocessing data,Creating dummy variables,Regression with categorical features,Handling missing data,Dropping missing data,Pipeline for song genre prediction: I,Pipeline for song genre prediction: II,Centering and scaling,Centering and scaling for regression,Centering and scaling for classification,Evaluating multiple models,Visualizing regression model performance,Predicting on the test set,Visualizing classification model performance,Pipeline for predicting song popularity,Congratulations","James Chapman,Amy Peterson,Izzy Weber","Data Scientist,Machine Learning Fundamentals,Machine Learning Scientist,Advertising and Sales,Diabetes,Telecom Churn,Music,Introduction to Statistics in Python",,
19,Streamlined Data Ingestion with pandas,4,16,53,"35,199",4500,"Before you can analyze data, you first have to acquire it. This course teaches you how to build pipelines to import data kept in common storage formats. You’ll use pandas, a major Python library for analytics, to get data from a variety of sources, from spreadsheets of survey responses, to a database of public service requests, to an API for a popular review site. Along the way, you’ll learn how to fine-tune imports to get only what you need and to address issues like incorrect data types. Finally, you’ll assemble a custom dataset from a mix of sources.","Introduction to flat files,Get data from CSVs,Get data from other flat files,Modifying flat file imports,Import a subset of columns,Import a file in chunks,Handling errors and missing data,Specify data types,Set custom NA values,Skip bad data","Introduction to databases,Connect to a database,Load entire tables,Refining imports with SQL queries,Selecting columns with SQL,Selecting rows,Filtering on multiple conditions,More complex SQL queries,Getting distinct values,Counting in groups,Working with aggregate functions,Loading multiple tables with joins,Joining tables,Joining and filtering,Joining, filtering, and aggregating","Introduction to spreadsheets,Get data from a spreadsheet,Load a portion of a spreadsheet,Getting data from multiple worksheets,Select a single sheet,Select multiple sheets,Work with multiple spreadsheets,Modifying imports: true/false data,Set Boolean columns,Set custom true/false values,Modifying imports: parsing dates,Parse simple dates,Get datetimes from multiple columns,Parse non-standard date formats","Introduction to JSON,Load JSON data,Work with JSON orientations,Introduction to APIs,Get data from an API,Set API parameters,Set request headers,Working with nested JSONs,Flatten nested JSONs,Handle deeply nested data,Combining multiple datasets,Append dataframes,Merge dataframes,Wrap-up","Adrián Soto,Hillary Green-Lerman","Data Engineer,Vermont tax return data by ZIP code,FreeCodeCamp New Developer Survey response subset,NYC weather and 311 housing complaints,Intermediate Python,Introduction to SQL",,
20,Feature Engineering for NLP in Python,4,15,52,"16,496",4200,"In this course, you will learn techniques that will allow you to extract useful information from text and process them into a format suitable for applying ML models. More specifically, you will learn about POS tagging, named entity recognition, readability scores, the n-gram and tf-idf models, and how to implement them using scikit-learn and spaCy. You will also learn to compute how similar two documents are to each other. In the process, you will predict the sentiment of movie reviews and build movie and Ted Talk recommenders. Following the course, you will be able to engineer critical features out of any text and solve some of the most challenging problems in data science!","Introduction to NLP feature engineering,Data format for ML algorithms,One-hot encoding,Basic feature extraction,Character count of Russian tweets,Word count of TED talks,Hashtags and mentions in Russian tweets,Readability tests,Readability of 'The Myth of Sisyphus',Readability of various publications","Building a bag of words model,Word vectors with a given vocabulary,BoW model for movie taglines,Analyzing dimensionality and preprocessing,Mapping feature indices with feature names,Building a BoW Naive Bayes classifier,BoW vectors for movie reviews,Predicting the sentiment of a movie review,Building n-gram models,n-gram models for movie tag lines,Higher order n-grams for sentiment analysis,Comparing performance of n-gram models","Tokenization and Lemmatization,Identifying lemmas,Tokenizing the Gettysburg Address,Lemmatizing the Gettysburg address,Text cleaning,Cleaning a blog post,Cleaning TED talks in a dataframe,Part-of-speech tagging,POS tagging in Lord of the Flies,Counting nouns in a piece of text,Noun usage in fake news,Named entity recognition,Named entities in a sentence,Identifying people mentioned in a news article","Building tf-idf document vectors,tf-idf weight of commonly occurring words,tf-idf vectors for TED talks,Cosine similarity,Range of cosine scores,Computing dot product,Cosine similarity matrix of a corpus,Building a plot line based recommender,Comparing linear_kernel and cosine_similarity,Plot recommendation engine,The recommender function,TED talk recommender,Beyond n-grams: word embeddings,Generating word vectors,Computing similarity of Pink Floyd songs,Congratulations!","Adrián Soto,Hillary Green-Lerman","Machine Learning Scientist,Natural Language Processing,Russian Troll Tweets,Movie Overviews and Taglines,Preprocessed Movie Reviews,TED Talk Transcripts,Real and Fake News Headlines,Introduction to Natural Language Processing in Python,Supervised Learning with scikit-learn",,
21,Performing Experiments in Python,4,16,53,"5,025",4400,"Data is all around us and can help us to understand many things. Making a pretty graph is great, but how can we tell the difference between a few outliers on a graph and a real, reliable effect? Is a trend that we see on a graph a reliable result or just random chance playing tricks? In this course, you will learn how to interrogate datasets in a rigorous way, giving clear answers to your questions. You will learn a range of statistical tests, how to apply them, how to understand their results, and how to deal with their shortcomings. Along the way, you will explore Olympic athlete data and the differences between populations of continents.","Welcome to the course!,Getting started with plotnine,Boxplots,Density plots,Student's t-test,Your first t-test,One-sample t-test,Two-sample t-test,Testing proportion and correlation,Chi-square test,Fisher's exact test,Pearson correlation","Type I errors,Bonferroni correction,Šídák correction,Sample size,Exploring sample size,Sample size for a t-test,Effect size,Effect size for a t-test,Computing Cohen's d,Effect size for a Fisher exact test,Effect sizes for Pearson correlation,Power,Power analysis for a t-test,Interpreting power analyses","Confounding variables,Exploring confounding variables,Finding confounding variables,Blocking and randomization,Random sampling,Blocking,Paired t-test,ANOVA,One-way ANOVA,Two-way ANOVA,Interactive effects,Two-way ANOVA with interactive effects,Choosing an appropriate test","Assumptions and normal distributions,Exploring distributions with summary stats,Q-Q plot,Testing for normality,Shapiro-Wilk test,Choosing tests and normality,Non-parametric tests: Wilcoxon rank-sum test,Wilcoxon rank-sum test,Wilcoxon signed-rank test,Parametric vs non-parametric tests,More non-parametric tests: Spearman correlation,Spearman correlation,Choosing the correct correlation test,Summary","Chester Ismay,Amy Peterson","Olympic dataset,UN dataset,Foundations of Probability in Python",,
22,Introduction to Deep Learning with Keras,4,15,59,"23,736",4950,"Deep learning is here to stay! It's the go-to technique to solve complex problems that arise with unstructured data and an incredible tool for innovation. Keras is one of the frameworks that make it easier to start developing deep learning models, and it's versatile enough to build industry-ready models in no time. In this course, you will learn regression and save the earth by predicting asteroid trajectories, apply binary classification to distinguish between real and fake dollar bills, use multiclass classification to decide who threw which dart at a dart board, learn to use neural networks to reconstruct noisy images and much more. Additionally, you will learn how to better control your models during training and how to tune them to boost their performance.","What is Keras?,Describing Keras,Would you use deep learning?,Your first neural network,Hello nets!,Counting parameters,Build as shown!,Surviving a meteor strike,Specifying a model,Training,Predicting the orbit!","Learning curves,Learning the digits,Is the model overfitting?,Do we need more data?,Activation functions,Different activation functions,Comparing activation functions,Comparing activation functions II,Batch size and batch normalization,Changing batch sizes,Batch normalizing  a familiar model,Batch normalization effects,Hyperparameter tuning,Preparing a model for tuning,Tuning the model parameters,Training with cross-validation","Binary classification,Exploring dollar bills,A binary classification model,Is this dollar bill fake ?,Multi-class classification,A multi-class model,Prepare your dataset,Training on dart throwers,Softmax predictions,Multi-label classification,An irrigation machine,Training with multiple labels,Keras callbacks,The history callback,Early stopping your model,A combination of callbacks","Tensors, layers, and autoencoders,It's a flow of tensors,Neural separation,Building an autoencoder,De-noising like an autoencoder,Intro to CNNs,Building a CNN model,Looking at convolutions,Preparing your input image,Using a real world model,Intro to LSTMs,Text prediction with LSTMs,Build your LSTM model,Decode your predictions,Test your model!,You're done!","Sara Billen,Hillary Green-Lerman","Deep Learning,Machine Learning Scientist,Darts,Banknotes,MNIST,Irrigation Machine,Digits,Machine Learning with scikit-learn",,
23,Exploratory Data Analysis in Python,4,16,52,"53,876",4150,"How do we get from data to answers? Exploratory data analysis is a process for exploring datasets, answering questions, and visualizing results. This course presents the tools you need to clean and validate data, to visualize distributions and relationships between variables, and to use regression models to predict and explain. You'll explore data related to demographics and health, including the National Survey of Family Growth and the General Social Survey. But the methods you learn apply to all areas of science, engineering, and business. You'll use Pandas, a powerful library for working with data, and other core Python libraries including NumPy and SciPy, StatsModels for regression, and Matplotlib for visualization. With these tools and skills, you will be prepared to work with real data, make discoveries, and present compelling results.","DataFrames and Series,Read the codebook,Exploring the NSFG data,Clean and Validate,Validate a variable,Clean a variable,Compute a variable,Filter and visualize,Make a histogram,Compute birth weight,Filter","Exploring relationships,PMF of age,Scatter plot,Jittering,Visualizing relationships,Height and weight,Distribution of income,Income and height,Correlation,Computing correlations,Interpreting correlations,Simple regression,Income and vegetables,Fit a line","Probability mass functions,Make a PMF,Plot a PMF,Cumulative distribution functions,Make a CDF,Compute IQR,Plot a CDF,Comparing distributions,Distribution of education,Extract education levels,Plot income CDFs,Modeling distributions,Distribution of income,Comparing CDFs,Comparing PDFs","Limits of simple regression,Regression and causation,Using StatsModels,Multiple regression,Plot income and education,Non-linear model of education,Visualizing regression results,Making predictions,Visualizing predictions,Logistic regression,Predicting a binary variable,Next steps","Yashas Roy,Chester Ismay","Data Analyst,Data Scientist,National Survey of Family Growth (NSFG),General Social Survey (GSS),Behavioral Risk Factor Surveillance System (BRFSS),Python Data Science Toolbox (Part 2)",,
24,Ensemble Methods in Python,4,15,52,"5,732",4050,"Continue your machine learning journey by diving into the wonderful world of ensemble learning methods! These are an exciting class of machine learning techniques that combine multiple individual algorithms to boost performance and solve complex problems at scale across different industries. Ensemble techniques regularly win online machine learning competitions as well! In this course, you’ll learn all about these advanced ensemble techniques, such as bagging, boosting, and stacking. You’ll apply them to real-world datasets using cutting edge Python machine learning libraries such as scikit-learn, XGBoost, CatBoost, and mlxtend.","Introduction to ensemble methods,Exploring Google apps data,Predicting the rating of an app,Voting,Choosing the best model,Assembling your first ensemble,Evaluating your ensemble,Averaging,Journey to Westeros,Predicting GoT deaths,Soft vs. hard voting","The effectiveness of gradual learning,Introducing the movie database,Exploring movie features,Predicting movie revenue,Boosting for predicted revenue,Adaptive boosting: award winning model,Your first AdaBoost model,Tree-based AdaBoost regression,Making the most of AdaBoost,Gradient boosting,Revisiting Google app reviews,Sentiment analysis with GBM,Gradient boosting flavors,Movie revenue prediction with CatBoost,Boosting contest: Light vs Extreme","The strength of “weak” models,Restricted and unrestricted decision trees,""Weak"" decision tree,Bootstrap aggregating,Training with bootstrapping,A first attempt at bagging,BaggingClassifier: nuts and bolts,Bagging: the scikit-learn way,Checking the out-of-bag score,Bagging parameters: tips and tricks,Exploring the UCI SECOM data,A more complex bagging model,Tuning bagging hyperparameters","The intuition behind stacking,Exploring the mushroom dataset,Predicting mushroom edibility,K-nearest neighbors for mushrooms,Build your first stacked ensemble,Applying stacking to predict app ratings,Building the second-layer classifier,Stacked predictions for app ratings,Let’s mlxtend it!,A first attempt with mlxtend,Back to regression with stacking,Mushrooms: a matter of life or death,Ensembling it all together","Yashas Roy,Hillary Green-Lerman","App ratings,App reviews,Game of Thrones,Pokémon,SECOM (Semiconductor Manufacturing),TMDb (The Movie Database),Linear Classifiers in Python,Machine Learning with Tree-Based Models in Python",,
25,Quantitative Risk Management in Python,4,15,54,"7,378",4500,"Managing risk using Quantitative Risk Management is a vital task across the banking, insurance, and asset management industries. It’s essential that financial risk analysts, regulators, and actuaries can quantitatively balance rewards against their exposure to risk. This course introduces you to financial portfolio risk management through an examination of the 2007—2008 financial crisis and its effect on investment banks such as Goldman Sachs and J.P. Morgan. You’ll learn how to use Python to calculate and mitigate risk exposure using the Value at Risk and Conditional Value at Risk measures, estimate risk with techniques like Monte Carlo simulation, and use cutting-edge technologies such as neural networks to conduct real time portfolio rebalancing.","Welcome!,Portfolio returns during the crisis,Asset covariance and portfolio volatility,Risk factors and the financial crisis,Frequency resampling primer,Visualizing risk factor correlation,Least-squares factor model,Modern portfolio theory,Practice with PyPortfolioOpt: returns,Practice with PyPortfolioOpt: covariance,Breaking down the financial crisis,The efficient frontier and the financial crisis","Parametric Estimation,Parameter estimation: Normal,Parameter estimation: Skewed Normal,Historical and Monte Carlo Simulation,Historical Simulation,Monte Carlo Simulation,Structural breaks,Crisis structural break: I,Crisis structural break: II,Crisis structural break: III,Volatility and extreme values,Volatility and structural breaks,Extreme values and backtesting","Measuring Risk,VaR for the Normal distribution,Comparing CVaR and VaR,Which risk measure is ""better""?,Risk exposure and loss,What's your risk appetite?,VaR and risk exposure,CVaR and risk exposure,Risk management using VaR & CVaR,VaR from a fitted distribution,Minimizing CVaR,CVaR risk management and the crisis,Portfolio hedging: offsetting risk,Black-Scholes options pricing,Options pricing and the underlying asset,Using options for hedging","Extreme value theory,Block maxima,Extreme events during the crisis,GEV risk estimation,Kernel density estimation,KDE of a loss distribution,Which distribution?,CVaR and loss cover selection,Neural network risk management,Single layer neural networks,Asset price prediction,Real-time risk management,Wrap-up and Future Steps",Adel Nehme,"Applied Finance,Amazon stock price,Portfolio,Introduction to Portfolio Analysis in Python",,
26,Analyzing Social Media Data in R,4,16,57,"4,010",4700,"Analyzing data from social media can provide you with valuable insights. It can inform campaign strategies, improve marketing and sales, measure customer engagement, perform competitor analysis, and identify untapped networks. In this course, you’ll use R to extract and visualize Twitter data, perform network analysis, and view the geolocation of tweets. You’ll use a variety of datasets to put what you’ve learned into play, including tweets about celebrities, technology companies, trending topics, and sports.","Analyzing twitter data,Power of twitter data,Pros and cons of twitter data,Extracting twitter data,Prerequisites to set up the R environment,Search and extract tweets,Search and extract timelines,Components of twitter data,User interest and tweet counts,Compare follower count,Retweet counts","Processing twitter text,Remove URLs and characters other than letters,Build a corpus and convert to lowercase,Remove stop words and  additional spaces,Visualize popular terms,Removing custom stop words,Visualize popular terms with bar plots,Word clouds for visualization,Topic modeling of tweets,The LDA algorithm,Create a document term matrix,Create a topic model,Twitter sentiment analysis,Extract sentiment scores,Perform sentiment analysis","Filtering tweets,Filtering for original tweets,Filtering on tweet language,Filter based on tweet popularity,Twitter user analysis,Extract user information,Explore users based on the golden ratio,Subscribers to twitter lists,Twitter trends,Available trends,Trends by country name,Trends by city and most tweeted trends,Plotting twitter data over time,Visualizing frequency of tweets,Create time series objects,Compare tweet frequencies for two brands","Twitter network analysis,Preparing data for a retweet network,Create a retweet network,Network centrality measures,Calculate out-degree scores,Compute the in-degree scores,Calculate the betweenness scores,Visualizing twitter networks,Create a network plot with attributes,Network plot based on centrality measure,Follower count to enhance the network plot,Putting twitter data on the map,Extract geolocation coordinates,Twitter data on the map,Course wrap-up","Adel Nehme,Anneleen Beckers","Marketing Analytics,Tweets on Artificial Intelligence,Telemedicine Tweets,Introduction to R",,
27,Building Web Applications with Shiny in R,4,16,61,"19,075",5050,"Shiny is an R package that makes it easy to build highly interactive web apps directly in R. Using Shiny, data scientists can create interactive web apps that allow your team to dive in and explore your data as dashboards or visualizations. If you want to bring your data to life, Shiny is the way to go! Using data about baby names, food ingredients, and UFO sightings, you'll build a variety of different Shiny apps that leverage different inputs and outputs. You’ll also learn the basics of reactive expressions. By the end of this course, you’ll have the Shiny skills you need to build your first app in R.","Introduction to Shiny,Client vs. Server,When to build a web-app?,Build a ""Hello, world"" Shiny app,Build a ""Hello, world"" Shiny app (2),""Hello, World"" app input (UI),""Hello, World"" app output (UI/Server),Build a babynames explorer Shiny app,Add input (UI),Add output (UI/Server),Update layout (UI),Update output (server)","Reactivity 101,Source vs. Conductor vs. Endpoint,Add a reactive expression,Understanding reactive expressions,Observers vs. reactives,Add another reactive expression,Does this have a side effect?,Add an observer to display notifications,Stop - delay - trigger,Stop reactions with isolate(),Delay reactions with eventReactive(),Trigger reactions with observeEvent(),Controlling action triggers,Applying reactivity concepts,Reactivity concepts: observe & reactive,Convert height from inches to centimeters","Inputs,Selecting an input,Add a select input,Add a slider input to select year,Outputs,Add a table output,Add an interactive table output,Add interactive plot output,Layouts and themes,Sidebar layouts,Tab layouts,Themes,Building apps,App 1: Multilingual Greeting,App 2: Popular Baby Names,App 3: Popular Baby Names Redux","Build an Alien Sightings Dashboard,Alien sightings: add inputs,Alien sightings: add outputs,Alien sightings: tab layout,Exploring the 2014 Mental Health in Tech Survey,The shinyWidgets gallery,Explore the Mental Health in Tech 2014 Survey,Validate that a user made a selection,Explore cuisines,Explore cuisines: top ingredients,Explore cuisines: top ingredients redux,Explore cuisines: wordclouds,Mass shootings,Mass shootings: add inputs,Mass shootings: modify output,Mass shootings: display help,Wrap up video","Maggie Matsui,Anneleen Beckers","Shiny Fundamentals,Recipes,UFO Sightings,Mental Health in Tech Survey,Shootings,Introduction to the Tidyverse,Intermediate R",,
28,Introduction to Writing Functions in R,4,14,52,"30,356",4350,"Being able to write your own functions makes your analyses more readable, with fewer errors, and more reusable from project to project. Function writing will increase your productivity more than any other skill! In this course you'll learn the basics of function writing, focusing on the arguments going into the function and the return values. You'll be writing useful data science functions, and using real-world data on Wyoming tourism, stock price/earnings ratios, and grain yields.","Why you should use functions,Calling functions,The benefits of writing functions,Converting scripts into functions,Converting a script to a function,Your first function: tossing a coin,Inputs to functions,Multiple inputs to functions,Y kant I reed ur code?,Data or detail?,Renaming GLM","Returning values from functions,Returning early,Returning invisibly,Returning multiple values from functions,Returning many things,Returning metadata,Environments,Creating and exploring environments,Do variables exist?,Scope and precedence,Can a function find its variables?,Can you access variables from inside functions?,Variable precedence 1,Variable precedence 2","Default arguments,Numeric defaults,Logical defaults,NULL defaults,Categorical defaults,Passing arguments between functions,Harmonic mean,Dealing with missing values,Passing arguments with ...,Checking arguments,Throwing errors with bad arguments,Custom error logic,Fixing function arguments","Grain yields and unit conversion,Converting areas to metric 1,Converting areas to metric 2,Converting yields to metric,Applying the unit conversion,Visualizing grain yields,Plotting yields over time,A nation divided,Plotting yields over time by region,Modeling grain yields,Running a model,Making yield predictions,Do it all over again,Congratulations",Marianna Lamnina,"Data Scientist,R Programmer,R Programming,Snake River visits,Standard & Poor 500 price/earnings ratios,NASS corn yields,NASS wheat yields,NASS barley yields,Introduction to the Tidyverse,Intermediate R",,
29,Market Basket Analysis in R,4,16,60,"3,272",4700,"Last time you were at the supermarket, what was in your shopping basket? Was there a connection between the products you purchased, like spaghetti and tomatoes or ham and pineapple? Whether online or offline, retailers use information from millions of customer’s baskets to analyze associations between items and extract insights using association rules. To help you quantify the degree of association between items you’ll use market basket analysis to uncover unseen connections and visualize relevant and insightful rules. You’ll then get to practice what you’ve learned on a movie dataset, as you predict which movies are watched together to create personalized movie recommendations for users.","Market basket introduction,Baskets and items,Single basket,What's in the basket?,Item combinations,Number of possible baskets,Subsets and supersets,Plot number of possible baskets,What is market basket analysis ?,Two baskets,Multiple baskets,Looking at specific items","Let's see what's in the basket,What's in the basket?,What's most popular ?,Getting fancy with the visuals,Visualizing metrics,Scatterplots,ArulesViz plots,Bringing rules to life,From rules to graph based visualizations,Playing with graphs,Understanding the graph,Portability of your graph,Alternative rule plots,Group matrix based visualizations,Parallel coordinates plots,Mastering the RuleExplorer","Transactional data,Transactionalizing the online data frame,Inspector retail,Density of the item matrix?,Metrics in market basket analysis,The support measure,Confidence and lift measures,Changing the appearance of rules,The apriori algorithm,Apriori principle,Let's go shopping for rules,Parameters of the apriori,“If this then that” with the apriori,Playing with the appearance,Redundant rules,Interpretation of rules","Recap on transactions,Gettting familiar with the MovieLens dataset,Movie transactions,Frequency plots,Mining association rules,Popularity of movies,Picking the right movie parameters,Extracting movie rules,Visualizing transactions and rules,Where is Pulp Fiction?,Visualizing movie rules,Our favorite movies as a graph,Making the most of market basket analysis,What influenced Pulp Fiction?,What did Pulp Fiction influence?,Use your market basket skills!","Adel Nehme,Anneleen Beckers","Marketing Analytics,Movielens,Online retail,Introduction to Data Visualization with ggplot2,Introduction to the Tidyverse",,
30,Introduction to Scala,3,13,46,"17,785",3700,"Get an introduction to the programming language Scala. You'll learn why and how companies like Netflix, Airbnb, and Morgan Stanley are choosing Scala for large-scale applications and data engineering infrastructure. You'll learn the basics of the language, including syntax and style, focusing on the most commonly used features in the Scala standard library. You'll learn by writing code for a real program that plays a computer version of the popular card game Twenty-One. You’ll get a taste of the value of a hybrid object-oriented and functional programming language, of which Scala is the foremost example. We recommend this course for learners with intermediate-level programming experience, which can be acquired in the listed prerequisites.","A scalable language,What is Scala?,Why use Scala?,Who uses Scala?,Scala code and the Scala interpreter,What makes Scala scalable?,Scala is object-oriented,Reasons for programming in Scala,Immutable variables (val) and value types,Define immutable variables (val),Don't try to change me,Mutable variables (var) and type inference,Define mutable variables (var),You can change me,Pros and cons of immutability","Scala's static type system,Static typing vs. dynamic typing,Pros and cons of static type systems,Make decisions with if and else,if and printing,if expressions result in a value,if and else inside of a function,while and the imperative style,A simple while loop,Loop over a collection with while,foreach and the functional style,Is Scala purely a functional language?,Converting while to foreach,Signs of style,The essence of Scala","Scripts, applications, and real-world workflows,Create and run a Scala script,Benefits of compiled languages,Functions,What do functions do?,Identify the body of a function,Call a function,Arrays,Create and parameterize an array,Initialize an array,An array, all at once,Updating arrays,Lists,Initialize and prepend to a list,Initialize a list using cons and Nil,Concatenate Lists",,Adrián Soto,"Data Engineer,Intermediate Python",,
31,Pandas Joins for Spreadsheet Users,4,12,44,"2,694",3700,"Joining two or more datasets is necessary for almost any real-world analysis. You’ve done it before with spreadsheets using VLOOKUP and related functions. Can you build on this experience as you transition to the world of Python? Yes! In this course you will learn the ins and outs of bringing datasets together with pandas, Python’s gold standard for manipulating tabular data. You’ll apply pandas functions to combine data from the National Football League (NFL) framed in a familiar spreadsheet environment. Armed with these skills you will be able to harness the power of pandas and integrate larger, more complex datasets into any analysis.","Joining data: a real-world necessity,The need for joining data,Working with split data,Working with complementary data,Concatenation,Concatenating rows,Concatenating rows with duplicated indexes,Concatenating columns,Power and flexibility,Advantages of pandas joins,Simple coding for complex merges","""Out of many, one"",Framework part 2: one-to-many merges,Identifying one-to-many relationships,Joining on key columns,Checking for duplicate keys,Completing a one-to-many merge,Index-based joins,Joining on index,Joining multiple tables,Reviewing the one-to-many join","Types of joins,One-to-one joins,One-to-many joins,Many-to-many joins,A closer look at one-to-one joins,Unscrambling the framework.,Replicating VLOOKUP,Merging on two or more keys,Combining common data with inner joins,Object-oriented merges,Basic inner joins,Dealing with different names,Choosing the correct join method","Joining data in real life,Mixing indexes and columns,Suffixes and indicators,Working with time data,Combining time series,Matching to the nearest time,Recap and case study,Case study challenge - part 1,Case study challenge - part 2,Case study challenge - part 3","Ruanne Van Der Walt,Anneleen Beckers","Games Plays,Players draft,Current players,NGS,Games,New weather data,Python for Spreadsheet Users",,
32,Introduction to Data Engineering,4,15,57,"76,379",4100,Have you heard people talk about data engineers and wonder what it is they do? Do you know what data engineers do but you're not sure how to become one yourself? This course is the perfect introduction. It touches upon all things you need to know to streamline your data processing. This introductory course will give you enough context to start exploring the world of data engineering. It's perfect for people who work at a company with several data sources and don't have a clear idea of how to use all those data sources in a scalable way. Be the first one to introduce these techniques to your company and become the company star employee.,"What is data engineering?,Tasks of the data engineer,Data engineer or data scientist?,Data engineering problems,Tools of the data engineer,Kinds of databases,Processing tasks,Scheduling tools,Cloud providers,Why cloud computing?,Big players in cloud computing,Cloud services","Extract,Data sources,Fetch from an API,Read from a database,Transform,Splitting the rental rate,Prepare for transformations,Joining with ratings,Loading,OLAP or OLTP,Writing to a file,Load into Postgres,Putting it all together,Defining a DAG,Setting up Airflow,Interpreting the DAG","Databases,SQL vs NoSQL,The database schema,Joining on relations,Star schema diagram,What is parallel computing,Why parallel computing?,From task to subtasks,Using a DataFrame,Parallel computation frameworks,Spark, Hadoop and Hive,A PySpark groupby,Running PySpark files,Workflow scheduling frameworks,Airflow, Luigi and cron,Airflow DAGs","Course ratings,Exploring the schema,Querying the table,Average rating per course,From ratings to recommendations,Filter out corrupt data,Using the recommender transformation,Scheduling daily jobs,The target table,Defining the DAG,Enable the DAG,Querying the recommendations,Congratulations",Adel Nehme,"Data Engineer,datacamp_application.sql,Intermediate Python,Introduction to SQL",,
33,Data Manipulation with dplyr,4,13,46,"84,613",3850,"Say you've found a great dataset and would like to learn more about it. How can you start to answer the questions you have about the data? You can use dplyr to answer those questions—it can also help with basic transformations of your data. You'll also learn to aggregate your data and add, remove, or change the variables. Along the way, you'll explore a dataset containing information about counties in the United States. You'll finish the course by applying these tools to the babynames dataset to explore trends of baby names in the United States.","The counties dataset,Understanding your data,Selecting columns,The filter and arrange verbs,Arranging observations,Filtering for conditions,Filtering and arranging,Mutate,Calculating the number of government employees,Calculating the percentage of women in a county,Select, mutate, filter, and arrange","Selecting,Selecting columns,Select helpers,The rename verb,Renaming a column after count,Renaming a column as part of a select,The transmute verb,Choosing among verbs,Using transmute,Matching verbs to their definitions,Choosing among the four verbs","The count verb,Counting by region,Counting citizens by state,Mutating and counting,The group by, summarize and ungroup verbs,Summarizing,Summarizing by state,Summarizing by state and region,The top_n verb,Selecting a county from each region,Finding the highest-income state in each region,Using summarize, top_n, and count together","The babynames data,Filtering and arranging for one year,Using top_n with babynames,Visualizing names with ggplot2,Grouped mutates,Finding the year each name is most common,Adding the total and maximum for each name,Visualizing the normalized change in popularity,Window functions,Using ratios to describe the frequency of a name,Biggest jumps in a name,Congratulations!",Amy Peterson,"Data Analyst,Data Manipulation,Data Scientist,R Programmer,counties,babynames,Introduction to the Tidyverse",,
34,Practicing Machine Learning Interview Questions in Python,4,16,60,"6,077",4600,"Have you ever wondered how to properly prepare for a Machine Learning Interview? Of course you have or you likely wouldn't be reading this right now! In this course, students will prepare to answer 15 common Machine Learning (ML) interview questions for a data scientist role in Python. These questions will revolve around 7 important topics: data preprocessing, data visualization, supervised learning, unsupervised learning, model ensembling, model selection, and model evaluation. By the end of the course, the students will possess both the required theoretical background and the ability to develop Python code to successfully answer these 15 questions. The coding examples will be mainly based on the scikit-learn package given its ease-of-use and ability to cover the most important ML techniques in the Python language.

The course does not teach machine learning fundamentals as these are covered in the course's prerequisites.","Handling missing data,The hunt for missing values,Simple imputation,Iterative imputation,Data distributions and transformations,Training vs test set distributions and transformations,Train/test distributions,Log and power transformations,Data outliers and scaling,Outlier detection,Handling outliers,Z-score standardization","Dimensionality reduction: feature extraction,The curse of dimensionality,Principal component analysis,Singular value decomposition,Dimensionality reduction: visualization techniques,Reducing high-dimensional data,Visualization separation of classes with PCA I,Visualization PCs with a scree plot,Clustering analysis: selecting the right clustering algorithm,Clustering algorithms,K-means clustering,Hierarchical agglomerative clustering,Clustering analysis: choosing the optimal number of clusters,What is the optimal k?,Silhouette method,Elbow method","Regression: feature selection,Best feature subset,Filter and wrapper methods,Feature selection through feature importance,Regression: regularization,Avoiding overfitting,Lasso regularization,Ridge regularization,Classification: feature engineering,Classification model features,Logistic regression baseline classifier,Ensemble methods,Bootstrap aggregation (bagging),Boosting,XG Boost","Model generalization: bootstrapping and cross-validation,Validating model performance,Decision tree,A forest of decision trees,Model evaluation: imbalanced classification models,X-ray weapon detection,Imbalanced class metrics,Resampling techniques,Model selection: regression models,Addressing multicollinearity,Multicollinearity techniques - feature engineering,Multicollinearity techniques - PCA,Model selection: ensemble models,Random forest vs gradient boosting,Random forest ensemble,Gradient boosting ensemble,Wrap-Up",Adel Nehme,"Diabetes,Loans dataset,Loans training set (reduced),Unsupervised Learning in Python,Supervised Learning with scikit-learn",,
35,Reporting with R Markdown,4,14,49,"23,773",4150,"R Markdown is an easy to use formatting language you can use to reveal insights from data and author your findings as a PDF, HTML file, or Shiny app. In this course, you'll learn how to create and modify each element of a Markdown file, including the code, text, and metadata. You'll analyze data with dplyr, create visualizations with ggplot2, and author your analyses and plots as reports. You’ll gain hands-on experience of building reports as you work with real-world data from the International Finance Corporation (IFC)—learning how to efficiently organize reports using code chunk options, create lists and tables, and include a table of contents. By the end of the course, you'll have the skills you need to add your brand’s fonts and colors using parameters and Cascading Style Sheets (CSS), to make your reports stand out.","Introduction to R Markdown,Creating your first R Markdown file,Adding code chunks to your file,Adding and formatting text,Formatting text,Adding sections to your report,Including links and images,The YAML header,Editing the YAML header,Formatting the date","Organizing the report,Creating a bulleted list,Creating a numbered list,Adding a table,Code chunk options,Comparing code chunk options,Collapsing blocks in the knit report,Modifying the report using include and echo,Warnings, messages, and errors,Excluding messages,Excluding warnings","Analyzing the data,Filtering for a specific country,Filtering for a specific year,Referencing code results in the report,Adding plots,Visualizing the Investment Annual Summary data,Visualizing all projects for one country,Visualizing all projects for one country and year,Plot options,Setting chunk options globally,Setting chunk options locally,Adding figure captions","Adding a table of contents,Adding the table of contents,Specifying headers and number sectioning,Adding table of contents options,Creating a report with a parameter,Adding a parameter to the report,Creating a new report using a parameter,Multiple parameters,Adding multiple parameters to the report,Creating a new report using multiple parameters,Customizing the report,Customizing the report style,Customizing the header and table of contents,Customizing the title, author, and date,Referencing the CSS file,Congratulations!",Maggie Matsui,"Data Scientist,Investment Services Projects,Investment Annual Summary,Introduction to the Tidyverse",,
36,Data Analysis in Excel,4,12,48,"101,964",2600,"There’s a lot more to Microsoft Excel than SUM and COUNT. Companies and institutions around the world use Excel’s powerful functions to efficiently transform mountains of raw data into clear insights, and now you can too.

In this course, you’ll develop employable analyst skills as you learn how to use time-saving keyboard shortcuts, convert and clean data types including text, times and dates, and build impressive logic functions and conditional aggregations. Through hands-on practice, you’ll learn over 35 new Excel functions, including CONCATENATE, VLOOKUP, and AVERAGEIF(S), and work with real-world Kickstarter data as you use your new-found Excel skills to analyze what makes a successful project.","Welcome to the wonderful world of Excel!,What can Excel do?,Data analysis steps,Setting up your environment,Navigating the worksheet,Exploring data in Excel,Looking for exact matches,Trimming your data,Sorting the table,Nesting functions,Understanding data types in Excel,Classifying data types,Changing to text,Rounding values","But who's COUNTing?,Choosing the right count function,Learning to count,Counting blank cells,Excel the great calculator,Math functions in Excel,Finding the minimum,Aggregating data,Logic functions,The arguments of the IF() function,Performing a logical test,Taking IF() to the next level,Conditional aggregations,Finding unique values,Counting projects,Determining the average,Wrap-up","Cleaning text data,Joining text strings,Capitalizing words,Using upper and lower case,Extracting text from cells,Counting characters,Extracting text,Replacing characters,Preparing date data,Using the system date,Working with dates,Finding the day of the week,Figuring out the month,The most important function in Excel,Finding the matching column,Working with range_lookup,Using VLOOKUP",,Sara Billen,"Solution Workbook,Raw Data",,
37,Object-Oriented Programming in Python,4,13,44,"44,685",3600,"Object-oriented programming (OOP) is a widely used programming paradigm that reduces development times—making it easier to read, reuse, and maintain your code. OOP shifts the focus from thinking about code as a sequence of actions to looking at your program as a collection of objects that interact with each other. In this course, you’ll learn how to create classes, which act as the blueprints for every object in Python. You’ll then leverage principles called inheritance and polymorphism to reuse and optimize code. Dive in and learn how to create beautiful code that’s clean and efficient!","What is OOP?,OOP termininology,Exploring object interface,Class anatomy: attributes and methods,Understanding class definitions,Create your first class,Using attributes in class definition,Class anatomy: the __init__ constructor,Correct use of __init__,Add a class constructor,Write a class from scratch","Operator overloading: comparison,Overloading equality,Checking class equality,Comparison and inheritance,Operator overloading: string representation,String formatting review,String representation of objects,Exceptions,Catching exceptions,Custom exceptions,Handling exception hierarchies","Instance and class data,Class-level attributes,Changing class attributes,Alternative constructors,Class inheritance,Understanding inheritance,Create a subclass,Customizing functionality via inheritance,Method inheritance,Inheritance of class attributes,Customizing a DataFrame","Designing for inheritance and polymorphism,Polymorphic methods,Square and rectangle,Managing data access: private attributes,Attribute naming conventions,Using internal attributes,Properties,What do properties do?,Create and set properties,Read-only properties,Congratulations!","Maggie Matsui,Amy Peterson","Data Engineer,Python Programmer,Python Programming,Writing Functions in Python",,
38,Introduction to Power BI,3,13,39,"151,996",3000,"Gain a 360° overview of exploring and using Power BI to build impactful reports. In this course, you’ll go from zero to hero as you discover how to use this popular business intelligence platform through hands-on exercises. Before diving into creating visualizations using Power BI's drag-and-drop functionality, you’ll first learn how to confidently load and transform data using Power Query and the importance of data models. You’ll also learn to drill down into reports and make your reports fully interactive. You've got the power!","Introduction to Power BI,Features of Power BI,Views in Power BI,Getting started!,Loading existing reports,Your first visualization,Add a card,Slicers and Tables,Slicers,More columns,Table","Visualization options,Choosing the right visual,Making changes,Changing visuals,Editing properties,Sorting and more formatting,Sorting data,Using the slicer,Making it look good","Transforming data,Cleaning data,Power Query Editor,Transform before load,Field aggregation,Transforming and formatting columns,Transforming columns,Formatting currency,Making maps with geographic data","Drilling down and filtering,Working with hierarchies,The underlying data and hierarchies,Looking at the data,Creating a hierarchy,Filters,Adding a filter,Turning off interactions,Applying advanced filtering,Congratulations!","Ginger Grant,Hadrien Lacroix","Data Analyst,Power BI Fundamentals,Exercises and Datasets,Navigation Cheatsheet,DataCamp vs. Local Experience",,
39,Data Visualization for Everyone,2,14,43,"57,542",2550,"Visualizing data using charts, graphs, and maps is one of the most impactful ways to communicate complex data. In this course, you’ll learn how to choose the best visualization for your dataset, and how to interpret common plot types like histograms, scatter plots, line plots and bar plots. You'll also learn about best practices for using colors and shapes in your plots, and how to avoid common pitfalls. Through hands-on exercises, you'll visually explore over 20 datasets including global life expectancies, Los Angeles home prices, ESPN's 100 most famous athletes, and the greatest hip-hop songs of all time.","A plot tells a thousand words,Motivating visualization,Continuous vs. categorical variables,Histograms,Interpreting histograms,Adjusting bin width,Box plots,Interpreting box plots,Ordering box plots","Higher dimensions,Another dimension for scatter plots,Another dimension for line plots,Using color,Eye-catching colors,Qualitative, sequential, diverging,Highlighting data,Plotting many variables at once,Interpreting pair plots,Interpreting correlation heatmaps,Interpreting parallel coordinates plots","Scatter plots,Interpreting scatter plots,Trends with scatter plots,Line plots,Interpreting line plots,Logarithmic scales for line plots,Line plots without dates on the x-axis,Bar plots,Interpreting bar plots,Interpreting stacked bar plots,Dot plots,Interpreting dot plots,Sorting dot plots","Polar coordinates,Pie plots,Rose plots,Axes of evil,Bar plot axes,Dual axes,Sensory overload,Chartjunk,Multiple plots,Congratulations",Lis Sulmont,"Data Analyst,Data Literacy Fundamentals",,
40,Cleaning Data in Python,4,13,44,"62,987",3500,"It's commonly said that data scientists spend 80% of their time cleaning and manipulating data and only 20% of their time analyzing it. The time spent cleaning is vital since analyzing dirty data can lead you to draw inaccurate conclusions. Data cleaning is an essential task in data science. Without properly cleaned data, the results of any data analysis or machine learning model could be inaccurate. In this course, you will learn how to identify, diagnose, and treat a variety of data cleaning problems in Python, ranging from simple to advanced. You will deal with improper data types, check that your data is in the correct range, handle missing data, perform record linkage, and more!","Data type constraints,Common data types,Numeric data or ... ?,Summing strings and concatenating numbers,Data range constraints,Tire size constraints,Back to the future,Uniqueness constraints,How big is your subset?,Finding duplicates,Treating duplicates","Uniformity,Ambiguous dates,Uniform currencies,Uniform dates,Cross field validation,Cross field or no cross field?,How's our data integrity?,Completeness,Is this missing at random?,Missing investors,Follow the money","Membership constraints,Members only,Finding consistency,Categorical variables,Categories of errors,Inconsistent categories,Remapping categories,Cleaning text data,Removing titles and taking names,Keeping it descriptive","Comparing strings,Minimum edit distance,The cutoff point,Remapping categories II,Generating pairs,To link or not to link?,Pairs of restaurants,Similar restaurants,Linking DataFrames,Getting the right index,Linking them together!,Congratulations!","Richie Cotton,Maggie Matsui,Amy Peterson","Data Scientist,Importing & Cleaning Data,Ride sharing dataset,Airlines dataset,Banking dataset,Restaurants dataset,Restaurants dataset II,Python Data Science Toolbox (Part 2),Joining Data with pandas",,
41,R For SAS Users,4,15,56,"2,288",4700,"If you have experience with SAS and want to learn R, this is the course for you. R is FREE (cost) and OPEN (license) and is one of the fastest growing software languages for statistics and data science. This course is a gentle introduction to the R language with every chapter providing a detailed mapping of R functions to SAS procedures highlighting similarities and differences. You will orient yourself in the R environment and discover how to wrangle, visualize, and model data plus customize your output for final presentation. Throughout the course, you will follow a consistent workflow of data quality checking and cleaning, exploring relationships, modeling, and presenting results. You will leave this course with coded examples that provide a template to use immediately with a dataset of your own.","Get help and load data in R,Getting help,Load dataset and get details,Add functionality with packages,Dataset contents and descriptive statistics,Load external dataset,Dataset contents,Descriptive statistics,Graphical visualizations,Histograms,Boxplots and violin plots,Scatterplots","Exploratory data analysis,Descriptive statistics and function masking,Specific statistics for one or more variables,Summary statistics by group,Correlations and t-tests,Bivariate correlations,Scatterplots,Correlations by sex,Tests for two groups,Categorical data: analyze and visualize,Chi-square tests,Mosaic plots,Age categories by shellweight categories","Objects - the building blocks of R,Create data objects in R,Create composite object types,Selecting elements from objects,Determine variable types,Select elements in objects,Manipulating datasets and data objects,Create new variables,Recode variables,Object type conversion,Data quality and cleaning,Variables inspection,Illogical weights,Check dimension measurements,Check final dataset","Working with output objects,Descriptive statistics output,Summarise output,Group_by output,Working with lists,Hmisc describe output,Correlations output,t-tests output,Chi-square tests output,ANOVA and linear models,ANOVA,Linear regression,Final models evaluation,Abalone age predictors,Best model by sex,Course summary and recommendations","Richie Cotton,Sara Billen",Abalone,,
42,Writing Functions in Python,4,15,46,"52,499",3650,"You've done your analysis, built your report, and trained a model. What's next? Well, if you want to deploy your model into production, your code will need to be more reliable than exploratory scripts in a Jupyter notebook. Writing Functions in Python will give you a strong foundation in writing complex and beautiful functions so that you can contribute research and engineering skills to your team. You'll learn useful tricks, like how to write context managers and decorators. You'll also learn best practices around how to write maintainable reusable functions with good documentation. They say that people who can do good research and write high-quality code are unicorns. Take this course and discover the magic!","Docstrings,Crafting a docstring,Retrieving docstrings,Docstrings to the rescue!,DRY and ""Do One Thing"",Extract a function,Split up a function,Pass by assignment,Mutable or immutable?,Best practice for default arguments","Functions are objects,Building a command line data app,Reviewing your co-worker's code,Returning functions for a math game,Scope,Understanding scope,Modifying variables outside local scope,Closures,Checking for closure,Closures keep your values safe,Decorators,Using decorator syntax,Defining a decorator","Using context managers,The number of cats,The speed of cats,Writing context managers,The timer() context manager,A read-only open() context manager,Advanced topics,Context manager use cases,Scraping the NASDAQ,Changing the working directory","Real-world examples,Print the return type,Counter,Decorators and metadata,Preserving docstrings when decorating functions,Measuring decorator overhead,Decorators that take arguments,Run_n_times(),HTML Generator,Timeout(): a real world example,Tag your functions,Check the return type,Great job!","Becca Robins,Hillary Green-Lerman","Data Engineer,Data Scientist,Python Programmer,Python Programming,Python Data Science Toolbox (Part 2)",,
43,Marketing Analytics in Spreadsheets,4,15,56,"8,444",4650,"Spreadsheets are an essential tool for any marketing professional, but how does one keep these spreadsheets clean and accurate - especially when multiple parties contribute data? Data validation and regular expressions are powerful tools for marketing analysts, but having clean data is only half the battle. After we learn how to clean the data, we will visualize it by building charts! Throughout the course, we will explore a dataset that includes the kind of information you will encounter in the world of digital marketing. We will spot errors in metrics using data validation, use regular expressions to aggregate campaign metrics, build charts to analyze campaign performance, and use everything we've learned to build a dynamic dashboard!","The importance of clean data entry,Test your knowledge,Fix the errors,Contribute to the data set,Create dropdowns from lists,Mitigating campaign name errors,List from a range,List of items,Validations using cell criteria and checkboxes,Text validation,Check the checkboxes,Putting it all together","Analyzing paid-search trends with line & area charts,Analyze cost data with a stacked area chart,Plotting campaign click-through-rates with a line chart,Visualizing ad group performance with column & bar charts,Using a bar chart to visualize total ad group spend,Assessing campaign performance with a column chart,Ad group overview with 100% stacked bar chart,Evaluating campaigns with pie & scatter plots,Assessing campaign goal completions with a pie chart,Understanding click through rate with a scatter plot,Visualizing goal completions with a bubble chart,Build a digital marketing dashboard,Visualizing impressions with a doughnut chart,Using a bubble chart to determine the better source,Source performance using a standard stacked bar chart","What are regular expressions?,Using regular expressions,Writing regular expressions,Test a string using REGEXMATCH,Filter table using REGEXMATCH,Aggregate campaign cost using REGEXMATCH,Aggregate ad group cost-per-click using REGEXMATCH,Modify a string using REGEXEXTRACT and REGEXREPLACE,Rename brand campaigns using REGEXREPLACE(),Rename all ad groups using REGEXREPLACE(),Extract brand campaign names using REGEXEXTRACT(),Create campaign IDs using REGEXEXTRACT(),Cleaning Campaign Names,Modify the campaign ID to include source,How much did each source spend?,Sum up campaigns with RegEx","Preparing the data,Dropdowns for source and campaign name,Create a filtered table,Prep for charts with a regex driven table,Visualize the data,Ad group impression share with a doughnut chart,Ad group metrics with a bar chart,Campaign and ad group analysis with a bubble chart,Putting it all together,Who are the dashboards for?,Add a campaign dropdown filter,Apply dynamic filter to dashboard,Wrap-up","Chester Ismay,Amy Peterson","Intermediate Spreadsheets,Intermediate Spreadsheets",,
44,Introduction to Deep Learning with PyTorch,4,17,53,"19,498",4300,"Neural networks have been at the forefront of Artificial Intelligence research during the last few years, and have provided solutions to many difficult problems like image classification, language translation or Alpha Go. PyTorch is one of the leading deep learning frameworks, being at the same time both powerful and easy to use. In this course you will use PyTorch to first learn about the basic concepts of neural networks, before building your first neural network to predict digits from MNIST dataset. You will then learn about convolutional neural networks, and use them to build much more powerful models which give more accurate results. You will evaluate the results and use different techniques to improve them. Following the course, you will be able to delve deeper into neural networks and start your career in this fascinating field.","Introduction to PyTorch,Creating tensors in PyTorch,Matrix multiplication,Forward propagation,Forward pass,Backpropagation by auto-differentiation,Backpropagation by hand,Backpropagation using PyTorch,Calculating gradients in PyTorch,Introduction to Neural Networks,Your first neural network,Your first PyTorch neural network","Convolution operator,Convolution operator - OOP way,Convolution operator - Functional way,Pooling operators,Max-pooling operator,Average-pooling operator,Convolutional Neural Networks,Your first CNN - __init__ method,Your first CNN - forward() method,Training Convolutional Neural Networks,Training CNNs,Using CNNs to make predictions","Activation functions,Neural networks,ReLU activation,ReLU activation again,Loss functions,Calculating loss function by hand,Calculating loss function in PyTorch,Loss function of random scores,Preparing a dataset in PyTorch,Preparing MNIST dataset,Inspecting the dataloaders,Training neural networks,Building a neural network - again,Training a neural network,Using the network to make predictions","The sequential module,Sequential module - init method,Sequential module - forward() method,The problem of overfitting,Validation set,Detecting overfitting,Regularization techniques,L2-regularization,Dropout,Batch-normalization,Transfer learning,Finetuning a CNN,Torchvision module,Congratulations!","Hadrien Lacroix,Hillary Green-Lerman","Deep Learning,Machine Learning with scikit-learn,Object-Oriented Programming in Python",,
45,Generalized Linear Models in Python,5,16,59,"7,031",4950,"Imagine being able to handle data where the response variable is either binary, count, or approximately normal, all under one single framework. Well, you don't have to imagine. Enter the Generalized Linear Models in Python course! In this course you will extend your regression toolbox with the logistic and Poisson models, by learning how to fit, understand, assess model performance and finally use the model to make predictions on new data. You will practice using data from real world studies such the largest population poisoning in world's history, nesting of horseshoe crabs and counting the bike crossings on the bridges in New York City.","Going beyond linear regression,Applying linear models,Linear model, a special case of GLM,How to build a GLM?,Data type and distribution family,Linear model and a binary response variable,Comparing predicted values,How to fit a GLM in Python?,Model fitting step-by-step,Results of the model fit using summary(),Extracting parameter estimates","Count data and Poisson distribution,Visualize the response,Fitting a Poisson regression,Interpreting model fit,Estimate parameter lambda,Interpret Poisson coefficients,Poisson confidence intervals,The Problem of Overdispersion,Is the mean equal to the variance?,Computing expected number of counts,Checking for overdispersion,Fitting negative binomial,Confidence intervals for negative Binomial model,Plotting a regression model,Plotting data and linear model fit,Plotting fitted values","Binary data and logistic regression,Compute odds and probabilities,Fit logistic regression,Interpreting coefficients,Coefficients in terms of odds,Model formula,Interpreting logistic model,Rate of change in probability,Interpreting model inference,Statistical significance,Computing Wald statistic,Confidence intervals,Computing and describing predictions,Visualize model fit using regplot(),Compute predictions,Compute confusion matrix","Multivariable logistic regression,Fit a multivariable logistic regression,The effect of multicollinearity,Compute VIF,Comparing models,Checking model fit,Compare two models,Deviance and linear transformation,Model formula,Model matrix for continuous variables,Variable transformation,Coding categorical variables,Categorical and interaction terms,Modeling with categorical variable,Interaction terms,Congratulations!","Chester Ismay,Adrián Soto","Well switch due to arsenic poisoning,Nesting of the female horseshoe crab,Credit default,Level of salary and years of work experience,Medical costs per person given age and BMI,Bike crossings in New York City,Introduction to Linear Modeling in Python",,
46,Analyzing Business Data in SQL,4,15,46,"20,744",3700,"Businesses track data on everything, from operations to marketing to HR. Leveraging this data enables businesses to better understand themselves and their customers, leading to higher profits and better performance. In this course, you’ll learn about the key metrics that businesses use to measure performance. You'll write SQL queries to calculate these metrics and produce report-ready results. Throughout the course, you'll study data from a fictional food delivery startup, modeled on data from real companies.","Revenue,Revenue per customer,Revenue per week,Cost and Common Table Expressions (CTEs),Total cost,Top meals by cost,Using CTEs,Profit,Profit per eatery,Profit per month","Unit economics,Average revenue per user,ARPU per week,Average orders per user,Histograms,Histogram of revenue,Histogram of orders,Bucketing,Bucketing users by revenue,Bucketing users by orders,Percentiles,Revenue quartiles,Interquartile range","Registrations and active users,Registrations by month,Monthly active users (MAU),Window functions,Registrations running total,MAU monitor (I),Growth,MAU monitor (II),MAU monitor (III),Order growth rate,Retention,New, retained, and resurrected users,Retention rate","Survey of useful functions,Formatting dates,Rank users by their count of orders,Pivoting,Pivoting user revenues by month,Costs,Producing executive reports,Report readability,Executive report,Course recap","Sara Billen,Mona Khalil","SQL for Business Analysts,Intermediate SQL",,
47,Improving Query Performance in SQL Server,4,16,58,"15,061",4450,"A mission critical assignment is depending on your SQL coding skills. You’ve been given some code to fix. It is giving the results you need but it’s running too slow, and it’s poorly formatted making it hard to read. The deadline is tomorrow. You’ll need to reformat the code and try different methods to improve performance. The pressure is on!!! In this course we’ll be using SQL on real world datasets, from sports and geoscience, to look at good coding practices and different ways how we can can improve the performance of queries to achieve the same outcome.","Introduction,Formatting - player BMI,Commenting - player BMI,Commenting - how many Kiwis in the NBA?,Aliasing,Ambiguous column names,Aliasing - team BMI,Query order,Processing order,Syntax order - New Zealand earthquakes,Syntax order - Japan earthquakes,Syntax order - very large earthquakes","Sub-queries,Uncorrelated sub-query,Correlated sub-query,Sub-query vs INNER JOIN,Presence and absence,INTERSECT,EXCEPT,Interrogating with INTERSECT,Alternative methods 1,IN and EXISTS,NOT IN and NOT EXISTS,NOT IN with IS NOT NULL,Alternative methods 2,INNER JOIN,Exclusive LEFT OUTER JOIN,Test your knowledge","Filtering with WHERE,Column does not exist,Functions in WHERE,Test your knowledge of WHERE,Filtering with HAVING,Row filtering with HAVING,Filtering with WHERE and HAVING,Test your knowledge of HAVING,Interrogation after SELECT,SELECT what you need,Limit the rows with TOP,Should I use ORDER BY?,Managing duplicates,Remove duplicates with DISTINCT(),UNION and UNION ALL,UNION or DISTINCT()?","Time statistics,STATISTICS TIME in queries,STATISTICS TIME results,Page read statistics,STATISTICS IO: Example 1,STATISTICS IO: Example 2,STATISTICS IO comparison,Indexes,Test your knowledge of indexes,Clustered index,Execution plans,Sort operator in execution plans,Test your knowledge of execution plans,Query performance tuning: final notes","Becca Robins,Mona Khalil,Marianna Lamnina","SQL Server Developer,SQL Server for Database Administrators,Orders dataset,NBAPlayers dataset,NBATeams dataset,NBAPlayersStatistics dataset,Intermediate SQL Server",,
48,Introduction to Data Visualization with Seaborn,4,14,44,"68,856",3700,"Seaborn is a powerful Python library that makes it easy to create informative and attractive visualizations. This course provides an introduction to Seaborn and teaches you how to visualize your data using plots such as scatter plots, box plots, and bar plots. You’ll do this while exploring survey responses about student hobbies and the factors that are associated with academic success. You’ll also learn about some of Seaborn’s advantages as a statistical visualization tool, such as how it automatically calculates confidence intervals. By the end of the course, you will be able to use Seaborn in a variety of situations to explore your data and effectively communicate the results of your data analyses to others.","Introduction to Seaborn,Making a scatter plot with lists,Making a count plot with a list,Using pandas with Seaborn,""Tidy"" vs. ""untidy"" data,Making a count plot with a DataFrame,Adding a third variable with hue,Hue and scatter plots,Hue and count plots","Count plots and bar plots,Count plots,Bar plots with percentages,Customizing bar plots,Box plots,Create and interpret a box plot,Omitting outliers,Adjusting the whiskers,Point plots,Customizing point plots,Point plots with subgroups","Introduction to relational plots and subplots,Creating subplots with col and row,Creating two-factor subplots,Customizing scatter plots,Changing the size of scatter plot points,Changing the style of scatter plot points,Introduction to line plots,Interpreting line plots,Visualizing standard deviation with line plots,Plotting subgroups in line plots","Changing plot style and color,Changing style and palette,Changing the scale,Using a custom palette,Adding titles and labels: Part 1,FacetGrids vs. AxesSubplots,Adding a title to a FacetGrid object,Adding titles and labels: Part 2,Adding a title and axis labels,Rotating x-tick labels,Putting it all together,Box plot with subgroups,Bar plot with subgroups and subplots,Well done! What's next?","Yashas Roy,Mona Khalil","Data Analyst,Data Scientist,Data Visualization,Countries,Mileage per gallon,Students,Survey responses,Introduction to Data Science in Python",,
49,Hyperparameter Tuning in Python,4,13,44,"12,207",3400,"Building powerful machine learning models depends heavily on the set of hyperparameters used. But with increasingly complex models with lots of options, how do you efficiently find the best settings for your particular problem? In this course you will get practical experience in using some common methodologies for automated hyperparameter tuning in Python using Scikit Learn. These include Grid Search, Random Search & advanced optimization methodologies including Bayesian & Genetic algorithms . You will use a dataset predicting credit card defaults as you build skills to dramatically increase the efficiency and effectiveness of your machine learning model building.","Introduction & 'Parameters',Parameters in Logistic Regression,Extracting a Logistic Regression parameter,Extracting a Random Forest parameter,Introducing Hyperparameters,Hyperparameters in Random Forests,Exploring Random Forest Hyperparameters,Hyperparameters of KNN,Setting & Analyzing Hyperparameter Values,Automating Hyperparameter Choice,Building Learning Curves","Introducing Random Search,Randomly Sample Hyperparameters,Randomly Search with Random Forest,Visualizing a Random Search,Random Search in Scikit Learn,RandomSearchCV inputs,The RandomizedSearchCV Object,RandomSearchCV in Scikit Learn,Comparing Grid and Random Search,Comparing Random & Grid Search,Grid and Random Search Side by Side","Introducing Grid Search,Build Grid Search functions,Iteratively tune multiple hyperparameters,How Many Models?,Grid Search with Scikit Learn,GridSearchCV inputs,GridSearchCV with Scikit Learn,Understanding a grid search output,Using the best outputs,Exploring the grid search results,Analyzing the best results,Using the best results","Informed Search: Coarse to Fine,Visualizing Coarse to Fine,Coarse to Fine Iterations,Informed Search: Bayesian Statistics,Bayes Rule in Python,Bayesian Hyperparameter tuning with Hyperopt,Informed Search: Genetic Algorithms,Genetic Hyperparameter Tuning with TPOT,Analysing TPOT's stability,Congratulations!","Chester Ismay,Hadrien Lacroix","Machine Learning Scientist,Credit Card Defaults,Supervised Learning with scikit-learn",,
50,Model Validation in Python,4,15,47,"14,749",3700,"Machine learning models are easier to implement now more than ever before. Without proper validation, the results of running new data through a model might not be as accurate as expected. Model validation allows analysts to confidently answer the question, how good is your model? We will answer this question for classification models using the complete set of tic-tac-toe endgame scenarios, and for regression models using fivethirtyeight’s ultimate Halloween candy power ranking dataset. In this course, we will cover the basics of model validation, discuss various validation techniques, and begin to develop tools for creating validated and high performing models.","Introduction to model validation,Modeling steps,Seen vs. unseen data,Regression models,Set parameters and fit a model,Feature importances,Classification models,Classification predictions,Reusing model parameters,Random forest classifier","The problems with holdout sets,Two samples,Potential problems,Cross-validation,scikit-learn's KFold(),Using KFold indices,sklearn's cross_val_score(),scikit-learn's methods,Implement cross_val_score(),Leave-one-out-cross-validation (LOOCV),When to use LOOCV,Leave-one-out-cross-validation","Creating train, test, and validation datasets,Create one holdout set,Create two holdout sets,Why use holdout sets,Accuracy metrics: regression models,Mean absolute error,Mean squared error,Performance on data subsets,Classification metrics,Confusion matrices,Confusion matrices, again,Precision vs. recall,The bias-variance tradeoff,Error due to under/over-fitting,Am I underfitting?","Introduction to hyperparameter tuning,Creating Hyperparameters,Running a model using ranges,RandomizedSearchCV,Preparing for RandomizedSearch,Implementing RandomizedSearchCV,Selecting your final model,Best classification accuracy,Selecting the best precision model,Course completed!","Chester Ismay,Becca Robins","Machine Learning Scientist,Candy dataset,Tic-Tac-Toe dataset,Supervised Learning with scikit-learn",,
51,Introduction to TensorFlow in Python,4,15,51,"34,285",4300,"Not long ago, cutting-edge computer vision algorithms couldn’t differentiate between images of cats and dogs. Today, a skilled data scientist equipped with nothing more than a laptop can classify tens of thousands of objects with greater accuracy than the human eye. In this course, you will use TensorFlow 2.6 to develop, train, and make predictions with the models that have powered major advances in recommendation systems, image classification, and FinTech. You will learn both high-level APIs, which will enable you to design and train deep learning models in 15 lines of code, and low-level APIs, which will allow you to move beyond off-the-shelf routines. You will also learn to accurately predict housing prices, credit card borrower defaults, and images of sign language gestures.","Constants and variables,Defining data as constants,Defining variables,Basic operations,Performing element-wise multiplication,Making predictions with matrix multiplication,Summing over tensor dimensions,Advanced operations,Reshaping tensors,Optimizing with gradients,Working with image data","Dense layers,The linear algebra of dense layers,The low-level approach with multiple examples,Using the dense layer operation,Activation functions,Binary classification problems,Multiclass classification problems,Optimizers,The dangers of local minima,Avoiding local minima,Training a network in TensorFlow,Initialization in TensorFlow,Defining the model and loss function,Training neural networks with TensorFlow","Input data,Load data using pandas,Setting the data type,Loss functions,Loss functions in TensorFlow,Modifying the loss function,Linear regression,Set up a linear regression,Train a linear model,Multiple linear regression,Batch training,Preparing to batch train,Training a linear model in batches","Defining neural networks with Keras,The sequential model in Keras,Compiling a sequential model,Defining a multiple input model,Training and validation with Keras,Training with Keras,Metrics and validation with Keras,Overfitting detection,Evaluating models,Training models with the Estimators API,Preparing to train with Estimators,Defining Estimators,Congratulations!","Alex Yarosh,Sara Billen,Mona Khalil","Deep Learning,Machine Learning Scientist,King County House Sales,UCI Credit Card Default,Sign Language MNIST,Supervised Learning with scikit-learn",,
52,Conditional Formatting in Spreadsheets,4,14,51,"7,414",4400,"Spreadsheets often suffer from having too much data. If you want to tell the underlying story that is in the data without creating additional reports, conditional formatting can help! Whether it's showing the age of your inventory by highlighting the items using a color scale, or accentuating the largest variances in year over year financial data, conditional formatting has built-in options that can be used without any complex code. It can be used instead of sorting or filtering since it works with the data that is already there! By the end, you will be creating your own report using conditional formatting to analyze a company's payroll.","A primer on conditional formatting,Conditional formatting,Additional rule,Conditional formatting of top and bottom values,Greater than,Weight range,Auditing an expense account,Conditional formatting using dates,Before last week,All dates except June,Dates","Highlight duplicate values,COUNTIF practice,Finding more duplicates,Conditionally formatting duplicates,Cleaning it up,Building a search box,SEARCH Function,Highlighting search,Highlight top values,SMALL function,Highlighting SMALL,Conditional formatting hacks,Cross off your to dos,Long term career goals,Ranking your goals,Crossing them off","Primer on custom formulas,Amount variance,Percentage variance,Working with AND / OR,Positive and negative,Both amount and variance,Quality control,Quality control further analysis,Highlighting an entire row,Formatting an entire row,Custom formula","Working with payroll dates,ISDATE function,Correcting your report,Checking for duplicates,Checking a payroll register,Paid time off totals,Pay allowed range,Moving to part-time,Overall payroll analysis,Year-to-date,Positive variances,Negative variances,Congratulations!","Chester Ismay,Amy Peterson",Data Analysis in Spreadsheets,,
53,Introduction to Spark SQL in Python,4,15,52,"11,586",4200,"You're familiar with SQL, and have heard great things about Apache Spark. Then this course is for you! Apache Spark is a computing framework for processing big data. Spark SQL is a component of Apache Spark that works with tabular data. Window functions are an advanced feature of SQL that take Spark to a new level of usefulness. You will use Spark SQL to analyze time series. You will extract the most common sequences of words from a text document. You will create feature sets from natural language text and use them to predict the last word in a sentence using logistic regression. Spark combines the power of distributed computing with the ease of use of Python and SQL. The course uses a natural language text dataset that is easy to understand. Sentences are sequences of words. Window functions are very suitable for manipulating sequence data. The same techniques taught here can be applied to sequences of song identifiers, video ids, or podcast ids. Exercises include discovering frequent word sequences, and converting word sequences into machine learning feature set data for training a text classifier.","Creating and querying a SQL table in Spark,Create a SQL table from a dataframe,Determine the column names of a table,Window function SQL,Running sums using window function SQL,Fix the broken query,Dot notation and SQL,Aggregation, step by step,Aggregating the same column twice,Aggregate dot SQL,Convert window function from dot notation to SQL","Caching,Practice query plans 2,Practicing caching: part 1,Practicing caching: the SQL,Practicing caching: putting it all together,Caching and uncaching tables,The Spark UI,Spark UI storage tab,Inspecting cache in the Spark UI,Logging,Practice logging,Practice logging 2,Query plans,Practice query plans,Practice reading query plans 2","Loading natural language text,Loading a dataframe from a parquet file,Split and explode a text column,Using monotonically_increasing_id(),Moving window analysis,Creating context window feature data,Repartitioning the data,Common word sequences,What type of data is this,Finding common word sequences,Unique 5-tuples in sorted order,Most frequent 3-tuples per chapter","Extract Transform Select,Practicing creating a UDF,Practicing array column,Creating feature data for classification,Creating a UDF for vector data,Applying a UDF to vector data,Transforming text to vector format,Text Classification,Label the data,Split the data,Train the classifier,Predicting and evaluating,Evaluate the classifier,Predict test data,Recap","Hadrien Lacroix,Hillary Green-Lerman","Sherlock (parquet file),Sherlock (txt file),Train schedule,Introduction to PySpark,Intermediate SQL,Python Data Science Toolbox (Part 2)",,
54,Financial Modeling in Spreadsheets,4,13,52,"10,209",4550,"Have you ever wanted to plan for retirement, understand the stock market, or create a cash flow for your business? In this course, you will learn how to build business and financial models in Sheets. Google Sheets is an excellent technology for business models! You can create a framework for your goal, like understanding the growth of investments, and then update that framework based on current data. You will learn the basics of business modeling focusing on cash flows, investments, annuities, loan amortization, and saving for retirement. By the end of the course, you will have gained referencing and function skills in Sheets that you can apply to all sorts of models.","How to love models,Format the income statement,Create the sum values,Copy sums for each year,Continuing simple models with balance sheets,Format a balance statement model,Balance all the years,Common size statement,Build a cash flow model,Update the cash flow,Complete cash flow for all years,Forecast Cash Flows","Retirement planning in real dollars,What's your nest egg?,How much do you need to pay?,Finish and visualize,Retirement planning in nominal dollars 1,Update yearly values,Add the estimate of fixed income,Break down the stock balance,Retirement planning in nominal dollars 2,Add withdrawals and money made,Calculate total year-end,How much initial money?","Value functions,Estimate effective interest rates,How much will I earn?,Double your money,Growing your money,Out-of-state tuition,Add some starter money,Can your child pay for college?,Study abroad for a year,Reducing your debt,Start the loan amortization table,Where did your money go?,Complete loan model","Living with uncertainty,Relative price and daily return,What is the average return?,Find volatility,A simple stock model,Expected return and random values,Certainty and uncertainty,Uncertainty charted,Stock probabilities,Stepping out the expected return,Create the steps for min and max stock prices,What is the most likely stock price?,Model stock price probability,Complete the probability table,Graph the stock distribution","Chester Ismay,Amy Peterson","Finance Fundamentals,Intermediate Spreadsheets",,
55,Machine Learning with PySpark,4,16,56,"15,970",4550,"Spark is a powerful, general purpose tool for working with Big Data. Spark transparently handles the distribution of compute tasks across a cluster. This means that operations are fast, but it also allows you to focus on the analysis rather than worry about technical details. In this course you'll learn how to get data into Spark and then delve into the three fundamental Spark Machine Learning algorithms: Linear Regression, Logistic Regression/Classifiers, and creating pipelines. Along the way you'll analyse a large dataset of flight delays and spam text messages. With this background you'll be ready to harness the power of Spark and apply it on your own Machine Learning projects!","Machine Learning & Spark,Characteristics of Spark,Components in a Spark Cluster,Connecting to Spark,Location of Spark master,Creating a SparkSession,Loading Data,Loading flights data,Loading SMS spam data","One-Hot Encoding,Encoding flight origin,Encoding shirt sizes,Regression,Flight duration model: Just distance,Interpreting the coefficients,Flight duration model: Adding origin airport,Interpreting the coefficients,Bucketing & Engineering,Bucketing departure time,Flight duration model: Adding departure time,Regularization,Flight duration model: More features!,Flight duration model: Regularisation!","Data Preparation,Removing columns and rows,Column manipulation,Categorical columns,Assembling columns,Decision Tree,Train/test split,Build a Decision Tree,Evaluate the Decision Tree,Logistic Regression,Build a Logistic Regression model,Evaluate the Logistic Regression model,Turning Text into Tables,Punctuation, numbers and tokens,Stop words and hashing,Training a spam classifier","Pipeline,Flight duration model: Pipeline stages,Flight duration model: Pipeline model,SMS spam pipeline,Cross-Validation,Cross validating simple flight duration model,Cross validating flight duration model pipeline,Grid Search,Optimizing flights linear regression,Dissecting the best flight duration model,SMS spam optimised,How many models for grid search?,Ensemble,Delayed flights with Gradient-Boosted Trees,Delayed flights with a Random Forest,Evaluating Random Forest,Closing thoughts","Hadrien Lacroix,Mona Khalil","Big Data with PySpark,Machine Learning Scientist,Flights,SMS,Introduction to PySpark,Supervised Learning with scikit-learn",,
56,Pivot Tables in Spreadsheets,4,13,54,"46,785",4150,"Working with large quantities of data in spreadsheets can be difficult and time-consuming. Have you ever wished there was a quick and efficient way to organize and evaluate your data within seconds? Pivot Tables are your answer! In this course we will explore the world of Pivot Tables within Google Sheets, and learn how to quickly organize thousands of datapoints with just a few clicks of the mouse. We will analyze the Average rainfall across multiple US cities, the Top 10 of the Fortune Global 500, and a selection of Films released between 2010 and 2016. You will learn techniques such as sorting, subtotaling, and filtering your data using these real world examples. By the end of the course, you will be able to create your own custom pivot tables with datasets of any size!","Introduction to pivot tables,Create a pivot table,Create a pivot table pt 2,Create a pivot table pt 3,Pivot table rows and columns,Select rows,Select columns,Rearrange rows and columns,Pivot table values,Selecting values,Selecting multiple values,Pivot table basics","Changing the calculation of values,Counting text values,Counting numerical values,Minimum and maximum values,Average and median,Calculated fields,What can be done with a calculated field,Create a calculated field,Create a calculated field pt 2,Create a calculated field pt 3,Data as percentages, drilling down, & grouping,Percentage of grand total,Percentage of rows,What does drilling down do?,Grouping rows","How a pivot table works,What does a pivot table do?,Analyze the pivot table,Analyze the pivot table pt 2,Using filters in a pivot table,Selecting filters,Filtering by using a string,Filtering on min/max values,Filtering on values,Putting all the pieces together,Building a complete pivot table,Building a complete pivot table pt 2,Building a complete pivot table pt 3","Adding or Changing Data,Changing the source data,Correct the dataset,Correcting Inconsistent Source Data,Find and correct the error in the data,Adding data,Troubleshooting and Errors,Finding Missing Data in a Dataset,Find missing data within this dataset,Best Practices and Recommendations,Types of Categories,Select the Measurements,Alternatives to Pivot Tables,Final Thoughts","Richie Cotton,Amy Peterson","Spreadsheet Fundamentals,Intermediate Spreadsheets",,
57,Support Vector Machines in R,4,13,47,"7,973",3950,"This course will introduce a powerful classifier, the support vector machine (SVM) using an intuitive, visual approach. Support Vector Machines in R will help students develop an understanding of the SVM model as a classifier and gain practical experience using R’s libsvm implementation from the e1071 package. Along the way, students will gain an intuitive understanding of important concepts, such as hard and soft margins, the kernel trick, different types of kernels, and how to tune SVM parameters. Get ready to classify data with this impressive model.","Sugar content of soft drinks,Visualizing a sugar content dataset,Identifying decision boundaries,Find the maximal margin separator,Visualize the maximal margin separator,Generating a linearly separable dataset,Generate a 2d uniformly distributed dataset.,Create a decision boundary,Introduce a margin in the dataset","Generating a radially separable dataset,Generating a 2d radially separable dataset,Visualizing the dataset,Linear SVMs on radially separable data,Linear SVM for a radially separable dataset,Average accuracy for linear SVM,The kernel trick,Visualizing transformed radially separable data,SVM with polynomial kernel,Tuning SVMs,Using `tune.svm()`,Building and visualizing the tuned model","Linear Support Vector Machines,Creating training and test datasets,Building a linear SVM classifier,Exploring the model and calculating accuracy,Visualizing Linear SVMs,Visualizing support vectors using ggplot,Visualizing decision & margin bounds using `ggplot2`,Visualizing decision & margin bounds using `plot()`,Tuning linear SVMs,Tuning a linear SVM,Visualizing decision boundaries and margins,When are soft margin classifiers useful?,Multiclass problems,A multiclass classification problem,Iris redux - a more robust accuracy.","Generating a complex dataset,Generating a complex dataset - part 1,Generating a complex dataset - part 2,Visualizing the dataset,Motivating the RBF kernel,Linear SVM for complex dataset,Quadratic SVM for complex dataset,The RBF Kernel,Polynomial SVM on a complex dataset,RBF SVM on a complex dataset,Tuning an RBF kernel SVM","Chester Ismay,Becca Robins","Machine Learning Scientist,Supervised Machine Learning,Introduction to R",,
58,Cleaning Data with PySpark,4,16,53,"15,926",4150,"Working with data is tricky - working with millions or even billions of rows is worse. Did you receive some data processing code written on a laptop with fairly pristine data? Chances are you’ve probably been put in charge of moving a basic data process from prototype to production. You may have worked with real world datasets, with missing fields, bizarre formatting, and orders of magnitude more data. Even if this is all new to you, this course helps you learn what’s needed to prepare data processes using Python with Apache Spark. You’ll learn terminology, methods, and some best practices to create a performant, maintainable, and understandable data processing platform.","Intro to data cleaning with Apache Spark,Data cleaning review,Defining a schema,Immutability and lazy processing,Immutability review,Using lazy processing,Understanding Parquet,Saving a DataFrame in Parquet format,SQL and Parquet","Caching,Caching a DataFrame,Removing a DataFrame from cache,Improve import performance,File size optimization,File import performance,Cluster configurations,Reading Spark configurations,Writing Spark configurations,Performance improvements,Normal joins,Using broadcasting on Spark joins,Comparing broadcast vs normal joins","DataFrame column operations,Filtering column content with Python,Filtering Question #1,Filtering Question #2,Modifying DataFrame columns,Conditional DataFrame column operations,when() example,When / Otherwise,User defined functions,Understanding user defined functions,Using user defined functions in Spark,Partitioning and lazy processing,Adding an ID Field,IDs with different partitions,More ID tricks","Introduction to data pipelines,Quick pipeline,Pipeline data issue,Data handling techniques,Removing commented lines,Removing invalid rows,Splitting into columns,Further parsing,Data validation,Validate rows via join,Examining invalid rows,Final analysis and delivery,Dog parsing,Per image count,Percentage dog pixels,Congratulations and next steps","Hadrien Lacroix,Hillary Green-Lerman","Big Data with PySpark,Data Engineer,Dallas Council Votes,Dallas Council Voters,Flights - 2014,Flights - 2015,Flights - 2016,Flights - 2017,Intermediate Python,Introduction to PySpark",,
59,Practicing Statistics Interview Questions in Python,4,15,46,"12,008",3700,"Are you looking to land that next job or hone your statistics interview skills to stay sharp? Get ready to master classic interview concepts ranging from conditional probabilities to A/B testing to the bias-variance tradeoff, and much more! You’ll work with a diverse collection of datasets including web-based experiment results and Australian weather data. Following the course, you’ll be able to confidently walk into your next interview and tackle any statistics questions with the help of Python!","Conditional probabilities,Setting up problems,Bayes' theorem applied,Central limit theorem,Samples from a rolled die,Simulating central limit theorem,Probability distributions,Bernoulli distribution,Binomial distribution,Normal distribution","Confidence intervals,Confidence interval by hand,Applying confidence intervals,Hypothesis testing,One tailed z-test,Two tailed t-test,Power and sample size,Effect on type II error,Calculating sample size,Visualizing the relationship,Multiple testing,Calculating error rates,Bonferroni correction","Descriptive statistics,Mean or median,Standard deviation by hand,Categorical data,Encoding techniques,Exploring laptop prices,Two or more variables,Types of relationships,Pearson correlation,Sensitivity to outliers","Regression models,Linear regression,Logistic regression,Evaluating models,Regression evaluation,Classification evaluation,Missing data and outliers,Handling null values,Identifying outliers,Bias-variance tradeoff,Test and training error,Visualizing the tradeoff,Wrapping up","Amy Peterson,Mona Khalil","Hypothesis Testing in Python,Supervised Learning with scikit-learn",,
60,Practicing Coding Interview Questions in Python,4,16,61,"14,679",5050,"Coding interviews can be challenging. You might be asked questions to test your knowledge of a programming language. On the other side, you can be given a task to solve in order to check how you think. And when you are interviewed for a data scientist position, it's likely you can be asked on the corresponding tools available for the language. In either of the cases, to get a cool position as a data scientist, you need to do a little work to perform the best. That's why it's very important to practice in order to prove your expertise! This course serves as a guide for those who just start their path to become a professional data scientist and as a refresher for those who seek for other opportunities. We'll go through fundamental as well as advanced topics that aim to prepare you for a coding interview in Python. Since it is not a normal step-by-step course, some exercises can be quite complex. But who said that interviews are easy to pass, right?","What are the main data structures in Python?,List methods,Operations on sets,Storing data in a dictionary,What are common ways to manipulate strings?,String indexing and concatenation,Operations on strings,Fixing string errors in a DataFrame,How to write regular expressions in Python?,Write a regular expression,Find the correct pattern,Splitting by a pattern","How to pass a variable number of arguments to a function?,Positional arguments of variable size,Keyword arguments of variable size,Combining argument types,What is a lambda expression?,Define lambda expressions,Converting functions to lambda expressions,Using a lambda expression as an argument,What are the functions map(), filter(), reduce()?,The map() function,The filter() function,The reduce() function,What is recursion?,Calculate the number of function calls,Calculate an average value,Approximate Pi with recursion","What are iterable objects?,enumerate(),Iterators,Traversing a DataFrame,What is a list comprehension?,Basic list comprehensions,Prime number sequence,Coprime number sequence,What is a zip object?,Combining iterable objects,Extracting tuples,Creating a DataFrame,What is a generator and how to create one?,Shift a string,Throw a dice,Generator comprehensions","What is the difference between a NumPy array and a list?,Incorrect array initialization,Accessing subarrays,Operations with NumPy arrays,How to use the .apply() method on a DataFrame?,Simple use of .apply(),Additional arguments,Functions with additional arguments,How to use the .groupby() method on a DataFrame?,Standard DataFrame methods,BMI of villains,NaN value imputation,How to visualize data in Python?,Explore feature relationships,Plot a histogram,Creating boxplots,Final thoughts","Hadrien Lacroix,Hillary Green-Lerman","Diabetes,Exams,Heroes,Retinol,Python Data Science Toolbox (Part 2),Regular Expressions in Python,Data Manipulation with pandas",,
61,Improving Query Performance in PostgreSQL,4,15,53,"5,465",4300,"Losing time on slow queries? Hesitant to share your queries with more seasoned coworkers? In this course, you will learn how to structure your PostgreSQL to run in a fraction of the time. Exploring intertwined data relating Olympic participation, country climate, and gross domestic product, you will experience firsthand how changes in filtering method and using subqueries impact query performance. You will learn the properties of a row oriented database while also seeing how Hawaii's volcanos impact air quality. Restructuring your queries with the query planner and the SQL order of operations, you will soon be dazzling your coworkers with your effortless efficiency.","All about joins,Where are all the athletes from,Using different joins to explore athletes' regions,What about the weather,Subqueries and common table expressions (cte),Filtering to freezing with a subquery,Where winter is white,Countries with subqueries or CTEs,Working with temporary tables,Canadians temp table,Analyze that temp table","Queries and tables and views, oh my,Data loading and storage,Finding the table type,Row-oriented storage and partitions,Row-oriented storage properties,Previewing a row-oriented table,Partitioning on location,Using and creating indexes,Finding the database indexes,Creating and using an index,Compare runtimes,Using column-oriented storage,Column-oriented storage properties,Using the information schema","What you write is not what SQL sees,Order of operations impact on query structure,Group by and aggregations,Count and count distinct,Filtering in the WHERE clause,OR versus IN with athletes,Data type filters,EXPLAIN the filter query plan step,Filtering while joining,Where to place a region filter,Filtering in the join, where, and select,Aggregating with different data granularities,Aggregate before joining tables,South African trends","Query lifecycle and the planner,Exploring pg_tables,Basic EXPLAIN,Index scans,EXPLAIN the WHERE,A deeper dive into EXPLAIN,EXPLAIN parameters,Aggregating and sorting populations,Joining in the query plan,Query structure and query execution,Subqueries vs. CTEs,Why the difference?,Filtering impacts,Congratulations","Becca Robins,Mona Khalil","SQL for Database Administrators,GDP,Olympic Athletes,Olympic Regions,AQI,Intermediate SQL",,
62,Analyzing IoT Data in Python,4,16,53,"3,927",4250,"Have you ever heard about Internet of Things devices? Of course, you have. Maybe you also have a Raspberry PI in your house monitoring the temperature and humidity. IoT devices are everywhere around us, collecting data about our environment. You will be analyzing Environmental data, Traffic data as well as energy counter data. Following the course, you will learn how to collect and store data from a data stream. You will prepare IoT data for analysis, analyze and visualize IoT data, before implementing a simple machine learning model to take action when certain events occur and deploy this model to a real-time data stream.","Introduction to IoT data,IoT devices,Data acquisition,Acquire data with pandas,Understand the data,Store data,Read data from file,Understanding the data,Introduction to Data streams,What is MQTT,MQTT single message,Save Datastream","Combining datasources for further analysis,Concatenate dataframes,Combine and resample,Correlation,Heatmaps,Pairplot,Outliers,Standard deviation,Autocorrelation,Seasonality and Trends,Seasonal decomposition,Seasonal decomposition II","Perform EDA,Line plots,Histogram Plot,Clean Data,Dealing with missing data,Missing data,Missing data II,Gather minimalistic incremental data,Which timestamp?,Cache Datastream,Date and Time,Prepare and visualize incremental data,Pivoting,Reformat data,Analyzing Energy counter data","Prepare data for machine learning,Train/Test split,Logistic Regression,Scaling data for machine learning,Model performance,Scaling,Scaling II,Develop machine learning pipeline,Creating Pipelines,Store Pipeline,Apply a machine learning model,Model predictions,Apply model to data stream,Wrapping up","Hadrien Lacroix,Hillary Green-Lerman","Environment,Traffic (heavy vehicles),Traffic (light vehicles),Data Manipulation with pandas",,
63,Error and Uncertainty in Spreadsheets,4,16,62,"4,707",5000,"You rely on predictions every day: you might check the weather app before choosing your outfit or peek at the traffic before starting your commute. Perhaps you are responsible for setting your organization’s strategy in the future. Do you find yourself wondering how accurate predictions are, how you can see into the future, and why the weatherman always seems to be wrong? In our Error and Uncertainty course, you’ll make some predictions yourself, learn to distinguish real differences from random noise, and explore psychological crutches we use that interfere with our rational decision making. You will uncover patterns in Seattle crime data, predict students’ final grades, prevent Nashville traffic accidents, and determine whether a bakery’s menu needs to change. Join us! We’re certain you’ll enjoy learning about error and uncertainty.","Defining error and uncertainty,Measures of central tendency,Crime time,IF functions,Extracting UNIQUE() values,Book 'em and count 'em,Averages and IF conditions,Counts with multiple criteria,Correlation,Rap sheet,Correlation preparation,A (crimes) committed relationship,Strong relationships","Outliers,Down and outlier,No filter,Addressing outliers,Sparklines,Can't start a fire without a spark(line),The max matters,What's the worst that could happen?,There are consequences,A likely story,Risky business,Risky business,Random numbers,How random,Be fruitful and multiply,Revisiting sparklines","Making the grade,We all have our (central) tendencies,Variable weights,Now weight a minute,Lying in weights,Advanced prediction strategies,What's in the FORECAST()?,Variation in predictions,Seems about right,How clear is your crystal ball?,Prediction accuracy,Absolute deviation,Average absolute deviation,Statistical significance,Significant differences,Significant differences of opinion","A half-baked idea?,Half-baked ideas,Falling on hearth times,Summary statistics,Do you know your muffins, man?,Changing prices,Bread on the rise?,Paying the price,Is change on the menu?,A recipe for change,Rain, rain, go away,Fed up,Review: Are we certain now?,Adding variation,Win some, lose some,Just t-testing,Wrap-up","Ruanne Van Der Walt,Chester Ismay,Becca Robins","Intermediate Spreadsheets,Seattle Crime Data,Student Math Scores,Risky Business Bakery,Introduction to Statistics in Spreadsheets",,
64,Unit Testing for Data Science in Python,4,17,55,"19,978",4250,"Every data science project needs unit testing. It comes with huge benefits - saving a lot of development and maintenance time, improving documentation, increasing end-user trust and reducing downtime of productive systems. As a result, unit testing has become a must-have skill in the industry, used by almost every company. This course teaches unit testing in Python using the most popular testing framework pytest. By the end of this course, you will have written a complete test suite for a data science project. In the process, you will learn to write unit tests for data preprocessors, models and visualizations, interpret test results and fix any buggy code. You will also learn advanced concepts like TDD, test organization, fixtures and mocking so that you can test your own data science projects properly.","Why unit test?,How frequently is a function tested?,Manual testing,Write a simple unit test using pytest,Your first unit test using pytest,Running unit tests,Understanding test result report,What causes a unit test to fail?,Spotting and fixing bugs,More benefits and test types,Benefits of unit testing,Unit tests as documentation","How to organize a growing set of tests?,Place test modules at the correct location,Create a test class,Mastering test execution,One command to run them all,Running test classes,Expected failures and conditional skipping,Mark a test class as expected to fail,Mark a test as conditionally skipped,Reasoning in the test result report,Continuous integration and code coverage,Build failing,What does code coverage mean?","Mastering assert statements,Write an informative test failure message,Testing float return values,Testing with multiple assert statements,Testing for exceptions instead of return values,Practice the context manager,Unit test a ValueError,The well tested function,Testing well: Boundary values,Testing well: Values triggering special logic,Testing well: Normal arguments,Test Driven Development (TDD),TDD: Tests for normal arguments,TDD: Requirement collection,TDD: Implement the function","Beyond assertion: setup and teardown,Use a fixture for a clean data file,Write a fixture for an empty data file,Fixture chaining using tmpdir,Mocking,Program a bug-free dependency,Mock a dependency,Testing models,Testing on linear data,Testing on circular data,Testing plots,Generate the baseline image,Run the tests for the plotting function,Fix the plotting function,Congratulations","Hadrien Lacroix,Hillary Green-Lerman","Data Engineer,Python Programmer,Python Programming,Intermediate Python",,
65,Functions for Manipulating Data in SQL Server,4,14,54,"15,586",4600,"In this course, you will learn how to make use of the most important functions for manipulating data provided by SQL Server. You can use these functions for processing and transforming data to get the results you want.","Welcome to this course!,Working with different types of data,Storing dates in a database,Types of character strings,Implicit conversion,Implicit conversion between data types,Data type precedence,Explicit conversion,CASTing data,CONVERTing data,Working with the correct data types","Functions for positions,Calculating the length of a string,Looking for a string within a string,Looking for a pattern within a string,Functions for string transformation,Changing to lowercase and uppercase,Using the beginning or end of a string,Extracting a substring,Replacing parts of a string,Functions manipulating groups of strings,Concatenating data,Aggregating strings,Splitting a string into pieces,Applying various string functions on data","Functions that return system date and time,Get the know the system date and time functions,Selecting parts of the system's date and time,Functions returning date and time parts,Extracting parts from a date,Generating descriptive date parts,Presenting parts of a date,Creating a date from parts,Performing arithmetic operations on dates,Arithmetic operations with dates,Modifying the value of a date,Calculating the difference between dates,Validating if an expression is a date,Changing the date format,Changing the default language,Correctly applying different date functions","Aggregate arithmetic functions,Learning how to count and add,MINimizing and MAXimizing some results,Analytic functions,Accessing values from the next row,Accessing values from the previous row,Getting the first and last value,Mathematical functions,Extracting the sign and the absolute value,Rounding numbers,Working with exponential functions,Manipulating numeric data,Wrapping things up","Sara Billen,Mona Khalil,Marianna Lamnina","SQL Server Developer,SQL Server Fundamentals,Voters dataset,Ratings dataset,Time Series Analysis in SQL Server",,
66,Data Processing in Shell,4,13,46,"13,220",3550,"We live in a busy world with tight deadlines. As a result, we fall back on what is familiar and easy, favoring GUI interfaces like Anaconda and RStudio. However, taking the time to learn data analysis on the command line is a great long-term investment because it makes us stronger and more productive data people.

In this course, we will take a practical approach to learn simple, powerful, and data-specific command-line skills. Using publicly available Spotify datasets, we will learn how to download, process, clean, and transform data, all via the command line. We will also learn advanced techniques such as command-line based SQL database operations. Finally, we will combine the powers of command line and Python to build a data pipeline for automating a predictive model.","Downloading data using curl,Using curl documentation,Downloading single file using curl,Downloading multiple files using curl,Downloading data using Wget,Installing Wget,Downloading single file using wget,Advanced downloading using Wget,Setting constraints for multiple file downloads,Creating wait time using Wget,Data downloading with Wget and curl","Pulling data from database,Using sql2csv documentation,Understand sql2csv connectors,Practice pulling data from database,Manipulating data using SQL syntax,Applying SQL to a local CSV file,Cleaner scripting via shell variables,Joining local CSV files using SQL,Pushing data back to database,Practice pushing data back to database,Database and SQL with csvkit","Getting started with csvkit,Installation and documentation for csvkit,Converting and previewing data with csvkit,File conversion and summary statistics with csvkit,Filtering data using csvkit,Printing column headers with csvkit,Filtering data by column with csvkit,Filtering data by row with csvkit,Stacking data and chaining commands with csvkit,Stacking files with csvkit,Chaining commands using operators,Data processing with csvkit","Python on the command line,Finding Python version on the command line,Executing Python script on the command line,Python package installation with pip,Understanding pip's capabilities,Installing Python dependencies,Running a Python model,Data job automation with cron,Understanding cron scheduling syntax,Scheduling a job with crontab,Model production on the command line,Course recap","Adrián Soto,Hillary Green-Lerman","Data Engineer,Spotify Songs Popularity Ranking,Spotify Song Attributes,Introduction to Shell,Intermediate Python,Introduction to SQL",,
67,Image Processing in Python,4,16,54,"29,344",4450,"Images are everywhere! We live in a time where images contain lots of information, which is sometimes difficult to obtain. This is why image pre-processing has become a highly valuable skill, applicable in many use cases. In this course, you will learn to process, transform, and manipulate images at your will, even when they come in thousands. You will also learn to restore damaged images, perform noise reduction, smart-resize images, count the number of dots on a dice, apply facial detection, and much more, using scikit-image. After completing this course, you will be able to apply your knowledge to different domains such as machine learning and artificial intelligence, machine and robotic vision, space and medical image analysis, retailing, and many more. Take the step and dive into the wonderful world that is computer vision!","Make images come alive with scikit-image,Is this gray or full of color?,RGB to grayscale,NumPy for images,Flipping out,Histograms,Getting started with thresholding,Apply global thresholding,When the background isn't that obvious,Trying other methods,Apply thresholding","Image restoration,Let's restore a damaged image,Removing logos,Noise,Let's make some noise!,Reducing noise,Reducing noise while preserving edges,Superpixels & segmentation,Number of pixels,Superpixel segmentation,Finding contours,Contouring shapes,Find contours of an image that is not binary,Count the dots in a dice's image","Jump into filtering,Edge detection,Blurring to reduce noise,Contrast enhancement,What's the contrast of this image?,Medical images,Aerial image,Let's add some impact and contrast,Transformations,Aliasing, rotating and rescaling,Enlarging images,Proportionally resizing,Morphology,Handwritten letters,Improving thresholded image","Finding the edges with Canny,Edges,Less edgy,Right around the corner,Perspective,Less corners,Face detection,Is someone there?,Multiple faces,Segmentation and face detection,Real-world applications,Privacy protection,Help Sally restore her graduation photo,Amazing work!","Sara Billen,Hillary Green-Lerman","Image Processing,Machine Learning Scientist,Images,Python Data Science Toolbox (Part 2)",,
68,Hierarchical and Recursive Queries in SQL Server,4,13,47,"8,074",3800,"Do you want to query complex data structures in an iterative way? Do you have access to hierarchical data structures that need to be queried? This course will teach you the tools required to solve these questions. You will learn how to write recursive queries and query hierarchical data structures. To do this, you will use Common Table Expressions (CTE) and the recursion principle on a wide variety of datasets. You will, for example, dig into a flight plan dataset and learn how to find the best and cheapest connection between two airports. After completing this course, you will understand the principle of recursion, and be able to identify and create hierarchical data models.","Recap of Common Table Expressions (CTE),A CTE is ... Find the wrong fact!,A CTE for IT-positions,A CTE for high-paid IT-positions,Introduction to recursion,Facts about recursion.,Calculate the factorial of 5,How to query the factorial of 6 recursively,Solve recursive maths problems,Counting numbers recursively,Calculate the sum of potencies","How to work with tables,Creating a table,Inserting and updating a table,Deleting data and dropping table,Changing a table structure,Working with relational data models,Defining primary and foreign keys,Inserting data to person and order history,Getting the number of orders & total costs,Working with hierarchical data models,Creating a hierarchical data model,Networked and hierarchical models,Creating a networked data model","Introduction to recursive CTE,Right or wrong?,Create the alphabet recursively,Create a time series of a year,Working with recursive queries,Who is your manager?,Get the hierarchy position,Which  supervisor do I have?,Analyze the family tree,Get the number of generations?,Get all possible parents in one field?","Travel planning for flight data,Get the anchor & recursive member,Get all possible airports,All flight routes from Vienna,How to assemble a car?,Create the parts list,Create a car's bill of material,Build up a BMW?,Modeling a power grid,Create a power grid,Get power lines to maintain,Summary of the course","Alex Yarosh,Sara Billen,Mona Khalil","Power grid data,Employee data,Department data,Salary data,Bill of materials products data,Bill of materials data,Flights data,Functions for Manipulating Data in SQL Server",,
69,ARIMA Models in Python,4,15,57,"12,882",4850,"Have you ever tried to predict the future? What lies ahead is a mystery which is usually only solved by waiting. In this course, you will stop waiting and learn to use the powerful ARIMA class models to forecast the future. You will learn how to use the statsmodels package to analyze time series, to build tailored models, and to forecast under uncertainty. How will the stock market move in the next 24 hours? How will the levels of CO2 change in the next decade? How many earthquakes will there be next year? You will learn to solve all these problems and more.","Intro to time series and stationarity,Exploration,Train-test splits,Is it stationary,Making time series stationary,Augmented Dicky-Fuller,Taking the difference,Other tranforms,Intro to AR, MA and ARMA models,Model order,Generating ARMA data,Fitting Prelude","Intro to ACF and PACF,AR or MA,Order of earthquakes,Intro to AIC and BIC,Searching over model order,Choosing order with AIC and BIC,AIC and BIC vs ACF and PACF,Model diagnostics,Mean absolute error,Diagnostic summary statistics,Plot diagnostics,Box-Jenkins method,Identification,Identification II,Estimation,Diagnostics","Fitting time series models,Fitting AR and MA models,Fitting an ARMA model,Fitting an ARMAX model,Forecasting,Generating one-step-ahead predictions,Plotting one-step-ahead predictions,Generating dynamic forecasts,Plotting dynamic forecasts,Intro to ARIMA models,Differencing and fitting ARMA,Unrolling ARMA forecast,Fitting an ARIMA model,Choosing ARIMA model","Seasonal time series,Seasonal decompose,Seasonal ACF and PACF,SARIMA models,Fitting SARIMA models,Choosing SARIMA order,SARIMA vs ARIMA forecasts,Automation and saving,Automated model selection,Saving and updating models,SARIMA and Box-Jenkins,Multiplicative vs additive seasonality,SARIMA model diagnostics,SARIMA forecast,Congratulations!","Chester Ismay,Adel Nehme","Time Series,US Monthly Candy Production,Monthly Record of CO2,Amazon Daily Closing Stock Price,Monthly Milk Production,Yearly Earthquakes,Supervised Learning with scikit-learn",,
70,Case Study: Analyzing Customer Churn in Tableau,3,4,25,"4,020",2200,"Are you ready to apply your Tableau skills to a real-world dataset? For subscription-based businesses, reducing customer churn is a top priority. In this Tableau case study, you'll investigate a dataset from an example telecom company called Databel and analyze their churn rates. Analyzing churn doesn’t just mean knowing what the churn rate is: it’s also about figuring out why customers are churning at the rate they are, and how to reduce churn. You'll answer these questions by creating calculated fields and various visualizations in Tableau, such as dual-axis graphs and scatter plots. You'll make your graphs dynamic by using filters and parameters, and combine everything into a story to share your insights.","Analyzing customer churn in Tableau,Tableau analysis process,Data check time,Calculating churn,Investigating churn reasons,Digging deeper in churn categories,Use maps to your advantage","Creating a cohesive story,Dashboarding best practices,Overview dashboard,Age brackets & groups,Payment method and contract type,International and data plan,Story time!,Wrap-up,Saving your work","Zooming out,Analyzing demographics,Age bins,Inspecting groups,Parameters,Unlimited plan,International calls,Advice to Databel,Contract type",,Sara Billen,"Tableau Fundamentals,Metadata sheet,Databel - Data,Workbooks,Introduction to Tableau,Analyzing Data in Tableau,Creating Dashboards in Tableau",,
71,Intermediate Regression with statsmodels in Python,4,14,52,"3,426",4300,"Linear regression and logistic regression are the two most widely used statistical models and act like master keys, unlocking the secrets hidden in datasets. In this course, you’ll build on the skills you gained in ""Introduction to Regression in Python with statsmodels"", as you learn about linear and logistic regression with multiple explanatory variables. Through hands-on exercises, you’ll explore the relationships between variables in real-world datasets, Taiwan house prices and customer churn modeling, and more. By the end of this course, you’ll know how to include multiple explanatory variables in a model, discover how interactions between variables affect predictions, and understand how linear and logistic regression work.","Parallel slopes linear regression,Fitting a parallel slopes linear regression,Interpreting parallel slopes coefficients,Visualizing each explanatory variable,Visualizing parallel slopes,Predicting parallel slopes,Predicting with a parallel slopes model,Visualizing parallel slopes model predictions,Manually calculating predictions,Assessing model performance,Comparing coefficients of determination,Comparing residual standard error","Two numeric explanatory variables,Interactive 3D scatter plot,Visualizing three numeric variables,Modeling two numeric explanatory variables,Visualizing two numeric explanatory variables,Including an interaction,More than two explanatory variables,Visualizing many variables,Different levels of interaction,Predicting again,How linear regression works,The sum of squares,Linear regression algorithm","Models for each category,One model per category,Predicting multiple models,Visualizing multiple models,Assessing model performance,One model with an interaction,Specifying an interaction,Interactions with understandable coeffs,Making predictions with interactions,Predicting with interactions,Manually calculating predictions with interactions,Simpson's Paradox,Modeling eBay auctions,Modeling each auction type","Multiple logistic regression,Logistic regression with two explanatory variables,Logistic regression prediction,Visualizing multiple explanatory variables,Confusion matrix,The logistic distribution,Cumulative distribution function,Inverse cumulative distribution function,Logistic distribution parameters,How logistic regression works,Likelihood & log-likelihood,Logistic regression algorithm,Congratulations!","Richie Cotton,Maggie Matsui,Amy Peterson","Statistics Fundamentals,Ad conversion,Customer churn,Taiwan real estate,Fish measurement data,eBay auctions,Introduction to Regression with statsmodels in Python",,
72,Introduction to Regression with statsmodels in Python,4,14,53,"7,410",4150,"Linear regression and logistic regression are two of the most widely used statistical models. They act like master keys, unlocking the secrets hidden in your data. In this course, you’ll gain the skills you need to fit simple linear and logistic regressions. Through hands-on exercises, you’ll explore the relationships between variables in real-world datasets, including motor insurance claims, Taiwan house prices, fish sizes, and more. By the end of this course, you’ll know how to make predictions from your data, quantify model performance, and diagnose problems with model fit.","A tale of two variables,Which one is the response variable?,Visualizing two numeric variables,Fitting a linear regression,Estimate the intercept,Estimate the slope,Linear regression with ols(),Categorical explanatory variables,Visualizing numeric vs. categorical,Calculating means by category,Linear regression with a categorical explanatory variable","Quantifying model fit,Coefficient of determination,Residual standard error,Visualizing model fit,Residuals vs. fitted values,Q-Q plot of residuals,Scale-location,Drawing diagnostic plots,Outliers, leverage, and influence,Leverage,Influence,Extracting leverage and influence","Making predictions,Predicting house prices,Visualizing predictions,The limits of prediction,Working with model objects,Extracting model elements,Manually predicting house prices,Regression to the mean,Home run!,Plotting consecutive portfolio returns,Modeling consecutive returns,Transforming variables,Transforming the explanatory variable,Transforming the response variable too,Back transformation","Why you need logistic regression,Exploring the explanatory variables,Visualizing linear and logistic models,Logistic regression with logit(),Predictions and odds ratios,Probabilities,Most likely outcome,Odds ratio,Log odds ratio,Quantifying logistic regression fit,Calculating the confusion matrix,Drawing a mosaic plot of the confusion matrix,Accuracy, sensitivity, specificity,Measuring logistic model performance,Congratulations","Richie Cotton,Maggie Matsui,Amy Peterson","Data Scientist,Statistics Fundamentals,Customer churn data,Taiwan real estate data,Ad conversion data,S&P 500 data,Fish measurement data,Introduction to Data Visualization with Seaborn,Introduction to Statistics in Python",,
73,Bond Valuation and Analysis in Python,4,14,49,,4100,"The world’s bond market has a value of around 120 trillion dollars; it plays a key role in helping both governments and businesses raise capital and is an essential part of most investment portfolios. In this course, you’ll gain the essential skills needed to work in the financial, insurance, and accounting industries, including understanding and analyzing markets. Through hands-on activities, you’ll discover how bonds work, how to price them, and how to assess some of their risks using numpy and numpy-financial packages.","Simple interest & compound interest,Calculating simple interest,Calculating compound interest,Future value & compounding frequencies,Calculating future value,Calculating compounding frequencies,More financial functions,Calculating the number of periods,Calculating the payment amount,Calculating the required interest rate,Solving real-world problems","Duration,Interest rate sensitivity of two bonds,Zero coupon and coupon bond duration,Factors affecting duration,The bond with the highest duration,Comparing the duration of two bonds directly,Using the steepness of the price/yield line,Plotting duration vs. the factor,Dollar duration & bond price prediction,Percent duration and dollar duration,Creating a duration neutral portfolio,Predicting price impacts from duration","Present value & zero coupon bonds,Calculating present value,Pricing zero coupon bonds,Coupon paying bonds,Impact of bond yields on price,Impact of coupons on price,Bond prices vs. bond yields,Discount vs. par vs. premium,Plotting bond prices against yields,Calculating bond yields,Comparing zero coupon bond yields,Comparing coupon bond yields","Convexity,Predicted vs. actual prices I,Predicted vs. actual prices II,Finding the convexity of a bond,Factors affecting convexity,The bond with the highest convexity,Comparing the convexity of two bonds directly,Using the curvature of the price/yield line,Plotting convexity vs. the factor,Dollar convexity and bond price prediction,Dollar convexity,Convexity adjustment,Combining duration and convexity,Congratulations!",Hadrien Lacroix,Python Data Science Toolbox (Part 1),,
74,Data-Driven Decision Making for Business,2,14,46,"5,991",2600,"Data literacy is an essential skill for every role within an organization—not just data scientists and analysts. As companies collect more data than ever before, it’s critical that everyone can read and analyze that data efficiently. In this course, you'll learn the basics of data-driven decision-making and get to apply these skills to three real-life examples from the world of finance, marketing, and operations. You’ll also discover how to uncover new insights and opportunities by applying supply and demand, cost and benefit, and risk and rewards frameworks—gaining practical skills to help you thrive in the new data-driven world.","Welcome!,Structuring a data-driven problem,Probing an analysis,Analysis as a journey,Analytical maturity,Common pitfalls,Applying the methods and  objectives,Identify the method,Identify the objective,Classifying the rest of the course","Traditional investing: risk vs reward,What good is the risk-free rate?,Use a CAPM-like chart to choose your investment,Other traditional asset investing,Calculate gross rental income,Review the best investment by cap rate,Select the best investment opportunity,Non-traditional investing: Magic the Gathering,Defining a simulation,Find the maximum price to pay,Calculate the expected profit","Marketing examples,Finding the best model,Focus on growth,Focus on efficient acquisition,Focus on profitability,Ad arbitrage,ID arbitrage examples,Identify the arbitrage opportunity,Calculate the profit,Data-driven product forecasting,Choose the right P, Q & M analogs,Diffusion modeling dashboard","Total addressable market,TAM: top-down market sizing,TAM: bottom up market sizing,Demand curve: meals and drinks,Fast (& furious) food demand,Scrutinizing a forecast,Supply curve: servers for your restaurant,Reviewing the Erlang-C,Make a data driven scheduling decision!,Customer input to improve your operation,Data to focus effort and training (1),Data to focus effort and training (2),Wrap up","Hadrien Lacroix,Sara Billen","Data Skills for Business,Machine Learning for Business",,
75,Streaming Concepts,2,16,47,,3750,"Streaming is a huge aspect of the data world right now and is being used by nearly every industry from manufacturing to healthcare. Would you like to learn more about the general concepts behind data pipelines and how the processes work?

This course provides a general introduction to streaming concepts including batching, queuing, and stream processing along with where they fit into data processing frameworks. It covers real-world examples of how streaming is implemented in production. It is designed as a general introduction to these concepts and does not require an extensive background in data processing.","Intro to batch processing,Batch characteristics,Batch ordering,Scaling batch processing,On the scale,Horizontally opposed,Batch issues,Batch problems,Batch scenarios","Intro to real-time streaming,Real-time?,Is it real this time?,Vertically scaling streaming systems,Scaling reasons,To vertically scale...?,Horizontally scaling streaming systems,Upscaled out,SLA guarantees,Streaming roadblocks,Streaming attributes,Issue types,Streaming challenges","Intro to event-based computing,In the event of...,Welcome to the event!,Queuing,Queue characteristics,To queue or not to queue,Single system data streaming,Log stream order,Log options,Batching vs streaming,Batch, queue, or stream?,Log stream processor","Popular streaming systems,Streaming truths,Crossing the streams...,Real-world use case: streaming music service,Message components,Answer me this...,Real-world use case: sensor data,Great order of the SLAs,Sensor scaling considerations,Real-world use case: vaccination clinic,Vaccination clinic - classify areas,A new problem...,Congratulations!","Hadrien Lacroix,Kelsey McNeillie",Data Engineering for Everyone,,
76,AWS Cloud Concepts,2,16,49,"3,320",4100,"Over 50% of all corporate data is stored in the cloud. As cloud computing becomes more and more ubiquitous, mastering at least one cloud platform is now crucial for data practitioners. In this course, you’ll get to grips with AWS—the market-leading cloud provider. You’ll also learn about its main core services, best practices to design AWS applications, and the benefits of using AWS for businesses.

This course is a great starting point to prepare you for the AWS Cloud Practitioner Certification.","Why learn about AWS as a data practitioner?,The benefits of Cloud Computing for data practitioners,Why choose AWS as a cloud provider?,AWS cloud offer and history,AWS characteristics,AWS history,Getting started with AWS,Low-level vs. high-level access means,Access methods vs. use cases","AWS categories and compute services,The benefits of compute services,Help MeetFoodies use AWS compute services,Storage and database,The benefits of storage and database services,Help MeetFoodies use AWS storage and database services,Networking and content delivery,The benefits of networking and content delivery services,Help MeetFoodies use AWS networking and content delivery services,Management, security and identity,The benefits of management, security and identity services,Help MeetFoodies use AWS management, security and identity services,Help MeetFoodies choose the right AWS services","Total cost of ownership (TCO),Cost categories,AWS cloud value framework and TCO,Staff productivity,Staff areas of focus,Staff productivity measuring and improving,Operational resilience,Operational resilience domains,Operational resilience measuring and improving,Business agility,Business agility characteristics,Business agility measuring and improving,Convince MeetFoodies to migrate to AWS","What is the Well-Architected Framework and why does it matter?,The AWS Well-Architected Framework,Help MeetFoodies define the AWS Well-Architected Framework pillars,Operational excellence and sustainability,Operational excellence and sustainability best practices,MeetFoodies, operational excellence and sustainability,Security and reliability,Security and reliability best practices,MeetFoodies, security and reliability,Performance efficiency and cost optimization,Performance efficiency and cost optimization best practices,MeetFoodies, performance efficiency and cost optimization,Help MeetFoodies audit their AWS architecture,Wrap-up","Hadrien Lacroix,Kelsey McNeillie","Cloud Computing for Everyone,Data Engineering for Everyone",,
77,Data Modeling in Power BI,3,9,26,"10,032",2050,"Proper data modeling is the foundation of data analysis and creating reports in Power BI. This course lets you explore a toolbox of data cleaning, shaping, and loading techniques, which you can apply to your data. You'll get to know how to choose between Power Query and Power BI, and discover the foundations of data modeling by going into star and snowflake schemas. You'll apply all of this to real-world datasets issued by the United States Census Bureau.","Data modeling and table properties,Power Query vs. Power BI,Load and transform data,Loading a CSV,Rounding, replacement, and sorting,Data categorization and visibility,Working with string columns","Dimensional modeling,Facts vs. dimensions,Creating a star schema,Splitting data into facts and dimensions,Load a new dimension,Create another dimension","Shaping tables,Power Query vs. Power BI again,Merging and appending queries,Breaking a file into multiple tables,Appending files,Column extraction","Star and snowflake schemas,Snowflake vs. star schema,Evaluating performance,Star schemas,Snowflake schemas,The performance analyzer,Congratulations!","Kevin Feasel,Lis Sulmont,Carl Rosseel,Nina Spreitzer","Data Analyst,Power BI Fundamentals,DataCamp vs. Local Experience,Exercises and Datasets,Introduction to Power BI",,
78,Programming with dplyr,4,15,47,,3850,"The tidyverse includes a tremendous set of packages that make working with data simple and fast. But have you ever tried to put dplyr functions inside functions and been stuck with strange errors or unexpected results? Those errors were likely due to tidy evaluation, which requires a little extra work to handle. In Programming with dplyr, you’ll be equipped with strategies for solving these errors via the rlang package. You’ll also learn other techniques for programming with dplyr using data from the World Bank and International Monetary Fund to analyze worldwide trends throughout. You’ll be a tidyverse function writing ninja by the end of the course!","Be fruitful and dplyr,select() vs. filter(),A great selection,Mutation necessary,Lending a helper hand,Don't get me started,See how that ended up,Finding our perfect match,Contain-ted love,Looking for matches","Join together for fun,Join with me,Further investigations,Lines that intersect are without parallel,Intersect vs. inner join,Speeding through the intersection,Deliver the state of the union,Save the union,Sign up for your local union, all,A little too excepting,Checking for equal sets,Checking for differences","Providing relocation assistance,Moving with select() and everything(),Rearranging with select() and last_col(),Shifting positions with relocate(),That has crossed the line,Mutate across multiple columns,Summarize across multiple variables,Combining count() with across(),Animal crossing: new rowwise's,across() vs. c_across(),Aggregations with rowwise(),One for any, one for all","What is your major mal-function?,Unemployment rates by region,Median unemployment rates by group,Bang-bang!!,Matching rlang operators,Bang bang into the room,Rlang-ing in your rocking chair,You are the walrus,Analyze the region results,A great ggplot twist,Plotting and scheming,The plot title thickens,Congratulations!","Maggie Matsui,James Chapman,Amy Peterson","International Monetary Fund (IMF),World Bank,Joining Data with dplyr,Introduction to Writing Functions in R",,
79,Marketing Analytics for Business,2,15,45,"4,874",3300,"In this no-code course, you’ll learn about the role of a Marketing Analyst and how they leverage data to better understand their customers and help companies grow. Through hands-on exercises, you’ll learn how to answer the big questions like ""did my campaign increase sales six months after launch?"" You’ll also work with real-world data to perform essential marketing analysis, including building customer segments, market response models, calculating customer lifetime value (LTV), and much more.","Marketing lever fundamentals,Campaign attributes,Channels and tactics,Lever hierarchy,Marketing roles,Internal partners,External partners,Marketing business questions,Marketing roles and business questions,Marketing roles and KPIs","Text analysis,Branded and non-branded keywords,Paid search analysis,Sentiment analysis,Social media comments,NLP or manual sentiment analysis,Audience segmentation,Segmentation data options,Cluster analysis attributes,Integrated campaigns,Campaign stages,Integrated campaign planning","Marketing data sources,Internal vs. advertiser data,Channel granularity,Audience targeting insights,Privacy laws,GDPR assessment,Cookie types,Indirect impact of marketing,Direct vs. Indirect channels,Blurred lines of channel impact","KPIs and metrics,Marketing funnel,KPI vs. supporting metric,Marketing forecasting,Forecast requirements,Forecasting process,Attribution modeling,LTA vs. MTA,Identify attribution model,Revenue and cost modeling,Spend and revenue considerations,CAC and LTV calculations,Wrap up","Maggie Matsui,James Chapman,Amy Peterson","Data Skills for Business,Data Science for Business",,
80,NoSQL Concepts,2,17,54,"4,151",4550,"Confused about NoSQL and how it differs from SQL? You've come to the right place! In this conceptual course (no coding required), you’ll be introduced tolearn the four major NoSQL databases, including Key-Value, Document, Column-Family, and Graph. You’ll learn about four popular NoSQL engines—including Redis, MongoDB, Apache Cassandra, and Neo4j—and when to apply them to achieve a specific business requirement. You’ll follow the data escapades of a fictional social network and learn how NoSQL can help them handle and extract insights from unstructured data like social posts. Lastly, you’ll study real use cases of when NoSQL databases were used—giving you the knowledge you need to effectively store data in any situation.","Welcome!,NoSQL vs relational databases,Keys and values,Advantages and limitations of key-value databases,Classifying advantages and limitations,True or false?,When to use key-value databases,Appropriate use cases,Suitable or not suitable,Redis case study,Redis features,Redis and Editoo","What is a column family database?,Identifying column family components,True or false?,Identifying the database,Advantages and limitations of column family databases,Classifying advantages and limitations,Examining the advantages and limitations,When to use column family databases,Appropriate use cases for column family databases,Suitable or not suitable,Apache Cassandra case study,Cassandra features,Bigmate and Cassandra","What is a document database?,Documents or collections?,True or false?,Key-value or document database?,Advantages and limitations of document databases,Classifying advantages and limitations,Examining the advantages and limitations,When to use document databases,Appropriate use cases for document databases,Suitable or not suitable,MongoDB case study,MongoDB features,MongoDB products,Shutterfly and MongoDB","What is a graph database?,Identifying graph database components,True or false?,Identifying the database,Advantages and limitations of graph databases,Classifying advantages and limitations,Examining the advantages and limitations,When to use graph databases,Appropriate use cases for graph databases,Suitable or not suitable,Neo4j case study,Neo4j features,Neo4j graph platform,Gousto and Neo4j,Congratulations!",Hadrien Lacroix,Database Design,,
81,Building Dashboards with Dash and Plotly,4,15,47,"4,059",3900,You don’t need expensive vendor software to create insight-rich dashboards—you can do this using Plotly and Dash. Come on a journey and learn how to turn your Plotly visualizations into interactive dashboards using global e-commerce data. You’ll learn the basics of web applications and discover how to structure and style your dashboards using HTML and CSS—building a portfolio of dashboards you can adapt to your data and projects. Are you ready to bring your plots to life?,"Plotly graphs and figures,Line graph of sales by country,Bar graph of sales by country,From Plotly to Dash,The core Dash app code,Sales in a Dash app,Positioning Dash components,Combining HTML and Dash,A draft sales dashboard","Callbacks in Dash,A dropdown for sales by country,Fixing a broken dashboard,Interactive components,Date picker for sales data,A date picker callback,Slider for sales data,Reusable Dash components,Re-using Dash components,DRY-styling Dash components,User inputs in Dash components,Searching product descriptions,Analyzing top customer locations","HTML in Dash,Adding logos and notes,Adding an HTML list to Dash,CSS Basics in Dash,Styling a Dash app with CSS,Switching to Darkmode,Advanced CSS in Dash,Practicing placement,A refined sales dashboard,Controlling object layout","Between-element interactivity,Generate key stats on hover,Hover to update another plot,Click to update another plot,Chained callbacks,Conditional dropdown options,Extending the chain,Dash Data Table introduction,Interactive key stats table,Paginating a key stats table,Enhancing the sales dashboard,Dash Data Table interactivity,Styling a key stats table,Interactive sales dashboard tables,Wrap-up video","Maggie Matsui,James Chapman","2011 Global e-commerce data,Introduction to Data Visualization with Plotly in Python,Data Manipulation with pandas",,
82,Statistical Techniques in Tableau,4,18,52,"3,978",4300,"Take your reporting skills to the next level with Tableau’s built-in statistical functions. Using drag and drop analytics, you'll learn how to perform univariate and bivariate exploratory data analysis and create regression models to spot hidden trends. Working with real-world datasets, you’ll also use machine learning techniques such as clustering and forecasting. It’s time to dig deeper into your data!","Welcome to the course!,Interpreting histograms,EDA in Tableau: tables and bar plots,Superstore data: table,Superstore data: bar plot,EDA in Tableau: histograms,Superstore data: histogram promo,Superstore data: histogram bin size,Box plots and distribution characteristics,Which visualization should you choose?,EDA in Tableau: box plots,Superstore data: boxplot,Superstore data: compare box plots","The relationship of two variables,Guess the correlation,Tableau: trend lines,Dinosaurs: what to predict?,Dinosaurs: how to disaggregate?,Dinosaurs: adding a trend line,Assessing a trend line,Model predictions: rigorous or randomness?,Tableau: describing trend models,Dinosaurs: model summary,Dinosaurs: model by clade,Dinosaurs: confidence intervals","Measures of spread,Statistics: true of false,Tableau: summary cards and spread,Superstore data: summary card,Superstore data: standard deviation,Bonus question: sample vs population,Superstore data: variance,Standard error and confidence intervals,A bunch of statistics and estimates,Tableau: adding lines and distribution bands,Superstore data: high workload,Superstore data: confidence intervals,Superstore data: mean or median?","Forecasting,Forecasting: true or false?,Tableau: forecasting,T-shirt sales: first forecast,T-shirt sales: aggregating,T-shirt sales: forecast adjustments,Clustering,To cluster or not to cluster?,Tableau: clustering,World indicators: clustering countries,World indicators: describing clusters,World indicators: mapping the clusters,World indicators: cluster results,Congratulations!","Hadrien Lacroix,Sara Billen","Workbooks and datasources,Introduction to Tableau",,
83,Machine Learning with Tree-Based Models in R,4,16,58,"3,046",4850,"Tree-based machine learning models can reveal complex non-linear relationships in data and often dominate machine learning competitions. In this course, you'll use the tidymodels package to explore and build different tree-based models—from simple decision trees to complex random forests. You’ll also learn to use boosted trees, a powerful machine learning technique that uses ensemble learning to build high-performing predictive models. Along the way, you'll work with health and credit risk data to predict the incidence of diabetes and customer churn.","Welcome to the course!,Why tree-based methods?,Specify that tree,Train that model,How to grow your tree,Train/test split,Avoiding class imbalances,From zero to hero,Predict and evaluate,Make predictions,Crack the matrix,Are you predicting correctly?","Tuning hyperparameters,Generate a tuning grid,Tune along the grid,Pick the winner,More model measures,Calculate specificity,Draw the ROC curve,Area under the ROC curve,Bagged trees,Create bagged trees,In-sample ROC and AUC,Check for overfitting,Random forest,Bagged trees vs. random forest,Variable importance","Continuous outcomes,Train a regression tree,Predict new values,Inspect model output,Performance metrics for regression trees,In-sample performance,Out-of-sample performance,Bigger mistakes, bigger penalty,Cross-validation,Create the folds,Fit the folds,Evaluate the folds,Bias-variance tradeoff,Call things by their names,Adjust model complexity,In-sample and out-of-sample performance","Introduction to boosting,Bagging vs. boosting,Specify a boosted ensemble,Gradient boosting,Train a boosted ensemble,Evaluate the ensemble,Compare to a single classifier,Optimize the boosted ensemble,Tuning preparation,The actual tuning,Finalize the model,Model comparison,Compare AUC,Plot ROC curves,Wrap-up","Maggie Matsui,James Chapman,Justin Saddlemyer","Machine Learning Fundamentals,Machine Learning Scientist,Supervised Machine Learning,Chocolate ratings,Diabetes risk,Bank customer churn,Modeling with tidymodels in R",,
84,Hypothesis Testing in R,4,16,53,"6,943",4000,"Hypothesis testing lets you ask questions about your datasets and answer them in a statistically rigorous way. In this course you'll learn how and when to use common tests like t-tests, proportion tests, and chi-square tests. You'll gain a deep understanding of how they work, and the assumptions that underlie them. You'll also learn how different hypothesis tests are related using the ""There is only one test"" framework, and use non-parametric tests that let you side-step the requirements of traditional hypothesis tests. Throughout the course, you'll explore a Stack Overflow user survey, and a dataset of late shipments of medical supplies.","To the lab for testing,Uses of A/B testing,Calculating the sample mean,Calculating a z-score,A tail of two z's,Criminal trials and hypothesis tests,Left tail, right tail, two tails,Calculating p-values,Statistically significant other,Decisions from p-values,Calculating confidence intervals,Type I and type II errors","Difference strokes for proportions, folks,t for proportions?,Test for single proportions,A sense of proportion,Test for two proportions,prop_test() for two samples,Declaration of independence,The chi-square distribution,How many tails for chi-square tests?,Chi-square test of independence,Does this dress make my fit look good?,Visualizing goodness of fit,Chi-square test of goodness of fit","Is this some kind of test statistic?,Two sample mean test statistic,Hypothesis testing workflow,Time for t,Why is t needed?,The t-distribution,From t to p,Pairing is caring,Is pairing needed?,Visualizing the difference,Using t.test(),P-hacked to pieces,Visualizing many categories,ANOVA,Pairwise t-tests","What do you assume?,Common assumptions of hypothesis tests,Testing sample size,X-ray specs: don't believe the hyp,There is only one test,Specifying & hypothesizing,The generation game,Generating & calculating,Observed statistic and p-value,Look ma! No parameters!,Simulation-based t-test,Rank sum tests,Congratulations",Dr. Chester Ismay,"Data Analyst,Statistician,Statistics Fundamentals,Late Shipments,Late shipments Bootstrap Distribution,Democratic Presidential Candidates by County,StackOverflow Survey,Sampling in R",,
85,Sampling in R,4,15,51,"5,461",4000,"Sampling is a cornerstone of inference statistics and hypothesis testing. It's tremendously important in survey analysis and experimental design. This course explains when and why sampling is important, teaches you how to perform common types of sampling, from simple random sampling to more complex methods like stratified and cluster sampling. Later, the course covers estimating population statistics, and quantifying uncertainty in your estimates by generating sampling distributions and bootstrap distributions. Throughout the course, you'll explore real-world datasets on coffee ratings, Spotify songs, and employee attrition.","Living the sample life,Reasons for sampling,Simple sampling with dplyr,Simple sampling with base-R,A little too convenient,Are findings from the sample generalizable?,Are the findings generalizable? 2,How does Sue do sampling?,Generating random numbers,Understanding random seeds","An ample sample,Calculating relative errors,Relative error vs. sample size,Baby back dist-rib-ution,Replicating samples,Replication parameters,Be our guess, put our samples to the test,Exact sampling distribution,Approximate sampling distribution,Exact vs. approximate,Err on the side of Gaussian,Population & sampling distribution means,Population and sampling distribution variation","Simple is as simple does,Simple random sampling,Systematic sampling,Is systematic sampling OK?,Can't get no stratisfaction,Which sampling method?,Proportional stratified sampling,Equal counts stratified sampling,Weighted sampling,What a cluster ...,Benefits of clustering,Cluster sampling,Straight to the point (estimate),3 kinds of sampling,Summary statistics on different kinds of sample","This bears a striking resample-lance,Principles of bootstrapping,With or without replacement,Generating a bootstrap distribution,A breath of fresh error,Bootstrap statistics and population statistics,Sampling distribution vs. bootstrap distribution,Compare sampling and bootstrap means,Compare sampling and bootstrap standard deviations,Venus infers,Confidence interval interpretation,Calculating confidence intervals,Congratulations",Dr. Chester Ismay,"Statistician,Statistics Fundamentals,Coffee ratings,Spotify song attributes,Employee attrition,Introduction to Statistics in R",,
86,Intermediate Regression in R,4,14,50,"10,907",4150,"Linear regression and logistic regression are the two most widely used statistical models and act like master keys, unlocking the secrets hidden in datasets. This course builds on the skills you gained in ""Introduction to Regression in R"", covering linear and logistic regression with multiple explanatory variables. Through hands-on exercises, you’ll explore the relationships between variables in real-world datasets, Taiwan house prices and customer churn modeling, and more. By the end of this course, you’ll know how to include multiple explanatory variables in a model, understand how interactions between variables affect predictions, and understand how linear and logistic regression work.","Parallel slopes linear regression,Fitting a parallel slopes linear regression,Interpreting parallel slopes coefficients,Visualizing each explanatory variable,Visualizing parallel slopes,Predicting parallel slopes,Predicting with a parallel slopes model,Manually calculating predictions,Assessing model performance,Comparing coefficients of determination,Comparing residual standard error","Two numeric explanatory variables,3D visualizations,Modeling 2 numeric explanatory variables,Including an interaction,More than 2 explanatory variables,Visualizing many variables,Different levels of interaction,Predicting again,How linear regression works,The sum of squares,Linear regression algorithm","Models for each category,One model per category,Predicting multiple models,Visualizing multiple models,Assessing model performance,One model with an interaction,Specifying an interaction,Interactions with understandable coeffs,Making predictions with interactions,Predicting with interactions,Manually calculating predictions with interactions,Simpson's Paradox,Modeling eBay auctions,Modeling each auction type","Multiple logistic regression,Visualizing multiple explanatory variables,Logistic regression with 2 explanatory variables,Logistic regression prediction,Confusion matrix,The logistic distribution,Cumulative distribution function,Inverse cumulative distribution function,binomial family argument,Logistic distribution parameters,How logistic regression works,Likelihood & log-likelihood,Logistic regression algorithm,Congratulations",Maggie Matsui,"Data Scientist,Machine Learning Scientist,Statistician,Statistics Fundamentals,Supervised Machine Learning,Taiwan real estate prices,eBay Palm Pilot auctions,Bank churn,Introduction to Regression in R",,
87,Data Privacy and Anonymization in Python,4,16,49,,3850,"Data privacy has never been more important. But how do you balance privacy with the need to gather and share valuable business insights? In this course, you'll learn how to do just that, using the same methods as Google and Amazon—including data generalization and privacy models, like k-Anonymity and differential privacy. In addition to touching on topics such as GDPR, you'll also discover how to build and train machine learning models in Python while protecting users’ sensitive information such as employee and income data. Let’s get started!","What's private, and why do we care?,Privacy is power,Is it sensitive or non-sensitive?,Suppression of sensitive attributes,Data masking and data generation with Faker,Masking sensitive PII,Removing names with faker,Anonymizing with data generalization,Reducing identification risk with generalization,Data aggregation and data generalization,Top and bottom coding White House salaries","Introduction to differential privacy,Epsilon (ϵ): the magic number,Histograms with differential privacy,Privacy budgets,Using privacy budgets,When no budget is left,Exploring data with a privacy budget accountant,Differentially private  machine learning models,Build a differentially private classifier,Predicting salaries,Differentially private clustering models,Pre-processing data,Segmenting customers","Anonymizing categorical data,Explore the distribution of data,Sampling from the same probability distribution,Anonymizing continuous data,Different distributions,Sampling from the best continuous distribution,Introduction to K-anonymity,Privacy attributes,Generalizing into ranges,Generalizing data using hierarchies,Using hierarchies for categorical data,K-anonymizing a dataset","PCA for anonymization,Anonymization of high-dimensional data,Data masking with PCA,Generating realistic datasets with Faker,Consistent synthetic dataset,Datasets with the same probabilistic distribution,Creating synthetic datasets using scikit-learn,Generating datasets for classification,Generating datasets for clustering,Safely release datasets to the public,Exploring and pseudonymizing a dataset,Preparing employee data for safe release,Great work!","Richie Cotton,Justin Saddlemyer","IBM HR Analytics Employee Attrition & Performance,US Adult Income,Mall Customers,2017-2018 NBA Salaries,Unsupervised Learning in Python",,
88,Working with Categorical Data in Python,4,15,52,"4,750",4200,"Being able to understand, use, and summarize non-numerical data—such as a person’s blood type or marital status—is a vital component of being a data scientist. In this course, you’ll learn how to manipulate and visualize categorical data using pandas and seaborn. Through hands-on exercises, you’ll get to grips with pandas' categorical data type, including how to create, delete, and update categorical columns. You’ll also work with a wide range of datasets including the characteristics of adoptable dogs, Las Vegas trip reviews, and census data to develop your skills at working with categorical data.","Course introduction,Categorical vs. numerical,Exploring a target variable,Ordinal categorical variables,Categorical data in pandas,Setting dtypes and saving memory,Creating a categorical pandas Series,Setting dtype when reading data,Grouping data by category in pandas,Create lots of groups,Setting up a .groupby() statement,Using pandas functions effectively","Introduction to categorical plots using Seaborn,Boxplot understanding,Creating a box plot,Seaborn bar plots,Creating a bar plot,Ordering categories,Bar plot using hue,Point and count plots,Creating a point plot,Creating a count plot,Review catplot() types,Additional catplot() options,One visualization per group,Updating categorical plots","Setting category variables,Setting categories,Adding categories,Removing categories,Updating categories,Collapsing categories knowledge check,Renaming categories,Collapsing categories,Reordering categories,Reordering categories in a Series,Using .groupby() after reordering,Cleaning and accessing data,Cleaning variables,Accessing and filtering data","Categorical pitfalls,Memory usage knowledge check,Overcoming pitfalls: string issues,Overcoming pitfalls: using numpy arrays,Label encoding,Create a label encoding and map,Using saved mappings,Creating a Boolean encoding,One-hot encoding,One-hot knowledge check,One-hot encoding specific columns,Wrap-up video","Amy Peterson,Justin Saddlemyer","Adult Census Income,Adoptable Dogs,Tripadvisor Reviews,Used Cars,Data Manipulation with pandas",,
89,Financial Trading in Python,4,15,50,"8,482",4000,"Are you fascinated by the financial markets and interested in financial trading? This course will help you to understand why people trade, what the different trading styles are, and how to use Python to implement and test your trading strategies. Start your trading adventure with an introduction to technical analysis, indicators, and signals. You'll learn to build trading strategies by working with real-world financial data such as stocks, foreign exchange, and cryptocurrencies. By the end of this course, you'll be able to implement custom trading strategies in Python, backtest them, and evaluate their performance.","What is financial trading,The concept of trading,Plot a time series line chart,Plot a candlestick chart,Getting familiar with your trading data,Resample the data,Plot a return histogram,Calculate and plot SMAs,Financial trading with bt,The bt process,Define and backtest a simple strategy","Trading signals,Understand trading signals,Build an SMA-based signal strategy,Build an EMA-based signal strategy,Trend-following strategies,Construct an EMA crossover signal,Build and backtest a trend-following strategy,Mean reversion strategy,Match the signals with the strategies,Construct an RSI based signal,Build and backtest a mean reversion strategy,Strategy optimization and benchmarking,Conduct a strategy optimization,Perform a strategy benchmarking","Trend indicator MAs,Calculate and plot two EMAs,SMA vs. EMA,Strength indicator: ADX,Understand the ADX,Calculate the ADX,Visualize the ADX,Momentum indicator: RSI,Understand the RSI,Calculate the RSI,Visualize the RSI,Volatility indicator: Bollinger Bands,Understand Bollinger Bands,Implement Bollinger Bands","Strategy return analysis,Review return results of a backtest,Plot return histograms of a backtest,Compare return results of multiple strategies,Drawdown,Review performance with drawdowns,Calculate and review the Calmar ratio,Sharpe ratio and Sortino ratio,Evaluate strategy performance by Sharpe ratio,Evaluate strategy performance by Sortino ratio,Congratulations!","Hadrien Lacroix,Justin Saddlemyer,Jen Bricker","Google Stock Data,Bitcoin Price Data,Amazon Stock Data,Tesla Stock Data,Intermediate Python for Finance",,
90,Connecting Data in Tableau,4,14,35,"8,030",2700,"Great analysis begins with great data. But how do you connect Tableau to your databases and other file types, so that you can build a view and analyze your data? In this course, you'll learn how to use connectors in Tableau to create a live connection to CSV and Excel files. Through hands-on exercises, you’ll also learn how to combine multiple data tables with joins, unions, and relationships. Finally, you'll learn to manage different data properties, like renaming data fields, assigning aliases, changing data types, and changing default properties for a data field.","Combining data tables,Joins and unions,Unioning tables,Combining time data,Editing the union,Joining tables,Returned orders,Sales representatives,Relationships,Functionality of relationships,Establishing a relationship,Relationship to manufacturers,Worst products,Extracts,Creating extracts,Tableau file types,Extract or live connection","Data properties,Naming and data labels,Managing the presentation of data,Using aliases and colors,Default formatting,More data management,Assigning geo roles,Creating a hierarchy,Default aggregations,Tableau connectors,Connecting to data,Database connectors,TDS data source files,Filters,Tableau filters,Tableau's filtering order of operation,Adding a context filter,Using different filters",,,Celia Fryar,"Tableau Fundamentals,Workbooks and datasources,Introduction to Tableau",,
91,Creating Dashboards in Tableau,4,12,34,"13,387",2800,"Dashboards are a must-have tool in today’s data-driven world. By combining curated data visualizations, dashboards allow users to interpret and ask their own questions of data. By reducing the time to insight and empowering business analysts, dashboards can have a big impact on business performance.

Tableau's dashboarding abilities are powerful and easy to use. In this course, you'll learn to apply dashboard-composition best practices, add interactive or explanatory elements, and use dashboard actions to make your dashboard interactive. Additionally, you'll learn to modify an existing dashboard layout for mobile devices to share as an image or a PDF. Finally, you'll learn how to share your data story through Tableau's story functionality.","Creating dashboards,The value of dashboards,Getting started,Building a simple dashboard,Improving your dashboard,Including user KPIs in the dashboard,Adding elements to the dashboard,Annotating your dashboard,Using a dynamic title,Dashboard objects and actions,Dashboard object or action?,Working with containers,Layout with containers,Cleaning up the legend,Dashboard interactivity,Applying filters to worksheets,Updating the tooltip,Putting it all together","Sharing data insights,Essential elements of an analytical presentation,Creating and formatting Story Points,Comparing subscribers and customers,Adding annotations,Advanced manipulations with Story Points,Side by side dashboards in Story Points,Highlighter pen,Sharing dashboards - mobile and exports,Exporting formats,Customizing for mobile users,Previewing mobile layout,Customizing a mobile layout,Mobile navigation and export options,Implementing navigation,Saving and exporting",,,"Celia Fryar,Lis Sulmont","Tableau Fundamentals,Workbooks and datasources,Introduction to Tableau,Analyzing Data in Tableau",,
92,Analyzing Data in Tableau,8,24,69,"21,446",5550,"Take your Tableau skills up a notch with advanced analytics and visualizations. In this course, you’ll learn how to create detail-rich map visualizations, configure date and time fields to show trends over time, and extend your data using Calculated Fields. You’ll also apply your new skills to complete a customer analytics case study. Through hands-on activities, you’ll learn how to create bins, customize filters and interactions, and apply quick table calculations. Finally, you’ll learn power user techniques, including how to slice and dice data and apply dynamic sets and groups—bringing you one step closer to being Tableau Desktop Specialist certification-ready.","Data preparation,Non-aggregating numerical dimensions,Preparing the data,Measures and calculated fields,Highlighter,Calculated Fields to extend data,DATEDIFF function,Weekday or weekend?,Highlighter for multiple rows,Visualizations for exploratory analysis of trends,Discrete or continuous time analysis?,Discrete time analysis and Quick Table Calculations,Low usage trends,Weekly pattern by  user type,Slicing and dicing,Weekday trends by gender and time of day,Bubble chart,Scheduling a promotional discount","Interactive mapping of customer activity over time,Customer activity in motion,Visualizing concentration of activity,Tableau's new density mark type,Layering and total dock utilization,Splitting the map,Enhancing the map,Overlaying the maps,Quick table calculations for ranking,What goes where?,Combining characteristic and quick table calculations,Adding details without noise,Breaking out by customer type,KPIs and time segments,Charting station KPIs,From bubbles to donuts,Analyzing our results","Who are your customers?,Missing information,Exploring user data,Getting to know the Divvy users,Adding filters,Building a KPI dashboard,Formatting user KPIs,Creating a user dashboard,Enhancing the dashboard,The distribution of users,Choosing the right chart type,Visualizing distributions,Using a histogram,Using a line chart,Working with bins,Customizing the bin size,Exploring day pass user age","Groups,Groups for regions,Lasso selection,Editing groups,Creating seasonal groups,Seasons,Ranking  dashboard,Embedding in the tooltip,Parameters and sets,Parameter characteristics,Parameters,Replacing rank with a parameter,Color by parameter,Sets,Set for windiness,Divvy trips and windiness,Divvy trips and temperature",Celia Fryar,"Tableau Fundamentals,Workbooks and datasources,Introduction to Tableau",,
93,Web Scraping in R,4,13,45,"6,963",3600,"Have you ever come across a website that displays a lot of data such as statistics, product reviews, or prices in a format that’s not data analysis-ready? Often, authorities and other data providers publish their data in neatly formatted tables. However, not all of these sites include a download button, but don’t despair. In this course, you’ll learn how to efficiently collect and download data from any website using R. You'll learn how to automate the scraping and parsing of Wikipedia using the rvest and httr packages. Through hands-on exercises, you’ll also expand your understanding of HTML and CSS, the building blocks of web pages, as you make your data harvesting workflows less error-prone and more efficient.","Introduction to HTML,Read in HTML,Beware of syntax errors!,Navigating HTML,Select all children of a list,Parse hyperlinks into a data frame,Scrape your first table,The right order of table elements,Turn a table into a data frame with html_table()","Introduction to XPATH,Find the correct CSS equivalent,Select by class and ID with XPATH,Use predicates to select nodes based on their children,XPATH functions and advanced predicates,Find a more elegant XPATH alternative,Get to know the position() function,Extract nodes based on the number of their children,The XPATH text() function,The shortcomings of html_table() with badly structured tables,Select directly from a parent element with XPATH's text(),Combine extracted data into a data frame,Scrape an element based on its text","Introduction to CSS,Select multiple HTML types,Order CSS selectors by the number of results,CSS classes and IDs,Identify the correct selector types,Leverage the uniqueness of IDs,Select the last child with a pseudo-class,CSS combinators,Select direct descendants with the child combinator,How many elements get returned?,Simply the best!,Not every sibling is the same","The nature of HTTP requests,Which of these statements about HTTP is false?,Do it the httr way,Houston, we got a 404!,Telling who you are with custom user agents,Check out your user agent,Add a custom user agent,How to be gentle and slow down your requests,Custom arguments for throttled functions,Apply throttling to a multi-page crawler,Recap: Web Scraping in R","Maggie Matsui,Amy Peterson","R Programmer,Intermediate R,Introduction to the Tidyverse",,
94,Introduction to Regression in R,4,14,52,"23,225",4050,"Linear regression and logistic regression are the two most widely used statistical models and act like master keys, unlocking the secrets hidden in datasets. In this course, you’ll gain the skills you need to fit simple linear and logistic regressions. Through hands-on exercises, you’ll explore the relationships between variables in real-world datasets, including motor insurance claims, Taiwan house prices, fish sizes, and more. By the end of this course, you’ll know how to make predictions from your data, quantify model performance, and diagnose problems with model fit.","A tale of two variables,Which one is the response variable?,Visualizing two variables,Fitting a linear regression,Estimate the intercept,Estimate the slope,Linear regression with lm(),Categorical explanatory variables,Visualizing numeric vs. categorical,Calculating means by category,lm() with a categorical explanatory variable","Quantifying model fit,Coefficient of determination,Residual standard error,Visualizing model fit,Residuals vs. fitted values,Q-Q plot of residuals,Scale-location,Drawing diagnostic plots,Outliers, leverage, and influence,Leverage,Influence,Extracting leverage and influence","Making predictions,Predicting house prices,Visualizing predictions,The limits of prediction,Working with model objects,Extracting model elements,Manually predicting house prices,Using broom,Regression to the mean,Home run!,Plotting consecutive portfolio returns,Modeling consecutive returns,Transforming variables,Transforming the explanatory variable,Transforming the response variable too","Why you need logistic regression,Exploring the explanatory variables,Visualizing linear and logistic models,Logistic regression with glm(),Predictions and odds ratios,Probabilities,Most likely outcome,Odds ratio,Log odds ratio,Quantifying logistic regression fit,Calculating the confusion matrix,Measuring logistic model performance,Accuracy, sensitivity, specificity,Congratulations","Maggie Matsui,Adel Nehme,Amy Peterson","Data Scientist,Statistician,Statistics Fundamentals,Taiwan Real Estate,Ad conversion data,Churn data,Introduction to Data Visualization with ggplot2,Introduction to Statistics in R",,
95,Introduction to Statistics in R,4,15,54,"39,055",4250,"Statistics is the study of how to collect, analyze, and draw conclusions from data. It’s a hugely valuable tool that you can use to bring the future into focus and infer the answer to tons of questions. For example, what is the likelihood of someone purchasing your product, how many calls will your support team receive, and how many jeans sizes should you manufacture to fit 95% of the population? In this course, you'll use sales data to discover how to answer questions like these as you grow your statistical skills and learn how to calculate averages, use scatterplots to show the relationship between numeric values, and calculate correlation. You'll also tackle probability, the backbone of statistical reasoning, and learn how to conduct a well-designed study to draw your own conclusions from data.","What is statistics?,Descriptive and inferential statistics,Data type classification,Measures of center,Mean and median,Mean vs. median,Measures of spread,Quartiles, quantiles, and quintiles,Variance and standard deviation,Finding outliers using IQR","The normal distribution,Distribution of Amir's sales,Probabilities from the normal distribution,Simulating sales under new market conditions,Which market is better?,The central limit theorem,Visualizing sampling distributions,The CLT in action,The mean of means,The Poisson distribution,Identifying lambda,Tracking lead responses,More probability distributions,Too many distributions,Modeling time between leads,The t-distribution","What are the chances?,With or without replacement?,Calculating probabilities,Sampling deals,Discrete distributions,Creating a probability distribution,Identifying distributions,Expected value vs. sample mean,Continuous distributions,Which distribution?,Data back-ups,Simulating wait times,The binomial distribution,Simulating sales deals,Calculating binomial probabilities,How many sales will be won?","Correlation,Guess the correlation,Relationships between variables,Correlation caveats,What can't correlation measure?,Transforming variables,Does sugar improve happiness?,Confounders,Design of experiments,Study types,Longitudinal vs. cross-sectional studies,Congratulations!","Richie Cotton,Adel Nehme","Data Analyst,Data Scientist,Statistician,Statistics Fundamentals,Food Consumption & Carbon Footprint,Amir's Sales,World Happiness Report,Data Manipulation with dplyr,Intermediate R",,
96,Machine Learning for Everyone,2,12,36,"121,992",2350,"What's behind the machine learning hype? In this non-technical course, you’ll learn everything you’ve been too afraid to ask about machine learning. There’s no coding required. Hands-on exercises will help you get past the jargon and learn how this exciting technology powers everything from self-driving cars to your personal Amazon shopping suggestions. How does machine learning work, when can you use it, and what is the difference between AI and machine learning? They’re all covered. Gain skills in this hugely in-demand and influential field, and discover why machine learning is for everyone!","What is machine learning?,Generating movie recommendations,AI, data science, and machine learning walk into a bar...,What's true about machine learning?,Machine learning concepts,Machine learning lingo,Supervised vs unsupervised,Machine learning workflow,Steps for building a model,A true step","Deep learning,What is deep learning?,Should I use deep learning?,Computer vision,Image data,The process,Natural Language Processing,Sentiment analysis,Classifying machine learning tasks,Bag of words,Limits of machine learning,To black box or not to black box?,Spotting bias in machine learning,Congratulations!","Supervised learning,Warm up,Regressing with class,Unsupervised learning,We don't need no supervision,Gotta cluster 'em all!,Evaluating performance,True or false?,Land of confusion,Improving performance,It's a long way to the top,Explore hyperparameter tuning",,,Data Literacy Fundamentals,,
97,Cleaning Data in R,4,13,44,"31,480",3700,"It's commonly said that data scientists spend 80% of their time cleaning and manipulating data and only 20% of their time analyzing it. The time spent cleaning is vital since analyzing dirty data can lead you to draw inaccurate conclusions.

In this course, you'll learn how to clean dirty data. Using R, you'll learn how to identify values that don't look right and fix dirty data by converting data types, filling in missing values, and using fuzzy string matching. As you learn, you’ll brush up on your skills by working with real-world datasets, including bike-share trips, customer asset portfolios, and restaurant reviews—developing the skills you need to go from raw data to awesome insights as quickly and accurately as possible!","Data type constraints,Common data types,Converting data types,Trimming strings,Range constraints,Ride duration constraints,Back to the future,Uniqueness constraints,Full duplicates,Removing partial duplicates,Aggregating partial duplicates","Uniformity,Date uniformity,Currency uniformity,Cross field validation,Validating totals,Validating age,Completeness,Types of missingness,Visualizing missing data,Treating missing data","Checking membership,Members only,Not a member,Categorical data problems,Identifying inconsistency,Correcting inconsistency,Collapsing categories,Cleaning text data,Detecting inconsistent text data,Replacing and removing,Invalid phone numbers","Comparing strings,Calculating distance,Small distance, small difference,Fixing typos with string distance,Generating and comparing pairs,Link or join?,Pair blocking,Comparing pairs,Scoring and linking,Score then select or select then score?,Putting it together,Congratulations!","Richie Cotton,Adel Nehme,Amy Peterson","Data Scientist,Importing & Cleaning Data,Zagat,Fodor's,Bike Sharing,SFO Satisfaction Survey,Customer Accounts,Joining Data with dplyr",,
98,Streaming Data with AWS Kinesis and Lambda,4,22,56,"3,279",4500,"What powers the systems that we use every day without realizing, like fraud detection to keep our transactions secure or traffic signals that keep traffic flowing smoothly? The answer is streaming data (data that is continuously generated by different sources) and serverless technologies—like Amazon Kinesis and AWS Lambda.

In this course, you’ll learn how to leverage these powerful technologies by helping a fictional data engineer named Cody. Your goal is to help her to collect real-time streaming data from city-owned vehicles, analyze the data, and send relevant alerts like speed warnings to drivers. Using Amazon Kinesis and Firehose, you’ll learn how to ingest data from millions of sources before using Kinesis Analytics to analyze data as it moves through the stream. You’ll also spin up serverless functions in AWS Lambda that will conditionally trigger actions based on the data received. By the end of this training you’ll know how to create live ElasticSearch dashboards with AWS QuickSight and CloudWatch—and hopefully helped Cody complete her ambitious project.","What is streaming and why does it matter?,Batch vs stream,Producers and destinations,Managing Firehose delivery streams,Getting ready for the first stream,Creating roles,IAM users vs. roles,Permissions practice,S3 bucket creation,Working with the Firehose delivery stream,Create your first Firehose stream,Writing to a Firehose stream,Reading Firehose data","A transformational Lambda,Transforming data inside a stream,Encoding and decoding base64,Create a transformational lambda,A barebones transformational lambda,Analyzing data in the stream,Creating a Kinesis data analytics application,Kinesis data analytics  vs transformational Lambda,Building a Kinesis data analytics application,Kinesis data analytics SQL components,Using multiple streams,Delivering data from Kinesis Analytics,Get the daily top speed,Using Kinesis data analytics for alerts","Going serverless,Creating and running Lambda functions,Serverless vs servers,Lambda function components,Reading data from S3 based on an event,Your first live lambda!,Adding a lambda layer,Lambda flow,Using environment variables,Serverless data workflow,Fast vs slow lambdas,A time-triggered lambda,Time-triggered lambda code,Serverless APIs,Create an API lambda,A serverless API","Streaming data case study,Creating an Elasticsearch cluster,RedShift vs Elasticsearch,Monitoring performance,Cloudwatch dasbhoards and alarms,Cloudwatch components,Cloudwatch monitoring flow,Visualizing streaming data,Working with ElasticSearch using Kibana,Cloudwatch vs Elasticsearch,Elasticsearch visualization flow,An alternative approach,Another alternative approach","Hadrien Lacroix,Jen Bricker,Lis Sulmont","Introduction to AWS Boto in Python,Introduction to Shell,Streaming Concepts",,
99,Data Science for Everyone,2,15,48,"326,854",3100,"What is data science, why is it so popular, and why did the Harvard Business Review hail it as the “sexiest job of the 21st century”? In this non-technical course, you’ll be introduced to everything you were ever too afraid to ask about this fast-growing and exciting field, without needing to write a single line of code. Through hands-on exercises, you’ll learn about the different data scientist roles, foundational topics like A/B testing, time series analysis, and machine learning, and how data scientists extract knowledge and insights from real-world data. So don’t be put off by the buzzwords. Start learning, gain skills in this hugely in-demand field, and discover why data science is for everyone!","What is data science?,Customer segmentation workflow,Building a customer service chatbot,Applications of data science,Assigning data science project,Investment research,Data science roles and tools,Editing a job post,Matching skills to jobs,Classifying data tasks","Data preparation,The truth is out there,Are you prepared?,Exploratory Data Analysis,Numerical EDA,Visual EDA,Visualization,Interactive dashboards,Improving a dashboard","Data sources,Sorting data sources,Asthma frequencies,Data types,Classifying data types,Net promoter score,Activity tracker,Data storage and retrieval,Cloud platforms,Querying a database,Which type of database?,Data Pipelines,Data pipeline characteristics,Extract Transform Load","A/B Testing,Creating an A/B testing workflow,Statistical significance,Intermediate results,Time series forecasting,Classifying time series data,Interpret a time series plot,Supervised machine learning,When to use supervised learning,Features and labels,Model Evaluation,Clustering,Supervised vs. unsupervised,Cluster size selection,Congratulations!",,Data Literacy Fundamentals,,
100,Market Basket Analysis in Python,4,15,52,"7,529",4350,"What do Amazon product recommendations and Netflix movie suggestions have in common? They both rely on Market Basket Analysis, which is a powerful tool for translating vast amounts of customer transaction and viewing data into simple rules for product promotion and recommendation. In this course, you’ll learn how to perform Market Basket Analysis using the Apriori algorithm, standard and custom metrics, association rules, aggregation and pruning, and visualization. You’ll then reinforce your new skills through interactive exercises, building recommendations for a small grocery store, a library, an e-book seller, a novelty gift retailer, and a movie streaming service. In the process, you’ll uncover hidden insights to improve recommendations for customers.","What is market basket analysis?,The basics of market basket analysis,Cross-selling products,Identifying association rules,Multiple antecedents and consequents,Preparing data for market basket analysis,Generating association rules,The simplest metric,One-hot encoding transaction data,Computing the support metric","Aggregation,Performing aggregation,Defining an aggregation function,The Apriori algorithm,Pruning and Apriori,Identifying frequent itemsets with Apriori,Selecting a support threshold,Basic Apriori results pruning,Generating association rules,Pruning with lift,Pruning with confidence,Advanced Apriori results pruning,Aggregation and filtering,Applying Zhang's rule,Advanced filtering with multiple metrics","Confidence and lift,Recommending books with support,Refining support with confidence,Further refinement with lift,Leverage and conviction,Lift versus leverage,Computing conviction,Computing conviction with a function,Promoting ebooks with conviction,Association and dissociation,Computing association and dissociation,Defining Zhang's metric,Applying Zhang's metric,Advanced rules,Filtering with support and conviction,Using multi-metric filtering to cross-promote books","Heatmaps,Visualizing itemset support,Heatmaps with lift,Interpreting heatmaps,Scatterplots,Pruning with scatterplots,Optimality of the support-confidence border,Parallel coordinates plot,Using parallel coordinates to visualize rules,Refining a parallel coordinates plot,Congratulations!","Adel Nehme,Amy Peterson","Marketing Analytics,Online Retail dataset,Bookstore Transactions,Movielens Ratings dataset,Data Manipulation with pandas",,
101,Machine Learning for Business,2,15,48,"16,035",3200,"This course will introduce the key elements of machine learning to the business leaders. We will focus on the key insights and base practices how to structure business questions as modeling projects with the machine learning teams. You will understand the different types of models, what kind of business questions they help answer, or what kind of opportunities they can uncover, also learn to identify situations where machine learning should NOT be applied, which is equally important. You will understand the difference between inference and prediction, predicting probability and amounts, and how using unsupervised learning can help build meaningful customer segmentation strategy.","Machine learning and data pyramid,Terminology clarification,Order data pyramid needs,Match tasks in data pyramid,Machine learning principles,Modeling types,Find supervised and unsupervised cases,Job roles, tools and technologies,Job role responsibilities,Match data projects with job roles,Team structure types","Business requirements,Identify situation, opportunity and action,Identify successful experiments,Model training,Model training process,Training, validation and test,Model performance measurement,Poor performance examples,Identify performance metrics,Machine learning risks,Fixing non performing models,Non-actionable models,Identify actionable recommendations","Prediction vs. inference dilemma,Inference and prediction differences,Identify inference vs. prediction use cases,Inference (causal) models,Experiments and causal models,Identify non actionable variables,Prediction models (supervised learning),Supervised modeling principles,Identify classification and regression models,Prediction models (unsupervised learning),Unsupervised modeling use cases,Classification, regression or unsupervised models","Machine learning mistakes,Identify machine learning mistakes,Data needs pyramid,Match ML mistakes by their types,Communication management,Business communication focus,Market testing,Machine learning in production,Production systems,Production systems ML use cases,ML in production launch,Wrap-up","Hadrien Lacroix,Sara Billen",Data Skills for Business,,
102,Introduction to Tableau,6,24,60,"129,775",4750,"Tableau is a widely used business intelligence (BI) and analytics software trusted by companies like Amazon, Experian, and Unilever to explore, visualize, and securely share data in the form of Workbooks and Dashboards. With its user-friendly drag-and-drop functionality it can be used by everyone to quickly clean, analyze, and visualize your team’s data. You’ll learn how to navigate Tableau’s interface and connect and present data using easy-to-understand visualizations. By the end of this training, you’ll have the skills you need to confidently explore Tableau and build impactful data dashboards. Let’s dive in.","Introduction,Connecting to data,Loading data,Loading workbooks,Navigating Tableau,Dimensions and measures,A tour of the interface,New York's neighborhoods prices,Segmenting by room type,Your first visualization,Building and improving visualizations,Building your first visualization,Improving your first visualization,Bringing it all together","Mapping your data,Creating a symbol map,Your first symbol map,More symbol map options,World population,Working with dates,Visualizing dates,Your data by year,Your data by month,Birth seasonality,Reference lines, trend lines, and forecasting,Adding reference lines, trend lines, and forecasting,Reference lines,Trend lines,Forecasting,Natality forecast","Filtering and sorting,Sorting and filtering through selection,Sorting and excluding multiple fields,Comparing G7 countries,Filtering through the filter shelf,Filtering for null values,Top filters on Tableau,Aggregation,Scatter plots and aggregations,CO2 Emissions and GDP in Sub Regions,Counting on GDP per capita,Standard deviation of life expectancy,Calculated fields,Creating calculated fields,Calculated field for rounding,Ratio between genders,Average across genders","Make your data visually appealing,The art of formatting,Applying visual best practices,Create a dual-axis graph,Expanding a dual-axis graph,Formatting your visualization,Dashboards & stories,Worksheet vs. dashboard vs. story,Creating dashboards and stories,Building a dashboard,Filters and dashboards,Creating and navigating a story,Congratulations!",Maarten Van den Broeck,"Tableau Fundamentals,Workbooks and Datasources",,
103,Handling Missing Data with Imputations in R,4,13,49,"3,040",4200,"Missing data is everywhere. The process of filling in missing values is known as imputation, and knowing how to correctly fill in missing data is an essential skill if you want to produce accurate predictions and distinguish yourself from the crowd. In this course, you’ll learn how to use visualizations and statistical tests to recognize missing data patterns and how to impute data using a collection of statistical and machine learning models. You’ll also gain decision-making skills, helping you decide which imputation method fits best in a particular situation. Finally, you’ll learn to incorporate uncertainty from imputation into your inference and predictions, making them more robust and reliable.","Missing data: what can go wrong,Linear regression with incomplete data,Analyzing regression output,Comparing models,Missing data mechanisms,Recognizing missing data mechanisms,t-test for MAR: data preparation,t-test for MAR: interpretation,Visualizing missing data patterns,Aggregation plot,Spine plot,Mosaic plot","Model-based imputation approach,Linear regression imputation,Initializing missing values & iterating over variables,Detecting convergence,Replicating data variability,Logistic regression imputation,Drawing from conditional distribution,Model-based imputation with multiple variable types,Tree-based imputation,Imputing with random forests,Variable-wise imputation errors,Speed-accuracy trade-off","Mean imputation,Smelling the danger of mean imputation,Mean-imputing the temperature,Assessing imputation quality with  margin plot,Hot-deck imputation,Vanilla hot-deck,Hot-deck tricks & tips I: imputing within domains,Hot-deck tricks & tips II: sorting by correlated variables,k-Nearest-Neighbors imputation,Choosing the number of neighbors,kNN tricks & tips I: weighting donors,kNN tricks & tips II: sorting variables","Multiple imputation by bootstrapping,Wrapping imputation & modeling in a function,Running the bootstrap,Bootstrapping confidence intervals,Multiple imputation by chained equations,The mice flow: mice - with - pool,Choosing default models,Using predictor matrix,Putting it all together,Analyzing missing data patterns,Imputing and inspecting outcomes,Inference with imputed data,Final remarks","Adel Nehme,Amy Peterson","Biopics dataset,Tropical Atmosphere Ocean dataset,Multiple and Logistic Regression in R,Dealing With Missing Data in R",,
104,Transactions and Error Handling in PostgreSQL,4,15,49,,3950,"Being able to leverage transactions and find and handle errors is critical to building resilient SQL scripts and working with databases. Transactions provide the protection needed to ensure that your data is consistent and operations work on the desired data in concurrent environments. Improper error handling can cause many serious and unexpected issues. Without the proper use of transactions and error handling, it's possible to make decisions based on incorrect data leading to false outcomes. In this course, we'll cover proper ways to use transactions and handle errors with a record of what went wrong. Additionally, we discuss how concurrently plays into the use of transactions and data outcomes. We'll practice these concepts on the FFEIC bank health data and with a patient data table.","Welcome to Transactions and Error Handling in PostgreSQL,Transaction structure,Making our first transaction,Multiple statement transactions,Transaction sizes and PostgreSQL protections,Using and making transactions,Single statement transactions,Isolation levels,Selecting isolation levels,Using an isolation level,Isolation levels and transactions","Catching exceptions,Writing do statements,Using exception handling wisely,Handling exceptions,Rollbacks, savepoints and exceptions,Multiple exception blocks,Understanding rollbacks and savepoints,Specific exception handling and messages,Capturing specific exceptions,Logging messages on specific exceptions,Graceful exception handling,When to use graceful degradation,Graceful degradation","Handling mistakes,Using rollbacks,Multistatement Rollbacks,Rolling back to a savepoint,Working with a single savepoint,Rolling back with a savepoint,Multiple savepoints and rollback,Multiple savepoints,Savepoints and rolling back,Understanding outcomes,Isolation levels, savepoints, and rollbacks,Working with repeatable read,Isolation levels comparison,Savepoint's effect on isolation levels","Enhancing exception handling with stacked diagnostics,Getting stacked diagnostics,What data is available in stacked diagnostics,Hints to help handle nested exceptions,Capturing a context stack,When to add custom exception logging and recording,Mixing it all together with debugging functions,Creating named functions and declaring variables,Structure of stacked diagnostics function,Putting it all together,Wrapping it up",Amy Peterson,"FFEIC data,Intermediate SQL",,
105,Working with Dates and Times in Python,4,14,48,"37,088",4100,"You'll probably never have a time machine, but how about a machine for analyzing time? As soon as time enters any analysis, things can get weird. It's easy to get tripped up on day and month boundaries, time zones, daylight saving time, and all sorts of other things that can confuse the unprepared. If you're going to do any kind of analysis involving time, you’ll want to use Python to sort it out. Working with data sets on hurricanes and bike trips, we’ll cover counting events, figuring out how much time has elapsed between events and plotting data over time. You'll work in both standard Python and in Pandas, and we'll touch on the dateutil library, the only timezone library endorsed by the official Python documentation. After this course, you'll confidently handle date and time data in any format like a champion.","Dates in Python,Which day of the week?,How many hurricanes come early?,Math with dates,Subtracting dates,Counting events per calendar month,Putting a list of dates in order,Turning dates into strings,Printing dates in a friendly format,Representing dates in different ways","UTC offsets,Creating timezone aware datetimes,Setting timezones,What time did the bike leave in UTC?,Time zone database,Putting the bike trips into the right time zone,What time did the bike leave? (Global edition),Starting daylight saving time,How many hours elapsed around daylight saving?,March 29, throughout a decade,Ending daylight saving time,Finding ambiguous datetimes,Cleaning daylight saving data with fold","Dates and times,Creating datetimes by hand,Counting events before and after noon,Printing and parsing datetimes,Turning strings into datetimes,Parsing pairs of strings as datetimes,Recreating ISO format with strftime(),Unix timestamps,Working with durations,Turning pairs of datetimes into durations,Average trip time,The long and the short of why time is hard","Reading date and time data in Pandas,Loading a csv file in Pandas,Making timedelta columns,Summarizing datetime data in Pandas,How many joyrides?,It's getting cold outside, W20529,Members vs casual riders over time,Combining groupby() and resample(),Additional datetime methods in Pandas,Timezones in Pandas,How long per weekday?,How long between rides?,Wrap-up","Sumedh Panchadhar,Chester Ismay","Data Scientist,Python Programmer,Python Toolbox,Florida Hurricanes,W20529 Bike Data (Capital Bikeshare),Data Manipulation with pandas",,
106,Dimensionality Reduction in Python,4,16,58,"18,796",4700,"High-dimensional datasets can be overwhelming and leave you not knowing where to start. Typically, you’d visually explore a new dataset first, but when you have too many dimensions the classical approaches will seem insufficient. Fortunately, there are visualization techniques designed specifically for high dimensional data and you’ll be introduced to these in this course. After exploring the data, you’ll often find that many features hold little information because they don’t show any variance or because they are duplicates of other features. You’ll learn how to detect these features and drop them from the dataset so that you can focus on the informative ones. In a next step, you might want to build a model on these features, and it may turn out that some don’t have any effect on the thing you’re trying to predict. You’ll learn how to detect and drop these irrelevant features too, in order to reduce dimensionality and thus complexity. Finally, you’ll learn how feature extraction techniques can reduce dimensionality for you through the calculation of uncorrelated principal components.","Introduction,Finding the number of dimensions in a dataset,Removing features without variance,Feature selection vs. feature extraction,Visually detecting redundant features,Advantage of feature selection,t-SNE visualization of high-dimensional data,t-SNE intuition,Fitting t-SNE to the ANSUR data,t-SNE visualisation of dimensionality","Selecting features for model performance,Building a diabetes classifier,Manual Recursive Feature Elimination,Automatic Recursive Feature Elimination,Tree-based feature selection,Building a random forest model,Random forest for feature selection,Recursive Feature Elimination with random forests,Regularized linear regression,Creating a LASSO regressor,Lasso model results,Adjusting the regularization strength,Combining feature selectors,Creating a LassoCV regressor,Ensemble models for extra votes,Combining 3 feature selectors","The curse of dimensionality,Train - test split,Fitting and testing the model,Accuracy after dimensionality reduction,Features with missing values or little variance,Finding a good variance threshold,Features with low variance,Removing features with many missing values,Pairwise correlation,Correlation intuition,Inspecting the correlation matrix,Visualizing the correlation matrix,Removing highly correlated features,Filtering out highly correlated features,Nuclear energy and pool drownings","Feature extraction,Manual feature extraction I,Manual feature extraction II,Principal component intuition,Principal component analysis,Calculating Principal Components,PCA on a larger dataset,PCA explained variance,PCA applications,Understanding the components,PCA for feature exploration,PCA in a model pipeline,Principal Component selection,Selecting the proportion of variance to keep,Choosing the number of components,PCA for image compression,Congratulations!","Chester Ismay,Hadrien Lacroix,Hillary Green-Lerman","Machine Learning Scientist,ANSUR Female,ANSUR Male,Diabetes,Grocery store sales,Boston Public Schools,Pokemon,Supervised Learning with scikit-learn",,
107,Big Data Fundamentals with PySpark,4,16,55,"31,351",4600,"There's been a lot of buzz about Big Data over the past few years, and it's finally become mainstream for many companies. But what is this Big Data? This course covers the fundamentals of Big Data via PySpark. Spark is a ""lightning fast cluster computing"" framework for Big Data. It provides a general data processing platform engine and lets you run programs up to 100x faster in memory, or 10x faster on disk, than Hadoop. You’ll use PySpark, a Python package for Spark programming and its powerful, higher-level libraries such as SparkSQL, MLlib (for machine learning), etc. You will explore the works of William Shakespeare, analyze Fifa 2018 data and perform clustering on genomic datasets. At the end of this course, you will have gained an in-depth understanding of PySpark and its application to general Big Data analysis.","What is Big Data?,The 3 V's of Big Data,PySpark: Spark with Python,Understanding SparkContext,Interactive Use of PySpark,Loading data in PySpark shell,Review of functional programming in Python,Use of lambda() with map(),Use of lambda() with filter()","Abstracting Data with DataFrames,RDD to DataFrame,Loading CSV into DataFrame,Operating on DataFrames in PySpark,Inspecting data in PySpark DataFrame,PySpark DataFrame subsetting and cleaning,Filtering your DataFrame,Interacting with DataFrames using PySpark SQL,Running SQL Queries Programmatically,SQL queries for filtering Table,Data Visualization in PySpark using DataFrames,PySpark DataFrame visualization,Part 1: Create a DataFrame from CSV file,Part 2: SQL Queries on DataFrame,Part 3: Data visualization","Abstracting Data with RDDs,RDDs from Parallelized collections,RDDs from External Datasets,Partitions in your data,Basic RDD Transformations and Actions,Map and Collect,Filter and Count,Pair RDDs in PySpark,ReduceBykey and Collect,SortByKey and Collect,Advanced RDD Actions,CountingBykeys,Create a base RDD and transform it,Remove stop words and reduce the dataset,Print word frequencies","Overview of PySpark MLlib,PySpark ML libraries,PySpark MLlib algorithms,Collaborative filtering,Loading Movie Lens dataset into RDDs,Model training and predictions,Model evaluation using MSE,Classification,Loading spam and non-spam data,Feature hashing and LabelPoint,Logistic Regression model training,Clustering,Loading and parsing the 5000 points data,K-means training,Visualizing clusters,Congratulations!","Chester Ismay,Hadrien Lacroix","Big Data with PySpark,Data Engineer,Complete Shakespeare,Movie ratings,5000 points,FIFA 2018,People,Spam,Ham,Introduction to Python",,
108,Analyzing US Census Data in Python,5,16,57,"3,925",4850,"Data scientists in diverse fields, from marketing to public health to civic hacking, need to work with demographic and socioeconomic data. Government census agencies offer richly detailed, high-quality datasets, but the number of variables and intricacies of administrative geographies (what is a Census tract anyway?) can make approaching this goldmine a daunting process. This course will introduce you to the Decennial Census and the annual American Community Survey, and show you where to find data on household income, commuting, race, family structure, and other topics that may interest you. You will use Python to request this data using the Census API for large and small geographies. You will manipulate the data using pandas, and create derived data such as a measure of segregation. You will also get a taste of the mapping capabilities of geopandas.","Census Subject Tables,Aggregate and Calculate Proportions,Calculate Proportions,Identify Extreme Values,Using the Census API,The Basic API Request,The API Response and Pandas,API to Visualization: Group Quarters,Census Geographies,Specific Places,Congressional Districts by State,Zip Code Tabulation Areas","Measuring Segregation: The Index of Dissimilarity,Calculating D for One State,Calculating D in a Loop,Calculating D Using Grouping in Pandas,Metropolitan Segregation,Joining Tracts and Metropolitan Areas,Create Function to Calculate D,Characteristics of Segregated Metros,Segregation Impacts: Unemployment,Calculating Unemployment,Impacts of Black-White Segregation by Sex,White and Black Unemployment,Neighborhood Segregation Over Time,Tract Demographics in a Segregated City,Segregation Begets More Segregation,Population Decline in Segregated Neighborhoods","Annual Change,Home Values in California,Health Insurance Coverage,Finding ACS Tables by Subject,Margins of Error,Plotting Margins of Error over Time,Significance of Difference of Estimates,Significance of Difference of Proportions,Basic Mapping with Geopandas,Choropleth Map of Internet Access,Proportional Symbol Map of Households w/ Internet,Bivariate Map of Broadband Access,Neighborhood Change,Identifying Gentrifiable Tracts,Identifying Gentrifying Tracts,Mapping Gentrification","Employment and the Labor Force,Unemployment,Labor Force Participation,Commuting,Heatmap of Travel Times By Commute Mode,Worker Population,Migration,Immigration,State-to-State Flows,Is the Rent Too Damn High?,Rent Burden in San Francisco,High Rent and Rent Burden,Congratulations!","Mari Nazary,Adrián Soto","Hispanic Origin & Race by State, 2010,Household Internet Access by State, 2017,Brooklyn Tract Demographics, 2000,Brooklyn Tract Geometries, 2000,Brooklyn Tract Demographics, 2010,Brooklyn Tract Geometries, 2010,Data Manipulation with pandas",,
109,Intermediate Predictive Analytics in Python,4,15,56,"4,028",4350,"Building good models only succeeds if you have a decent base table to start with. In this course you will learn how to construct a good base table, create variables and prepare your data for modeling. We finish with advanced topics on the matter.","The basetable timeline,Timeline violations,Available data,Timeline violation,The population,Select the relevant population,A timeline compliant population,Removing duplicate objects,The target,Calculate an event target,Calculate an aggregated target","Creating dummies,Creating a dummy from a two-category variable,Creating dummies from a many-categories variable,Missing values,How to replace missing values,Creating a missing value dummy,Replace missing values with the median value,Replace missing values with a fixed value,Handling outliers,Influence of outliers on predictive models,Handle outliers with winsorization,Handle outliers with standard deviation,Transformations,Interactions,Square root transformation,Adding interactions to the basetable","Adding fixed variables,Selecting the right value,Adding age,Adding the donor segment,Adding living place,Adding aggregated variables,Selecting the appropriate date,Maximum value last year,Recency of donations,Adding evolutions,Ratio of last month's and last year's average,Absolute difference between two years,Using evolution variables,Performance of evolution variables,Meaning of evolution","Seasonality,Seasonality or not,Detecting seasonality,The effect of seasonality,Using multiple snapshots,Target values,Calculating snapshot targets,Calculating aggregated variables,Stacking basetables,The timegap,Events during the timegap,Calculating aggregated variables with timegap,Adding age with timegap,Congratulations","Lore Dirick,Nick Solomon,Hadrien Lacroix","Donor IDs,Basetable with countries and age,Basetable used in Ex 2.13,Living place of donors,Donations,Introduction to Predictive Analytics in Python",,
110,Defensive R Programming,4,16,51,"3,476",3400,"Writing R scripts is easy. Writing good R code is hard. In this course, we'll discuss defensive programming - a set of standard techniques that will help reduce bugs and aid working in teams. We examine techniques for avoiding common errors and also how to handle the inevitable error that arises in our code. The course will conclude looking at when to make the transition from script to project to package.","Defensive R Programming,Real Programmers...,Don't reinvent the wheel/package,Updating Packages,Out of Date Packages,Task Views,Packages and Namespaces,Number of Loaded Packages,Counting Exported Functions,The Conflicted Package","Preparing your defences,What does DRY mean?,Refactoring: functions,Just one comment,Header comments,A little bit dotty,Use a full stop in variable names,Avoiding the .,Coding Style,Importance of consistent style,Static Code Analysis for R,Code tidying,More linting","Early warning systems,To TRUE or not to T,Let's be evil,If it weren't for those pesky kids,Message in a bottle,Did you get the message?,Suppressing startup messages,Stop being noisy!!!,Using message in practice,You have been warned,Messages vs Warnings,Suppressing warnings,Stop (right now),Warnings vs Stop,Using the stop() function","A battle plan,The importance of consistency,Give me some space,Human readable filenames,What date format should we use?,Organizing a project,Avoiding absolute directories,The input/ directory,Absolute vs relative,Graphics and output,Generating graphics,Graphics/,One final work flow","Richie Cotton,Hadrien Lacroix","R Programmer,Intermediate R",,
111,Feature Engineering in R,4,13,44,"3,826",3500,"Feature engineering helps you uncover useful insights from your machine learning models. The model building process is iterative and requires creating new features using existing variables that make your model more efficient. In this course, you will explore different data sets and apply a variety of feature engineering techniques to both continuous and discrete variables.","Introduction to feature engineering in R,Examples of feature engineering,One-hot encoding,Binning encoding: content driven,Leveraging content knowledge,Converting new categories to numeric,Binning encoding: data driven,Categorical proportions by outcome,Reducing categories using outcome","Box and Yeo transformations,Box-Cox vs. Yeo-Johnson,Box-Cox transformations,Yeo-Johnson transformations,Normalization techniques,Scaling,Mean centering,Caret mean centering,Z-score standardization,Standardization one variable case,Caret standardization","Numerical bucketing or binning,Visualizing the distribution,Creating uniform buckets from a distribution,Binning numerical data using quantiles,Balanced bucketing,Full matrix encoding,Unique attributes of adaptive bucketing,Date and time feature extraction,Converting  string types  to date types,Converting dates,Visualize time features","Feature crossing,How many features to expect,Exploring features visually,Exploring potential crosses,Crossing two categorical features,Principal component analysis,Conduct PCA,PCA results,Interpreting PCA output,Proportion of variance by PCA,Visualizing results with a scree plot,Visualizing components,Wrap-up","Chester Ismay,Amy Peterson",Exploratory Data Analysis in R,,
112,Probability Puzzles in R,4,13,45,"2,861",3750,"Do you want to take your probability skills to the next level? This course will help get you there, using problem-based learning with probability puzzles as the framework. As you are guided through their solutions, you will gain coding tools and general strategies for solving probability problems that you might encounter in many other situations. Organized by theme, the course begins with classic problems like the Birthday Problem and Monty Hall, and ends with puzzles that involve poker like Texas Hold'em and the World Series of Poker!","Introduction to the Course,Writing a simple function,Writing a simple for loop,Setting a seed,The Birthday Problem,Simulation of a single n,Using the pbirthday function,Make a plot,Monty Hall,Win probability with ""stick"",Writing a function to ""switch"",Win probability with ""switch""","Factoring a Quadratic,Which condition will return TRUE?,Write a function to check factorability,Simulate the factorable probability,Four Digit iPhone Passcodes,Four known values,Three known values,Sign Error Cancellations,Simulate sign errors: constant probabilities,Simulate sign errors: changing probabilities","Yahtzee,Probability of a Yahtzee,Probability of a large straight,Probability of a full house,Settlers of Catan,Simulate one game,Simulate 10000 games,Craps,Function to keep rolling when point is established,Function to run one round,Probability of winning the pass line bet","Texas Hold'em,Calculate expected value with one card to come,Two cards to come,Consecutive Cashes,Two consecutive years,Function to evaluate set of five years,Simulate probability for a given set of five years,von Neumann Model of Poker,One round of von Neumann Poker,Function to simulate one round with betting,Simulate many iterations of von Neumann model,Congratulations!","Chester Ismay,Amy Peterson","Intermediate R,Foundations of Probability in R",,
113,Topic Modeling in R,4,14,49,"4,933",3950,"This course introduces students to the areas involved in topic modeling: preparation of corpus, fitting of topic models using Latent Dirichlet Allocation algorithm (in package topicmodels), and visualizing the results using ggplot2 and wordclouds.","Why learn topic modeling,Topics as word contexts,Topic prevalence,Probabilities of words belonging to topics,Counting words,Removal of punctuation marks,Word frequencies,Our first LDA model,Displaying frequencies with ggplot,Simple LDA model","Using topic models as classifiers,Same k, different alpha,Probabilities of words in topics,From word windows to dtm,Regex patterns for entity matching,Making a corpus,From dtm to topic model,Corpus alignment and classification,Train a topic model,Align corpus,Classify test data,Explore the results","Random nature of LDA algorithm,Probabilities of words in topics,Effect of argument alpha,Manipulating the vocabulary,Making a dtm - refresher,Removing stopwords,Keeping the needed words,Word clouds,Wordcloud of term frequency,History of the Byzantine Empire,LDA model fitting - first iteration,Capturing the actions - dtm with verbs,Making a chart,Use wordclouds","Finding the best number of topics,Preparing the dtm,Filtering by word frequency,Fitting one model,Using perplexity to find the best k,Topic models fitted to novels,Generating chunk numbers,Inner join and cast dtm,Finding the best value for k,Locking topics by using seed words,Topics without seedwords,Topics with seedwords,Final words (and more things to learn)","Richie Cotton,Hadrien Lacroix","History Data,Document Corpus,Text Mining with Bag-of-Words in R,Introduction to Natural Language Processing in R",,
114,Data Visualization in Spreadsheets,4,16,55,"26,097",4700,"A picture can tell a thousand words - but only if you use the right picture! This course teaches you the fundamentals of data visualization with Google Sheets. You'll learn how to create common chart types like bar charts, histograms, and scatter charts, as well as more advanced types, such as sparkline and candlestick charts. You will look at how to prepare your data and use Data Validation and VLookup formulas to target specific data to chart. You'll learn how to use Conditional Formatting to apply a format to a cell or a range of cells based on certain criteria, and finally, how to create a dashboard showing plots and data together. Along the way, you'll use data from the Olympics, sharks attacks, and Marine Technology from the ASX.","Using Sheets as a Business Intelligence platform,Using data validation controls view medal tallies,Using data validation controls to pick from a list,Using conditional formatting on a dashboard ,Setting up a basic dashboard,Creating a column chart from your data,Setting up your worksheet with formulas of reference,Charting the medal statistics,Setting up your data,Getting started,Format dates and numbers","Data validation,Setting up your data,Format numbers within your dataset,Using VLOOKUP with data validation,Creating and testing the data validation,Adding the calculation,Creating the line plot,Formatting your line chart,Chart titles, axis, font, gridlines,Other formatting options","Using conditional formatting,Creating a simple rule to highlight cells ,Highlighting cells between a range,Using formulas and tidying up the dashboard,Using a custom formula to highlight a row,Highlighting duplicates,Using wildcard characters to highlight dates,Change a condition in a format,Congratulations","Efficient column charts,Creating a column chart for your dashboard,Format chart, axis titles and series,Axis, gridlines, and changing the plot,Removing a series,Changing the plotted range,Named ranges,Using named ranges,Summing using a named range,Averaging using a named range","Richie Cotton,Amy Peterson","Spreadsheet Fundamentals,Intermediate Spreadsheets","Histograms,Inserting the VLOOKUP,Creating a histogram on the dashboard,Formatting your histogram,Candlestick charts,Changing your dates to text,Creating the candlestick for the dashboard,Formatting the candlestick,Scatter charts,Creating a scatter chart,Formatting your scatter chart,Sparkline charts within a cell,Sparklines,Changing the color of your sparkline,The column sparkline",
115,Fraud Detection in Python,4,16,57,"13,121",4800,"A typical organization loses an estimated 5% of its yearly revenue to fraud. In this course, you will learn how to fight fraud by using data. For example, you'll learn how to apply supervised learning algorithms to detect fraudulent behavior similar to past ones, as well as unsupervised learning methods to discover new types of fraud activities. Moreover, in fraud analytics you often deal with highly imbalanced datasets when classifying fraud versus non-fraud, and during this course you will pick up some techniques on how to deal with that. The course provides a mix of technical and theoretical insights and shows you hands-on how to practically implement fraud detection models. In addition, you will get tips and advice from real-life experience to help you prevent making common mistakes in fraud analytics.","Introduction to fraud detection,Checking the fraud to non-fraud ratio,Plotting your data,Increasing successful detections using data resampling,Resampling methods for imbalanced data,Applying SMOTE,Compare SMOTE to original data,Fraud detection algorithms in action,Exploring the traditional way to catch fraud,Using ML classification to catch fraud,Logistic regression combined with SMOTE,Using a pipeline","Normal versus abnormal behavior,Exploring your data,Customer segmentation,Using statistics to define normal behavior,Clustering methods to detect fraud,Scaling the data,K-means clustering,Elbow method,Assigning fraud versus non-fraud,Detecting outliers,Checking model results,Other clustering fraud detection methods,DBSCAN,Assessing smallest clusters,Checking results","Review of classification methods,Natural hit rate,Random Forest Classifier - part 1,Random Forest Classifier - part 2,Performance evaluation,Performance metrics for the RF model,Plotting the Precision Recall Curve,Adjusting your algorithm weights,Model adjustments,Adjusting your Random Forest to fraud detection,GridSearchCV to find optimal parameters,Model results using GridSearchCV,Ensemble methods,Logistic Regression,Voting Classifier,Adjust weights within the Voting Classifier","Using text data,Word search with dataframes,Using list of terms,Creating a flag,Text mining to detect fraud,Removing stopwords,Cleaning text data,Topic modeling on fraud,Create dictionary and corpus,LDA model,Flagging fraud based on topics,Interpreting the topic model,Finding fraudsters based on topic,Recap","Hadrien Lacroix,Mari Nazary","Chapter 1 datasets,Chapter 2 datasets,Chapter 3 datasets,Chapter 4 datasets,Unsupervised Learning in Python,Supervised Learning with scikit-learn",,
116,Course Creation at DataCamp,3,20,68,,3900,"Welcome to the DataCamp family! You are about to begin creating a course that, in just a few months, will be available to over 3 million students worldwide! If you're new to eLearning, you'll soon learn that teaching an online course is very different from teaching in a classroom. But we're here to help! This course will provide a guide to the DataCamp Course Creation process; an introduction to the tools we use, including GitHub, Asana, and our very own course editor; and the different types of exercises and slides you can use, and how to make sure you're reaching students at the other end of the screen. While creating your course, you will find you have other questions, such as, ""How will my course be marketed?"", ""How do I recommend other instructors to DataCamp?"", or ""When do I get paid?"". This course will also provide you with direction on where to find answers to all your questions. Following this course, you should be familiar with the DataCamp Course Creation process and be ready to start your very own DataCamp course. Have fun and see you in the course!","Welcome to DataCamp!,Course specs,Content Developers,Course maintenance,Course design,Which parts require the course editor?,Course design tasks,Course development,Who owns the course IP,Instructor vs CD responsibilities","Structure and optimal flow,Lesson framework,Motivating a lesson,Progressive build-up,Defining learning objectives,Clear learning objectives,Real-world scenarios,Optimizing for digital learning,Creating course descriptions,Deciding on prerequisites,Using analogies and heuristics,Fostering learner engagement,Keeping learners motivated,What to avoid in interactive exercises","Post-dev review and course launch,Screencasts vs. audio recordings,Submission Correctness Tests (SCTs),Soft launch vs. hard launch,Course maintenance,Content Dashboard,Maintenance process,Marketing and royalties,Marketing courses,Understanding royalties,Congratulations!","Accountability, transparency, and predictability,Why are deadlines important?,Are DataCamp deadlines flexible?,How hard can it be?,Course management tools,Asana is our ground truth,Understanding our meeting tools,Communication strategy,Navigating the DataCamp course editor,Using the course outline,Text vs. code fields,Saving in the course editor,GitHub and course development,GitHub files,Saving and commits","Amy Peterson,Lis Sulmont",,"Video exercises: Slides & transcript,Animating text & code,Animating images,A great video,Components of interactive exercises,Anatomy of an exercise,What is sample code,Interactive exercise fields,Types of interactive exercises,Choosing the right coding exercise,Choosing the right non-coding exercise,Striking the right balance,Respect the guidelines,Learning the guidelines,Course evaluation,GitHub for course review,Pull request in your Github repo,GitHub resources",
117,GARCH Models in R,4,16,60,"5,921",4550,"Are you curious about the rhythm of the financial market's heartbeat? Do you want to know when a stable market becomes turbulent? In this course on GARCH models you will learn the forward looking approach to balancing risk and reward in financial decision making. The course gradually moves from the standard normal GARCH(1,1) model to more advanced volatility models with a leverage effect, GARCH-in-mean specification and the use of the skewed student t distribution for modelling asset returns. Applications on stock and exchange rate returns include portfolio optimization, rolling sample forecast evaluation, value-at-risk forecasting and studying dynamic covariances.","Analyzing volatility,Computing returns,Standard deviation on subsamples,Roll, roll, roll,The GARCH equation for volatility prediction,GARCH(1,1) reaction to one-off shocks,Prediction errors,The recursive nature of the GARCH variance,The rugarch package,Specify and taste the GARCH model flavors,Out-of-sample forecasting,Volatility targeting in tactical asset allocation","Statistical significance,Significance testing,Analyzing estimation output,A better model for EUR/USD returns,Goodness of fit,Parsimony,Mean squared prediction errors,Comparing likelihood and information criteria,Diagnosing absolute standardized returns,Validation of GARCH model assumptions,Correlogram and Ljung-Box test,Change estimation sample,Backtesting using ugarchroll,ugarchroll arguments,In-sample versus rolling sample vol,Horse race","Non-normality of standardized returns,Skewed student t distribution parameters,Estimation of non-normal GARCH model,Standardized returns,Leverage effect,News impact curve,Estimation of GJR garch model,Mean model,Predicting returns,The AR(1)-GJR GARCH dynamics of MSFT returns,Effect of mean model on volatility predictions,Avoid unnecessary complexity,Modeling choices,Fixing GARCH parameters,Parameter bounds and impact on forecasts,Variance targeting","Value-at-risk,VaR plot,Comovement between predicted vol and VaR,Sensitivity of coverage to distribution model,For production and simulation,Actual versus simulated returns,Use in production,Use in simulation,Model risk,Robustniks,Starting values,GARCH covariance,Estimation of beta,Minimum variance portfolio weights,GARCH & Co,Congratulations","Chester Ismay,Hadrien Lacroix,Sara Billen","Applied Finance,Daily EUR/USD returns,Daily Microsoft returns,S&P 500 prices,S&P 500 returns,Simulated return data,Time Series Analysis in R,Manipulating Time Series Data with xts and zoo in R",,
118,Analyzing Social Media Data in Python,4,14,51,"16,870",4000,"Twitter produces hundreds of million messages per day, with people around the world discussing sports, politics, business, and entertainment. You can access thousands of messages flowing in this stream in a matter of minutes. In this course, you will learn how to collect Twitter data and analyze tweet text, Twitter networks, and the geographical origin of the tweet. We'll be doing this with datasets on tech companies, data science hashtags, and the 2018 State of the Union address. Using these methods, you will be able to inform business and political decision-making by discovering the prevalence of important topics, the diversity of discussion networks, and a topic's geographical reach.","Analyzing Twitter data,Why Analyze Twitter Data?,Uses of Twitter analysis,Collecting data through the Twitter API,Twitter APIs,Setting up tweepy authentication,Collecting data on keywords,Understanding Twitter JSON,Loading and accessing tweets,Accessing user data,Accessing retweet data","Twitter networks,Types of Twitter networks,Which direction is the arrow?,Importing and visualizing Twitter networks,Creating retweet network,Creating reply network,Visualizing retweet network,Individual-level network metrics,In-degree centrality,Betweenness centrality,Ratios","Processing Twitter text,Tweet Items and Tweet Flattening,A tweet flattening function,Loading tweets into a DataFrame,Counting words,Finding keywords,Looking for text in all the wrong places,Comparing #python to #rstats,Time series,Creating time series data frame,Generating mean frequency,Plotting mean frequency,Sentiment analysis,Loading VADER,Calculating sentiment scores,Plotting sentiment scores","Maps and Twitter data,Motivations,Comparisons,Geographical data in Twitter JSON,Coordinates and bounding boxes,Accessing user-defined location,Accessing bounding box,Calculating the centroid,Creating Twitter maps,Creating Basemap map,Plotting centroid coordinates,Coloring by sentiment,Congratulations!","David Campos,Greg Wilson,Kara Woo,Eunkyung Park,Shon Inouye","Marketing Analytics,Data Science Hashtag dataset,State of the Union Reply Network dataset,State of the Union Retweet Networking dataset,Data Manipulation with pandas",,
119,Fraud Detection in R,4,16,49,"5,740",3900,"The Association of Certified Fraud Examiners estimates that fraud costs organizations worldwide $3.7 trillion a year and that a typical company loses five percent of annual revenue due to fraud. Fraud attempts are expected to even increase further in future, making fraud detection highly necessary in most industries. This course will show how learning fraud patterns from historical data can be used to fight fraud. Some techniques from robust statistics and digit analysis are presented to detect unusual observations that are likely associated with fraud. Two main challenges when building a supervised tool for fraud detection are the imbalance or skewness of the data and the various costs for different types of misclassification. We present techniques to solve these issues and focus on artificial and real datasets from a wide variety of fraud applications.","Introduction & Motivation,Imbalanced class distribution,Cost of not detecting fraud,Time features,Circular histogram,Suspicious timestamps,Frequency features,Frequency feature for one account,Frequency feature for multiple accounts,Recency features,Recency feature,Comparing frequency & recency","Dealing with imbalanced datasets,How to deal with class imbalance?,Visualizing patterns in the data,Random over-sampling,Random under-sampling,Shrinking the majority group,Combining ROS & RUS,Synthetic Over-sampling,Have you met SMOTE?,SMOTE,From dataset to detection model,Build your own detection model,True cost of fraud detection","Social network analytics,Analyzing a network,Overlapping edges,Fraud and social network analysis,Looking for homophily in a network,Visualizing node attributes,Social network based inference,Relational vs non-relational models,Relational neighbor classifier,Social network metrics,Degree, closeness & betweenness,Adding network features","Digit analysis using Benford's law,Benford's Law for first digit,Conformity of census data,Benford's Law for fraud detection,Conformity to Benford's Law,Fire insurance claims,Payments data set,Detecting univariate outliers,Computing robust z-scores,Boxplot,Detecting multivariate outliers,Multivariate outlier detection","Chester Ismay,Hadrien Lacroix,Sara Billen","Chapter 1 datasets,Chapter 2 datasets,Chapter 3 datasets,Chapter 4 datasets,Unsupervised Learning in R,Supervised Learning in R: Classification",,
120,Supply Chain Analytics in Python,4,16,48,"13,614",3600,"Supply Chain Analytics transforms supply chain activities from guessing, to ones that makes decision using data. An essential tool in Supply Chain Analytics is using optimization analysis to assist in decision making. According to Deloitte, 79% of organizations with high performing supply chains achieve revenue growth that is significantly above average. This course will introduce you to PuLP, a Linear Program optimization modeler written in Python. Using PuLP, the course will show you how to formulate and answer Supply Chain optimization questions such as where a production facility should be located, how to allocate production demand across different facilities, and more. We will explore the results of the models and their implications through sensitivity and simulation testing. This course will help you position yourself to improve the decision making of a supply chain by leveraging the power of Python and PuLP.","Basics of optimization,To LP, or to not IP?,Choosing exercise routine,Basics of PuLP modeling,Getting started with LpProblem(),Simple resource scheduling exercise,Using lpSum,Trying out lpSum,Logistics planning problem","Common constraint mistakes,Dependent demand constraint exercise,Constraint combination exercise,Capacitated plant location - case study P2,Constraints of case study exercise,Adding logical constraint in case study exercise,Solve the PuLP model,Choose the model status exercise,Solving production plan exercise,Sanity checking the solution,Reviewing model specification exercise,Sanity checking exercise","LpVariable dictionary function,Logistics planning problem 2,Traveling salesman problem (TSP),Example of a scheduling problem,Scheduling workers problem,Preventative maintenance scheduling,Capacitated plant location - case study P1,Review data for case study,Decision variables of case study,Objective function of case study,Logical constraints,Logical constraint exercise,Logical constraints exercise 2","Shadow price sensitivity analysis,Sensitivity analysis exercise,Shadow price and slack exercise pt1,Shadow price and slack exercise pt2,Capacitated plant location - case study P3,Solving the model case study exercise,Sensitivity case study exercise,Simulation testing solution,Simulation testing solution exercise,What is the risk exercise,Capacitated plant location - case study P4,Simulation testing capacitated model,Interpreting simulation results exercise,Final summary","Hadrien Lacroix,Mari Nazary",Data Manipulation with pandas,,
121,Data Analysis in Spreadsheets,3,,27,"73,663",2700,"This course will dig deeper into some of the core functionality of Google Sheets. There's a whole bunch of predefined functions we'll cover, like `SUM()` and `AVERAGE()`, and `VLOOKUP()`. We'll apply these techniques to do some analysis on your grades in school, look at performance statistics within a company, track monthly sales, and look at some real geographical information about the countries of the world.","First function - ROUND,Function composition - SQRT,Functions and ranges - MIN, MAX,Selecting ranges - SUM, AVERAGE, MEDIAN,Multiple arguments - RANK,Even more arguments - RANK,String manipulation - LEFT, RIGHT,String information - LEN, SEARCH,Combining strings - CONCATENATE,Date functions - WEEKDAY,Comparing dates ,Combining functions","Performance statistics,Flow control - IF,Nested logical functions - IF,Combining logical values - OR, WEEKDAY,Conditional counting - COUNTIF,Conditional aggregation - COUNTIF,Conditional sum - SUMIF,Conditional average - AVERAGEIF,Advanced conditions - AVERAGEIF,Filters - FILTER, DATEVALUE, MEDIAN,Grades in class,Automating the lookup - VLOOKUP,More about lookup - VLOOKUP,Horizontal lookup - HLOOKUP,Weighted average - SUMPRODUCT, HLOOKUP",,,Richie Cotton,Spreadsheet Fundamentals,,
122,Introduction to Spreadsheets,2,,23,"60,840",2300,"Spreadsheet software is one of the most popular and powerful tools in data analysis. Millions of people use tools like Google Sheets or Microsoft Excel on a daily basis. Even the most experienced data scientists often started their careers with spreadsheets and still use it to test assumptions or to look at data for the first time. In this course, you will learn the basics of spreadsheets by working with rows, columns, addresses, and ranges. You will create your own formulas and learn how to use references.","How it works,Rows and Columns,Cells,Ranges,Formulas,Exponents and parentheses,Percentages,Comparison operators,Data types: text and numbers,Data types: currency and date,Data types: logic","Cell references,Circular references,Copying references,Copying horizontally,Copying columns,Mathematical operators and references,Percentages and references,Comparison operators and references,Absolute references,Absolute references: row,Absolute references: column,Combine everything",,,Richie Cotton,,,
123,Advanced NLP with spaCy,5,15,55,"15,272",4450,"If you're working with a lot of text, you'll eventually want to know more about it. For example, what's it about? What do the words mean in context? Who is doing what to whom? What companies and products are mentioned? Which texts are similar to each other? In this course, you'll learn how to use spaCy, a fast-growing industry standard library for NLP in Python, to build advanced natural language understanding systems, using both rule-based and machine learning approaches.","Introduction to spaCy,Getting Started,Documents, spans and tokens,Lexical attributes,Statistical models,Model packages,Loading models,Predicting linguistic annotations,Predicting named entities in context,Rule-based matching,Using the Matcher,Writing match patterns","Processing pipelines,What happens when you call nlp?,Inspecting the pipeline,Custom pipeline components,Use cases for custom components,Simple components,Complex components,Extension attributes,Setting extension attributes (1),Setting extension attributes (2),Entities and extensions,Components with extensions,Scaling and performance,Processing streams,Processing data with context,Selective processing","Data Structures (1),Strings to hashes,Vocab, hashes and lexemes,Data Structures (2),Creating a Doc,Docs, spans and entities from scratch,Data structures best practices,Word vectors and similarity,Inspecting word vectors,Comparing similarities,Combining models and rules,Debugging patterns (1),Debugging patterns (2),Efficient phrase matching,Extracting countries and relationships","Training and updating models,Purpose of training,Creating training data (1),Creating training data (2),The training loop,Setting up the pipeline,Building a training loop,Exploring the model,Training best practices,Good data vs. bad data,Training multiple labels,Wrapping up","Mari Nazary,Adrián Soto","Natural Language Processing,Introduction to Natural Language Processing in Python",,
124,Writing Functions and Stored Procedures in SQL Server,4,16,57,"17,121",4700,"Take your SQL Server programming to the next level. First, we demystify how to manipulate datetime data by performing temporal exploratory data analysis with the Washington DC BikeShare transactional dataset. Then, you’ll master how to create, update, and execute user-defined functions and stored procedures. You will learn the proper context for each modular programming tool and best practices. In the final chapter, you will apply all of your new skills to solve a real-world business case identifying the New York City yellow taxi utilization for each borough, and which pickup locations should be scheduled for each driver shift.","Introduction to the course,Transactions per day,Seconds or no seconds?,Which day of week is busiest?,Find the outliers,Variables for datetime data,DECLARE & CAST,DECLARE a TABLE,INSERT INTO @TABLE,Date manipulation,Parameters matter with DATEDIFF,First day of month","Stored procedures,CREATE PROCEDURE with OUTPUT,Output parameters vs. Return values,Oh CRUD!,Use SP to INSERT,Use SP to UPDATE,Use SP to DELETE,Let's EXEC!,EXECUTE with OUTPUT parameter,EXECUTE with return value,EXECUTE with OUTPUT & return value,TRY & CATCH those errors!,Your very own TRY..CATCH,CATCH an error","Scalar user defined functions,What was yesterday?,One in one out,Multiple inputs one output,Table valued UDFs,Inline TVF,Multi statement TVF,UDFs in action,Execute scalar with select,EXEC scalar,Execute TVF into variable,Maintaining user defined functions,CREATE OR ALTER,Best practices","Case study EDA & imputation,Use EDA to find impossible scenarios,SPs vs UDFs,Mean imputation,Hot Deck imputation,Case study UDFs,CREATE FUNCTIONs,Test FUNCTIONs,Formatting tools,Logical weekdays with Hot Deck,Format for Germany,Case study stored procedures,NYC Borough statistics SP,NYC Borough statistics results,Pickup locations by shift,Pickup locations by shift results,Congratulations!","Chester Ismay,Amy Peterson","SQL Server Developer,SQL Server for Database Administrators,Trip Data,Bike Share Data,Functions for Manipulating Data in SQL Server",,
125,Generalized Linear Models in R,4,14,51,"13,799",4050,"Linear regression serves as a workhorse of statistics, but cannot handle some types of complex data. A generalized linear model (GLM) expands upon linear regression to include non-normal distributions including binomial and count data. Throughout this course, you will expand your data science toolkit to include GLMs in R. As part of learning about GLMs, you will learn how to fit model binomial data with logistic regression and count data with Poisson regression. You will also learn how to understand these results and plot them with ggplot2.","Limitations of linear models,Assumptions of linear models,Refresher on fitting linear models,Poisson regression,Fitting a Poisson regression in R,Comparing linear and Poisson regression,Intercepts-comparisons versus means,Basic lm() functions with glm(),Applying summary(), print(), and tidy() to glm,Extracting coefficients from glm(),Predicting with glm()","Poisson regression coefficients,Poisson link,lm vs. Poisson coefficients,Plotting Poisson regression,Poisson regression plotting,Understanding output from logistic regression,Understanding odds ratios,Extracting and interpreting odds-ratios,Odds-ratios & confidence intervals in the Tidyverse,ggplot2 and binomial regression,Default trend lines,Methods for trend lines,Comparing probits and logits","Overview of logistic regression,Fitting a logistic regression,Examining & interpreting logistic regression outputs,Bernoulli versus binomial distribution,Bernoulli versus binomial,Simulating binary data,Long-form logistic regression input,Wide-form input logistic regression,Comparing logistic regression outputs,Link functions-Probit compared to logit,Probit versus logit,Fitting probits and logits,Simulating a logit,Simulating a probit","Multiple logistic regression,Fitting a multiple logistic regression,Building two models,Comparing regression outputs,Comparing variable order,Formulas in R,Multiple slopes,Intercepts,Multiple intercepts,Assumptions of multiple logistic regression,Simpson's paradox,Non-linear logistic regression,Conclusion","David Campos,Chester Ismay,Shon Inouye","Bus Commuter dataset,Intermediate Regression in R",,
126,Linear Algebra for Data Science in R,4,15,56,"10,934",4000,"Linear algebra is one of the most important set of tools in applied mathematics and data science. In this course, you’ll learn how to work with vectors and matrices, solve matrix-vector equations, perform eigenvalue/eigenvector analyses and use principal component analysis to do dimension reduction on real-world datasets. All analyses will be performed in R, one of the world’s most-popular programming languages.","Motivations,Creating Vectors in R,The Algebra of Vectors,Creating Matrices in R,Matrix-Vector Operations,Matrix-Vector Compatibility,Matrix Multiplication as a Transformation,Reflections,Matrix-Matrix Calculations,Matrix Multiplication Compatibility,Matrix Multiplication - Order Matters,Intro to The Matrix Inverse","Intro to Eigenvalues and Eigenvectors,Interpreting Scalar Multiplication,Scaling Different Axes,Definition of Eigenvalues and Eigenvectors,Why ""Eigen""?,Finding Eigenvalues in R,Scalar Multiplies of Eigenvectors are Eigenvectors,Computing Eigenvalues and Eigenvectors in R,How Many Eigenvalues?,Verifying the Math on Eigenvalues,Computing Eigenvectors in R,Some More on Eigenvalues and Eigenvectors,Eigenvalue Ordering,Markov Models for Allele Frequencies","Motivation for Solving Matrix-Vector Equations,The Meaning of Ax = b,Exploring WNBA Data,Matrix-Vector Equations - Some Theory,Why is a Matrix Not Invertible?,Understanding a Linear System's Three Outcomes,Understanding the Massey Matrix,Adjusting the Massey Matrix,Inverting the Massey Matrix,Solving Matrix-Vector Equations,An Analogy with Regular Algebra,2017 WNBA Ratings!,Who Was the Champion?,Other Considerations for Matrix-Vector Equations,Other Methods for Matrix-Vector Equations,Alternatives to the Regular Matrix Inverse","Intro to the Idea of PCA,What Does ""Big Data"" Mean?,Finding Redundancies,The Linear Algebra Behind PCA,Covariance Explored,Standardizing Your Data,Variance/Covariance Calculations,Eigenanalyses of Combine Data,Where's the Variance?,Performing PCA in R,Scaling Data Before PCA,Summarizing PCA in R,Does Subsetting Change Things?,Wrap-Up","David Campos,Chester Ismay,Shon Inouye","NFL Player dataset,WNBA Massey Matrix dataset,WNBA Point Differentials dataset,Introduction to R",,
127,Image Processing with Keras in Python,4,13,45,"27,722",3650,"Deep learning methods use data to train neural network algorithms to do a variety of machine learning tasks, such as classification of different classes of objects. Convolutional neural networks are deep learning algorithms that are particularly powerful for analysis of images. This course will teach you how to construct, train and evaluate convolutional neural networks. You will also learn how to improve their ability to learn from data, and how to interpret the results of the training.","Introducing convolutional neural networks,Images as data: visualizations,Images as data: changing images,Classifying images,Using one-hot encoding to represent images,Evaluating a classifier,Classification with Keras,Build a neural network,Compile a neural network,Fitting a neural network model to clothing data,Cross-validation for neural network evaluation","Going deeper,Creating a deep learning network,Train a deep CNN to classify clothing images,What is special about a deep network?,How many parameters?,How many parameters in a CNN?,How many parameters in a deep CNN?,Pooling operations,Write your own pooling operation,Keras pooling layers,Train a deep CNN with pooling to classify images","Convolutions,One dimensional convolutions,Image convolutions,Defining image convolution kernels,Implementing image convolutions in Keras,Convolutional network for image classification,Training a CNN to classify clothing types,Evaluating a CNN with test data,Tweaking your convolutions,Add padding to a CNN,Add strides to a convolutional network,Calculate the size of convolutional layer output","Tracking learning,Plot the learning curves,Using stored weights to predict in a test set,Regularization,Adding dropout to your network,Add batch normalization to your network,Interpreting the model,Extracting a kernel from a trained network,Shape of the weights,Visualizing kernel responses,Next steps","Sumedh Panchadhar,Lore Dirick,Eunkyung Park","Image Processing,Machine Learning Scientist,Introduction to Deep Learning in Python",,
128,Intermediate Spreadsheets,4,12,48,"32,821",4150,"This course will expand your Google Sheets vocabulary. You'll dive deeper into data types, practice manipulating numeric and logical data, explore missing data and error types, and calculate some summary statistics. As you go, you'll explore datasets on 100m sprint world records, asteroid close encounters, benefit claims, and butterflies.","Data types for data science,What IS*() the data type?,Checking rarer data types,Finding missing data,Dteectnig bdaly tpyed dtaa,Convert or die!,Making numbers while the sun shines,How the 104% live,Converting logical values to numbers,Preaching to the CONVERT()ed","Logical operations,Logical operations are hard... NOT!,AND now for something completely different,Yea OR nay,Flow control,IF only,Lots of IFS,SWITCH it on!,Blanks, missing values, & errors,Blankety blank,Going missing,Errors and omissions,What's the problem?","Common data transformations,Logarithmic transformations,Exponential transformations,Square root transformations,Rounding and formatting numbers,Round and round,From floor to ceiling,Rounding negative numbers,Generating random numbers,Generating uniform random numbers,Generating random numbers from other distributions","Cell addresses,Working with cell addresses,From addresses to values,Finding nearby cells with offsets,Local addresses,Lookups & matching,A VLOOKUP refresher,Sorted!
,Matching values,Bringing it all together,Advanced filtering,Conditional summary statistics,Simple imputation,Congratulations!",,"Spreadsheet Fundamentals,Data Analysis in Spreadsheets",,
129,Designing and Analyzing Clinical Trials in R,4,15,48,"3,918",4000,"Clinical trials are scientific experiments that are conducted to assess whether treatments are effective and safe. They are used by a variety of organizations, including pharmaceutical companies for drug development. Biostatisticians play a key role in ensuring the success of a clinical trial. In this course you will gain an overview of the important principles and a practical introduction to commonly used statistical analyses. This course would be valuable for data analysts, medical students, clinicians, medical researchers and others interested in learning about the design and analysis of clinical trials.","Fundamentals,Data exploration,Patient characteristics,Types of data and endpoints,Exploration of continuous endpoints,Exploration of binary endpoints,Exploration of composite endpoints,Basic statistical analysis,Comparing means,Comparing distributions,Comparing proportions","Introduction to sample size and power,Sample size for comparing means,Sample size and treatment difference,Sample size for comparing proportions,Sample size adjustments,Sample size for unequal groups,Sample size for one-sided tests,Interim analyses and stopping rules,Stopping rules,Sample size adjustments for interim analyses,Sample size for alternative trial designs,Sample size for equivalence binary outcomes,Sample size for equivalence continuous outcomes","Randomization methods,Simple randomization,Block randomization,Stratified randomization,Crossover, factorial and cluster randomized trials,Factorial designs: exploring data,Factorial designs: generating odds ratios,Equivalence and non-inferiority trials,Equivalence trials,Interpreting results from equivalence trials,Bioequivalence trials,Concentration profiles,Pharmacokinetic parameters","Regression analysis,Multiple linear regression,Model prediction,Multiple logistic regression,Analysis sets, subgroups and interactions,Analysis sets,Interaction,Multiplicity of data,Subgroups,Composite endpoints,Conclusion","David Campos,Richie Cotton,Shon Inouye","Acupuncture dataset,Fact dataset,PK dataset,Introduction to Statistics in R",,
130,Working with Geospatial Data in Python,4,16,53,"8,000",4500,"A good proportion of the data out there in the real world is inherently spatial. From the population recorded in the national census, to every shop in your neighborhood, the majority of datasets have a location aspect that you can exploit to make the most of what they have to offer. This course will show you how to integrate spatial data into your Python Data Science workflow. You will learn how to interact with, manipulate and augment real-world data using their geographic dimension. You will learn to read tabular spatial data in the most common formats (e.g. GeoJSON, shapefile, geopackage) and visualize them in maps. You will then combine different sources using their location as the bridge that puts them in relation to each other. And, by the end of the course, you will be able to understand what makes geographic data unique, allowing you to transform and repurpose them in different contexts.","Geospatial data,Restaurants in Paris,Adding a background map,Introduction to GeoPandas,Explore the Paris districts (I),Explore the Paris districts (II),The Paris restaurants as a GeoDataFrame,Exploring and visualizing spatial data,Visualizing the population density,Using pandas functionality: groupby,Plotting multiple layers","Coordinate Reference Systems,Geographic vs projected coordinates,Working with coordinate systems in GeoPandas,Projecting a GeoDataFrame,Projecting a Point,Calculating distance in a projected CRS,Projecting to Web Mercator for using web tiles,Spatial operations: creating new geometries,Exploring a Land Use dataset,Intersection of two polygons,Intersecting a GeoDataFrame with a Polygon,Overlaying spatial datasets,Overlay of two polygon layers,Inspecting the overlay result","Shapely geometries and spatial relationships,Creating a Point geometry,Shapely's spatial methods,Spatial relationships with GeoPandas,In which district in the Eiffel Tower located?,How far is the closest restaurant?,The spatial join operation,Paris: spatial join of districts and bike stations,Map of tree density by district (1),Map of tree density by district (2),Choropleths,Equal interval choropleth,Quantiles choropleth,Compare classification algorithms","Introduction to the dataset,Import and explore the data,Convert to common CRS and save to a file,Styling a multi-layered plot,Additional spatial operations,Buffer around a point,Mining sites within national parks,Applying custom spatial operations,Finding the name of the closest National Park,Applying a custom operation to each geometry,Working with raster data,Import and plot raster data,Extract information from raster layer,The end","Mari Nazary,Sara Billen","Paris,Mining,Data Manipulation with pandas",,
131,Web Scraping in Python,4,17,56,"52,609",4500,"The ability to build tools capable of retrieving and parsing information stored across the internet has been and continues to be valuable in many veins of data science. In this course, you will learn to navigate and parse html code, and build tools to crawl websites automatically. Although our scraping will be conducted using the versatile Python library scrapy, many of the techniques you learn in this course can be applied to other popular Python libraries as well, including BeautifulSoup and Selenium. Upon the completion of this course, you will have a strong mental model of html structure, will be able to build tools to parse html code and access desired information, and create a simple scrapy spiders to crawl the web at scale.","Web Scraping Overview,Web-scraping is not nonsense!,HyperText Markup Language,HTML tree wordy navigation,From Tree to HTML,Attributes,Keep it Classy,Finding href,Crash Course in XPath,Where am I?,It's Time to P,A classy span","From XPath to CSS,The (X)Path to CSS Locators,Get an ""a"" in this Course,The CSS Wildcard,CSS Attributes and Text Selection,You've been `href`ed,Top Level Text,All Level Text,Respond Please!,Reveal By Response,Responding with Selectors,Selecting from a Selection,Survey,Titular,Scraping with Children","XPathology,Counting Elements in the Wild,Body Appendages,Choose DataCamp!,Off the Beaten XPath,Where it's @,Check your Class,Hyper(link) Active,Secret Links,Selector Objects,XPath Chaining,Divvy Up This Exercise,The Source of the Source,Course Class by Inspection,Requesting a Selector","Your First Spider,Inheriting the Spider,Hurl the URLs,Start Requests,Self Referencing is Classy,Starting with Start Requests,Parse and Crawl,Pen Names,Crawler Time,Capstone,Time to Run,DataCamp Descriptions,Capstone Crawler,The Finale","David Campos,Mari Nazary,Shon Inouye","Python Programmer,DataCamp webpage HTML,Intermediate Python",,
132,Introduction to Data Visualization with ggplot2,4,14,52,"82,976",4300,"The ability to produce meaningful and beautiful data visualizations is an essential part of your skill set as a data scientist. This course, the first R data visualization tutorial in the series, introduces you to the principles of good visualizations and the grammar of graphics plotting concepts implemented in the ggplot2 package. ggplot2 has become the go-to tool for flexible and professional plots in R. Here, we’ll examine the first three essential layers for making a plot - Data, Aesthetics and Geometries. By the end of the course you will be able to make complex exploratory plots.","Introduction,Explore and explain,Drawing your first plot,Data columns types affect plot types,The grammar of graphics,Mapping data columns to aesthetics,Understanding variables,ggplot2 layers,Adding geometries,Changing one geom or every geom,Saving plots as variables","Scatter plots,Overplotting 1: large datasets,Overplotting 2: Aligned values,Overplotting 3: Low-precision data,Overplotting 4: Integer data,Histograms,Drawing histograms,Positions in histograms,Bar plots,Position in bar and col plots,Overlapping bar plots,Bar plots: sequential color palette,Line plots,Basic line plots,Multiple time series","Visible aesthetics,All about aesthetics: color, shape and size,All about aesthetics: color vs. fill,All about aesthetics: comparing aesthetics,Aesthetics for categorical & continuous variables,Using attributes,All about attributes: color, shape, size and alpha,All about attributes: conflicts with aesthetics,Going all out,Modifying aesthetics,Updating aesthetic labels,Setting a dummy aesthetic,Aesthetics best practices,Appropriate mappings","Themes from scratch,Moving the legend,Modifying theme elements,Modifying whitespace,Theme flexibility,Built-in themes,Exploring ggthemes,Setting themes,Publication-quality plots,Effective explanatory plots,Using geoms for explanatory plots,Using annotate() for embellishments","Richie Cotton,Shon Inouye,Jonathan Ng","Data Analyst,Data Scientist,Data Visualization,Diamonds,Iris,Recession,Fish,Introduction to the Tidyverse",,
133,Machine Learning for Marketing in Python,4,16,53,"8,928",4450,"The rise of machine learning (almost sounds like ""rise of the machines""?) and applications of statistical methods to marketing have changed the field forever. Machine learning is being used to optimize customer journeys which maximize their satisfaction and lifetime value. This course will give you the foundational tools which you can immediately apply to improve your company’s marketing strategy. You will learn how to use different techniques to predict customer churn and interpret its drivers, measure, and forecast customer lifetime value, and finally, build customer segments based on their product purchase patterns. You will use customer data from a telecom company to predict churn, construct a recency-frequency-monetary dataset from an online retailer for customer lifetime value prediction, and build customer segments from product purchase data from a grocery shop.","Why use ML for marketing? Strategies and use cases,Identify supervised learning examples,Supervised vs. unsupervised learning,Preparation for modeling,Investigate the data,Separate numerical and categorical columns,Encode categorical and scale numerical variables,ML modeling steps,Split data to training and testing,Fit a decision tree,Predict churn with decision tree","Customer Lifetime Value (CLV) basics,Build retention and churn tables,Explore retention and churn,Calculating and projecting CLV,Calculate basic CLV,Calculate granular CLV,Calculate traditional CLV,Data preparation for purchase prediction,Build features,Define target variable,Split data to training and testing,Predicting customer transactions,Predict next month transactions,Measure model fit,Explore model coefficients","Churn prediction fundamentals,Explore churn rate and split data,Separate features and target variable,Predict churn with logistic regression,Fit logistic regression model,Fit logistic regression with L1 regularization,Identify optimal L1 penalty coefficient,Predict churn with decision trees,Fit decision tree model,Identify optimal tree depth,Identify and interpret churn drivers,Explore logistic regression coefficients,Break down decision tree rules","Customer and product segmentation basics,Explore customer product purchase dataset,Understand differences in variables,Data preparation for segmentation,Unskew the variables,Normalize the variables,Build customer and product segmentation,Determine the optimal number of clusters,Build segmentation with k-means clustering,Alternative segmentation with NMF,Visualize and interpret segmentation solutions,K-means segmentation averages,NMF segmentation averages,Congratulations!",Adel Nehme,"Marketing Analytics,Telecom Dataset,Supervised Learning with scikit-learn",,
134,Introduction to Natural Language Processing in R,4,15,47,"5,319",3750,"As with any fundamentals course, Introduction to Natural Language Processing in R is designed to equip you with the necessary tools to begin your adventures in analyzing text. Natural language processing (NLP) is a constantly growing field in data science, with some very exciting advancements over the last decade. This course will cover the basics of these topics and prepare you for expanding your analysis capabilities. We dive into regular expressions, topic modeling, named entity recognition, and others, all while providing thorough examples that can be used to kick start your future analysis.","Regular expression basics,Practicing syntax with grep,Exploring regular expression functions.,Tokenization,tidytext functions,Tokenization: sentences,Text cleaning basics,Text preprocessing: remove stop words,Text preprocessing: Stemming","Preparing text for modeling,Data preparation,Removing sparse terms,Classification modeling,Classification modeling example,Confusion matrices,TFIDF tibble vs dtm,Introduction to topic modeling,LDA practice,Assigning topics to documents,LDA in practice,Testing perplexity,Reviewing LDA results","Understanding an R corpus,Explore an R corpus,Creating a tibble from a corpus,Creating a corpus,The bag-of-words representation,Practice BoW,BoW Example,Sparse matrices,The TFIDF,Manual calculations,TFIDF Practice,Cosine Similarity,An example of failing at text analysis,Cosine similarity example","Sentiment analysis,tidytext lexicons,Sentiment scores,Sentiment and emotion,Word embeddings,h2o practice,word2vec,Additional NLP analysis,Reviewing methods #1,Review methods #2,Conclusion","Chester Ismay,Adel Nehme,Mona Khalil","Animal Farm,Russian Troll tweets,Intermediate R,Introduction to the Tidyverse",,
135,Introduction to TensorFlow in R,4,15,51,"4,003",4150,"TensorFlow is a state-of-the-art machine learning framework that specializes in the ability to develop deep learning neural networks. And now, it's available in R! This course will walk you through the basics of using TensorFlow in R. From simple linear regressions to more complex deep learning neural networks (which perform extremely well with BIG datasets) , you'll be introduced to both the basics of TensorFlow and higher-level APIs such as Keras and TFEstimators. We'll put your new-found skills to the test by exploring whether there is a predictable relationship between beer consumption and weather, and find out if we can accurately build a deep neural network to help predict whether a banknote is forged or genuine based on image data.","What is TensorFlow?,Translating a dataflow graph,Starting with sessions,TensorFlow syntax, variables, and placeholders,Variables, constants, and placeholders, oh my!,Create tensors yourself,TensorBoard: visualizing TensorFlow models,Creating a single-step TensorBoard,Creating a multi-step TensorBoard,Sessions, constants, and variables in TensorFlow","A gentle introduction to neural networks,Calculating an output,Create a deep neural network model with Keras API,Defining your arguments,Defining and compiling your model,Fitting your model,Evaluate, predict and visualize your model,Find the accuracy of your model,Predict the future!,Exploring a DNN classifier in TensorBoard,Create a DNN using the Estimators API,Go with the (work)flow,DNN classifier training using Estimators,DNN classifier using Keras API","Core API: linear regression,Choosing the correct API,Can you define your x and y data?,Weights, biases, and equations,Core API: linear regression part II,Defining a cost function,Launching the graph and initializing the variables,Core API: linear regression part III,Training your model,Evaluating your model,Estimators API: multiple linear regression,Defining feature columns,Choosing a model and input function,Training and evaluating the model,Visualizing the linear regression","L2 Regularization Technique using Keras,Defining the regularizer,Compiling and fitting the model,Evaluating the L2 regularization model,Dropout technique using TFEstimators,Defining the feature columns and input function,Defining the dropout clause,Evaluating the dropout model,Hyperparameter tuning with tfruns,Hyperparameter tuning for a DNN model,Multiple hyperparameter tuning,So long and thanks for all the fish","Maggie Matsui,Mona Khalil","Banknote Authentication,Student Grades,Machine Learning with caret in R",,
136,Credit Risk Modeling in Python,4,15,57,"12,034",4850,"If you've ever applied for a credit card or loan, you know that financial firms process your information before making a decision. This is because giving you a loan can have a serious financial impact on their business. But how do they make a decision? In this course, you will learn how to prepare credit application data. After that, you will apply machine learning and business rules to reduce risk and ensure profitability. You will use two data sets that emulate real credit applications while focusing on business value. Join me and learn the expected value of credit risk modeling!","Understanding credit risk,Explore the credit data,Crosstab and pivot tables,Outliers in credit data,Finding outliers with cross tables,Visualizing credit outliers,Risk with missing data in loan data,Replacing missing credit data,Removing missing data,Missing data intuition","Gradient boosted trees with XGBoost,Trees for defaults,Gradient boosted portfolio performance,Assessing gradient boosted trees,Column selection for credit risk,Column importance and default prediction,Visualizing column importance,Column selection and model performance,Cross validation for credit models,Cross validating credit models,Limits to cross-validation testing,Cross-validation scoring,Class imbalance in loan data,Undersampling training data,Undersampled tree performance,Undersampling intuition","Logistic regression for probability of default,Logistic regression basics,Multivariate logistic regression,Creating training and test sets,Predicting the probability of default,Changing coefficients,One-hot encoding credit data,Predicting probability of default,Credit model performance,Default classification reporting,Selecting report metrics,Visually scoring credit models,Model discrimination and impact,Thresholds and confusion matrices,How thresholds affect performance,Threshold selection","Model evaluation and implementation,Comparing model reports,Comparing with ROCs,Calibration curves,Credit acceptance rates,Acceptance rates,Visualizing quantiles of acceptance,Bad rates,Acceptance rate impact,Credit strategy and minimum expected loss,Making the strategy table,Visualizing the strategy,Estimated value profiling,Total expected loss,Course wrap up","Ruanne Van Der Walt,Mona Khalil","Applied Finance,Raw credit data,Clean credit data (outliers and missing data removed),Credit data (ready for modeling),Introduction to Python for Finance,Intermediate Python",,
137,Transactions and Error Handling in SQL Server,4,14,52,"10,480",3850,"It is critical to know how to handle errors and manage transactions when programming SQL scripts. Unhandled errors can be very harmful and can cause unexpected situations, such as inconsistent data in your database, or even worse, errors can lead you to make wrong business decisions. In this course, you will learn how to handle errors and discover how to manage transactions in case of an error. Additionally, you will study what happens when two or more people interact at the same time with the same data. You will practice all these concepts using two datasets, one of them based on bank accounts and the other one on an electric bike store.","Welcome!,The TRY...CATCH syntax,Your first error-handling  script,Nesting TRY...CATCH constructs,Error anatomy and uncatchable errors,Anatomy review,Correcting compilation errors,Giving information about errors,Error function syntax,Using error functions,Using error functions in a nested TRY...CATCH","Transactions,Transaction statements,Correcting a transaction,Rolling back a transaction if there is an error,Choosing when to commit or rollback a transaction,@@TRANCOUNT and savepoints,Modifiers of the @@TRANCOUNT value,Checking @@TRANCOUNT in a TRY...CATCH construct,Using savepoints,XACT_ABORT & XACT_STATE,XACT_ABORT behavior,XACT_ABORT and THROW,Doomed transactions","RAISERROR,RAISERROR syntax,CATCHING the RAISERROR,THROW,THROW with or without parameters,THROW without parameters,Executing a stored procedure that throws an error,THROW with parameters,Customizing error messages in the THROW statement,Ways of customizing error messages,Concatenating the message,FORMATMESSAGE with message string,FORMATMESSAGE with message number","Transaction isolation levels,Concurrency phenomena,Using the READ UNCOMMITTED isolation level,READ COMMITTED & REPEATABLE READ,Choosing the correct isolation level,Prevent dirty reads,Preventing non-repeatable reads,SERIALIZABLE isolation level,Prevent phantom reads in a table,Prevent phantom reads just in some rows,SNAPSHOT,Setting READ COMMITTED SNAPSHOT to ON,Comparing WITH (NOLOCK) & READ UNCOMMITTED,Avoid being blocked,Congratulations!","Mona Khalil,Marianna Lamnina","SQL Server Developer,SQL Server for Database Administrators,Electric bike store dataset and Bank accounts dataset,Intermediate SQL Server",,
138,Practicing Machine Learning Interview Questions in R,4,16,59,"2,181",5050,"Preparing for a Machine Learning (ML) interview could be quite challenging. Where to start? What topics to focus on? Theory or practice? Well, fear not! In this course, you will learn to answer 30 non-trivial questions that often pop up in ML interviews. These questions revolve around seven important topics: data preprocessing, data visualization, supervised learning, unsupervised learning, model ensembling, selection, and evaluation. You will practice these concepts while learning to predict the rating of an Android app or segmenting mall customers based on their purchasing behaviors. Keep in mind -- this course is meant to be more challenging than your average DataCamp course. Make sure to complete your prerequisite courses so you can gain the most out of the topics we will cover!","Data normalization,Understanding when to normalize data,Normalizing features,Handling missing data,Exploring and summarizing missing data,Show me your missingness,Imputing missing data,Evaluating imputation models,Detecting anomalies in data,Univariate outlier detection: the IQR rule,The KNN distance score,The LOF score","K-means clustering,Checking K-means assumptions,Using the elbow method,Interpreting your clustering results,Clustering algorithms,Comparing clustering methods: internal measures,Comparing clustering methods: stability measures,Visualizing cluster prototypes,Feature selection,Types of feature selection methods,Removing near-zero-variance features,Removing correlated features,Feature extraction,PCA to the rescue,LDA to the rescue","Interpretable models,Interpreting linear regression,Interpreting decision tree,Regularization,Ridge regression,Lasso regression,Elastic net regression,Bias and variance,Bias-variance analysis,Reducing avoidable bias,Building ensemble models,Recruiting the base learners,Evaluating base learners' performance,Stacking the base learners,Predicting on test data","Model evaluation,Evaluating classification models,Evaluating regression models,Evaluating clustering methods,Handling imbalanced data,Checking for class imbalance,Applying subsampling in each resample,Evaluating model performance,Hyperparameter tuning,Default grid search in caret,Customizing the grid search,Random search,Random Forests or Gradient Boosted Trees?,The Random Forest model,The GBM model,Evaluating GBM and RF predictions on test data,You made it!","Maggie Matsui,Sara Billen,Mona Khalil","Fifa Sample,Google Play Store Apps,Car Fuel Consumption,Machine Learning with caret in R,Unsupervised Learning in R",,
139,Introduction to Portfolio Analysis in Python,4,15,52,"10,107",4200,"Have you ever had wondered whether an investment fund is actually a good investment? Or compared two investment options and asked what the difference between the two is? What does the risk indicator of these funds even mean? Or do you frequently work with financial data in your daily job and you want to get an edge? In this course, you’re going to get familiar with the exciting world of investing, by learning about portfolios, risk and return, and how to critically analyze them. By working on actual historical stock data, you’ll learn how to calculate meaningful measures of risk, how to break-down performance, and how to calculate an optimal portfolio for the desired risk and return trade-off. After this course, you’ll be able to make data-driven decisions when it comes to investing and have a better understanding of investment portfolios.","Welcome to Portfolio Analysis!,Why invest in portfolios,The effect of diversification,Portfolio returns,Portfolio losses and gaining it back,Calculate mean returns,Portfolio cumulative returns,Measuring risk of a portfolio,Portfolio variance,Standard deviation versus variance","Comparing against a benchmark,Active return,Industry attribution,Risk factors,Size factor,Momentum factor,Value factor,Factor models,Fama French factor correlations,Linear regression model,Fama French Factor model,Portfolio analysis tools,Performance tear sheet,Industry exposures with Pyfolio","Annualized returns,Annualizing portfolio returns,Comparing annualized rates of return,Risk adjusted returns,Interpreting the Sharpe ratio,S&P500 Sharpe ratio,Portfolio Sharpe ratio,Non-normal distribution of returns,Skewness of the S&P500,Calculating skewness and kurtosis,Comparing distributions of stock returns,Alternative measures of risk,Sortino ratio,Maximum draw-down portfolio","Modern portfolio theory,Understanding the efficient frontier,Calculating expected risk and returns,PyPortfolioOpt risk functions,Optimal portfolio performance,Maximum Sharpe vs. minimum volatility,Portfolio optimization: Max Sharpe,Minimum volatility optimization,Comparing max Sharpe to min vol,Alternative portfolio optimization,Exponentially weighted returns and risk,Comparing approaches,Changing the span,Recap","Ruanne Van Der Walt,Hillary Green-Lerman","Finance Fundamentals,Small portfolio,S&P500,Large portfolio,Factors for portfolio returns,Portfolio factors,Manipulating Time Series Data in Python,Introduction to Python for Finance",,
140,Building Data Engineering Pipelines in Python,4,14,52,"17,898",3950,"In any data-driven company, you will undoubtedly cross paths with data engineers. Among other things, they facilitate some of your work by making data readily available to everyone within the organization, and possibly in bringing machine learning models into production. One way to speed up this process is through building an understanding of what it means to bring processes into production and what features are of high-grade code. In this course, we’ll be looking at various data pipelines the data engineer is building, and how some of the tools he or she is using can help you in getting your models into production or run repetitive tasks consistently and efficiently.

In this course, we illustrate common elements of data engineering pipelines. In Chapter 1, you will learn how to ingest data. Chapter 2 will go one step further with cleaning and transforming data. In Chapter 3, you will learn how to safely deploy code. Finally, in Chapter 4 you will schedule complex dependencies between applications.

Building Data Engineering Pipelines covers new technologies and material, so we recommend that you have a strong understanding of the prerequisites to get the most out of this course.","Components of a data platform,Dashboards providing business value,Snapshots in a data lake,The data catalog,Introduction to data ingestion with Singer,Working with JSON,Specifying the schema of the data,Running an ingestion pipeline with Singer,Properly propagating state,Communicating with an API,Streaming records,Chain taps and targets","On the importance of tests,Regression errors,Characteristics of tests,Writing unit tests for PySpark,Creating in-memory DataFrames,Making a function more widely reusable,Continuous testing,A high-level view on CI/CD,Understanding the output of pytest,Improving style guide compliancy","Basic introduction to PySpark,Reading a CSV file,Defining a schema,Cleaning data,Sensible data types,Removing invalid rows,Filling unknown data,Conditionally replacing values,Transforming data with Spark,Selecting and renaming columns,Grouping and aggregating data,Packaging your application,Creating a deployable artifact,Submitting your Spark job,Debugging simple errors,Verifying your pipeline’s output","Modern day workflow management,Specifying the DAG schedule,Setting up daily tasks,Specifying operator dependencies,Building a data pipeline with Airflow,Preparing a DAG for daily pipelines,Scheduling bash scripts with Airflow,Scheduling Spark jobs with Airflow,Scheduling the full data pipeline with Airflow,Deploying Airflow,Airflow’s executors,Recovering from deployed but broken DAGs,Running tests on Airflow,Final thoughts","Hadrien Lacroix,Hillary Green-Lerman","prices.csv,purchased.csv,ratings.csv,ratings_with_incomplete_rows.csv,ratings_with_invalid_rows.csv,Introduction to Shell,Intermediate Importing Data in Python,Introduction to Data Engineering,Introduction to PySpark,Unit Testing for Data Science in Python",,
141,Spoken Language Processing in Python,4,14,53,"4,392",4400,"We learn to speak far before we learn to read. Even in the digital age, our main method of communication is speech. Spoken Language Processing with Python will help you load, transform and transcribe audio files. You'll start by seeing what raw audio looks like in Python. And then finish by working through an example business use case, transcribing and classifying phone call data.","Introduction to audio data in Python,The right frequency,Importing an audio file with Python,Converting sound wave bytes to integers,The right data type,Bytes to integers,Finding the time stamps,Visualizing sound waves,Staying consistent,Processing audio data with Python","Introduction to PyDub,Import an audio file with PyDub,Play an audio file with PyDub,Audio parameters with PyDub,Adjusting audio parameters,Manipulating audio files with PyDub,Turning it down... then up,Normalizing an audio file with PyDub,Chopping and changing audio files,Splitting stereo audio to mono with PyDub,Converting and saving audio files with PyDub,Exporting and reformatting audio files,Manipulating multiple audio files with PyDub,An audio processing workflow","SpeechRecognition Python library,Pick the wrong speech_recognition API,Using the SpeechRecognition library,Using the Recognizer class,Reading audio files with SpeechRecognition,From AudioFile to AudioData,Recording the audio we need,Dealing with different kinds of audio,Different kinds of audio,Multiple Speakers 1,Multiple Speakers 2,Working with noisy audio","Creating transcription helper functions,Converting audio to the right format,Finding PyDub stats,Transcribing audio with one line,Using the helper functions you've built,Sentiment analysis on spoken language text,Analyzing sentiment of a phone call,Sentiment analysis on formatted text,Named entity recognition on transcribed text,Named entity recognition in spaCy,Creating a custom named entity in spaCy,Classifying transcribed speech with Sklearn,Preparing audio files for text classification,Transcribing phone call excerpts,Organizing transcribed phone call data,Create a spoken language text classifier,Congratulations!","Maggie Matsui,Adrián Soto,Hillary Green-Lerman","Natural Language Processing,Pre- and post-purchase audio snippet transcriptions,Intermediate Python,Introduction to Natural Language Processing in Python,Machine Learning with scikit-learn",,
142,Machine Translation in Python,4,16,58,"2,934",4950,"The need to pack a bilingual dictionary for your European holiday or keeping one on your desk to complete your foreign language homework is a thing of the past. You just hop on the internet and make use of a language translation service to quickly understand what the street sign means or finding out how to greet and thank a foreigner in their language. Behind the language translation services are complex machine translation models. Have you ever wondered how these models work? This course will allow you to explore the inner workings of a machine translation model. You will use Keras, a powerful Python-based deep learning library, to implement a translation model. You will then train the model to perform an English to French translation, and you will be shown techniques to improve your model. At the end of this course, you would have developed an in-depth understanding of machine translation models and appreciate them even more!","Introduction to machine translation,Understanding one-hot vectors,Part 1: Exploring the to_categorical() function,Part 2: Exploring the to_categorical() function,Encoder decoder architecture,Part 1: Text reversing model -  Encoder,Part 2: Text reversing model -  Encoder,Complete text reversing model,Understanding sequential models,Part 1: Understanding GRU models,Part 2: Understanding GRU models,Understanding sequential model output","Part 1: Preprocessing the Data,Tokenizing sentences with Keras,Controlling the vocabulary with the Tokenizer,Part 2: Preprocessing the Data,Adding special tokens,Padding sentences,Reversing sentences,Training the NMT model,Training the model,Splitting data to training and validation sets,Training the model with validation,Generating translations with the NMT,Part 1: Treasure hunt,Part 2: Treasure hunt,Generating English-French translations","Implementing the encoder,Part 1: Exploring the dataset,Part 2: Exploring the dataset,Defining the encoder,Implementing the decoder,Understanding the RepeatVector layer,The shape of a RepeatVector layer output,Defining the decoder,Dense and TimeDistributed layers,Part 1: Enter to win amazing prizes,Part 2: Let's play a few more games,Implementing the full encoder decoder model,Part 1: Defining the full model,Part 2: Defining the full model","Introduction to Teacher Forcing,Defining the Teacher Forcing model layers,Defining the Teacher Forcing model,Preprocessing data,Training the model with Teacher Forcing,Training the model,Splitting training and validation data,Training the model with validation,Generating translations from the model,Defining the decoder of the inference model,Link between the trained and inference model,Generating translations,Using word embedding for machine translation,Measuring word vector similarity,Defining the embedding model,Training the word embedding based model,Wrap-up and the final showdown","Ruanne Van Der Walt,Mona Khalil","Deep Learning for NLP,French vocabulary,English vocabulary,Introduction to Deep Learning in Python",,
143,Recurrent Neural Networks for Language Modeling in Python,4,16,54,"9,921",4500,"Machine Learning models are based on numerical values to make predictions/classification, but how can computers deal with text data? With the huge increase of available text data, applications such as automatic document classification, text generation, and neural machine translation became possible. In this course, you will learn how to use Recurrent Neural Networks to classify text (binary and multiclass), generate phrases simulating the character Sheldon from The Big Bang Theory TV Show, and translate Portuguese sentences into English. Are you ready to start your journey into Language Models using Keras and Python? Dive in!","Introduction to the course,Keras models: Sequential,Keras models: Model,Comparing the number of parameter of RNN and ANN,Sentiment analysis,Sequence to sequence models,Introduction to language models,Getting used to text data,Preparing text data for model input,Transforming new text,Introduction to RNN inside Keras,Keras models,Keras preprocessing,Your first RNN model","Data pre-processing,Prepare label vectors,Pre-process data,Transfer learning for language models,Transfer learning starting point,Word2Vec,Multi-class classification models,Exploring 20 News Groups dataset,Classifying news articles,Assessing the model's performance,Precision-Recall trade-off,Precision or Recall, that is the question,Performance on multi-class classification","Vanishing and exploding gradients,Exploding gradient problem,Vanishing gradient problem,GRU and LSTM cells,GRU cells are better than simpleRNN,Stacking RNN layers,The Embedding layer,Number of parameters comparison,Transfer learning,Embeddings improves performance,Sentiment classification revisited,Better sentiment classification,Using the CNN layer","Sequence to Sequence Models,Text generation examples,NMT example,The Text Generating Function,Predict next character,Generate sentence with context,Change the probability scale,Text Generation Models,Create vectors of sentences and next characters,Preparing the data for training,Creating the text generation model,Neural Machine Translation,Preparing the input text,Preparing the output text,Translate Portuguese to English,Congratulations!","Chester Ismay,Adrián Soto","Deep Learning for NLP,Scripts of the TV show The Big Bang Theory.,Sample of small sentences in English and Portuguese,Introduction to Deep Learning in Python,Introduction to Natural Language Processing in Python",,
144,Dealing with Missing Data in Python,4,14,46,"13,490",3800,"Tired of working with messy data? Did you know that most of a data scientist's time is spent in finding, cleaning and reorganizing data?! Well turns out you can clean your data in a smart way! In this course Dealing with Missing Data in Python, you'll do just that! You'll learn to address missing values for numerical, and categorical data as well as time-series data. You'll learn to see the patterns the missing data exhibits! While working with air quality and diabetes data, you'll also learn to analyze, impute and evaluate the effects of imputing the data.","Why deal with missing data?,Steps for treating missing values,Null value operations,Finding Null values,Handling missing values,Detecting missing values,Replacing missing values,Replacing hidden missing values,Analyze the amount of missingness,Analyzing missingness percentage,Visualize missingness","Mean, median & mode imputations,Mean & median imputation,Mode and constant imputation,Visualize imputations,Imputing time-series data,Filling missing time-series data,Impute with interpolate method,Visualizing time-series imputations,Visualize forward fill imputation,Visualize backward fill imputation,Plot interpolations","Is the data missing at random?,Guess the missingness type,Deduce MNAR,Finding patterns in missing data,Finding correlations in your data,Identify the missingness type,Visualizing missingness across a variable,Fill dummy values,Generate scatter plot with missingness,When and how to delete missing data,Delete MCAR,Will you delete?","Imputing using fancyimpute,KNN imputation,MICE imputation,Imputing categorical values,Ordinal encoding of a categorical column,Ordinal encoding of a DataFrame,KNN imputation of categorical values,Evaluation of different imputation techniques,Analyze the summary of linear model,Comparing R-squared and coefficients,Comparing density plots,Conclusion",Adel Nehme,"Python Toolbox,Diabetes,Air Quality,Introduction to Data Visualization with Matplotlib,Supervised Learning with scikit-learn",,
145,Regular Expressions in Python,4,15,54,"26,173",4650,"As a data scientist, you will encounter many situations where you will need to extract key information from huge corpora of text, clean messy data containing strings, or detect and match patterns to find useful words. All of these situations are part of text mining and are an important step before applying machine learning algorithms. This course will take you through understanding compelling concepts about string manipulation and regular expressions. You will learn how to split strings, join them back together, interpolate them, as well as detect, extract, replace, and match strings using regular expressions. On the journey to master these skills, you will work with datasets containing movie reviews or streamed tweets that can be used to determine opinion, as well as with raw text scraped from the web.","Introduction to string manipulation,First day!,Artificial reviews,Palindromes,String operations,Normalizing reviews,Time to join!,Split lines or split the line?,Finding and replacing,Finding a substring,Where's the word?,Replacing negations","Introduction to regular expressions,Are they bots?,Find the numbers,Match and split,Repetitions,Everything clean,Some time ago,Getting tokens,Regex metacharacters,Finding files,Give me your email,Invalid password,Greedy vs. non-greedy matching,Understanding the difference,Greedy matching,Lazy approach","Positional formatting,Put it in order!,Calling by its name,What day is today?,Formatted string literal,Literally formatting,Make this function,On time,Template method,Preparing a report,Identifying prices,Playing safe","Capturing groups,Try another name,Flying home,Alternation and non-capturing groups,Love it!,Ugh! Not for me!,Backreferences,Parsing PDF files,Close the tag, please!,Reeepeated characters,Lookaround,Surrounding words,Filtering phone numbers,Finishing line","Sara Billen,Hillary Green-Lerman","Python Programmer,Python Toolbox,Movie Reviews,Wikipedia Web Page,Sentiment140,Intermediate Python",,
146,Survey and Measurement Development in R,4,13,51,"2,957",4450,"How can we measure something like “brand loyalty?” It’s an obvious concept of interest to marketers, but we can’t quite take a ruler to it. Instead, we can design and analyze a survey to indirectly measure such a so-called “latent construct.” In this course, you’ll learn how to design and analyze a marketing survey to describe and even predict customers’ behavior based on how they rate items on “a scale of 1 to 5.” You’ll wrangle survey data, conduct exploratory & confirmatory factor analyses, and conduct various survey diagnostics such as checking for reliability and validity.","Surveys in marketing research,Measuring expert agreement,Inter-rater reliability,Content validity,Measurement, validity & reliability,Visualizing response frequencies,Reverse-coding items,Describing survey results,Missing values,Exploring item correlations,Preparing the brand reputation survey","CFA & EFA,Factor loadings in EFA & CFA,Building a CFA in lavaan,A not-so-good CFA,CFA assumptions & interpretation,Adjusting for non-normality,Comparing models using absolute fit measures,Comparing CFA models using ANOVA,Group CFA,Construct validity,Construct validity & model fit,Construct validity & reliability,Deeper into AVE & CR,CFA of the brand reputation survey","What is a latent variable?,From correlations to factors,Building your first EFA,EFA: How many factors?,EFA & item refinement,Refining the brand reputation survey,Comparing EFA model fits,EFA model iteration,Assessing internal reliability,Measuring coefficient (Cronbach's) alpha,Coefficient alpha by dimension,Split-half reliability,Measuring loyalty","Concurrent validity & model diagrams,Preparing a scaled data frame,Plotting and analyzing a concurrent validity model,Concurrent validity & Likert-style items,Predictive validity & factor scores,Statistical significance & r-square,Prediction & causation,Exploring factor scores,Factor scores & regression,Repeated measures, replication & factor scores,Test-retest reliability,CFA, EFA & replication,Wrap-up: from generation to replication...",Chester Ismay,"Brand reputation survey,Brand quality survey,Customer satisfaction survey,Customer loyalty survey,Introduction to Regression in R",,
147,Time Series Analysis in SQL Server,5,16,60,"19,685",5150,"SQL Server has a robust set of tools to prepare, aggregate, and query time series data. This course will show you how to build and work with dates, parse dates from strings (and deal with invalid strings), and format dates for reporting. From there, you will see how SQL Server's built-in aggregation operators and window functions can solve important business problems like calculating running totals, finding moving averages, and displaying month-over-month differences using realistic sample data sets. You will also see how taking a different perspective on your data can solve difficult problems.","Building dates,Break out a date into year, month, and day,Break a date and time into component parts,Date math and leap years,Rounding dates,Formatting dates for reporting,Formatting dates with CAST() and CONVERT(),Formatting dates with FORMAT(),Working with calendar tables,The benefits of calendar tables,Try out a calendar table,Joining to a calendar table","Basic aggregate functions,Summarize data over a time frame,Calculating distinct counts,Calculating filtered aggregates,Statistical aggregate functions,Working with statistical aggregate functions,Calculating median in SQL Server,Downsampling and upsampling data,Downsample to a daily grain,Downsample to a weekly grain,Downsample using a calendar table,Grouping by ROLLUP, CUBE, and GROUPING SETS,Generate a summary with ROLLUP,View all aggregations with CUBE,Generate custom groupings with GROUPING SETS,Combine multiple aggregations in one query","Building dates from parts,Build dates from parts,Build dates and times from parts,Build dates and times with offsets from parts,Translating date strings,Cast strings to dates,Convert strings to dates,Parse strings to dates,Working with offsets,Changing a date's offset,Using the time zone DMV to look up times,Converting to a date offset,Handling invalid dates,Try out type-safe date functions,Convert imported data to dates with time zones,Test type-safe conversion function performance","Using aggregation functions over windows,Contrasting ROW_NUMBER(), RANK(), and DENSE_RANK(),Aggregate window functions,Calculating running totals and moving averages,Running totals with SUM(),Investigating window frames,Calculating moving averages,Working with LAG() and LEAD(),Seeing prior and future periods,Seeing the prior three periods,Calculating days elapsed between incidents,Finding maximum levels of overlap,Analyze client data for potential fraud,Build a stream of events,Complete the fraud analysis,Wrapping up","Chester Ismay,Mona Khalil","SQL Server Developer,SQL Server Fundamentals,Calendar,Day Spa Rollup,Day Spa Visit,Incident Rollup,Incident Type,Imported Time,Intermediate SQL Server",,
148,Functions for Manipulating Data in PostgreSQL,4,13,50,"24,505",4200,"This course will provide you an understanding of how to use built-in PostgreSQL functions in your SQL queries to manipulate different types of data including strings, character, numeric and date/time. We'll travel back to a time where Blockbuster video stores were on every corner and if you wanted to watch a movie, you actually had to leave your house to rent a DVD! You'll also get an introduction into the robust full-text search capabilities which provides a powerful tool for indexing and matching keywords in a PostgreSQL document. And finally, you'll learn how to extend these features by using PostgreSQL extensions.","Welcome!,Text data types,Getting information about your database,Determining data types,Date and time data types,Properties of date and time data types,Interval data types,Working with ARRAYs,Accessing data in an ARRAY,Searching an ARRAY with ANY,Searching an ARRAY with @>","Reformatting string and character data,Concatenating strings,Changing the case of string data,Replacing string data,Parsing string and character data,Determining the length of strings,Truncating strings,Extracting substrings from text data,Combining functions for string manipulation,Truncating and padding string data,Padding,The TRIM function,Putting it all together","Overview of basic arithmetic operators,Adding and subtracting date and time values,INTERVAL arithmetic,Calculating the expected return date,Functions for retrieving current date/time,Current timestamp functions,Working with the current date and time,Manipulating the current date and time,Extracting and transforming date/ time data,Using EXTRACT,Using DATE_TRUNC,Putting it all together","Introduction to full-text search,A review of the LIKE operator,What is a tsvector?,Basic full-text search,Extending PostgreSQL,User-defined data types,Getting info about user-defined data types,User-defined functions in Sakila,Intro to PostgreSQL extensions,Enabling extensions,Measuring similarity between two strings,Levenshtein distance examples,Putting it all together,Wrap Up",Marianna Lamnina,"Data Analyst,SQL Fundamentals,Sakila schema,Intermediate SQL",,
149,Sentiment Analysis in Python,4,16,60,"11,516",5050,"Have you left a review to express how you feel about a product or a service? And do you have a habit of checking a product’s reviews online before you buy it? This kind of information is valuable not only for you but also for companies. In this course, you will learn how to make sense of the sentiment expressed in various documents. You will use real-world datasets featuring tweets, movie and product reviews, and use Python’s nltk and scikit-learn packages. By the end of the course, you will be able to carry an end-to-end sentiment analysis task based on how US airline passengers expressed their feelings on Twitter.","Welcome!,Elements of a sentiment analysis problem,How many positive and negative reviews are there?,Longest and shortest reviews,Sentiment analysis types and approaches,Detecting the sentiment of Tale of Two Cities,Comparing the sentiment of two strings,What is the sentiment of a movie review?,Let's build a word cloud!,Your first word cloud,Which words are in the word cloud?,Word Cloud on movie reviews","Stop words,Word cloud of tweets,Airline sentiment with stop words,Multiple text columns,Capturing a token pattern,Specify the token pattern,String operators with the Twitter data,More string operators and Twitter,Stemming and lemmatization,Stems and lemmas from GoT,Stem Spanish reviews,Stems from tweets,TfIdf: More ways to transform text,Your first TfIdf,TfIdf on Twitter airline sentiment data,Tfidf and a BOW on same data","Bag-of-words,Which statement about BOW is true?,Your first BOW,BOW using product reviews,Getting granular with n-grams,Specify token sequence length with BOW,Size of vocabulary of movies reviews,BOW with n-grams and vocabulary size,Build new features from text,Tokenize a string from GoT,Word tokens from the Avengers,A feature for the length of a review,Can you guess the language?,Identify the language of a string,Detect language of a list of strings,Language detection of product reviews","Let's predict the sentiment!,Logistic regression of movie reviews,Logistic regression using Twitter data,Did we really predict the sentiment well?,Build and assess a model: movies reviews,Performance metrics of Twitter data,Build and assess a model: product reviews data,Logistic regression: revisited,Predict probabilities of movie reviews,Product reviews with regularization,Regularizing models with Twitter data,Bringing it all together,Step 1: Word cloud and feature creation,Step 2: Building a vectorizer,Step 3: Building a classifier,Wrap up","Ruanne Van Der Walt,Chester Ismay,Hillary Green-Lerman","Natural Language Processing,Amazon product reviews,IMDB movie reviews,Tweets of US airline passengers,Python Data Science Toolbox (Part 2)",,
150,Winning a Kaggle Competition in Python,4,16,52,"12,336",4200,"Kaggle is the most famous platform for Data Science competitions. Taking part in such competitions allows you to work with real-world datasets, explore various machine learning problems, compete with other participants and, finally, get invaluable hands-on experience. In this course, you will learn how to approach and structure any Data Science competition. You will be able to select the correct local validation scheme and to avoid overfitting. Moreover, you will master advanced feature engineering together with model ensembling approaches. All these techniques will be practiced on Kaggle competitions datasets.","Competitions overview,Explore train data,Explore test data,Prepare your first submission,Determine a problem type,Train a simple model,Prepare a submission,Public vs Private leaderboard,What model is overfitting?,Train XGBoost models,Explore overfitting XGBoost","Feature engineering,Arithmetical features,Date features,Categorical features,Label encoding,One-Hot encoding,Target encoding,Mean target encoding,K-fold cross-validation,Beyond binary classification,Missing data,Find missing data,Impute missing data","Understand the problem,Understand the problem type,Define a competition metric,Initial EDA,EDA statistics,EDA plots I,EDA plots II,Local validation,K-fold cross-validation,Stratified K-fold,Validation usage,Time K-fold,Overall validation score","Baseline model,Replicate validation score,Baseline based on the date,Baseline based on the gradient boosting,Hyperparameter tuning,Grid search,2D grid search,Model ensembling,Model blending,Model stacking I,Model stacking II,Final tips,Testing Kaggle forum ideas,Select final submissions,Final thoughts","Hadrien Lacroix,Hillary Green-Lerman","Machine Learning Scientist,Demand forecasting (train),Demand forecasting (test),House prices (train),House prices (test),Taxi rides (train),Taxi rides (test),Extreme Gradient Boosting with XGBoost",,
151,Building and Optimizing Triggers in SQL Server,4,15,49,"9,516",3800,"Auditing your SQL Server database and keeping data integrity can be a challenging task for DBAs and database developers. SQL Server triggers are special types of stored procedures designed to help you achieve consistency and integrity of your database. This course will teach you how to work with triggers and use them in real-life examples. Specifically, you will learn about the use cases and limitations of triggers and get practice designing and implementing them. You will also learn to optimize triggers to fit your specific needs.","Introduction,Types of trigger,Creating your first trigger,Practicing creating triggers,How DML triggers are used,When to use triggers,Creating a trigger to keep track of data changes,Trigger alternatives,Triggers vs. stored procedures,Triggers vs. computed columns","Known limitations of triggers,Trigger limitations,Creating a report on existing triggers,Use cases for AFTER triggers (DML),Keeping a history of row changes,Table auditing using triggers,Use cases for INSTEAD OF triggers (DML),Preventing changes to Products,Checking stock before placing orders,Use cases for DDL triggers,Database auditing,Preventing server changes","AFTER triggers (DML),Tracking retired products,The TrackRetiredProducts trigger in action,Practicing with AFTER triggers,INSTEAD OF triggers (DML),Preventing changes to orders,PreventOrdersUpdate in action,Creating the PreventNewDiscounts trigger,DDL triggers,Tracking table changes,Using FOR in a trigger,Preventing table deletion,Logon triggers,Enhancing database security,Defining a logon trigger","Deleting and altering triggers,Removing unwanted triggers,Modifying a trigger's definition,Disabling a trigger,Re-enabling a disabled trigger,Trigger management,Managing existing triggers,Counting the AFTER triggers,Troubleshooting triggers,Keeping track of trigger executions,Identifying problematic triggers,Wrapping up","Becca Robins,Mona Khalil,Marianna Lamnina","SQL Server Developer,SQL Server for Database Administrators,Discounts table,Orders table,Products table,Intermediate SQL Server",,
152,Loan Amortization in Spreadsheets,4,13,56,"3,014",4800,"A loan amortization schedule sounds like something that's only used by bankers and financial traders, right? Wrong! In this course, we'll be looking at the key financial formulas in Google Sheets that you can use to investigate your own loans, like student loans, car loans, and mortgages. We'll build up a dashboard in Google Sheets which uses visualizations and conditional formulas to produce presentation-ready spreadsheets which will impress any finance manager!","Introduction to loan amortization,Your ""friend,"" the loan shark,Paying off your student loan in 1 year,Guess the right payment,Calculation of monthly payments,Required fields for the PMT() function.,Inputs for an annual loan,Inputs for a monthly loan.,Entering the PMT() formula,Calculation of interest and principal payments,Using the IPMT() function ,Using the PPMT() function ,Amortization table with two periods","Working with conditions and case statements,Working with IF() functions,SWITCH with baseball,School grades with IFS(),Adjusting dates for different time periods,IF() formulas for monthly or bi-weekly periods,IF() formulas to calculate semi-monthly periods,IFS() formula for all payment types,Loan visualizations,Adding data to the chart.,Adding the x-axis,Adding the title,Hiding unused cells,Using FILTER to create a new table without NAs,Fixing visualizations after using FILTER,Hiding unused values using IFS","Your first amortization schedule,Entering loan terms,Finishing the amortization schedule,Adjusting for annual periods,Cumulative financial functions,Cumulative functions and opening balance.,Working with a single cumulative function,Adding cumulative functions to the schedule,Measuring balance over time,Counting forward periods with EOMONTH(),Counting same month and backward with EOMONTH(),Adding dates and LTV to the schedule","Fees and Annual Percentage Rate,Practice with APR,Your friend, the payday loan shark.,Calculating APR on the schedule,Lump sum payments,Manually calculating interest and principal.,Modifying closing balances for a lump sum,Hiding unused rows review,Fixing the payment function,Floating Rates,Negative amortization scenario,Impact of rising interest rates,Longer-term loans and negative amortization,Maximum annual rate,Max interest rate with APR","Chester Ismay,Marianna Lamnina","Finance Fundamentals,Financial Modeling in Spreadsheets",,
153,Financial Analytics in Spreadsheets,4,15,56,"17,162",4650,"Monitoring the evolution of traded assets is key in finance. In this course, you will learn how to build a graphical dashboard with spreadsheets to track the performance of financial securities. You will focus on historical prices and dividends of the hypothetical stock ABC. You will learn how to visualize its prices, how to measure essential reward and risk indicators, and see if your investment in ABC outperformed a benchmark index. At the end of the course, you should be able to use spreadsheets to build great monitoring tools used by traders and financial analysts in their day-to-day business life!","Introduction and first metrics,What is a stock?,Count prices and dividends
,Find minimum and maximum prices
,Find minimum and maximum dividends
,Identifying dates with unusual prices,Find price at a given date ,Find dates with minimum and maximum prices,Visualizing the price evolution,Plot a line chart of historical prices,Customize the chart,Highlight minimum and maximum prices","Histogram of stock returns,Define bins,Find the frequency of each bin,Convert frequencies into relative frequencies,Build the histogram,The Gaussian model,Plot the standard Gaussian model,Change the location of the Gaussian model,Change the dispersion of the Gaussian model,Calibrating the Gaussian model,Calibrate the Gaussian model on historical returns,Overlay the Gaussian model to the empirical histogram ,Compute the 5% value-at-risk from the Gaussian model,Limitations of the Gaussian model,What are the limitations of the Gaussian model?,Compute skewness and kurtosis of the historical returns","From prices to returns,What are dollar and percentage returns?,Compute historical returns,Count positive and negative returns,Reward metrics,Compute the average return,Compute the effective rate of return using PRODUCT() and COUNT(),Compute the effective rate of return using ARRAYFORMULA(),Risk metrics,Compute the volatility,Compute the volatility with STDEV(),Compute the historical value-at-risk
,Risk-adjusted metrics,Compute the Sharpe ratio,Compute the semideviation
,Compute the Sortino ratio
","Benchmarking,How to choose a good benchmark?,Compare the final wealth,Plot the cumulative wealth,Performance metrics comparison,Compare the Sharpe ratios,Compare the drawdowns,Compare the maximum drawdowns,Correlation analysis,Compute the correlation coefficient ,Compute the rolling-window correlation,Creating the dashboard","Chester Ismay,Sara Billen","Finance Fundamentals,Stock ABC,Data Visualization in Spreadsheets",,
154,Analyzing Marketing Campaigns with pandas,4,14,53,"14,601",4500,"One of the biggest challenges when studying data science technical skills is understanding how those skills and concepts translate into real jobs. Whether you're looking to level up in your marketing job by incorporating Python and pandas or you're trying to get a handle on what kinds of work a data scientist in a marketing organization might do, this course is a great match for you. We'll practice translating common business questions into measurable outcomes, including ""How did this campaign perform?"", ""Which channel is referring the most subscribers?"", ""Why is a particular channel underperforming?"" and more using a fake marketing dataset based on the data of an online subscription business. This course will build on Python and pandas fundamentals, such as merging/slicing datasets, groupby(), correcting data types and visualizing results using matplotlib.","Introduction to pandas for marketing,Importing the dataset,Examining the data,Data types and data merging,Updating the data type of a column,Adding new columns,Date columns,Initial exploratory analysis,Daily marketing reach by channel,Visualizing daily marketing reach","Building functions to automate analysis,Building a conversion function,Test and visualize conversion function,Plotting function,Putting it all together,Identifying inconsistencies,House ads conversion rate,Analyzing House ads conversion rate,House ads conversion by language,Creating a DataFrame for house ads,Confirming house ads error,Resolving inconsistencies,Setting up conversion indexes,Analyzing user preferences,Creating a DataFrame based on indexes,Assessing bug impact","Introduction to common marketing metrics,Calculating conversion rate,Calculating retention rate,Customer segmentation,Comparing language conversion rate (I),Comparing language conversion rate (II),Aggregating by date,Plotting campaign results (I),Visualize conversion rate by language,Creating daily conversion rate DataFrame,Setting up our data to visualize daily conversion,Visualize daily conversion rate,Plotting campaign results (II),Marketing channels across age groups,Grouping and counting by multiple columns,Analyzing retention rates for the campaign","A/B testing for marketing,Determining key metrics,Test allocation,Comparing conversion rates,Calculating lift & significance testing,Creating a lift function,Evaluating statistical significance,A/B testing & segmentation,Building an A/B test segmenting function,Using your segmentation function,Wrap-up","Sumedh Panchadhar,Mona Khalil","Marketing Analytics,Marketing dataset 1,Marketing dataset 2,Data Manipulation with pandas",,
155,Applying SQL to Real-World Problems,4,13,47,"12,342",3550,"Now that you’ve learned the basic tools of SQL you are ready to synthesize them into practical, real-world skills. In this course, you will work with a database of a fictional movie rental company. The size and complexity of this database will allow you to experience the challenges of working with databases firsthand. Throughout this course, you will use SQL to answer business-driven questions. You will learn new skills that will empower you to find the tables you need. You will then learn how to store and manage this data in tables and views that you create. Best of all you will also learn how to write code that not only clearly conveys your intent but is also legible.","Essential SQL,Review the essentials,Practice the essentials,Transforming your results,Transform numeric & strings,Extract what you need,Working with aggregate functions,Aggregating finances,Aggregating strings,Which tables?","Store your data,Storing new data,Using existing data,TABLE vs VIEW,Update your data,What should you modify?,Update the price of rentals,Updated based on other tables,Delete your data,Deleting all table data,Delete selected records,A family friendly video store","Find the right table,LIMITing your search,Which table to use?,What tables are in your database?,Determine the monthly income,Join the correct tables,What columns are in your database?,A VIEW of all your columns,Testing out your new VIEW,The average length of films by category,Complex joins,Build the entity relationship diagram,Which films are most frequently rented?","Convey your intent,How to convey our intent,Clarify the intent of this query,Fix this query - intent,Write readable code,How to make code easier to read,Make this query easier to read - Part I,Make this query easier to read - Part II,Avoid common mistakes,What are the don'ts of writing SQL code?,Apply best practices to your code,Recap","Chester Ismay,Adrián Soto","SQL for Business Analysts,DVD Rental Database,Intermediate SQL",,
156,AI Fundamentals,4,14,49,"18,888",3350,"So what is all this AI fuss about? Machine Learning, Deep Learning, Predictive Analytics -- what is the reality behind the hype? How do machines actually learn and what are their limits? How can we use Machine Learning to recognize written digits, predict customer churn and find structure in Elon Musk's tweets? All this -- and much more -- is the topic of this course, which will introduce you to the world of AI in a gentle, but firm and very practical manner.","Do androids dream of electric sheep?,General vs Narrow AI,Why Python?,The elephant in the room,All models are wrong but some are useful,Parameters & hyper-parameters,Too much of a good thing,Three flavors of Machine Learning,Guess the flavor I,Guess the flavor II,Simple digit recognition","Dimensionality reduction,Principal Component Analysis,Visitors from outer space,Clustering,Lucky number K,Elbow reading,DBSCAN,Anomaly detection,How unsupervised really?,The go-to algorithm,The odd one out,Elon's tweets,Selecting the right model,Fruits of knowledge,Predicting customer churn","Supervised Learning Fundamentals,Regression or Classification I,When regression means classification,Training and evaluating classification models,SPAMtastic!,Hold-out,Training and evaluating regression models,Tailor made,Going non-linear","Deep Learning & Beyond,The nucleus,How to train your dragon,Your first neural net,Deep Learning,Layers,Guess the architecture,Rolling in the deep,Convolutional Neural Networks,The Beauty of the Beast,One-liner modeling,One-line evaluation,Deep Learning for Digit Recognition,Congratulations!","Hadrien Lacroix,Hillary Green-Lerman","Data Skills for Business,Customer Churn,MNIST",,
157,Cluster Analysis in Python,4,14,46,"38,265",3650,"You have probably come across Google News, which automatically groups similar news articles under a topic. Have you ever wondered what process runs in the background to arrive at these groups? In this course, you will be introduced to unsupervised learning through clustering using the SciPy library in Python. This course covers pre-processing of data and application of hierarchical and k-means clustering. Through the course, you will explore player statistics from a popular football video game, FIFA 18. After completing the course, you will be able to quickly apply various clustering algorithms on data, visualize the clusters formed and analyze results.","Unsupervised learning: basics,Unsupervised learning in real world,Pokémon sightings,Basics of cluster analysis,Pokémon sightings: hierarchical clustering,Pokémon sightings: k-means clustering,Data preparation for cluster analysis,Normalize basic list data,Visualize normalized data,Normalization of small numbers,FIFA 18: Normalize data","Basics of k-means clustering,K-means clustering: first exercise,Runtime of k-means clustering,How many clusters?,Elbow method on distinct clusters,Elbow method on uniform data,Limitations of k-means clustering,Impact of seeds on distinct clusters,Uniform clustering patterns,FIFA 18: defenders revisited","Basics of hierarchical clustering,Hierarchical clustering: ward method,Hierarchical clustering: single method,Hierarchical clustering: complete method,Visualize clusters,Visualize clusters with matplotlib,Visualize clusters with seaborn,How many clusters?,Create a dendrogram,How many clusters in comic con data?,Limitations of hierarchical clustering,Timing run of hierarchical clustering,FIFA 18: exploring defenders","Dominant colors in images,Extract RGB values from image,How many dominant colors?,Display dominant colors,Document clustering,TF-IDF of movie plots,Top terms in movie clusters,Clustering with multiple features,Clustering with many features,Basic checks on clusters,FIFA 18: what makes a complete player?,Farewell!","Sara Billen,Hillary Green-Lerman","Data Scientist,Machine Learning Scientist,FIFA sample,FIFA,Movies,Intermediate Python",,
158,Improving Your Data Visualizations in Python,4,15,54,"10,907",4650,"Great data visualization is the cornerstone of impactful data science. Visualization helps you to both find insight in your data and share those insights with your audience. Everyone learns how to make a basic scatter plot or bar chart on their journey to becoming a data scientist, but the true potential of data visualization is realized when you take a step back and think about what, why, and how you are visualizing your data. In this course you will learn how to construct compelling and attractive visualizations that help you communicate the results of your analyses efficiently and effectively. We will cover comparing data, the ins and outs of color, showing uncertainty, and how to build the right visualization for your given audience through the investigation of a datasets on air pollution around the US and farmer's markets. We will finish the course by examining open-access farmers market data to build a polished and impactful visual report.","Highlighting data,Hardcoding a highlight,Programmatically creating a highlight,Comparing groups,Comparing with two KDEs,Improving your KDEs,Beeswarms,Annotations,A basic text annotation,Arrow annotations,Combining annotations and color","Point estimate intervals,Basic confidence intervals,Annotating confidence intervals,Confidence bands,Making a confidence band,Separating a lot of bands,Cleaning up bands for overlaps,Beyond 95%,90, 95, and 99% intervals,90 and 95% bands,Using band thickness instead of coloring,Visualizing the bootstrap,The bootstrap histogram,Bootstrapped regressions,Lots of bootstraps with beeswarms","Color in visualizations,Getting rid of unnecessary color,Fixing Seaborn's bar charts,Continuous color palettes,Making a custom continuous palette,Customizing a diverging palette heatmap,Adjusting your palette according to context,Categorical palettes,Using a custom categorical palette,Dealing with too many categories,Coloring ordinal categories,Choosing the right variable to encode with color","First explorations,Looking at the farmers market data,Scatter matrix of numeric columns,Digging in with basic transforms,Exploring the patterns,Is latitude related to months open?,What state is the most market-friendly?,Popularity of goods sold by state,Making your visualizations efficient,Stacking to find trends,Using a plot as a legend,Tweaking your plots,Cleaning up the background,Remixing a plot,Enhancing legibility,Congrats!","Becca Robins,Hillary Green-Lerman","Data Visualization,State populations dataset,U.S. farmer's markets dataset,Pollution dataset,Python Data Science Toolbox (Part 2),Introduction to Data Visualization with Matplotlib,Introduction to Data Visualization with Seaborn",,
159,Python for Spreadsheet Users,4,13,48,"20,615",3900,"Are you looking for a better solution than the one you’ve built in a spreadsheet? If so, then Python for Spreadsheet Users is a great introduction to the Python language, and will put you on the right path towards automating repetitive work, diving deeper into your data, and widening the scope of what you are capable of accomplishing. Throughout the course, we’ll draw parallels to common spreadsheet functions and techniques, so you’ll always have a familiar reference point as you dive head first into Python.","Welcome to Python!,Importing packages,Loading data,Looking at data with print(),DataFrames and their methods,The .head() method,.info() and .describe() methods,The .sort_values() method,Filtering rows and creating columns,Filtering,Creating columns,Putting it all together","Working with multiple sheets,pd.ExcelFile() function,.sheet_names attribute,.parse() method,Preparing to put tables together,.str.lower() and .str.title(),.str.strip(),Selecting and .drop(),Merging: The VLOOKUP of Python,Merging for ticket prices,Merging for theater locations,Putting it all together again","Grouping and summing: the beginner's pivot table,Pure summary with .sum(),.groupby() and .sum() together,Summarizing and sorting values,Grouping by multiple columns,Which is a list?,Movie genre performance by location,What do seniors like?,More useful summary tools,Best-selling movie by location,Which movie averages the most sales","How visualization works in Python,How to build a graph in Python,Top grossing films,Best genres,Building up the barplot,Put a title on it,Label your axes!,Make it pretty with sns,The power of hue,Interpreting hue,Genre by market,Genre by ticket type,Wrapping up","Amy Peterson,Hillary Green-Lerman","Movie Theater Sales dataset,Pivot Tables in Spreadsheets",,
160,Writing Efficient Code with pandas,4,14,45,"11,940",3500,"The ability to efficiently work with big datasets and extract valuable information is an indispensable tool for every aspiring data scientist. When working with a small amount of data, we often don’t realize how slow code execution can be. This course will build on your knowledge of Python and the pandas library and introduce you to efficient built-in pandas functions to perform tasks faster. Pandas’ built-in functions allow you to tackle the simplest tasks, like targeting specific entries and features from the data, to the most complex tasks, like applying functions on groups of entries, much faster than Python's usual methods. By the end of this course, you will be able to apply a function to data based on a feature value, iterate through big datasets rapidly, and manipulate data belonging to different groups efficiently. You will apply these methods on a variety of real-world datasets, such as poker hands or restaurant tips.","The need for efficient coding I,What does time.time() measure?,Measuring time I,Measuring time II,Locate rows: .iloc[] and .loc[],Row selection: loc[] vs iloc[],Column selection: .iloc[] vs by name,Select random rows,Random row selection,Random column selection","Looping using the .iterrows() function,Create a generator for a pandas DataFrame,The iterrows() function for looping,Looping using the .apply() function,.apply() function in every cell,.apply() for rows iteration,Vectorization over pandas series,Why vectorization in pandas is so fast?,pandas vectorization in action,Vectorization with NumPy arrays using .values(),Best method of vectorization,Vectorization methods for looping a DataFrame","Replace scalar values using .replace(),Replacing scalar values I,Replace scalar values II,Replace values using lists,Replace multiple values I,Replace multiple values II,Replace values using dictionaries,Replace single values I,Replace single values II,Replace multiple values III,Most efficient method for scalar replacement","Data transformation using .groupby().transform,The min-max normalization using .transform(),Transforming values to probabilities,Validation of normalization,When to use transform()?,Missing value imputation using transform(),Identifying missing values,Missing value imputation,Data filtration using the filter() function,When to use filtration?,Data filtration,Congratulations!","Hadrien Lacroix,Hillary Green-Lerman","Python Programming,Poker,Popular Baby Names,Restaurant,Data Manipulation with pandas",,
161,Foundations of Probability in Python,5,16,61,"7,026",5050,"Probability is the study of regularities that emerge in the outcomes of random experiments. In this course, you'll learn about fundamental probability concepts like random variables (starting with the classic coin flip example) and how to calculate mean and variance, probability distributions, and conditional probability. We'll also explore two very important results in probability: the law of large numbers and the central limit theorem. Since probability is at the core of data science and machine learning, these concepts will help you understand and apply models more robustly. Chances are everywhere, and the study of probability will change the way you see the world. Let’s get random!","Let’s flip a coin in Python,Flipping coins,Using binom to flip even more coins,Probability mass and distribution functions,Predicting the probability of defects,Predicting employment status,Predicting burglary conviction rate,Expected value, mean, and variance,Calculating the expected value and variance,Calculating the sample mean,Checking the result,Calculating the mean and variance of a sample","Normal distributions,Range of values,Plotting normal distributions,Within three standard deviations,Normal probabilities,Restaurant spending example,Smartphone battery example,Adults' heights example,Poisson distributions,ATM example,Highway accidents example,Generating and plotting Poisson distributions,Geometric distributions,Catching salmon example,Free throws example,Generating and plotting geometric distributions","Calculating probabilities of two events,Any overlap?,Measuring a sample,Joint probabilities,Deck of cards,Conditional probabilities,Delayed flights,Contingency table,More cards,Total probability law,Formula 1 engines,Voters,Bayes' rule,Conditioning,Factories and parts,Swine flu blood test","From sample mean to population mean,Generating a sample,Calculating the sample mean,Plotting the sample mean,Adding random variables,Sample means,Sample means follow a normal distribution,Adding dice rolls,Linear regression,Fitting a model,Predicting test scores,Studying residuals,Logistic regression,Fitting a logistic model,Predicting if students will pass,Passing two tests,Wrapping up","Adrián Soto,Hillary Green-Lerman",Introduction to Statistics in Python,,
162,Reporting in SQL,4,15,54,"20,203",4450,"Become a master at building complex reports! In this course, you will apply all the SQL concepts and functions you have learned in previous courses to build out your very own dashboard. By navigating through an Olympics database, you will become an expert data explorer and learn how to understand novel database quickly and effectively. Since data is never perfect, you will gain valuable strategies to deal with real-world issues commonly found with SQL, including how to remove data duplication and how to turn messy data into clean, organized reports. Lastly, you’ll conquer complex calculations using window functions and layered calculations, all within the same report. This is a perfect class for anyone who will be commonly pulling data from databases and is a great complement for those who use R or Python for data science.","Case study,Identifying the base report,Building the base report,Athletes vs events by sport,The Olympics dataset,Planning queries with an E:R diagram,Age of oldest athlete by region,Number of events in each sport,Exploring our data,Exploring summer_games,Validating our query,Report 1: Most decorated summer athletes","Converting data types,Identifying data types,Interpreting error messages,Using date functions on strings,Cleaning strings,String functions,Replacing and removing substrings,Fixing incorrect groupings,Dealing with nulls,Filtering out nulls,Fixing calculations with coalesce,Report duplication,Identifying duplication,Fixing duplication through a JOIN,Report 3: Countries with high medal rates","Planning the query,Planning the SELECT statement,Planning the filter,Combining tables,JOIN then UNION query,UNION then JOIN query,Creating custom fields,CASE statement refresher,BMI bucket by sport,Troubleshooting CASE statements,Filtering and finishing touches,Filtering with a JOIN,Filtering with a subquery,Report 2: Top athletes in nobel-prized countries","Building complex calculations,Testing out window functions,Average total country medals by region,Most decorated athlete per region,Comparing groups,Volume vs efficiency metrics,Percent of gdp per country,GDP per capita performance index,Comparing dates,Month-over-month comparison,Week-over-week comparison,Report 4: Tallest athletes and % GDP by region,Course summary","Sara Billen,Mona Khalil","SQL for Business Analysts,Course Database Entity Relationship Diagram,Course Database Creation Code,Athletes,Countries,Country Stats,Summer Games,Winter Games,Intermediate SQL",,
163,PostgreSQL Summary Stats and Window Functions,4,12,44,"32,192",3550,"Have you ever wondered how data professionals use SQL to solve real-world business problems, like generating rankings, calculating moving averages and running totals, deduplicating data, or performing time intelligence? If you already know how to select, filter, order, join and group data with SQL, this course is your next step. By the end, you will be writing queries like a pro! You will learn how to create queries for analytics and data engineering with window functions, the SQL secret weapon! Using flights data, you will discover how simple it is to use window functions, and how flexible and efficient they are.","Introduction,Window functions vs GROUP BY,Numbering rows,Numbering Olympic games in ascending order,ORDER BY,Numbering Olympic games in descending order,Numbering Olympic athletes by medals earned,Reigning weightlifting champions,PARTITION BY,Reigning champions by gender,Reigning champions by gender and event,Row numbers with partitioning","Aggregate window functions,Running totals of athlete medals,Maximum country medals by year,Minimum country medals by year,Frames,Number of rows in a frame,Moving maximum of Scandinavian athletes' medals,Moving maximum of Chinese athletes' medals,Moving averages and totals,Moving average's frame,Moving average of Russian medals,Moving total of countries' medals","Fetching,Future gold medalists,First athlete by name,Last country by name,Ranking,Ranking athletes by medals earned,Ranking athletes from multiple countries,DENSE_RANK's output,Paging,Paging events,Top, middle, and bottom thirds","Pivoting,A basic pivot,Pivoting with ranking,ROLLUP and CUBE,Country-level subtotals,All group-level subtotals,A survey of useful functions,Cleaning up results,Summarizing results","Sumedh Panchadhar,Mona Khalil,Marianna Lamnina","Data Analyst,SQL Fundamentals,Summer olympics dataset,Intermediate SQL",,
164,Introduction to Statistics in Spreadsheets,4,15,51,"23,978",4350,"Statistics is the science that deals with the collection, analysis, and interpretation of data. Having a solid foundation in statistics will help you effectively work with your data to test hypotheses and uncover insights that can help solve your problems. This course is designed to give you that foundation in statistics. Using Spreadsheets functions, you'll dive into averages, distributions, hypothesis testing, and conclude the course by applying your newfound knowledge in a case study. Along the way, you'll work with a variety of datasets ranging from eBay auctions to train ridership to historical presidential approval ratings. Enjoy!","Welcome to the course!,Don't be average!,Presidential approval rating averages,Difference between median and mean,Modal madness,How far from average?,Train variation,Calculating standard deviations,Playing quarters,Standardizing data,Comparing z-scores,Exploring eBay auctions","Central to Stats: Sampling!,Sampling in Spreadsheets,Does sampling size matter?,Central Limit Theorem in action,Hypothesis Testing,Comparing samples with a t-test,Paired t-test,Hypothesis Testing with the Z-test,Performing a Z-test,What changes in a two-tailed test?,Hypothesis Testing with the Chi-squared test,Performing a chi-squared test,Are bank loans getting worse?","Visualizing Distributions,""Normal"" views of money,Visualizing customer longevity,Visualizing customer donations,Is the data ""normally"" distributed?,Visualizing Correlations,Correlation between price and quantity sold,Correlation between seller rating and closing price,Adding a trend line,Bar charts,Bar chart of competitive counts,Visualizing categories","Dating Data!,Understanding the distribution of ages,What's the drinking age?,Profile login behavior,Visuals & Distributions,Visualizing logins,How old do users look?,Tipping the scale to positive correlation,Investigating age and volunteering,More complex relationships,Are gender and number of roommates independent?,Getting old and rich,Multiple relationships!,Congratulations!","Yashas Roy,Chester Ismay","Data Skills for Business,Intermediate Spreadsheets,Data Analysis in Spreadsheets",,
165,Feature Engineering for Machine Learning in Python,4,16,53,"19,385",4350,"Every day you read about the amazing breakthroughs in how the newest applications of machine learning are changing the world. Often this reporting glosses over the fact that a huge amount of data munging and feature engineering must be done before any of these fancy models can be used. In this course, you will learn how to do just that. You will work with Stack Overflow Developers survey, and historic US presidential inauguration addresses, to understand how best to preprocess and engineer features from categorical, continuous, and unstructured data. This course will give you hands-on experience on how to prepare any data for your own machine learning models.","Why generate features?,Getting to know your data,Selecting specific data types,Dealing with categorical features,One-hot encoding and dummy variables,Dealing with uncommon categories,Numeric variables,Binarizing columns,Binning values","Data distributions,What does your data look like? (I),What does your data look like? (II),When don't you have to transform your data?,Scaling and transformations,Normalization,Standardization,Log transformation,When can you use normalization?,Removing outliers,Percentage based outlier removal,Statistical outlier removal,Scaling and transforming new data,Train and testing transformations (I),Train and testing transformations (II)","Why do missing values exist?,How sparse is my data?,Finding the missing values,Dealing with missing values (I),Listwise deletion,Replacing missing values with constants,Dealing with missing values (II),Filling continuous missing values,Imputing values in predictive models,Dealing with other data issues,Dealing with stray characters (I),Dealing with stray characters (II),Method chaining","Encoding text,Cleaning up your text,High level text features,Word counts,Counting words (I),Counting words (II),Limiting your features,Text to DataFrame,Term frequency-inverse document frequency,Tf-idf,Inspecting Tf-idf values,Transforming unseen data,N-grams,Using longer n-grams,Finding the most common words,Wrap-up","Sumedh Panchadhar,Hillary Green-Lerman","Machine Learning Scientist,Stack Overflow Survey Responses (Modified),US Presidential Inauguration Addresses,Supervised Learning with scikit-learn",,
166,Introduction to Text Analysis in R,4,15,46,"16,583",3850,"From social media to product reviews, text is an increasingly important type of data across applications, including marketing analytics. In many instances, text is replacing other forms of unstructured data due to how inexpensive and current it is. However, to take advantage of everything that text has to offer, you need to know how to think about, clean, summarize, and model text. In this course, you will use the latest tidy tools to quickly and easily get started with text. You will learn how to wrangle and visualize text, perform sentiment analysis, and run and interpret topic models.","Text as data,Airline tweets data,Grouped summaries,Counting categorical data,Counting user types,Summarizing user types,Tokenizing and cleaning,Tokenizing and counting,Cleaning and counting","Sentiment dictionaries,Counting the NRC sentiments,Visualizing the NRC sentiments,Appending dictionaries,Counting sentiment,Visualizing sentiment,Improving sentiment analysis,Practicing reshaping data,Practicing with grouped summaries,Visualizing sentiment by complaint type","Plotting word counts,Visualizing complaints,Visualizing non-complaints,Improving word count plots,Adding custom stop words,Visualizing word counts using factors,Faceting word count plots,Counting by product and reordering,Visualizing word counts with facets,Plotting word clouds,Creating a word cloud,Adding a splash of color","Latent Dirichlet allocation,Topics as word probabilities,Summarizing topics,Visualizing topics,Document term matrices,Creating a DTM,Evaluating a DTM as a matrix,Running topic models,Fitting an LDA,Tidying LDA output,Comparing LDA output,Interpreting topics,Naming three topics,Naming four topics,Wrap-up","Sumedh Panchadhar,Chester Ismay","Marketing Analytics,Text Mining,Airline tweets,Roomba reviews,Introduction to the Tidyverse",,
167,Introduction to Data Visualization with Matplotlib,4,14,44,"109,480",3600,"Visualizing data in plots and figures exposes the underlying patterns in the data and provides insights. Good visualizations also help you communicate your data to others, and are useful to data analysts and other consumers of the data. In this course, you will learn how to use Matplotlib, a powerful Python data visualization library. Matplotlib provides the building blocks to create rich visualizations of many different kinds of datasets. You will learn how to create visualizations for different kinds of data and how to customize, automate, and share these visualizations.","Introduction to data visualization with Matplotlib,Using the matplotlib.pyplot interface,Adding data to an Axes object,Customizing your plots,Customizing data appearance,Customizing axis labels and adding titles,Small multiples,Creating a grid of subplots,Creating small multiples with plt.subplots,Small multiples with shared y axis","Quantitative comparisons: bar-charts,Bar chart,Stacked bar chart,Quantitative comparisons: histograms,Creating histograms,""Step"" histogram,Statistical plotting,Adding error-bars to a bar chart,Adding error-bars to a plot,Creating boxplots,Quantitative comparisons: scatter plots,Simple scatter plot,Encoding time by color","Plotting time-series data,Read data with a time index,Plot time-series data,Using a time index to zoom in,Plotting time-series with different variables,Plotting two variables,Defining a function that plots time-series data,Using a plotting function,Annotating time-series data,Annotating a plot of time-series data,Plotting time-series: putting it all together","Preparing your figures to share with others,Selecting a style for printing,Switching between styles,Saving your visualizations,Saving a file several times,Save a figure with different sizes,Automating figures from data,Unique values of a column,Automate your visualization,Where to go next","Chester Ismay,Amy Peterson","Data Scientist,Data Visualization,Seattle weather,Austin weather,Climate data,Medals by country,Medalist weights,Introduction to Python",,
168,Data-Driven Decision Making in SQL,4,15,54,"15,502",4550,"In this course, you will learn how to use SQL to support decision making. It is based on a case study about an online movie rental company with a database about customer information, movie ratings, background information on actors and more. You will learn to apply SQL queries to study for example customer preferences, customer engagement, and sales development. This course also covers SQL extensions for online analytical processing (OLAP), which makes it easier to obtain key insights from multidimensional aggregated data.","Introduction to data driven decision making,Exploring the database,Exploring the table renting,Filtering and ordering,Working with dates,Selecting movies,Select from renting,Aggregations - summarizing data,Summarizing customer information,Ratings of movie 25,Examining annual rentals","Nested query,Often rented movies,Frequent customers,Movies with rating above average,Correlated nested queries,Analyzing customer behavior,Customers who gave low ratings,Movies and ratings with correlated queries,Queries with EXISTS,Customers with at least one rating,Actors in comedies,Queries with UNION and INTERSECT,Young actors not coming from the USA,Dramas with high ratings","Grouping movies,First account for each country.,Average movie ratings,Average rating per customer,Joining movie ratings with customer data,Join renting and customers,Aggregating revenue, rentals and active customers,Movies and actors,Money spent per customer with sub-queries,Income from movies,Age of actors from the USA,Identify favorite actors of customer groups,Identify favorite movies for a group of customers,Identify favorite actors for Spain,KPIs per country","OLAP: CUBE operator,Groups of customers,Categories of movies,Analyzing average ratings,ROLLUP,Number of customers,Analyzing preferences of genres across countries,GROUPING SETS,Queries with GROUPING SETS,Exploring nationality and gender of actors,Exploring rating by country and gender,Bringing it all together,Customer preference for genres,Customer preference for actors","Hadrien Lacroix,Mona Khalil","Data Analyst,SQL for Business Analysts,MovieNow,Intermediate SQL",,
169,Predictive Analytics using Networked Data in R,4,14,56,"3,570",4300,"In this course, you will learn to perform state-of-the art predictive analytics using networked data in R. The aim of network analytics is to predict to which class a network node belongs, such as churner or not, fraudster or not, defaulter or not, etc. To accomplish this, we discuss how to leverage information from the network and its underlying structure in a predictive way. More specifically, we introduce the idea of featurization such that network features can be added to non-network features as such boosting the performance of any resulting analytical model. In this course, you will use the igraph package to generate and label a network of customers in a churn setting and learn about the foundations of network learning. Then, you will learn about homophily, dyadicity and heterophilicty, and how these can be used to get key exploratory insights in your network. Next, you will use the functionality of the igraph package to compute various network features to calculate both node-centric as well as neighbor based network features. Furthermore, you will use the Google PageRank algorithm to compute network features and empirically validate their predictive power. Finally, we teach you how to generate a flat dataset from the network and analyze it using logistic regression and random forests.","Motivation: social networks and predictive analytics,Most likely to churn,Create a network from an edgelist,Labeled networks and network learning,Labeling nodes,Coloring nodes,Visualizing Churners,Relational Neighbor Classifier,Challenges of network-based inference,Challenges in Network learning,Probabilistic Relational Neighbor Classifier,Collective Inferencing","Basic Network features,Simple network features,Centrality features,Transitivity,Link-Based Features,Adjacency matrices,Link-based features,Second order link-based features,Neighborhood link-based features,PageRank,Most influential node,Changes in PageRank,Convergence of PageRank,Personalized PageRank,Extract PageRank features","Homophily,Homophilic networks,Extracting types of edges,Counting types of edges,Counting nodes and computing connectance,Dyadicity,Same label edges,Dyadicity of churners,Dyadicity of non-churners,Heterophilicity,Cross label edges,Compute heterophilicity,Summary of homophily,Dyadicity, Heterophilicity, & Homophily,Is the network homophilic?","Extract a dataset,Getting a flat dataset,Missing Values,Replace missing values,Correlated variables,Building a predictive model,Split into train and test,Logistic regression model,Random forest model,Evaluating model performance,Predicting churn,Measure AUC,Measure top decile lift,Summary and final thoughts","David Campos,Chester Ismay,Shon Inouye","Network Analysis,Student Customers dataset,Student Edge List dataset,Student Network dataset,Network Analysis in R,Supervised Learning in R: Classification",,
170,Machine Learning in the Tidyverse,5,15,52,"11,726",4300,"This course will teach you to leverage the tools in the ""tidyverse"" to generate, explore, and evaluate machine learning models. Using a combination of tidyr and purrr packages, you will build a foundation for how to work with complex model objects in a ""tidy"" way. You will also learn how to leverage the broom package to explore your resulting models. You will then be introduced to the tools in the test-train-validate workflow, which will empower you evaluate the performance of both classification and regression models as well as provide the necessary information to optimize model performance via hyperparameter tuning.","Foundations of ""tidy"" machine learning,Nesting your data,Unnesting your data,Explore a nested cell,The map family of functions,Mapping your data,Expecting mapped output,Mapping many models,Tidy your models with broom,The three ways to tidy your model,Extracting model statistics tidily,Augmenting your data","Training, test and validation splits,The test-train split,Cross-validation data frames,Measuring cross-validation performance,Build cross-validated models,Preparing for evaluation,Evaluate model performance,Building and tuning a random forest model,Build a random forest model,Evaluate a random forest model,Fine tune your model,The best performing parameter,Measuring the test performance,Build & evaluate the best model","Exploring coefficients across models,Tidy up the coefficients of your models,What can we learn about these 77 countries?,Evaluating the fit of many models,Glance at the fit of your models,Best and worst fitting models,Visually inspect the fit of many models,Augment the fitted values of each model,Explore your best and worst fitting models,Improve the fit of your models,Build better models,Predicting the future","Logistic regression models,Prepare train-test-validate parts,Build cross-validated models,Evaluating classification models,Predictions of a single model,Performance of a single model,Prepare for cross-validated performance,Calculate cross-validated performance,Random forest for classification,Tune random forest models,Random forest performance,Build final classification model,Measure final model performance,Wrap-up","Sumedh Panchadhar,Chester Ismay,Eunkyung Park","Intermediate Tidyverse Toolbox,Machine Learning Scientist,Supervised Machine Learning,Gapminder,Attrition,Modeling with Data in the Tidyverse",,
171,Intermediate Interactive Data Visualization with plotly in R,4,15,54,"3,521",4400,"The plotly package enables the construction of interactive and animated graphics entirely within R. This goes beyond basic interactivity such as panning, zooming, and tooltips. In this course, you will extend your understanding of plotly to create animated and linked interactive graphics, which will enable you to communicate multivariate stories quickly and effectively. Along the way, you will review the basics of plotly, learn how to wrangle your data in new ways to facilitate cumulative animations, and learn how to add filters to your graphics without using Shiny.","Interactive and dynamic graphics,Which is the interactive graphic?,A simple time series plot,A simple scatterplot,Adding aesthetics to represent a variable,Color and size,Plotting symbols,Polishing your graphics,Moving Beyond Simple Interactivity,Bubble charts,Many time series","Linking two charts,sharedData objects,Linking scatterplots,highlighting() charts,Brushing groups,Highlighting time series data,Linking a dotplot and a time series plot,Linking a bar chart to a scatterplot,Selection strategies,Searching for clusters,Adding dropdown menus,Making shinier charts,Arranging views with bscols(),Adding checkboxes,Adding a slider","Introduction to animated graphics,What's the frame?,Why do we need ids?,Animating a scatterplot,Factors as frames,Polishing animations,Polishing your regional animation,Polishing your HPI animation,Layering in plotly,Adding background text,Plotting the baseline,Cumulative animations,How many rows?,Median life expectancies,Animating median life expectancies","Introduction to the space launches data,Launches over time,Space race timeline,State vs. private launches,Recap: Animation,Animating the space race,Animating the private space race,Recap: linked views and selector widgets,Linking for group selection,Linked brushing,Linked views for summarization,Adding a slider for time,Wrap-up","David Campos,Chester Ismay","Interactive Data Visualization,Economic indicators for the 50 states and Washington, D.C. from 1997 to 2017,Complete list of all orbital space launches between 1957 and 2018,Interactive Data Visualization with plotly in R",,
172,Building Recommendation Engines with PySpark,4,15,56,"9,381",4550,"This course will show you how to build recommendation engines using Alternating Least Squares in PySpark. Using the popular MovieLens dataset and the Million Songs dataset, this course will take you step by step through the intuition of the Alternating Least Squares algorithm as well as the code to train, test and implement ALS models on various types of customer data.","Why learn how to build recommendation engines?,See the power of a recommendation engine,Power of recommendation engines,Recommendation engine types and data types,Collaborative vs content-based filtering,Collaborative vs content based filtering part II,Implicit vs explicit data,Ratings data types,Uses for recommendation engines,Alternate uses of recommendation engines.,Confirm understanding of latent features","Introduction to the MovieLens dataset,Viewing the MovieLens Data,Calculate sparsity,The GroupBy and Filter methods,MovieLens Summary Statistics,View Schema,ALS model buildout on MovieLens Data,Create test/train splits and build your ALS model,Tell Spark how to tune your ALS model,Build your cross validation pipeline,Best Model and Best Model Parameters,Model Performance Evaluation,Generate predictions and calculate RMSE,Interpreting the RMSE,Do recommendations make sense","Overview of matrix multiplication,Matrix multiplication,Matrix multiplication part II,Overview of matrix factorization,Matrix factorization,Non-negative matrix factorization,How ALS alternates to generate predictions,Estimating recommendations,RMSE as ALS alternates,Data preparation for Spark ALS,Correct format and distinct users,Assigning integer id's to movies,ALS parameters and hyperparameters,Build out an ALS model,Build RMSE evaluator,Get RMSE","Introduction to the Million Songs Dataset,Confirm understanding of implicit rating concepts,MSD summary statistics,Grouped summary statistics,Add zeros,Evaluating implicit ratings models,Specify ALS hyperparameters,Build implicit models,Running a cross-validated implicit ALS model,Extracting parameters,Overview of binary, implicit ratings,Binary model performance,Recommendations from binary data,Course recap","Lore Dirick,Nick Solomon,Adrián Soto","Big Data with PySpark,Introduction to PySpark,Supervised Learning with scikit-learn",,
173,Survival Analysis in R,4,14,50,"8,922",3650,"Do patients taking the new drug survive longer than others? How fast do people get a new job after getting unemployed? What can I do to make my friends stay on the dancefloor at my party? All these questions require the analysis of time-to-event data, for which we use special statistical methods. This course introduces basic concepts of time-to-event data analysis, also called survival analysis. Learn how to deal with time-to-event data and how to compute, visualize and interpret survivor curves as well as Weibull and Cox models.","The term ""survival analysis"",Introducing the GBSG2 dataset,What will this course cover?,Why learn survival methods?,Digging into the GBSG2 dataset 1,Using the Surv() function for GBSG2,The UnempDur dataset,Measures used in survival analysis,Interpreting a survival curve I,Interpreting a survival curve II,Interpreting a survival curve III","Why use the Weibull model,Interpreting coefficients,Compute Weibull model,Visualizing Weibull models,ggsurvplot() versus ggsurvplot_df(),Computing a Weibull model and the survival curves,Visualising a Weibull model,Plotting options,Other distributions than Weibull,survreg() arguments,Computing a Weibull and a log-normal model,Comparing Weibull and Log-Normal Model I,Comparing Weibull and Log-Normal Model II","Kaplan-Meier estimate,Function to compute the Kaplan-Meier estimate,First Kaplan-Meier estimate,When does the Kaplan-Meier curve drop?,Why use Kaplan-Meier,Understanding and visualizing Kaplan-Meier curves,Exercise ignoring censoring,Estimating and visualizing a survival curve,The Weibull model for estimating survival curves,Estimating median survival from a Weibull model,Survival curve quantiles from a Weibull model,Estimating the survival curve with survreg(),Visualizing the results of Weibull models,Comparing Weibull model and Kaplan-Meier estimate","The Cox model,Computing a Cox model,Proportional hazards assumption,Visualizing the Cox model,Computing the survival curve from a Cox model,Visualizing a Cox model,surv_summary(),What we've learned,Why ""imaginary patients""?,Capstone: The Cox model,Capstone: Comparing survival curves,Good bye","David Campos,Richie Cotton,Shon Inouye","Statistician,Introduction to Regression in R",,
174,Visualizing Geospatial Data in Python,4,14,51,"12,787",4250,"One of the most important tasks of a data scientist is to understand the relationships between their data's physical location and their geographical context. In this course you'll be learning to make attractive visualizations of geospatial data with the GeoPandas package. You will learn to spatially join datasets, linking data to context. Finally you will learn to overlay geospatial data to maps to add even more spatial cues to your work. You will use several datasets from the City of Nashville's open data portal to find out where the chickens are in Nashville, which neighborhood has the most public art, and more!","Introduction,Plotting a scatterplot from longitude and latitude,Styling a scatterplot,Extracting longitude and latitude,Plotting chicken locations,Geometries and shapefiles,Creating a GeoDataFrame & examining the geometry,Plotting shapefile polygons,Scatterplots over polygons,Geometry,Plotting points over polygons - part 1,Plotting points over polygons - part 2","GeoSeries attributes and methods I,Find the area of the Urban Residents neighborhood,GeoSeries attributes and methods II,The center of the Urban Residents neighborhood,Prepare to calculate distances,Art distances from neighborhood center,Street maps with folium,Create a folium location from the urban centroid,Create a folium map of downtown Nashville,Folium street map of the downtown neighborhood,Creating markers and popups in folium,Adding markers for the public art,Troubleshooting data issues,A map of downtown art","GeoJSON and plotting with geopandas,Working with GeoJSON,Colormaps,Map Nashville neighborhoods,Projections and coordinate reference systems,Changing coordinate reference systems,Construct a GeoDataFrame from a DataFrame,Spatial joins,Spatial join practice,Finding the neighborhood with the most public art,Aggregating points within polygons,Plotting the Urban Residents neighborhood and art","What is a choropleth?,Finding counts from a spatial join,Council district areas and permit counts,Calculating a normalized metric,Choropleths with geopandas,Geopandas choropleths,Area in km squared, geometry in decimal degrees,Spatially joining and getting counts,Building a polished Geopandas choropleth,Choropleths with folium,Folium choropleth,Folium choropleth with markers and popups,Closing thoughts","Greg Wilson,Adrián Soto","Data Visualization,Building permits issued in Nashville in 2017,Council district GIS data,Nashville neighborhoods GIS data,Public artworks in Nashville,School district GIS data,Schools in Nashville,Introduction to Data Visualization with Matplotlib,Data Manipulation with pandas",,
175,Python for MATLAB Users,4,15,51,"5,560",4200,"Python is a versatile programming language that is becoming more and more popular for doing data science. Companies worldwide are using Python to harvest insights from their data and get a competitive edge. This course focuses on helping Matlab users learn to use Python specifically for data science. You will quickly learn how to migrate from Matlab to Python for data analysis and visualization. Learn the fundamentals of Python syntax, how to use numpy arrays to store and manipulate data. You will learn how to use matplotlib to discover trends, correlations, and patterns in real datasets, including bicycle traffic in the city of Seattle and avocado prices across the United States.","Welcome to Python!,Basic calculations,Forecasting an investment,Types of variables,Methods and packages,Manipulating strings with methods,Using Python packages,Arrays & plotting,Getting started with NumPy arrays,Plotting bicycle traffic,What predicts animal longevity?","Dictionaries,Which keys?,Get data out,Modifying dictionaries,Introduction to DataFrames,Explore a pandas DataFrame,Plot data from a DataFrame,Accessing pandas DataFrames,Accessing rows and columns,The many flavors of .iloc,Creating pandas DataFrames,From a CSV file,From a dictionary of lists,From a list of dictionaries","Diving into NumPy arrays,Forecasting over time,How much more do organic avocados cost?,Indexing NumPy arrays,Getting columns from NumPy arrays,Bike traffic throughout the week,Filtering arrays with Boolean indexing,Lists,List exploration,Making NumPy arrays from lists,Operating on lists and arrays,Customizing plots,Colors, linestyles, and legends,Encoding data in color & size,Determine engine types in wildlife strikes","Looping through data,Looping through lists,Overlaying multiple plots on a figure,Comparisons and control flow,Counting different types of aircraft,Finding certain rows in a DataFrame,Filtering data,Boolean indexing for quick stats,Booleans for the win!,Boolean indexing and Matplotlib fun,Well done!","Becca Robins,Mari Nazary","FAA Wildlife Strikes,Fremont Bridge - hourly traffic,Fremont Bridge - daily traffic,Animal taxonomy,Historical avocado data",,
176,Statistical Simulation in Python,4,16,58,"15,421",4800,"Simulations are a class of computational algorithms that use the relatively simple idea of random sampling to solve increasingly complex problems. Although they have been around for ages, they have gained in popularity recently due to the rise in computational power and have seen applications in multiple domains including Artificial Intelligence, Physics, Computational Biology and Finance just to name a few. Students will use simulations to generate and analyze data over different probability distributions using the important NumPy package. This course will give students hands-on experience with simulations using simple, real-world applications.","Introduction to random variables,np.random.choice(),Poisson random variable,Shuffling a deck of cards,Simulation basics,Throwing a fair die,Throwing two fair dice,Simulating the dice game,Using simulation for decision-making,Simulating one lottery drawing,Should we buy?,Calculating a break-even lottery price","Introduction to resampling methods,Sampling with replacement,Probability example,Bootstrapping,Running a simple bootstrap,Non-standard estimators,Bootstrapping regression,Jackknife resampling,Basic jackknife estimation - mean,Jackknife confidence interval for the median,Permutation testing,Generating a single permutation,Hypothesis testing - Difference of means,Hypothesis testing - Non-standard statistics","Probability basics,Queen and spade,Two of a kind,Game of thirteen,More probability concepts,The conditional urn,Birthday problem,Full house,Data generating process,Driving test,National elections,Fitness goals,eCommerce Ad Simulation,Sign up Flow,Purchase Flow,Probability of losing money","Simulation for Business Planning,Modeling Corn Production,Modeling Profits,Optimizing Costs,Monte Carlo Integration,Integrating a Simple Function,Calculating the value of pi,Simulation for Power Analysis,Factors influencing Statistical Power,Power Analysis - Part I,Power Analysis - Part II,Applications in Finance,Portfolio Simulation - Part I,Portfolio Simulation - Part II,Portfolio Simulation - Part III,Wrap Up","Lore Dirick,Becca Robins,Sara Snell",Sampling in Python,,
177,Introduction to Anomaly Detection in R,4,13,47,"6,140",3900,"Are you concerned about inaccurate or suspicious records in your data, but not sure where to start? An anomaly detection algorithm could help! Anomaly detection is a collection of techniques designed to identify unusual data points, and are crucial for detecting fraud and for protecting computer networks from malicious activity. In this course, you'll explore statistical tests for identifying outliers, and learn to use sophisticated anomaly scoring algorithms like the local outlier factor and isolation forest. You'll apply anomaly detection algorithms to identify unusual wines in the UCI Wine quality dataset and also to detect cases of thyroid disease from abnormal hormone measurements.","What do we mean when we talk about anomalies?,Recognizing anomaly types,Exploring the river nitrate data,Testing the extremes with Grubbs' test,Visual check of normality,Grubbs' test,Hunting multiple outliers using Grubbs' test,Anomalies in time series,Visual assessment of seasonality,Seasonal Hybrid ESD algorithm,Interpreting Seasonal-Hybrid ESD output,Seasonal-Hybrid ESD versus Grubbs' test","Isolation trees,Fit and predict with an isolation tree,Score interpretation,Isolation forest,Fit an isolation forest,Checking convergence,Visualizing the isolation score,A grid of points,Prediction over a grid,Anomaly contours","k-nearest neighbors distance score,Exploring wine,kNN distance matrix,kNN distance score,Visualizing kNN distance,Standardizing features,Appending the kNN score,Visualizing kNN distance score,Local outlier factor,LOF calculation,LOF visualization,LOF vs kNN","Labeled anomalies,Thyroid data,Visualizing thyroid disease,Anomaly score,Measuring performance,Binarized scores,Cross-tabulate binary scores,Thyroid precision and recall,Working with categorical features,Converting character to factor,Isolation forest with factors,LOF with factors,Wrap-up","Chester Ismay,Amy Peterson","Furniture,Wine,Thyroid,Intermediate R",,
178,Intermediate Data Visualization with Seaborn,4,13,50,"47,083",4200,"Do you want to make beautiful, informative visualizations with ease? If so, then you must learn seaborn! Seaborn is a visualization library that is an essential part of the python data science toolkit. In this course, you will learn how to use seaborn's sophisticated visualization tools to analyze multiple real world datasets including the American Housing Survey, college tuition data, and guests from the popular television series, The Daily Show. Following this course, you will be able to use seaborn functions to visualize your data in several different formats and customize seaborn plots for your unique needs.","Introduction to Seaborn,Seaborn foundation,Reading a csv file,Comparing a histogram and displot,Using the distribution plot,Plot a histogram,Rug plot and kde shading,Interpreting the results,Regression Plots in Seaborn,Create a regression plot,Plotting multiple variables,Facetting multiple regressions","Categorical Plot Types,stripplot() and swarmplot(),boxplots, violinplots and boxenplots,barplots, pointplots and countplots,Regression Plots,Regression and residual plots,Regression plot parameters,Binning data,Matrix plots,Creating heatmaps,Customizing heatmaps","Using Seaborn Styles,Setting the default style,Comparing styles,Removing spines,Colors in Seaborn,Matplotlib color codes,Using default palettes,Color Palettes,Creating Custom Palettes,Customizing with matplotlib,Using matplotlib axes,Additional plot customizations,Adding annotations,Multiple plots","Using FacetGrid, catplot and lmplot,Building a FacetGrid,Using a catplot,Using a lmplot,Using PairGrid and pairplot,Building a PairGrid,Using a pairplot,Additional pairplots,Using JointGrid and jointplot,Building a JointGrid and jointplot,Jointplots and regression,Complex jointplots,Selecting Seaborn Plots","Kara Woo,Becca Robins,Sara Snell","Data Scientist,US Housing and Urban Development FY 2018 Fair Market Rent,Washington DC Bike Share,2018 College Scorecard Tuition,Daily Show Guests,Automobile Insurance Premiums,2010 US School Improvement Grants,Data Manipulation with pandas",,
179,Analyzing US Census Data in R,4,17,59,"3,632",5050,"Analysts across industries rely on data from the United States Census Bureau in their work. In this course, students will learn how to work with Census tabular and spatial data in the R environment. The course focuses on the tidycensus package for acquiring data from the decennial US Census and American Community survey in a tidyverse-friendly format, and the tigris package for accessing Census geographic data within R. By the end of this course, students will be able to rapidly visualize and explore demographic data from the Census Bureau using ggplot2 and other tidyverse tools, and make maps of Census demographic data with only a few lines of R code.","Census data in R: an overview,Obtain and set your Census API key,Getting Census data with tidycensus,Basic tidycensus functionality,Understanding tidycensus options,Tidy and wide data in tidycensus,Searching for data with tidycensus,Loading variables in tidycensus,Exploring variables with tidyverse tools,Visualizing Census data with ggplot2,Comparing geographies with ggplot2 visualizations,Customizing ggplot2 visualizations of ACS data","Understanding census geography and tigris basics,Getting Census boundary files with tigris,Getting geographic features with tigris,Understanding the structure of tigris objects,Customizing tigris options,TIGER/Line and cartographic boundary files,Getting data as simple features objects,Setting a cache directory,Working with historic shapefiles,Combining and joining census geographic datasets,Combining datasets of the same tigris type,Getting data for multiple states,Joining data from an external data frame,Plotting data with tigris and ggplot2,Plotting simple features with geom_sf(),Customizing geom_sf() plots","Tables and summary variables in tidycensus,Download and view a table of data from the ACS,Get a summary variable and calculate percentages,Census data wrangling with tidy tools,Finding the largest group by county,Recoding variables and calculating group sums,Comparing ACS estimates for multiple years,Working with margins of error in tidycensus,Inspecting margins of error,Using margin of error functions in tidycensus,Calculating group-wise margins of error,Visualizing margins of error from the ACS,Quick visual exploration of ACS margins of error,Customizing a ggplot2 margin of error plot","Simple feature geometry and tidycensus,Getting simple feature geometry,Joining data from tigris and tidycensus,Shifting Alaska and Hawaii geometry,Mapping demographic data with ggplot2,Making a choropleth map,Modifying map colors,Customizing the map output,Advanced demographic mapping,Graduated symbol maps,Faceted maps with ggplot2,Interactive visualization with mapview,Cartographic workflows with tigris and tidycensus,Generating random dots with sf,Obtaining data for cartography with tigris,Making a dot-density map with ggplot2,Next steps for working with demographic data in R","Chester Ismay,Becca Robins","Introduction to the Tidyverse,Spatial Analysis with sf and raster in R",,
180,Analyzing Police Activity with pandas,4,16,50,"53,722",4100,"Now that you have learned the foundations of pandas, this course will give you the chance to apply that knowledge by answering interesting questions about a real dataset! You will explore the Stanford Open Policing Project dataset and analyze the impact of gender on police behavior. During the course, you will gain more practice cleaning messy data, creating visualizations, combining and reshaping datasets, and manipulating time series data. Analyzing Police Activity with pandas will give you valuable experience analyzing a dataset from start to finish, preparing you for your data science career!","Stanford Open Policing Project dataset,Examining the dataset,Dropping columns,Dropping rows,Using proper data types,Finding an incorrect data type,Fixing a data type,Creating a DatetimeIndex,Combining object columns,Setting the index","Does time of day affect arrest rate?,Calculating the hourly arrest rate,Plotting the hourly arrest rate,Are drug-related stops on the rise?,Plotting drug-related stops,Comparing drug and search rates,What violations are caught in each district?,Tallying violations by district,Plotting violations by district,How long might you be stopped for a violation?,Converting stop durations to numbers,Plotting stop length","Do the genders commit different violations?,Examining traffic violations,Comparing violations by gender,Does gender affect who gets a ticket for speeding?,Filtering by multiple conditions,Comparing speeding outcomes by gender,Does gender affect whose vehicle is searched?,Calculating the search rate,Comparing search rates by gender,Adding a second factor to the analysis,Does gender affect who is frisked during a search?,Counting protective frisks,Comparing frisk rates by gender","Exploring the weather dataset,Plotting the temperature,Plotting the temperature difference,Categorizing the weather,Counting bad weather conditions,Rating the weather conditions,Changing the data type to category,Merging datasets,Preparing the DataFrames,Merging the DataFrames,Does weather affect the arrest rate?,Comparing arrest rates by weather rating,Selecting from a multi-indexed Series,Reshaping the arrest rate data,Conclusion","Becca Robins,Sara Snell","Data Manipulation,Data Scientist,Traffic stops in Rhode Island,Weather in Providence, Rhode Island,Joining Data with pandas",,
181,RNA-Seq with Bioconductor in R,4,16,44,"11,883",3150,"RNA-Seq is an exciting next-generation sequencing method used for identifying genes and pathways underlying particular diseases or conditions. As high-throughput sequencing becomes more affordable and accessible to a wider community of researchers, the knowledge to analyze this data is becoming an increasingly valuable skill. Join us in learning about the RNA-Seq workflow and discovering how to identify which genes and biological processes may be important for your condition of interest! We will start the course with a brief overview of the RNA-Seq workflow with an emphasis on differential expression (DE) analysis. Starting with the counts for each gene, the course will cover how to prepare data for DE analysis, assess the quality of the count data, and identify outliers and detect major sources of variation in the data. The DESeq2 R package will be used to model the count data using a negative binomial model and test for differentially expressed genes. Visualization of the results with heatmaps and volcano plots will be performed and the significant differentially expressed genes will be identified and saved.","Introduction to RNA-Seq,Core Concepts,RNA-Seq Packages,RNA-Seq Workflow,Read Alignments,Exploring the raw count matrix,Differential gene expression overview,DGE Theory,DGE Theory: Metadata","DE analysis,Creating the DE object,DESeq2 model - dispersion,DESeq2 model - exploring dispersions,Interpreting the dispersion plot,DESeq2 model - contrasts,DESeq2 model - extracting results,DESeq2 results - LFC shrinkage,DESeq2 results,DESeq2 results exploration,Summarizing DESeq2 results,DESeq2 significant results","Introduction to differential expression analysis,Practice with the DESeq2 vignette,Organizing the data for DESeq2,Matching metadata and counts data,Count normalization,Normalizing counts with DESeq2,Hierarchical heatmap,Hierarchical heatmap by condition,Hierarchical heatmap analysis,Principal component analysis,PCA analysis,PCA practice: exploring variations,PCA practice: exploring additional variations","Visualization of results,DESeq2 visualizations - MA and volcano plots,DESeq2 visualizations - heatmap,RNA-Seq DE analysis summary - setup,RNA-Seq DE analysis - experimental planning,RNA-Seq DE workflow summary,RNA-Seq DE analysis summary,DE analysis,DE analysis results,RNA-Seq next steps","David Campos,Richie Cotton,Shon Inouye","Analyzing Genomic Data,Fibrosis raw counts dataset,Introduction to Bioconductor in R,Introduction to Data Visualization with ggplot2",,
182,Introduction to A/B Testing in R,4,16,60,"9,891",4700,"In this course, you will learn the foundations of A/B testing, including hypothesis testing, experimental design, and confounding variables. You will also be exposed to a couple more advanced topics, sequential analysis and multivariate testing. The first dataset will be a generated example of a cat adoption website. You will investigate if changing the homepage image affects conversion rates (the percentage of people who click a specific button). For the remainder of the course you will use another generated dataset of a hypothetical data visualization website.","Introduction,Goals of A/B testing,Preliminary data exploration,Baseline conversion rates,Current conversion rate day of week,Current conversion rate week,Plotting conversion rate seasonality,Experimental design, power analysis,Randomized vs. sequential,SSizeLogisticBin() documentation,Power analysis August,Power analysis August 5 percentage point increase","A/B testing research questions,Article click frequency monthly,'Like' click frequency plot,'Like' / 'Share' click frequency plot,Assumptions and types of A/B testing,Between vs. within,Plotting A/A data,Analyzing A/A data,Confounding variables,Examples of confounding variables,Confounding variable example analysis,Confounding variable example plotting,Side effects,Confounding variable vs. side effect,Side effect load time plot,Side effects experiment plot","Analyzing results,Plotting results,glm() documentation,Practice with glm(),Designing follow-up experiments,Follow-up experiment 1 design,Follow-up experiment 1 power analysis,Follow-up experiment 1 analysis,Pre-follow-up experiment assumptions,Plot 8 months data,Plot styling 1,Plot styling 2,Follow-up experiment assumptions,Conversion rate between years,Re-run power analysis for follow-up,Re-run glm() for follow-up","Power analyses,Logistic regression power analysis,pwr.t.test() documentation,T-test power analysis,Statistical tests,Logistic regression,T-test,Stopping rules and sequential analysis,What is a sequential analysis?,Sequential analysis three looks,Sequential analysis sample sizes,Multivariate testing,Plotting time homepage in multivariate experiment,Plotting 'like' clicks in multivariate experiment,Multivariate design statistical test,A/B Testing Recap","David Campos,Chester Ismay,Shon Inouye","Click dataset,Experiment dataset,Data Visualization Website - April 2018,Intermediate R,Foundations of Inference,Experimental Design in R",,
183,Analyzing Election and Polling Data in R,4,15,55,"6,474",4650,"This is an introductory course to the R programming language as applied in the context of political data analysis. In this course students learn how to wrangle, visualize, and model data with R by applying data science techniques to real-world political data such as public opinion polling and election results. The tools that you'll use in this course, from the dplyr, ggplot2, and choroplethr packages, among others, are staples of data science and can be used to analyze almost any dataset you get your hands on. Students will learn how to mutate columns and filter datasets, graph points and lines on charts, make maps, and create models to understand relationships between variables and predict the future. This course is suitable for anyone who already has downloaded R and knows the basics, like how to install packages.","Introduction,Selecting columns of data,Filtering rows of data,Averaging job approval by president,Averaging approval ratings by president,Averaging a column,Visualizing Trump's approval over time,Averaging president Trump's approval by month,Calculating a rolling average of polls,Visualizing Donald Trump's approval polls,Bonus: Visualizing every president's approval","The 2016 US presidential election,County-level election results and spread(),County-level demographic data and left_join(),Merging demographic and voting data,Analyzing votes and demographic data,Making county-level maps in R,Mapping the Democratic vote by county,Mapping the concentration of white Americans,Analyzing results with linear regression,Answering ""why"" questions for elections,Multivariate regression in R,The 2016 UK referendum to leave the EU (Brexit),Who was ""supposed"" to win?,Brexit results,UKIP and Brexit,The ""why"" question for Brexit","Elections and political parties,Tidyverse refresher,Measuring support for U.S. political parties,Mutating a new column,73 Years of ""generic ballot"" polls,Comparing the Democratic lead by year,A time series of House and Senate polling,Visualizing a time series,Graphing trend lines with geom_smooth(),Calculating and visualizing error in polls,Calculating error in polls,Confidence intervals,Geom_point()  and geom_errorbar(),Predicting winners with linear regression,Fitting a model to past polls and results,Making a prediction on new data","The House of Representatives in 2018,The ""generic ballot"" in 2018,Polls  in August and September,Training a model to predict the future with polls,Training a model,Predictions on new data,Uncertainty,The presidency in 2020,A model for presidential elections,Training the model,Predicting 2020 with the model,Course recap","David Campos,Chester Ismay,Shon Inouye","Brexit Polls,Brexit Results,Gallup Approval Polls,Generic Ballot,US Pres 2016 by County,Introduction to the Tidyverse",,
184,Interactive Maps with leaflet in R,4,16,55,"11,847",4500,"Get ready to have some fun with maps! Interactive Maps with leaflet in R will give you the tools to make attractive and interactive web maps using spatial data and the tidyverse. In this course, you will create maps using the IPEDS dataset, which contains data on U.S. colleges and universities. Along the way, you will customize our maps using labels, popups, and custom markers, and add layers to enhance interactivity. Following the course, you will be able to create and customize your own interactive web maps to reveal patterns in your data.","Introduction to leaflet,Loading the leaflet Library,Creating an Interactive Web Map,Map Tiles,Provider Tiles,Adding a Custom Map Tile,Setting the Default Map View,A Map with a View I,A Map with a Narrower View,Plotting DataCamp HQ,Mark it,Adding Popups and Storing your Map","The Leaflet Extras Package,Middle America,Building a Base,Down South,Overlay Groups,Mapping Public Colleges,Mapping Public and Private Colleges,Mapping All Colleges,Base Groups,Change up the Base,Putting it all Together,Pieces of Flair,Adding a Piece of Flair,A Cluster Approach","Introduction to IPEDS Data,Cleaning up the Base Map,Exploring the IPEDS Data,Exploring the IPEDS Data II,Mapping California Colleges,California Colleges,The City of Colleges,Circle Markers,Labels and Pop-ups,Making our Map Pop,What is California's Northernmost College?,Building a Better Pop-up,Swapping Popups for Labels,Color Coding Colleges,Creating a Color Palette using colorFactor,A Legendary Map","Spatial Data,Introduction to Spatial Data,Exploring Spatial Data,Joining Spatial Data,Mapping Polygons,addPolygons() Function,NC High Income Zips,addPolygon() Options,Let's do some Logging,Putting it All Together,Wealthiest Zip Codes in America,Final Map,Thank you!","Chester Ismay,Becca Robins","Interactive Data Visualization,Spatial Data,IPEDS All 4-Year Colleges,NC Zipcode Income data,NC Zipcode Polygons,America's Wealthiest Zipcodes,Introduction to the Tidyverse",,
185,Hyperparameter Tuning in R,4,14,47,"5,558",3500,"For many machine learning problems, simply running a model out-of-the-box and getting a prediction is not enough; you want the best model with the most accurate prediction. One way to perfect your model is with hyperparameter tuning, which means optimizing the settings for that specific model. In this course, you will work with the caret, mlr and h2o packages to find the optimal combination of hyperparameters in an efficient manner using grid search, random search, adaptive resampling and automatic machine learning (AutoML). Furthermore, you will work with different datasets and tune different supervised learning models, such as random forests, gradient boosting machines, support vector machines, and even neural nets. Get ready to tune!","Parameters vs hyperparameters,Model parameters vs. hyperparameters,Hyperparameters in linear models,What are the coefficients?,Recap of machine learning basics,Machine learning with caret,Resampling schemes,Hyperparameter tuning in caret,Hyperparameters in Stochastic Gradient Boosting,Changing the number of hyperparameters to tune,Tune hyperparameters manually","Machine learning with mlr,Machine Learning with mlr,Modeling with mlr,Grid and random search with mlr,Random search with mlr,Perform hyperparameter tuning with mlr,Evaluating hyperparameters with mlr,Why to evaluate tuning?,Evaluating hyperparameter tuning results,Advanced tuning with mlr,Define advanced tuning controls,Define aggregated measures,Setting hyperparameters","Hyperparameter tuning in caret,Finding hyperparameters,Cartesian grid search in caret,Plot hyperparameter model output,Grid vs. Random Search,Grid search with range of hyperparameters,Find train() option for random search,Random search with caret,Adaptive resampling,Advantages of Adaptive Resampling,Adaptive Resampling with caret","Machine learning with h2o,Prepare data for modelling with h2o,Modeling with h2o,Grid and random search with h2o,Grid search with h2o,Random search with h2o,Stopping criteria,Automatic machine learning with H2O,AutoML in h2o,Scoring the leaderboard,Extract h2o models and evaluate performance,Wrap-up","Chester Ismay,Hadrien Lacroix","Machine Learning Scientist,Supervised Machine Learning,Bc test data,Bc train data,Breast cancer data,Breast cancer data orig,Datasets descriptions,Knowledge data,Knowledge orig,Knowledge test data,Knowledge train data,Seeds data,Seeds dataset,Seeds test data,Seeds train data,Voters data,Voters orig,Voters test data,Voters train data,Machine Learning with caret in R",,
186,Introduction to MongoDB in Python,4,16,60,"14,541",4450,"MongoDB is a tool to explore data structured as you see fit. As a NoSQL database, it doesn't follow the strict relational format imposed by SQL. By providing capabilities that typically require adding layers to SQL, it collapses complexity. With dynamic schema, you can handle vastly different data together and consolidate analytics. The flexibility of MongoDB empowers you to keep improving and fix issues as your requirements evolve. In this course, you will learn the MongoDB language and apply it to search and analytics. Working with unprocessed data from the official nobelprize.org API, you will explore and answer questions about Nobel Laureates and prizes.","Intro to MongoDB and the Nobel Prize dataset,Count documents in a collection,Listing databases and collections,List fields of a document,Finding documents,""born"" approximation,Composing filters,We've got options,Dot notation: reach into substructure,Choosing tools,Starting our ascent,Our 'born' approximation, and a special laureate","Projection,Shares of the 1903 Prize in Physics,Rounding up the G.S. crew,Doing our share of data validation,Sorting,What the sort?,Sorting together: MongoDB + Python,Gap years,What are indexes?,High-share categories,Recently single?,Born and affiliated,Limits,Setting a new limit?,The first five prizes with quarter shares,Pages of particle-prized people","Survey Distinct Values,Categorical data validation,Never from there, but sometimes there at last,Countries of affiliation,Distinct Values Given Filters,Born here, went there,Triple plays (mostly) all around,Filter Arrays using Distinct Values,Sharing in physics after World War II,Meanwhile, in other categories...,Organizations and prizes over time,Distinct As You Like It,Glenn, George, and others in the G.B. crew,Germany, then and now,The prized transistor","Intro to Aggregation,Sequencing stages,Aggregating a few individuals' country data,Passing the aggregation baton to Python,Aggregation Operators and Grouping,Field Paths and Sets,Organizing prizes,Gap years, aggregated,Zoom into Array Fields,Embedding aggregation expressions,Here and elsewhere,Countries of birth by prize category,Something Extra: $addFields to Aid Analysis,""...it's the life in your years"",How many prizes were awarded to immigrants?,Refinement: filter out ""unaffiliated"" people,Wrap-Up","Alex Yarosh,Greg Wilson,Hadrien Lacroix,Mari Nazary","Data Engineer,Laureates dataset,Prizes dataset,Python Data Science Toolbox (Part 2),Data Types for Data Science in Python,NoSQL Concepts",,
187,Data Engineering for Everyone,2,11,32,"123,934",2300,"In 2019, the average salary for data engineers overtook data scientists. How did this happen? Companies wanting to find the gold within their data realized it wasn’t possible if they hadn’t yet built the mine. Data engineers lay the foundations that make data science possible.

In this course, you’ll learn about a data engineer’s core responsibilities, how they differ from data scientists, and facilitate the flow of data through an organization. Through hands-on exercises you’ll follow Spotflix, a fictional music streaming company, to understand how their data engineers collect, clean, and catalog their data. By the end of the course, you’ll understand what your company's data engineers do, be ready to have a conversation with a data engineer, and have a solid foundation to start your own data engineer journey.","Data engineering and big data,Go with the flow,Not responsible,Big time,Data engineers vs. data scientists,Tell me the truth,Who is it,The data pipeline,It's not true,Pipeline","Processing data,Connect the dots,Scheduling data,Schedules,One or the other,Parallel computing,Whenever, whenever,Parallel universe,Cloud computing,Obscured by clouds,Somewhere I belong,We are the champions","Data structures,Structures,What's the difference,SQL databases,We can work it out,Columns,Different breeds,Data warehouses and data lakes,Tell the truth,Our warehouse (in the middle of our street)",,"Richie Cotton,Lis Sulmont","Data Engineer,Data Literacy Fundamentals,Lexicon",,
188,Introduction to Anomaly Detection in R,4,13,47,"6,140",3900,"Are you concerned about inaccurate or suspicious records in your data, but not sure where to start? An anomaly detection algorithm could help! Anomaly detection is a collection of techniques designed to identify unusual data points, and are crucial for detecting fraud and for protecting computer networks from malicious activity. In this course, you'll explore statistical tests for identifying outliers, and learn to use sophisticated anomaly scoring algorithms like the local outlier factor and isolation forest. You'll apply anomaly detection algorithms to identify unusual wines in the UCI Wine quality dataset and also to detect cases of thyroid disease from abnormal hormone measurements.","What do we mean when we talk about anomalies?,Recognizing anomaly types,Exploring the river nitrate data,Testing the extremes with Grubbs' test,Visual check of normality,Grubbs' test,Hunting multiple outliers using Grubbs' test,Anomalies in time series,Visual assessment of seasonality,Seasonal Hybrid ESD algorithm,Interpreting Seasonal-Hybrid ESD output,Seasonal-Hybrid ESD versus Grubbs' test","Isolation trees,Fit and predict with an isolation tree,Score interpretation,Isolation forest,Fit an isolation forest,Checking convergence,Visualizing the isolation score,A grid of points,Prediction over a grid,Anomaly contours","k-nearest neighbors distance score,Exploring wine,kNN distance matrix,kNN distance score,Visualizing kNN distance,Standardizing features,Appending the kNN score,Visualizing kNN distance score,Local outlier factor,LOF calculation,LOF visualization,LOF vs kNN","Labeled anomalies,Thyroid data,Visualizing thyroid disease,Anomaly score,Measuring performance,Binarized scores,Cross-tabulate binary scores,Thyroid precision and recall,Working with categorical features,Converting character to factor,Isolation forest with factors,LOF with factors,Wrap-up","Chester Ismay,Amy Peterson","Furniture,Wine,Thyroid,Intermediate R",,
189,Machine Learning with scikit-learn,4,17,54,"309,548",4200,"Machine learning is the field that teaches machines and computers to learn from existing data to make predictions on new data: Will a tumor be benign or malignant? Which of your customers will take their business elsewhere? Is a particular email spam? In this course, you'll learn how to use Python to perform supervised learning, an essential component of machine learning. You'll learn how to build predictive models, tune their parameters, and determine how well they will perform with unseen data—all while using real world datasets. You'll be using scikit-learn, one of the most popular and user-friendly machine learning libraries for Python.","Supervised learning,Which of these is a classification problem?,Exploratory data analysis,Numerical EDA,Visual EDA,The classification challenge,k-Nearest Neighbors: Fit,k-Nearest Neighbors: Predict,Measuring model performance,The digits recognition dataset,Train/Test Split + Fit/Predict/Accuracy,Overfitting and underfitting","How good is your model?,Metrics for classification,Logistic regression and the ROC curve,Building a logistic regression model,Plotting an ROC curve,Precision-recall Curve,Area under the ROC curve,AUC computation,Hyperparameter tuning,Hyperparameter tuning with GridSearchCV,Hyperparameter tuning with RandomizedSearchCV,Hold-out set for final evaluation,Hold-out set reasoning,Hold-out set in practice I: Classification,Hold-out set in practice II: Regression","Introduction to regression,Which of the following is a regression problem?,Importing data for supervised learning,Exploring the Gapminder data,The basics of linear regression,Fit & predict for regression,Train/test split for regression,Cross-validation,5-fold cross-validation,K-Fold CV comparison,Regularized regression,Regularization I: Lasso,Regularization II: Ridge","Preprocessing data,Exploring categorical features,Creating dummy variables,Regression with categorical features,Handling missing data,Dropping missing data,Imputing missing data in a ML Pipeline I,Imputing missing data in a ML Pipeline II,Centering and scaling,Centering and scaling your data,Centering and scaling in a pipeline,Bringing it all together I: Pipeline for classification,Bringing it all together II: Pipeline for regression,Final thoughts",Yashas Roy,"Automobile miles per gallon,Boston housing,Diabetes,Gapminder,US Congressional Voting Records (1984),White wine quality,Red wine quality,Statistical Thinking in Python (Part 1)",,
190,Case Study: Analyzing Job Market Data in Power BI,3,4,24,"3,152",2150,"In this Power BI case study, you’ll explore a real-world job posting dataset to uncover insights for a fictional recruitment company called DataSearch. Using what you’ve learned from previous courses, you’ll use Power Query to investigate and clean the data to find out what skills are most in-demand for data scientists, data analysts, and data engineers. You’ll then use DAX to build insightful visualizations of your findings. Finally, you’ll bring it all together using everything Power BI has to offer to create a business dashboard so that you can answer questions for the DataSearch team.","Job market analysis with Power BI,EDA questions to ask,Data import with Power Query,Initial EDA with Power Query,Job posting trend analysis,Data cleanup of job titles,Effect of years experience on salary,Trends found with EDA","Building job market analysis dashboard,How to design a dashboard,Begin dashboard templates,Designing a dashboard layout,Exploring top skills for jobs,Salary gauge for companies,Adding interactivity with bookmarks,Case study wrap-up","Market insight analysis,Key insights to focus,Cleanup and skill analysis,Likelihood of skills in job posting,Trends in skills over time,Deep dive into key job descriptions,Other job recommendations,Trends from analysis",,"Maarten Van den Broeck,Carl Rosseel","Data Analyst,Power BI Fundamentals,Metadata sheet,Dataset,DataCamp vs. Local Experience,Data Visualization in Power BI,Introduction to DAX in Power BI",,
191,Optimizing R Code with Rcpp,4,15,52,"2,847",4350,"R is a great language for data science, but sometimes the code can be slow to run. Combining the comfort of R with the speed of a compiled language is a great way to reclaim the performance your code deserves. C++ is a modern, high performance language that is simple enough to learn in the context of accelerating R code. With the help of the Rcpp package, C++ integrates very neatly with R. You will learn how to create and manipulate typical R objects (vectors and lists), and write your own C++ functions to dramatically boost the performance of your R code.","Welcome to the course,Benchmarking with microbenchmark,Simple C++ Expressions with evalCpp,Conversion between numbers using cast,Inline functions with cppFunction,First function,Euclidean distance from 0,Debugging,Print to the console,Error messages","Rcpp classes and vectors,First and last values of a vector,Indexing a vector,Sum of double vector,Creating vectors,Sequence of integers,Create vector with given values,Vector cloning,Weighted mean,Weighted mean (C++ version),Handling of missing values,Vectors from the STL,Don't change the size of Rcpp vectors,STL vectors","C++ functions belong to C++ files,What happens when you compile this C++ file,Boiler plate,Writing functions in C++,First function - again,Exported and unexported functions,R code in C++ files,if and if/else,For loops,Calculating square roots with a for loop,Breaking out of a for loop,While loops,Calculating square roots with a while loop,Do it again: do-while loop","Random number generation,Scalar random number generation,Sampling from a mixture of distributions (I),Sampling from a mixture of distributions (II),Rolling operations,Rolling means,Rolling means (in C++),Last observation carried forward,Mean carried forward,Auto regressive model,Simulate AR(p) model,Simulate MA(q) model,ARMA (p, q) model,Congratulations!","Sumedh Panchadhar,Richie Cotton",Introduction to Writing Functions in R,,
192,Importing and Managing Financial Data in Python,5,16,53,"34,209",4350,"If you want to apply your new 'Python for Data Science' skills to real-world financial data, then this course will give you some very valuable tools. First, you will learn how to get data out of Excel into pandas and back. Then, you will learn how to pull stock prices from various online APIs like Google or Yahoo! Finance, macro data from the Federal Reserve, and exchange rates from OANDA. Finally, you will learn how to calculate returns for various time horizons, analyze stock performance by sector for IPOs, and calculate and summarize correlations.","Reading, inspecting, and cleaning data from CSV,Import stock listing info from the NASDAQ,How to fix the data import?,Read data using .read_csv() with adequate parsing arguments,Read data from Excel worksheets,Load listing info from a single sheet,Load listing data from two sheets,Combine data from multiple worksheets,Load all listing data and iterate over key-value dictionary pairs,How many companies are listed on the NYSE and NASDAQ?,Automate the loading and combining of data from multiple Excel worksheets","Summarize your data with descriptive stats,List the poorest and richest countries worldwide,Global incomes: Central tendency,Describe the distribution of your data with quantiles,Global incomes: Dispersion,Deciles of the global income distribution,Getting all the statistics,Visualize the distribution of your data,Visualizing international income distribution,Growth rates in Brazil, China, and the US,Highlighting values in the distribution,Summarize categorical variables,Companies by sector on all exchanges,Technology IPOs by year on all exchanges","The DataReader: Access financial data online,Get stock data for a single company,Visualize a stock price trend,Economic data from the Federal Reserve,Visualize the long-term oil price trend,Compare labor market participation and unemployment rates,Compare bond and stock performance,Select stocks and get data from Google Finance,Select the top 5 listed consumer companies,Get the ticker of the largest consumer services company,Get the largest consumer company listed after 1998,Get several stocks & manage a MultiIndex,Get data for the 3 largest financial companies","Aggregate your data by category,Median market capitalization by sector,Median market capitalization by IPO year,All summary statistics by sector,More ways to aggregate your data,Company value by exchange and sector,Calculate several metrics by sector and exchange,Summary statistics by category with seaborn,Plot IPO timeline for all exchanges using countplot(),Global median per capita income over time,Calculate several metrics by sector and IPO year,Distributions by category with seaborn,Inflation trends in China, India, and the US,Distribution of inflation rates in China, India, and the US,Congratulations!",Lore Dirick,"Finance Fundamentals,Amex listings .csv file,Income growth .csv file,Listings .xlsx file,Nasdaq listings .csv file,Per capita income .csv file,Data Manipulation with pandas",,
193,Supervised Learning in R: Regression,4,19,65,"32,198",5300,"From a machine learning perspective, regression is the task of predicting numerical outcomes from various inputs. In this course, you'll learn about different regression models, how to train these models in R, how to evaluate the models you train and use them to make predictions.","Welcome and Introduction,Identify the regression tasks,Linear regression - the fundamental method,Code a simple one-variable regression,Examining a model,Predicting once you fit a model,Predicting from the unemployment model,Multivariate linear regression (Part 1),Multivariate linear regression (Part 2),Wrapping up linear regression","Categorical inputs,Examining the structure of categorical inputs,Modeling with categorical inputs,Interactions,Modeling an interaction,Modeling an interaction (2),Transforming the response before modeling,Relative error,Modeling log-transformed monetary output,Comparing RMSE and root-mean-squared Relative Error,Transforming inputs before modeling,Input transforms: the ""hockey stick"",Input transforms: the ""hockey stick"" (2)","The intuition behind tree-based methods,Predicting with a decision tree,Random forests,Build a random forest model for bike rentals,Predict bike rentals with the random forest model,Visualize random forest bike model predictions,One-Hot-Encoding Categorical Variables,vtreat on a small example,Novel levels,vtreat the bike rental data,Gradient boosting machines,Find the right number of trees for a gradient boosting machine,Fit an xgboost bike rental model and predict,Evaluate the xgboost bike rental model,Visualize the xgboost bike rental model","Evaluating a model graphically,Graphically evaluate the unemployment model,The gain curve to evaluate the unemployment model,Root Mean Squared Error (RMSE),Calculate RMSE,R-Squared,Calculate R-squared,Correlation and R-squared,Properly Training a Model,Generating a random test/train split,Train a model using test/train split,Evaluate a model using test/train split,Create a cross validation plan,Evaluate a modeling procedure using n-fold cross-validation","Sumedh Panchadhar,Richie Cotton","Data Scientist,Machine Learning Fundamentals,Machine Learning Scientist,Bikes,Blood Pressure,Cricket,House Prices,Income,Mpg,Soybean,Unemployment,Sparrow,Introduction to Regression in R","Logistic regression to predict probabilities,Fit a model of sparrow survival probability,Predict sparrow survival,Poisson and quasipoisson regression to predict counts,Poisson or quasipoisson,Fit a model to predict bike rental counts,Predict bike rentals on new data,Visualize the bike rental predictions,GAM to learn non-linear transforms,Writing formulas for GAM models,Writing formulas for GAM models (2),Model soybean growth with GAM,Predict with the soybean model on test data",
194,Case Studies: Building Web Applications with Shiny in R,4,16,59,"15,780",4850,"After learning the basics of using Shiny to build web applications, this course takes you to the next level by putting your newly acquired skills into practice. You'll get experience developing fun and realistic Shiny apps for different common use cases, such as using Shiny to explore a dataset, generate a customized plot, and even create a word cloud. With all this practice and new knowledge, you will be well-equipped to develop Shiny apps for your own use.","Introduction,Simple text,Formatted text,Adding structure to your app,Inputs and outputs,Adding inputs,Adding placeholders for outputs,Constructing output objects,Reactivity 101,Reactivity: simple reactive variable,Reactivity: composed reactive variable,Reactive contexts","Explore a dataset with Shiny,See the data in a table,Filter by life expectancy,Select a continent to view,Allow ""All"" continents to be viewed,More ways to view data: plot and download,Plot the data,Download the filtered data,Reactive variables,Reactive variables reduce code duplication,More benefits of reactive variables,Visual enhancements,Make the table interactive,Place different outputs on different tabs,Add CSS to modify the look of the app","Make the perfect plot using Shiny,Explore the Gapminder data,More exploration of the Gapminder data,Adding simple inputs to modify a plot,Add a plot title: text input,Change the point size: numeric input,Fit a smooth curve: checkbox input,More input types,Add colours to your plot: radio buttons,Add a continent selector: select input,Add a year filter: numeric slider input,Advanced features to improve your plot,Add colours to your plot: color input,Making your plot larger,Make your plot interactive","Word clouds in Shiny,Word cloud Shiny app,Change the word cloud parameters,Add a layout,Adding word sources,Use your own words,Upload a text file (ui),Upload a text file (server),Combining all the word sources,Choose the data source (ui),Choose the data source (server),Conditionally show or hide required inputs,Fine tune the reactivity,Don't continuously create new word clouds,Reactivity: effects of isolation,Create a new word cloud on demand,Wrap-up: Go and make your own apps!",Richie Cotton,"Shiny Fundamentals,Building Web Applications with Shiny in R",,
195,Equity Valuation in R,4,16,58,"6,660",4750,"How do we know when a stock is cheap or expensive? To do this, we need to compare the stock's price with its value. The price of the stock can be obtained by looking at various public sources, such as Yahoo Finance or Google Finance. The value of the stock though is much harder to identify. Every investor has to form his or her valuation of the stock. In this course, you will learn the fundamentals of valuing stocks using present value approaches, such as free cash flow to equity and dividend discount models, and valuation multiples. By the end of this course, you will be able to build your own valuation models.","Course Intro and Fundamental Valuation,Time Value of Money,Difference Between Valuing Enterprise and Equity Cash Flows,The Free Cash Flow to Equity Model,Calculating Operating Profit,Calculate Free Cash Flow to Equity,Calculating Terminal Value,Calculating Equity Value,Calculating Present Value of Free Cash Flow to Equity,Calculate Present Value of Terminal Value,Calculate Equity Value","What is a discount rate?,Risk and Return,Calculating Returns,Estimating Beta,Unlevering Betas,Hamada vs. Fernandez Formula,Beta Unlevering Exercise,Beta Relevering Exercise,Risk-Free Rate and Equity Risk Premium,Obtain Risk-Free Rate Data,Calculate Historical Equity Risk Premium,Calculate the Cost of Equity","Fundamental Valuation: Analyzing Projections,Visually Inspecting the Data,Using Regression to Test the Projections,Fundamental Valuation: Implementation,Cost of Equity,Calculate Value During Projection Period,Calculate the Terminal Value,Equity Value Per Free Cash Flow to Equity Model,Equity Value per Dividend Discount Model,Relative Valuation,Equity Value Per Price-to-Earnings Multiples,Combine valuation into a summary table,Congratulations!","Analyzing the Projections,Analyze Revenue Trends - Bar Chart,Analyze Revenue Trends - Regression,Perpetuity Growth Rate,Calculate Retention Ratio,Perpetuity Growth Rate Calculation,Dividend Discount Model,Valuing Preferred Stock,Valuation Assuming No Dividends For First Few Years,Valuation Assuming 2-Stages of Dividends","Sumedh Panchadhar,Lore Dirick","Applied Finance,Historical returns,US Treasury data,S&P 400 Midcap Index,Mylan prices,Importing and Managing Financial Data in R","Relative Valuation,Identifying Comparable Firms,Valuation Multiples,Calculating Valuation Multiples,Calculating the Relevant Multiple,Implied Price,Analyzing Determinants of Multiples,Calculate ROE and P/B,Plot P/B vs. ROE,Strength of Relationship,Implied Price Using Regression,Difference in Implied Values",
196,Extreme Gradient Boosting with XGBoost,4,16,49,"39,481",3750,"Do you know the basics of supervised learning and want to use state-of-the-art models on real-world datasets? Gradient boosting is currently one of the most popular techniques for efficient modeling of tabular datasets of all sizes. XGboost is a very fast, scalable implementation of gradient boosting, with models using XGBoost regularly winning online data science competitions and being used at scale across different industries. In this course, you'll learn how to use this powerful library alongside pandas and scikit-learn to build and tune supervised learning models. You'll work with real-world datasets to solve classification and regression problems.","Welcome to the course!,Which of these is a classification problem?,Which of these is a binary classification problem?,Introducing XGBoost,XGBoost: Fit/Predict,What is a decision tree?,Decision trees,What is Boosting?,Measuring accuracy,Measuring AUC,When should I use XGBoost?,Using XGBoost","Why tune your model?,When is tuning your model a bad idea?,Tuning the number of boosting rounds,Automated boosting round selection using early_stopping,Overview of XGBoost's hyperparameters,Tuning eta,Tuning max_depth,Tuning colsample_bytree,Review of grid search and random search,Grid search with XGBoost,Random search with XGBoost,Limits of grid search and random search,When should you use grid search and random search?","Regression review,Which of these is a regression problem?,Objective (loss) functions and base learners,Decision trees as base learners,Linear base learners,Evaluating model quality,Regularization and base learners in XGBoost,Using regularization in XGBoost,Visualizing individual XGBoost trees,Visualizing feature importances: What features are most important in my dataset","Review of pipelines using sklearn,Exploratory data analysis,Encoding categorical columns I: LabelEncoder,Encoding categorical columns II: OneHotEncoder,Encoding categorical columns III: DictVectorizer,Preprocessing within a pipeline,Incorporating XGBoost into pipelines,Cross-validating your XGBoost model,Kidney disease case study I: Categorical Imputer,Kidney disease case study II: Feature Union,Kidney disease case study III: Full pipeline,Tuning XGBoost hyperparameters,Bringing it all together,Final Thoughts","Hugo Bowne-Anderson,Yashas Roy","Machine Learning Scientist,Ames housing prices (preprocessed),Ames housing prices (original),Chronic kidney disease,Machine Learning with scikit-learn,Case Study: School Budgeting with Machine Learning in Python",,
197,Building Chatbots in Python,4,15,49,"62,283",4100,"Messaging and voice-controlled devices are the next big platforms, and conversational computing has a big role to play in creating engaging augmented and virtual reality experiences. This course will get you started on the path toward building such applications. There are a number of unique challenges to building these kinds of programs, like how do I turn human language into instructions for machines? In this course, you'll tackle this first with rule-based systems and then with machine learning. Some chat systems are designed to be useful, while others are just good fun. You will build one of each and put everything together to make a helpful, friendly chatbot. Once you complete the course, you’ll also learn how to connect your chatbot to Facebook Messenger!","Introduction to conversational software,EchoBot I,EchoBot II,Creating a personality,Chitchat,Adding variety,ELIZA I: asking questions,Text processing with regular expressions,ELIZA II: Extracting key phrases,ELIZA III: Pronouns,ELIZA IV: Putting it all together","Virtual assistants and accessing data,SQL basics,SQL statements in Python,Exploring a DB with natural language,Creating queries from parameters,Using your custom function to find hotels,Creating SQL from natural language,Incremental slot filling and negation,Refining your search,Basic negation,Filtering with excluded slots","Understanding intents and entities,Intent classification with regex I,Intent classification with regex II,Entity extraction with regex,Word vectors,word vectors with spaCy,Intents and classification,Intent classification with sklearn,Entity extraction,Using spaCy's entity recognizer,Assigning roles using spaCy's parser,Robust language understanding with rasa NLU,Rasa NLU,Data-efficient entity recognition","Why statefulness is key,Form filling,Asking contextual questions,Dealing with rejection,Asking questions & queuing answers,Pending actions I,Pending actions II,Pending state transitions,Putting it all together I,Putting it all together II,Frontiers of dialogue research,Generating text with neural networks,Congratulations!","Hugo Bowne-Anderson,Yashas Roy","Natural Language Processing,ATIS (Airline Travel Information System),Hotels database,Introduction to Natural Language Processing in Python",,
198,Introduction to Natural Language Processing in Python,4,15,51,"86,552",3750,"In this course, you'll learn natural language processing (NLP) basics, such as how to identify and separate words, how to extract topics in a text, and how to build your own fake news classifier. You'll also learn how to use basic libraries such as NLTK, alongside libraries which utilize deep learning to solve common NLP problems. This course will give you the foundation to process and parse text as you move forward in your Python learning.","Introduction to regular expressions,Which pattern?,Practicing regular expressions: re.split() and re.findall(),Introduction to tokenization,Word tokenization with NLTK,More regex with re.search(),Advanced tokenization with NLTK and regex,Choosing a tokenizer,Regex with NLTK tokenization,Non-ascii tokenization,Charting word length with NLTK,Charting practice","Named Entity Recognition,NER with NLTK,Charting practice,Stanford library with NLTK,Introduction to SpaCy,Comparing NLTK with spaCy NER,spaCy NER Categories,Multilingual NER with polyglot,French NER with polyglot I,French NER with polyglot II,Spanish NER with polyglot","Word counts with bag-of-words,Bag-of-words picker,Building a Counter with bag-of-words,Simple text preprocessing,Text preprocessing steps,Text preprocessing practice,Introduction to gensim,What are word vectors?,Creating and querying a corpus with gensim,Gensim bag-of-words,Tf-idf with gensim,What is tf-idf?,Tf-idf with Wikipedia","Classifying fake news using supervised learning with NLP,Which possible features?,Training and testing,Building word count vectors with scikit-learn,CountVectorizer for text classification,TfidfVectorizer for text classification,Inspecting the vectors,Training and testing a classification model with scikit-learn,Text classification models,Training and testing the ""fake news"" model with CountVectorizer,Training and testing the ""fake news"" model with TfidfVectorizer,Simple NLP, complex problems,Improving the model,Improving your model,Inspecting your model","Hugo Bowne-Anderson,Yashas Roy","Machine Learning Scientist,Natural Language Processing,English stopwords,Monty Python and the Holy Grail,News articles,Wikipedia articles,Python Data Science Toolbox (Part 2)",,
199,Inference for Linear Regression in R,4,15,59,"10,758",4650,"Previously, you learned the fundamentals of both statistical inference and linear models; now, the next step is to put them together. This course gives you a chance to think about how different samples can produce different linear models, where your goal is to understand the underlying population model. From the estimated linear model, you will learn how to create interval estimates for the effect size as well as how to determine if the effect is significant. Prediction intervals for the response variable will be contrasted with estimates of the average response. Throughout the course, you'll gain more practice with the dplyr and ggplot2 packages, and you will learn about the broom package for tidying models; all three packages are invaluable in data science.","Variability in regression lines,Regression output: example I,First random sample, second random sample,Superimpose lines,Research question,Regression hypothesis,Variability of coefficients,Original population - change sample size,Hypothetical population - less variability around the line,Hypothetical population - less variability in x direction,What changes the variability of the coefficients?","Mathematical approximation,How do the theoretical results play a role?,t-statistic,Working with R-output (1),Working with R-output (2),Comparing randomization inference and t-inference,Intervals in regression,CI using t-theory,Comparing randomization CIs and t-based CIs,Different types of intervals,Confidence intervals for the average response at specific values,Confidence intervals for the average response for all observations,Prediction intervals for the individual response","Inference on transformed variables,Transformed model,Interpreting transformed coefficients,Multicollinearity,LA Homes, multicollinearity (1),LA Homes, multicollinearity (2),LA Homes, multicollinearity (3),Multiple linear regression,Inference on coefficients,Interpreting coefficients,Summary","Simulation-based Inference,Null sampling distribution of the slope,SE of the slope,p-value,Inference on slope,Simulation-based CI for slope,Bootstrapping the data,SE method - bootstrap CI for slope,Percentile method - bootstrap CI for slope,Inference from randomization and bootstrapped distributions","Nick Carchedi,Nick Solomon","Statistical Inference,LA home price data,NYC restaurant data,Twin data,Foundations of Inference,Intermediate Regression in R","Technical conditions for linear regression,Violation of LINE conditions (1),Violation of LINE conditions (2),Using residuals (1),Using residuals (2),Why do we need the LINE assumptions?,Effect of an outlier,Estimation with and without outlier,Inference with and without outlier (t-test),Inference with and without outlier (randomization),Moving forward when model assumptions are violated,Adjusting for non-linear relationship,Adjusting for non-constant errors,Adjusting for non-normal errors",
200,Multiple and Logistic Regression in R,4,19,59,"41,780",4250,"In this course you'll take your skills with simple linear regression to the next level. By learning multiple and logistic regression techniques you will gain the skills to model and predict both numeric and categorical outcomes using multiple input variables. You'll also learn how to fit, visualize, and interpret these models. Then you'll apply your skills to learn about Italian restaurants in New York City!","What if you have two groups?,Fitting a parallel slopes model,Reasoning about two intercepts,Visualizing parallel slopes models,Using geom_line() and augment(),Interpreting parallel slopes coefficients,Intercept interpretation,Common slope interpretation,Three ways to describe a model,Syntax from math,Syntax from plot","Adding a numerical explanatory variable,Fitting a MLR model,Tiling the plane,Models in 3D,Conditional interpretation of coefficients,Coefficient magnitude,Practicing interpretation,Adding a third (categorical) variable,Visualizing parallel planes,Parallel plane interpretation,Higher dimensions,Interpretation of coefficient in a big model","Italian restaurants in NYC,Exploratory data analysis,SLR models,Incorporating another variable,Parallel lines with location,A plane in 3D,Higher dimensions,Parallel planes with location,Interpretation of location coefficient,Impact of location,Full model,Wrap-up","Model fit, residuals, and prediction,R-squared vs. adjusted R-squared,Prediction,Understanding interaction,Thought experiments,Fitting a model with interaction,Visualizing interaction models,Simpson's Paradox,Consequences of Simpson's paradox,Simpson's paradox in action",Nick Solomon,"Average SAT scores by state,New York City Zagat restaurant reviews,Correlation and Regression in R","What is logistic regression?,Fitting a line to a binary response,Fitting a line to a binary response (2),Fitting a model,Visualizing logistic regression,Using geom_smooth(),Using bins,Three scales approach to interpretation,Odds scale,Log-odds scale,Interpretation of logistic regression,Using a logistic model,Making probabilistic predictions,Making binary predictions",
201,Intermediate Network Analysis in Python,4,13,46,"11,315",3850,"Have you taken DataCamp's Introduction to Network Analysis in Python course and are yearning to learn more sophisticated techniques to analyze your networks, whether they be social, transportation, or biological? Then this is the course for you! Herein, you'll build on your knowledge and skills to tackle more advanced problems in network analytics! You'll gain the conceptual and practical skills to analyze evolving time series of networks, learn about bipartite graphs, and how to use bipartite graphs in product recommendation systems. You'll also learn about graph projections, why they're so useful in Data Science, and figure out the best ways to store and load graph data from files. You'll consolidate all of this knowledge in a final chapter case study, in which you'll analyze a forum dataset and come out of this course a Pythonista Network Analyst ninja!","Definitions & basic recap,Exploratory data analysis,Plotting using nxviz,Bipartite graphs,The bipartite keyword,Degree centrality distribution of user nodes,Degree centrality distribution of project nodes,Bipartite graphs and recommendation systems,Shared nodes in other partition,User similarity metric,Find similar users,Recommend repositories","Introduction to graph differences,List of graphs,Graph differences over time,Plot number of edge changes over time,Evolving graph statistics,Number of edges over time,Degree centrality over time,Zooming in & zooming out: Overall graph summary,Find nodes with top degree centralities,Visualizing connectivity","Concept of projection,Reading graphs,Computing projection,Plot degree centrality on projection,Bipartite graphs as matrices,Properties of bipartite adjacency matrices.,Compute adjacency matrix,Find shared membership: Transposition,Representing network data with pandas,Make nodelist,Make edgelist","Introduction to the dataset,Create a graph from the pandas DataFrame,Visualize the degree centrality distribution of the students projection,Visualize the degree centrality distribution of the forums projection,Time based filtering,Time filter on edges,Visualize filtered graph using nxviz,Time series analysis,Plot number of posts being made over time,Extract the mean degree centrality day-by-day on the students partition,Find the most popular forums day-by-day: I,Find the most popular forums day-by-day: II,Congratulations!","Hugo Bowne-Anderson,Yashas Roy","American Revolution,GitHub,College forum messages,Introduction to Network Analysis in Python",,
202,Data Types for Data Science in Python,4,18,58,"51,328",4850,"Have you got your basic Python programming chops down for Data Science but are yearning for more? Then this is the course for you. Herein, you'll consolidate and practice your knowledge of lists, dictionaries, tuples, sets, and date times. You'll see their relevance in working with lots of real data and how to leverage several of them in concert to solve multistep problems, including an extended case study using Chicago metropolitan area transit data. You'll also learn how to use many of the objects in the Python Collections module, which will allow you to store and manipulate your data for a variety of Data Scientific purposes. After taking this course, you'll be ready to tackle many Data Science challenges Pythonically.","Introduction and lists,Manipulating lists for fun and profit,Looping over lists,Meet the Tuples,Data type usage,Using and unpacking tuples,Making tuples by accident,Sets for unordered and unique data,Finding all the data and the overlapping data between sets,Determining set differences","Counting made easy,Using Counter on lists,Finding most common elements,Dictionaries of unknown structure - Defaultdict,Creating dictionaries of an unknown structure,Safely appending to a key's value list,Maintaining Dictionary Order with OrderedDict,Working with OrderedDictionaries,Powerful Ordered popping,What do you mean I don't have any class? Namedtuple,Creating namedtuples for storing data,Leveraging attributes on namedtuples","Counting within Date Ranges,Reading your data with CSV Reader and Establishing your Data Containers,Find the Months with the Highest Number of Crimes,Transforming your Data Containers to Month and Location,Find the Most Common Crimes by Location Type by Month in 2016,Dictionaries with Time Windows for Keys,Reading your Data with DictReader and Establishing your Data Containers,Determine the Arrests by District by Year,Unique Crimes by City Block,Final thoughts","Using dictionaries,Creating and looping through dictionaries,Safely finding by key,Dealing with nested data,Altering dictionaries,Adding and extending dictionaries,Popping and deleting from dictionaries,Pythonically using dictionaries,Working with dictionaries more pythonically,Checking dictionaries for data,Working with CSV files,Reading from a file using CSV reader,Creating a dictionary from a file","Hugo Bowne-Anderson,Yashas Roy","Python Programmer,Baby names,Chicago crime,CTA daily station totals,CTA daily summary totals,Intermediate Python","There and Back Again a DateTime Journey,Strings to DateTimes,Converting to a String,Working with Datetime Components and current time,Pieces of Time,Creating DateTime Objects... Now,Timezones,Time Travel (Adding and Subtracting Time),Finding a time in the future and from the past,Finding differences in DateTimes,HELP! Libraries to make it easier,Localizing time with pendulum,Humanizing Differences with Pendulum",
203,Introduction to Spark with sparklyr in R,4,4,50,"17,357",4600,"R is mostly optimized to help you write data analysis code quickly and readably. Apache Spark is designed to analyze huge datasets quickly. The sparklyr package lets you write dplyr R code that runs on a Spark cluster, giving you the best of both worlds. This course teaches you how to manipulate Spark DataFrames using both the dplyr interface and the native interface to Spark, as well as trying machine learning techniques. Throughout the course, you'll explore the Million Song Dataset.","Getting started,Made for each other,Here be dragons,The connect-work-disconnect pattern,Copying data into Spark,Big data, tiny tibble,Exploring the structure of tibbles,Selecting columns,Filtering rows,Arranging rows,Mutating columns,Summarizing columns","Two new interfaces,Popcorn double feature,Transforming continuous variables to logical,Transforming continuous variables into categorical (1),Transforming continuous variables into categorical (2),More than words: tokenization (1),More than words: tokenization (2),More than words: tokenization (3),Sorting vs. arranging,Exploring Spark data types,Shrinking the data by sampling,Training/testing partitions","Leveling up,Mother's little helper (1),Mother's little helper (2),Selecting unique rows,Common people,Collecting data back from Spark,Storing intermediate results,Groups: great for music, great for data,Groups of mutants,Advanced Selection II: The SQL,Left joins,Anti joins,Semi joins","Machine learning on Spark,Machine learning functions,(Hey you) What's that sound?,Working with parquet files,Come together,Partitioning data with a group effect,Gradient boosted trees: modeling,Gradient boosted trees: prediction,Gradient boosted trees: visualization,Random Forest: modeling,Random Forest: prediction,Random Forest: visualization,Comparing model performance",Tom Jeon,"Big Data,Machine Learning Scientist,Anti-join,Both-model-responses,Gbt-model-responses,Inner-join,Left-join,Predicted vs actual,Residual density,Semi-join,Timbre,Timbre parquet,Title text parquet,Track data parquet,Track data to model parquet,Track data to predict parquet,Track metadata,Intermediate R",,
204,Data Visualization with lattice in R,4,17,60,"4,936",4950,"Visualization is an essential component of interactive data analysis in R. Traditional (base) graphics is powerful, but limited in its ability to deal with multivariate data. Trellis graphics is the natural successor to traditional graphics, extending its simple philosophy to gracefully handle common multivariable data visualization tasks. This course introduces the lattice package, which implements Trellis graphics for R, and illustrates its basic use.","Introduction,Formula interface in histogram() and xyplot(),Create a histogram,Create a scatterplot,Differences between base R graphics and lattice histogram,Optional arguments,Y-axis value in histogram(),Labels,Density plots,Box and whisker plots and reordering levels,Box and whisker plot,Whisker extents and outliers","Combining scales,Explicit limits,Per-panel explicit limits,Customizing axis annotation,Logarithmic scales,Annotating logarithmic scales,Finding patterns by sex,Log scales in economic data,Graphical parameters,ggplot2 styling with par.settings,Changing graphical parameters in histogram,Changing plotting characters,Using simpleTheme(),Changing plotting characters revisited,Changing parameters in grouped density plot","New methods,The xyplot() method for time series objects,The xyplot() method with panel.horizonplot(),New high-level functions,Map projections,Confidence bands using the segplot() function,Hexagonal binning of bivariate data,Manipulation of trellis objects,The directlabels package,Adding ggplot2-style layers","Conditioning,A conditioned plot of the airquality dataset,Conditioning in density plots,Data summary and transformation, grouping,Superposition in density plots,Enhancing the legend,Incorporating external data sources,Conditioned scatter plot,The as.table argument,Custom strips labels for box and whisker plots,The trellis object,Modifying strip labels,Matrix-like subsetting","Tom Jeon,Richie Cotton",Data Visualization in R,"Panel Functions,Scatter plot with rugs,Alternative panel function - panel.violin(),Alternative panel functions - panel.smoothScatter(),Prepanel Functions to control limits,Prepanel functions with scales,Optional arguments of default panel functions,Interaction plot of residuals,Optional arguments of panel.bwplot(),Using emojis as plotting symbols",
205,Spatial Statistics in R,4,16,60,"9,007",4950,"Everything happens somewhere, and increasingly the place where all these things happen is being recorded in a database. There is some truth behind the oft-repeated statement that 80% of data have a spatial component. So what can we do with this spatial data? Spatial statistics, of course! Location is an important explanatory variable in so many things - be it a disease outbreak, an animal's choice of habitat, a traffic collision, or a vein of gold in the mountains - that we would be wise to include it whenever possible. This course will start you on your journey of spatial data analysis. You'll learn what classes of statistical problems present themselves with spatial data, and the basic techniques of how to deal with them. You'll see how to look at a mess of dots on a map and bring out meaningful insights.","Problems in spatial statistics,Simple spatial principles,Plotting areas,Uniform in a circle,Simulation and testing with spatstat,Quadrat count test for uniformity,Creating a uniform point pattern with spatstat,Simulating clustered and inhibitory patterns,Point pattern testing,Further testing,Nearest-neighbor distributions,Other point pattern distribution functions,Tree location pattern","Areal statistics,London EU referendum data,Cartogram,Spatial autocorrelation test,Spatial health data,London health data,Binomial confidence intervals,Exceedance probabilities,Generalized linear models in space,A Poisson GLM,Residuals,Correlation in spatial GLMs,Fit a Bayesian GLM,Adding a spatially autocorrelated effect,Mapping the spatial effects","Bivariate point patterns,Crime in Preston,Violent crime proportion estimation,Spatial segregation,Bandwidth selection,Segregation probabilities,Mapping segregation,Space-time data,Sasquatch data,Spatial pattern of bigfoot sightings,Temporal pattern of bigfoot sightings,Temporal pattern analysis,Space-time clustering,Preparing data for space-time clustering,Monte-carlo test of space-time clustering,Space-time clustering explanation","Geostatistical data,Canadian geochemical survey data,Fitting a trend surface,Predicting from a trend surface,The variogram,Variogram estimation,Variogram with spatial trend,Variogram model fitting,Kriging predictions,Filling in the gaps,Making a prediction grid,Gridded predictions,Automatic kriging,Auto-kriging at point locations,Auto-kriging over a grid,Last words","Tom Jeon,Richie Cotton","Spatial Data,Canadian geological survey soil acidity,Bounding region for ca_geo.rds,Flu incidents by London borough, 2017,EU referendum voting by London borough, 2016,An OpenStreetMap map of Preston, UK,Crime in Preston, UK,Ph grid,Sasquatch sightings, 1990 to 2016,Visualizing Geospatial Data in R,Foundations of Probability in R",,
206,Quantitative Risk Management in R,5,18,55,"11,370",4350,"In Quantitative Risk Management (QRM), you will build models to understand the risks of financial portfolios. This is a vital task across the banking, insurance and asset management industries. The first step in the model building process is to collect data on the underlying risk factors that affect portfolio value and analyze their behavior. In this course, you will learn how to work with risk-factor return series, study the empirical properties or so-called ""stylized facts"" of these data - including their typical non-normality and volatility, and make estimates of value-at-risk for a portfolio.","Welcome to the course!,Exploring risk-factor time series: equity indexes,Exploring risk-factor time series: individual equities,Exploring risk-factor data: exchange rates,Risk-factor returns,Exploring return series,Different ways of plotting risk-factor and return series,Aggregating log-returns,Aggregating log-return series,A test on aggregation of log-returns,Exploring other kinds of risk factors,Commodities data,Interest-rate data","Characteristics of volatile return series,Spotting a volatile time series,Estimating serial correlations,Using acf plots to reveal volatility,The Ljung-Box test,Applying Ljung-Box tests to return data,Applying Ljung-Box tests to longer-interval returns,Looking at the extremes in volatile return series,Extreme values in volatile time series,Cross correlations between risk-factor return series,The stylized facts of return series,Volatility and correlation of FX returns,Volatility and correlation of interest-rate data,Reviewing knowledge of volatility and correlation","The normal distribution,Graphical methods for assessing normality,Testing for normality,Q-Q plots for assessing normality,Skewness, kurtosis and the Jarque-Bera test,Numerical tests of normality,Testing normality for longer time horizons,Overlapping returns,Reviewing knowledge of normal distributions and returns,The Student t distribution,Fitting t distribution to data,Testing FX returns for normality,Testing interest-rate returns for normality,Testing gold price returns for normality","Value-at-risk and expected shortfall,Computing VaR and ES for normal distribution,International equity portfolio,Examining risk factors for international equity portfolio,Historical simulation,Estimating VaR and ES,Option portfolio and Black Scholes,Compute Black-Scholes price of an option,Equity and implied volatility risk factors,Historical simulation for the option example,Historical simulation of losses for option portfolio,Estimating VaR and ES for option portfolio,Computing VaR for weekly losses,Wrap-up",Lore Dirick,"Applied Finance,Quantitative Analyst,Manipulating Time Series Data with xts and zoo in R",,
207,Working with Web Data in R,4,16,56,"17,748",4500,"Most of the useful data in the world, from economic data to news content to geographic information, lives somewhere on the internet - and this course will teach you how to access it. You'll explore how to work with APIs (computer-readable interfaces to websites), access data from Wikipedia and other sources, and build your own simple API client. For those occasions where APIs are not available, you'll find out how to use R to scrape information out of web pages. In the process you'll learn how to get data out of even the most stubborn website, and how to turn it into a format ready for further analysis. The packages you'll use and learn your way around are rvest, httr, xml2 and jsonlite, along with particular API client packages like WikipediR and pageviews.","Introduction: Working With Web Data in R,Downloading files and reading them into R,Saving raw files to disk,Saving formatted files to disk,Understanding Application Programming Interfaces,API test,Using API clients,Access tokens and APIs,Using access tokens","JSON,Can you spot JSON?,Parsing JSON,Manipulating JSON,Manipulating parsed JSON,Reformatting JSON,XML structure,Do you understand XML structure?,Examining XML documents,XPATHs,Extracting XML data,Extracting XML attributes,Wrapup: returning nice API output","CSS web scraping in theory,Using CSS to scrape nodes,Scraping names,Scraping text,Test: CSS web scraping,Final case study: Introduction,API calls,Extracting information,Normalising information,Reproducibility,Wrap Up","GET and POST requests in theory,GET requests in practice,POST requests in practice,Extracting the response,Multiple Choice: GET and POST requests,Graceful httr,Handling http failures,Constructing queries (Part I),Constructing queries (Part II),Respectful API usage,Using user agents,Rate-limiting,Tying it all together",Richie Cotton,Intermediate R,"Web scraping 101,Reading HTML,Extracting nodes by XPATH,HTML structure,Extracting names,Extracting values,Test: HTML reading and extraction,Reformatting Data,Extracting tables,Cleaning a data frame",
208,Forecasting in R,5,18,55,"42,132",4450,"Forecasting involves making predictions about the future. It is required in many situations: deciding whether to build another power generation plant in the next ten years requires forecasts of future demand; scheduling staff in a call centre next week requires forecasts of call volumes; stocking an inventory requires forecasts of stock requirements. Forecasts can be required several years in advance (for the case of capital investments), or only a few minutes beforehand (for telecommunication routing). Whatever the circumstances or time horizons involved, forecasting is an important aid to effective and efficient planning. This course provides an introduction to time series forecasting using R.","Welcome to Forecasting Using R,Creating time series objects in R,Time series plots,Seasonal plots,Trends, seasonality, and cyclicity,Autocorrelation of non-seasonal time series,Autocorrelation of seasonal and cyclic time series,Match the ACF to the time series,White noise,Stock prices and white noise","Exponentially weighted forecasts,Simple exponential smoothing,SES vs naive,Exponential smoothing methods with trend,Holt's trend methods,Exponential smoothing methods with trend and seasonality,Holt-Winters with monthly data,Holt-Winters method with daily data,State space models for exponential smoothing,Automatic forecasting with exponential smoothing,ETS vs seasonal naive,Match the models to the time series,When does ETS fail?","Dynamic regression,Forecasting sales allowing for advertising expenditure,Forecasting electricity demand,Dynamic harmonic regression,Forecasting weekly data,Harmonic regression for multiple seasonality,Forecasting call bookings,TBATS models,TBATS models for electricity demand,Your future in forecasting!","Forecasts and potential futures,Naive forecasting methods,Fitted values and residuals,Checking time series residuals,Training and test sets,Evaluating forecast accuracy of non-seasonal methods,Evaluating forecast accuracy of seasonal methods,Do I have a good forecasting model?,Time series cross-validation,Using tsCV() for time series cross-validation","Davis Vaughan,Lore Dirick","Quantitative Analyst,Time Series,Excelfile in the first exercise,Time Series Analysis in R","Transformations for variance stabilization,Box-Cox transformations for time series,Non-seasonal differencing for stationarity,Seasonal differencing for stationarity,ARIMA models,Automatic ARIMA models for non-seasonal time series,Forecasting with ARIMA models,Comparing auto.arima() and ets() on non-seasonal data,Seasonal ARIMA models,Automatic ARIMA models for seasonal time series,Exploring auto.arima() options,Comparing auto.arima() and ets() on seasonal data",
209,Writing Efficient R Code,4,14,43,"36,275",3100,"The beauty of R is that it is built for performing data analysis. The downside is that sometimes R can be slow, thereby obstructing our analysis. For this reason, it is essential to become familiar with the main techniques for speeding up your analysis, so you can reduce computational time and get insights as quickly as possible.","Welcome!,R version,Benchmarking,Comparing read times of CSV and RDS files,Operational differences: ""<-"" and ""="",Elapsed time,Relative time,How good is your machine?,DataCamp hardware,Benchmark DataCamp's machine","What is code profiling,Profiling a function,Where's the hold-up?,Profvis in action,Profvis: Larger example,Change the data frame to a matrix,Calculating row sums,Use && instead of &,Monopoly overview","Memory allocation,Why is this piece of code slow?,Timings - growing a vector,Timings - pre-allocation,Importance of vectorizing your code,Vectorized code: multiplication,Vectorized code: calculating a log-sum,Data frames and matrices,Data frames vs matrices,Data frames and matrices - column selection,Selecting a row in a data frame,Row timings","CPUs - why do we have more than one,How many cores does this machine have?,What sort of problems benefit from parallel computing?,Can this loop run in parallel (1)?,Can this loop run in parallel (2)?,The parallel package - parApply,Moving to parallel programming,Moving to parApply,The parallel package - parSapply,Using parSapply(),Timings parSapply(),You can write efficient R code!","Tom Jeon,Richie Cotton","Big Data,R Programmer,R Programming,Information on 45,000 movies,Intermediate R",,
210,String Manipulation with stringr in R,4,17,60,"26,038",5150,"Character strings can turn up in all stages of a data science project. You might have to clean messy string input before analysis, extract data that is embedded in text or automatically turn numeric results into a sentence to include in a report. Perhaps the strings themselves are the data of interest, and you need to detect and match patterns within them. This course will help you master these tasks by teaching you how to pull strings apart, put them back together and use stringr to detect, extract, match and split strings using regular expressions, a powerful way to express patterns.","Welcome!,Quotes,What you see isn't always what you have,Escape sequences,Turning numbers into strings,Using format() with numbers,Controlling other aspects of the string,formatC(),Putting strings together,Annotation of numbers,A very simple table,Let's order pizza!","Regular expressions,Matching the start or end of the string,Matching any character,Combining with stringr functions,More regular expressions,Alternation,Character classes,Repetition,Shortcuts,Hunting for phone numbers,Extracting age and gender from accident narratives,Parsing age and gender into pieces","Case study,Getting the play into R,Identifying the lines, take 1,Identifying the lines, take 2,A case study on case,Changing case to ease matching,Ignoring case when matching,Fixing case problems,Wrapping up,An interview with Hadley Wickham","Introducing stringr,Putting strings together with stringr,String length,Extracting substrings,Hunting for matches,Detecting matches,Subsetting strings based on match,Counting matches,Splitting strings,Parsing strings into variables,Some simple text statistics,Replacing matches in strings,Replacing to tidy strings,Review,Final challenges","Tom Jeon,Richie Cotton","R Programmer,Text Mining,DNA sequences from the genome of Yersinia pestis,Narratives,Adverbs,Importance of being earnest,Cat-related accidents,Intermediate R","Capturing,Capturing parts of a pattern,Pulling out parts of a phone number,Extracting age and gender again,Backreferences,Using backreferences in patterns,Replacing with regular expressions,Replacing with backreferences,Unicode and pattern matching,Matching a specific code point or code groups,Matching a single grapheme",
211,Supervised Learning in R: Classification,4,14,55,"72,127",3950,"This beginner-level introduction to machine learning covers four of the most common classification algorithms. You will come away with a basic understanding of how each algorithm approaches a learning task, as well as learn the R functions needed to apply these tools to your own work.","Classification with Nearest Neighbors,Recognizing a road sign with kNN,Thinking like kNN,Exploring the traffic sign dataset,Classifying a collection of road signs,What about the 'k' in kNN?,Understanding the impact of 'k',Testing other 'k' values,Seeing how the neighbors voted,Data preparation for kNN,Why normalize data?","Making binary predictions with regression,Building simple logistic regression models,Making a binary prediction,The limitations of accuracy,Model performance tradeoffs,Calculating ROC Curves and AUC,Comparing ROC curves,Dummy variables, missing data, and interactions,Coding categorical features,Handling missing data,Understanding missing value indicators,Building a more sophisticated model,Automatic feature selection,The dangers of stepwise regression,Building a stepwise regression model","Understanding Bayesian methods,Computing probabilities,Understanding dependent events,A simple Naive Bayes location model,Examining ""raw"" probabilities,Understanding independence,Understanding NB's ""naivety"",Who are you calling naive?,A more sophisticated location model,Preparing for unforeseen circumstances,Understanding the Laplace correction,Applying Naive Bayes to other problems,Handling numeric predictors","Making decisions with trees,Building a simple decision tree,Visualizing classification trees,Understanding the tree's decisions,Growing larger classification trees,Why do some branches split?,Creating random test datasets,Building and evaluating a larger tree,Conducting a fair performance evaluation,Tending to classification trees,Preventing overgrown trees,Creating a nicely pruned tree,Why do trees benefit from pruning?,Seeing the forest from the trees,Understanding random forests,Building a random forest model","Nick Carchedi,Nick Solomon","Data Scientist,Machine Learning Fundamentals,Machine Learning Scientist,Lending Club loan data,Traffic sign image data,Donation data,Brett's location data,Intermediate R",,
212,Intermediate R for Finance,5,15,59,"29,080",5050,"If you enjoyed the Introduction to R for Finance course, then you will love Intermediate R for Finance. Here, you will first learn the basics about how dates work in R, an important skill for the rest of the course. Your next step will be to explore the world of if statements, loops, and functions. These are powerful ideas that are essential to any financial data scientist's toolkit. Finally, we will spend some time working with the family of apply functions as a vectorized alternative to loops. And of course, all examples will be finance related! Enjoy!","An introduction to dates in R,What day is it?,From char to date,Many dates,Date formats and extractor functions,Date formats (1),Date formats (2),Subtraction of dates,months() and weekdays() and quarters(), oh my!","Repeat loops,Repeat, repeat, repeat,When to break?,While loops,While with a print,While with a plot,Break it,For loops,Loop over a vector,Loop over data frame rows,Loop over matrix elements,Break and next","Why use apply?,lapply() on a list,lapply() on a data frame,FUN arguments,sapply() - simplify it!,sapply() VS lapply(),Failing to simplify,vapply() - specify your output!,vapply() VS sapply(),More vapply(),Anonymous functions,Congratulations","Relational operators,Relational practice,Vectorized operations,Logical operators,And / Or,Not!,Logicals and subset(),All together now!,If statements,If this,If this, Else that,If this, Else If that, Else that other thing,Can you If inside an If?,ifelse()",Davis Vaughan,"Finance Fundamentals,Quantitative Analyst,Introduction to R for Finance","What are functions?,Function help and documentation,Optional arguments,Functions in functions,Writing functions,Your first function,Multiple arguments (1),Multiple arguments (2),Function scope (1),Function scope (2),Packages,tidyquant package",
213,Introduction to R for Finance,4,14,62,"64,695",5300,"In this finance-oriented introduction to R, you will learn essential data structures such as lists and data frames and have the chance to apply that knowledge to real-world financial examples. By the end of the course, you will be comfortable with the basics of manipulating your data to perform financial analysis in R.","Welcome to Introduction to R for Finance!,Your first R script,Arithmetic in R (1),Arithmetic in R (2),Assignment and variables (1),Assignment and variables (2),Financial returns,Financial returns (1),Financial returns (2),Basic data types,Data type exploration,What's that data type?","What is a data frame?,Create your first data.frame(),What goes in a data frame?,Making head()s and tail()s of your data with some str()ucture,Naming your columns / rows,Data frame manipulation,Accessing and subsetting data frames (1),Accessing and subsetting data frames (2),Accessing and subsetting data frames (3),Adding new columns,Present value,Present value of projected cash flows (1),Present value of projected cash flows (2)","What is a list?,Create a list,Named lists,Access elements in a list,Adding to a list,Removing from a list,A few list creating functions,Split it,Split-Apply-Combine,Attributes,Congratulations!","What is a vector?,c()ombine,Coerce it,Vector names(),Visualize your vector,Vector manipulation,Weighted average (1),Weighted average (2),Weighted average (3),Vector subsetting,Matrix - a 2D vector,Create a matrix!,Matrix <- bind vectors,Visualize your matrix,cor()relation,Matrix subsetting",Davis Vaughan,"Finance Fundamentals,Quantitative Analyst","What is a factor?,Create a factor,Factor levels,Factor summary,Visualize your factor,Bucketing a numeric variable into a factor,Ordering and subsetting factors,Create an ordered factor,Subsetting a factor,stringsAsFactors",
214,Case Study: School Budgeting with Machine Learning in Python,4,15,51,"56,189",3800,"Data science isn't just for predicting ad-clicks-it's also useful for social impact! This course is a case study from a machine learning competition on DrivenData. You'll explore a problem related to school district budgeting. By building a model to automatically classify items in a school's budget, it makes it easier and faster for schools to compare their spending with other schools. In this course, you'll begin by building a baseline model that is a simple, first-pass approach. In particular, you'll do some natural language processing to prepare the budgets for modeling. Next, you'll have the opportunity to try your own techniques and see how they compare to participants from the competition. Finally, you'll see how the winner was able to combine a number of expert techniques to build the most accurate model.","Introducing the challenge,What category of problem is this?,What is the goal of the algorithm?,Exploring the data,Loading the data,Summarizing the data,Looking at the datatypes,Exploring datatypes in pandas,Encode the labels as categorical variables,Counting unique labels,How do we measure success?,Penalizing highly confident wrong answers,Computing log loss with NumPy","Pipelines, feature & text preprocessing,Instantiate pipeline,Preprocessing numeric features,Text features and feature unions,Preprocessing text features,Multiple types of processing: FunctionTransformer,Multiple types of processing: FeatureUnion,Choosing a classification model,Using FunctionTransformer on the main dataset,Add a model to the pipeline,Try a different class of model,Can you adjust the model or parameters to improve accuracy?","It's time to build a model,Setting up a train-test split in scikit-learn,Training a model,Making predictions,Use your model to predict values on holdout data,Writing out your results to a csv for submission,A very brief introduction to NLP,Tokenizing text,Testing your NLP credentials with n-grams,Representing text numerically,Creating a bag-of-words in scikit-learn,Combining text columns for tokenization,What's in a token?","Learning from the expert: processing,How many tokens?,Deciding what's a word,N-gram range in scikit-learn,Learning from the expert: a stats trick,Which models of the data include interaction terms?,Implement interaction modeling in scikit-learn,Learning from the expert: the winning model,Why is hashing a useful trick?,Implementing the hashing trick in scikit-learn,Build the winning model,What tactics got the winner the best score?,Next steps and the social impact of your work","Hugo Bowne-Anderson,Casey Fitzpatrick,Yashas Roy",Supervised Learning with scikit-learn,,
215,Scalable Data Processing in R,4,15,49,"5,141",3950,"Datasets are often larger than available RAM, which causes problems for R programmers since by default all the variables are stored in memory. You’ll learn tools for processing, exploring, and analyzing data directly from disk. You’ll also implement the split-apply-combine approach and learn how to write scalable code using the bigmemory and iotools packages. In this course, you'll make use of the Federal Housing Finance Agency's data, a publicly available data set chronicling all mortgages that were held or securitized by both Federal National Mortgage Association (Fannie Mae) and Federal Home Loan Mortgage Corporation (Freddie Mac) from 2009-2015.","What is Scalable Data Processing?,Why is your code slow?,How does processing time vary by data size?,Working with ""Out-of-Core"" Objects using the Bigmemory Project,Reading a big.matrix object,Attaching a big.matrix object,Creating tables with big.matrix objects,Data summary using bigsummary,References vs. Copies,Copying matrices and big matrices","Introduction to chunk-wise processing,Can you split-compute-combine it?,Foldable operations (I),Foldable operations (II),A first look at iotools: Importing data,Compare read.delim() and read.delim.raw(),Reading raw data and turning it into a data structure,chunk.apply,Reading chunks in as a matrix,Reading chunks in as a data.frame,Parallelizing calls to chunk.apply","The Bigmemory Suite of Packages,Tabulating using bigtable,Borrower Race and Ethnicity by Year (I),Split-Apply-Combine,Female Proportion Borrowing,Split,Apply,Combine,Visualize your results using the tidyverse,Visualizing Female Proportion Borrowing,The Borrower Income Ratio,Tidy Big Tables,Limitations of bigmemory,Where should you use bigmemory?","Overview of types of analysis for this chapter,Race and Ethnic Representation in the Mortgage Data,Comparing the Borrower Race/Ethnicity and their Proportions,Are the data missing at random?,Looking for Predictable Missingness,A little more about missingness,Analyzing the Housing Data,Borrower Race and Ethnicity by Year (II),Visualizing the Adjusted Demographic Trends,Relative change in demographic trend,Borrower Lending Trends: City vs. Rural,Borrower Region by Year,Who is securing federally guaranteed loans?,Congratulations!","Sumedh Panchadhar,Richie Cotton","Big Data,Mortgage data (sample),Writing Efficient R Code",,
216,Foundations of Probability in R,4,13,54,"30,112",4350,"Probability is the study of making predictions about random phenomena. In this course, you'll learn about the concepts of random variables, distributions, and conditioning, using the example of coin flips. You'll also gain intuition for how to solve probability problems through random simulation. These principles will help you understand statistical inference and can be applied to draw conclusions from data.","Flipping coins in R,Simulating coin flips,Simulating draws from a binomial,Density and cumulative density,Calculating density of a binomial,Calculating cumulative density of a binomial,Varying the number of trials,Expected value and variance,Calculating the expected value,Calculating the variance","Updating with evidence,Updating,Updating with simulation,Updating after 16 heads,Updating with simulation after 16 heads,Prior probability,Updating with priors,Updating with three coins,Bayes' theorem,Updating with Bayes theorem,Updating for other outcomes,More updating with priors","Probability of event A and event B,Solving for probability of A and B,Simulating the probability of A and B,Simulating the probability of A, B, and C,Probability of A or B,Solving for probability of A or B,Simulating probability of A or B,Probability either variable is less than or equal to 4,Multiplying random variables,Expected value of multiplying a random variable,Simulating multiplying a random variable,Variance of a multiplied random variable,Adding two random variables,Solving for the sum of two binomial variables,Simulating adding two binomial variables,Simulating variance of sum of two binomial variables","The normal distribution,Approximating a binomial to the normal,Simulating from the binomial and the normal,Comparing the cumulative density of the binomial,Comparing the distributions of the normal and binomial for low n,The Poisson distribution,Approximating a binomial with a Poisson,Simulating from a Poisson and a binomial,Density of the Poisson distribution,Sum of two Poisson variables,The geometric distribution,Waiting for first coin flip,Using replicate() for simulation,Simulating from the geometric distribution,Probability of a machine lasting X days,Graphing the probability that a machine still works","Nick Carchedi,Tom Jeon,Nick Solomon","Statistician,Introduction to R",,
217,Life Insurance Products Valuation in R,4,17,55,"5,276",4450,"Understanding the basic principles of life insurance products is essential for your personal financial planning, ranging from taking out a mortgage to designing your retirement plan and seeking financial protection for the risk of dying early. In this course, you'll study the time value of money and you’ll work with human mortality data to derive demographic markers (such as the life expectancy). Combining the basics of cash flow valuation with the calculation of survival and death probabilities in R will allow you to construct insightful tools to design life insurance products. You'll come out of this course understanding the valuation of life contingent claims: life annuities, which provide an income upon survival, and life insurance products, which pay a benefit upon death of the policyholder.","Cash flows and discounting,Present value of a cash flow,Net present value of investments,Valuation,Anywhere, anytime?,Actuarial equivalence,Saving for university,Deposits of the saving plan,Change of period and term structure,The interest rates they are a-changin',From yearly to monthly interest rate,Monthly mortgage loan payments","The basics,To survive or not to survive,Short- and long-term,The whole, temporary and deferred life annuity,Ages, interest rates and the whole life annuity,A function to price a life annuity,Immediate vs due,Temporary vs lifelong,Guaranteed payments,Pension calculations ignoring mortality,Pension calculations accounting for mortality,On premium payments and retirement plans,A retirement plan for Miss Cathleen,From single to annual premium,A good deal? Outliving your life expectancy","Random future lifetime,Like it's 1999!,Visualizing one year of mortality data,Men versus women,Binomial experiments,How likely is Cynthia to live to 100?,The number of deaths,Calculating probabilities,Multiplication rules!,Deferred mortality probabilities,Calculating life expectancies,Curtate vs complete life expectancy,Plotting life expectancies by age,Dynamics,Mortality rates over time,Cohort survival probabilities","The basics,Lucy and Kevin’s mortgage protection,Take it easy: a simple life insurance,The whole, temporary and deferred life insurance,Life annuity vs life insurance,Whole life insurance,Temporary life insurance,Deferred life insurance,Combined benefits,A life insurance plan for Miss Cathleen,Best of both worlds – the endowment insurance,Wrap-up","Sumedh Panchadhar,Lore Dirick","Applied Finance,Life table for females in Belgium, 1999,Life table for females in Belgium, 1841 to 2015,Intermediate R,Foundations of Probability in R",,
218,Visualizing Time Series Data in R,4,11,45,"12,139",3550,"As the saying goes, “A chart is worth a thousand words”. This is why visualization is the most used and powerful way to get a better understanding of your data. After this course you will have a very good overview of R time series visualisation capabilities and you will be able to better decide which model to choose for subsequent analysis. You will be able to also convey the message you want to deliver in an efficient and beautiful way.","Refresher on xts and the plot() function,plot() function quiz,plot() function - basic parameters,plot() function - basic parameters (2),Control graphic parameters,Graphic parameters quiz,Other useful visualizing functions,Adding an extra series to an existing chart,Highlighting events in a time series,Highlighting a specific period in a time series,A fancy stock chart,A fancy stock chart (2)","Dealing with higher dimensions,Two time series grouped or stacked,Visualizing bivariate relationships,Multivariate time series,Correlation matrix,Scatterplots for multiple pairs of data,Correlation plot,Higher dimension time series,Correlation matrix as heatmap,Wrap up quiz","Univariate time series analysis,Representing a univariate time series,Other visualization tools,Histogram of returns,Box and whisker plot,Autocorrelation,q-q plot,How to use everything we learned so far?,A comprehensive time series diagnostic,A comprehensive time series diagnostic (2),Time Series quiz,Stock quiz","Case study presentation,Current portfolio description,Existing portfolio quiz,New stocks,New stocks description,New stocks description (2),Portfolio quiz,Compare old and new portfolios,A more accurate comparison of portfolios,Wrap up quiz,Congratulations!","Davis Vaughan,Lore Dirick","Quantitative Analyst,Time Series,Returns for XOM, C, MSFT, DOW, and YHOO,Existing portfolio,Stock data for GS, KO, DIS, and CAT,Daily stocks for YHOO, MSFT, C, and DOW,Daily returns for Apple,Old versus new portfolio,Manipulating Time Series Data with xts and zoo in R",,
219,Unsupervised Learning in Python,4,13,52,"102,944",4150,"Say you have a collection of customers with a variety of characteristics such as age, location, and financial history, and you wish to discover patterns and sort them into clusters. Or perhaps you have a set of texts, such as Wikipedia pages, and you wish to segment them into categories based on their content. This is the world of unsupervised learning, called as such because you are not guiding, or supervising, the pattern discovery by some prediction task, but instead uncovering hidden structure from unlabeled data. Unsupervised learning encompasses a variety of techniques in machine learning, from clustering to dimension reduction to matrix factorization. In this course, you'll learn the fundamentals of unsupervised learning and implement the essential algorithms using scikit-learn and SciPy. You will learn how to cluster, transform, visualize, and extract insights from unlabeled datasets, and end the course by building a recommender system to recommend popular musical artists.","Unsupervised Learning,How many clusters?,Clustering 2D points,Inspect your clustering,Evaluating a clustering,How many clusters of grain?,Evaluating the grain clustering,Transforming features for better clusterings,Scaling fish data for clustering,Clustering the fish data,Clustering stocks using KMeans,Which stocks move together?","Visualizing the PCA transformation,Correlated data in nature,Decorrelating the grain measurements with PCA,Principal components,Intrinsic dimension,The first principal component,Variance of the PCA features,Intrinsic dimension of the fish data,Dimension reduction with PCA,Dimension reduction of the fish measurements,A tf-idf word-frequency array,Clustering Wikipedia part I,Clustering Wikipedia part II","Visualizing hierarchies,How many merges?,Hierarchical clustering of the grain data,Hierarchies of stocks,Cluster labels in hierarchical clustering,Which clusters are closest?,Different linkage, different hierarchical clustering!,Intermediate clusterings,Extracting the cluster labels,t-SNE for 2-dimensional maps,t-SNE visualization of grain dataset,A t-SNE map of the stock market","Non-negative matrix factorization (NMF),Non-negative data,NMF applied to Wikipedia articles,NMF features of the Wikipedia articles,NMF reconstructs samples,NMF learns interpretable parts,NMF learns topics of documents,Explore the LED digits dataset,NMF learns the parts of images,PCA doesn't learn parts,Building recommender systems using NMF,Which articles are similar to 'Cristiano Ronaldo'?,Recommend musical artists part I,Recommend musical artists part II,Final thoughts","Hugo Bowne-Anderson,Yashas Roy","Data Scientist,Machine Learning Fundamentals,Machine Learning Scientist,Company stock price movements,Eurovision 2016,Fish measurements,Grains,LCD digits,Musical artists,Wikipedia articles,Wine,Supervised Learning with scikit-learn",,
220,Sentiment Analysis in R,4,14,52,"11,180",4200,"Add sentiment analysis to your text mining toolkit! Sentiment analysis is used by text miners in marketing, politics, customer service and elsewhere. In this course you will learn to identify positive and negative language, specific emotional intent, and make compelling visualizations. You will end the course by applying your sentiment analysis skills to Airbnb reviews to learn what makes for a good rental.","Let's talk about our feelings,Jump right in! Visualize polarity,TM refresher (I),TM refresher (II),How many words do YOU know? Zipf's law & subjectivity lexicon,What is a subjectivity lexicon?,Where can you observe Zipf's law?,Polarity on actual text,Explore qdap's polarity & built-in lexicon,Happy songs!,LOL, this song is wicked good,Stressed Out!","Parlor trick or worthwhile?,Real insight?,Unhappy ending? Chronological polarity,Word impact, frequency analysis,Introspection using sentiment analysis,Divide & conquer: Using polarity for a comparison cloud,Emotional introspection,Compare & contrast stacked bar chart,Interpreting visualizations,Kernel density plot,Box plot,Radar chart,Treemaps for groups of documents","Plutchik's wheel of emotion, polarity vs. sentiment,One theory of emotion,DTM vs. tidytext matrix,Getting Sentiment Lexicons,Bing lexicon with an inner join explanation,Bing tidy polarity: Simple example,Bing tidy polarity: Count & spread the white whale,Bing tidy polarity: Call me Ishmael (with ggplot2)!,AFINN & NRC methodologies in more detail,AFINN: I'm your Huckleberry,The wonderful wizard of NRC","Refresher on the text mining workflow,Step 1: What do you want to know?,Step 2: Identify Text Sources,Quickly examine the basic polarity,Step 3: Organize (& clean) the text,Create Polarity Based Corpora,Create a Tidy Text Tibble!,Compare Tidy Sentiment to Qdap Polarity,Step 4: Feature Extraction & Step 5: Time for analysis... almost there!,Assessing author effort,Comparison Cloud,Scaled Comparison Cloud,Step 6: Reach a conclusion,Confirm an expected conclusion,Choose a less expected insight,Your turn!",,"Text Mining,Line by line polarity for 4 books,4 books as a tidy data frame,4 books as DocumentTermMatrices,Polarity scores of Boston Airbnb reviews,Housing rental reviews from Airbnb in Boston,Text Mining with Bag-of-Words in R",,
221,Object-Oriented Programming with S3 and R6 in R,4,17,55,"15,927",4200,"Object-oriented programming (OOP) lets you specify relationships between functions and the objects that they can act on, helping you manage complexity in your code. This is an intermediate level course, providing an introduction to OOP, using the S3 and R6 systems. S3 is a great day-to-day R programming tool that simplifies some of the functions that you write. R6 is especially useful for industry-specific analyses, working with web APIs, and building GUIs.","What is Object-Oriented Programming?,Should I OOP?,You've Already Been Working With Objects,The Nine Systems,Which Systems Should I Use?,How does R Distinguish Variables?,What's my type?,Assigning Classes,Make it Classy (1),Make it Classy (2)","The Object Factory,Specifying the Microwave Oven Class,Making Microwave Ovens,Hiding Complexity with Encapsulation,Learning to Cook,Close the Door,First Thing's First,Getting and Setting with Active Bindings,Read the Rating,Control the Power","Environments, Reference Behavior, & Shared Fields,Working with Environments (1),Working with Environments (2),Static Electricity,Cloning R6 Objects,Attack of the Clones (1),Attack of the Clones (2),Shut it Down,The Final Countdown,This is the End (of an R6 Object)","Generics and Methods or Function Overload,What's in a Name?,Creating a Generic Function,Creating an S3 Method (1),Creating an S3 method (2),Methodical Thinking,Finding Available Methods (1),Finding Available Methods (2),Method Lookup for Primitive Generics,Primitive Generic Functions,Who is Calling?,Too Much Class,Very Classy,Writing the Next Method",,"R Programmer,R Programming,Cooking times (SQLite file),Introduction to Writing Functions in R","Propagating Functionality with Inheritance,Specifying a Fancy Microwave Oven,Who's the Daddy?,Making a Fancy Microwave Oven,Embrace, Extend, Override,Extending the Cooking Capabilities,Overriding the Cooking Capabilities,Multiple Levels of Inheritance,Exposing your Parent,Over-Overriding the Cooking Capabilities,Remembering Your Origins",
222,Introduction to Deep Learning in Python,4,17,50,"215,532",3500,"Deep learning is the machine learning technique behind the most exciting capabilities in diverse areas like robotics, natural language processing, image recognition, and artificial intelligence, including the famous AlphaGo. In this course, you'll gain hands-on, practical knowledge of how to use deep learning with Keras 2.0, the latest version of a cutting-edge library for deep learning in Python.","Introduction to deep learning,Comparing neural network models to classical regression models,Forward propagation,Coding the forward propagation algorithm,Activation functions,The Rectified Linear Activation Function,Applying the network to many observations/rows of data,Deeper networks,Forward propagation in a deeper network,Multi-layer neural networks,Representations are learned,Levels of representation","Creating a keras model,Understanding your data,Specifying a model,Compiling and fitting a model,Compiling the model,Fitting the model,Classification models,Understanding your classification data,Last steps in classification models,Using models,Making predictions","The need for optimization,Calculating model errors,Understanding how weights change model accuracy,Coding how weight changes affect accuracy,Scaling up to multiple data points,Gradient descent,Calculating slopes,Improving model weights,Making multiple updates to weights,Backpropagation,The relationship between forward and backward propagation,Thinking about backward propagation,Backpropagation in practice,A round of backpropagation","Understanding model optimization,Diagnosing optimization problems,Changing optimization parameters,Model validation,Evaluating model accuracy on validation dataset,Early stopping: Optimizing the optimization,Experimenting with wider networks,Adding layers to a network,Thinking about model capacity,Experimenting with model structures,Stepping up to images,Building your own digit recognition model,Final thoughts","Hugo Bowne-Anderson,Yashas Roy","Deep Learning,Machine Learning Fundamentals,Machine Learning Scientist,Hourly wages,MNIST,Titanic,Machine Learning with scikit-learn",,
223,Case Studies: Manipulating Time Series Data in R,4,12,50,"11,195",3950,"In this course, you will strengthen your knowledge of time series topics through interactive exercises and interesting datasets. You’ll explore a variety of datasets about Boston, including data on flights, weather, economic trends, and local sports teams.","Review xts fundamentals,Identify the time series,Flight data,Pick out the xts object,Encoding your flight data,Manipulating and visualizing your data,Exploring your flight data,Visualize flight data,Calculate time series trends,Saving and exporting xts objects,Assessing flight trends,Saving time - I,Saving time - II","Handling missingness,Exploring economic data,Replace missing data - I,Replace missing data - II,Estimating missing GDP,Lagging and differencing,Exploring unemployment data,Lagging unemployment,Differencing unemployment,Rolling functions,Add a discrete rolling sum to GDP data,Add a continuous rolling average to unemployment data,Manipulating MA unemployment data","Merging time series data by row,Exploring temperature data,Next steps - I,Merging using rbind(),Visualizing Boston winters,Merging time series data by column,Subsetting and adjusting periodicity,Generating a monthly average,Using merge() and plotting over time,Are flight delays related to temperature?,Time series data workflow,Next steps - II,Expanding your data,Are flight delays related to visibility or wind?","Advanced features of xts,Encoding and plotting Red Sox data,Calculate a closing average,Calculate and plot a seasonal average,Calculate and plot a rolling average,Indexing commands in xts,Extract weekend games,Calculate a rolling average across all sports,Viewing sports trends,Congratulations",,"Quantitative Analyst,Time Series,Flights arriving at Boston Logan airport,Boston monthly average visibility,Wind speeds in Boston,Boston monthly temperature data,US and Massachusetts unemployment,US GDP data,Boston-area sports teams data,Manipulating Time Series Data with xts and zoo in R",,
224,Introduction to SQL,4,,41,"1,407,922",3450,"The role of a data scientist is to turn raw data into actionable insights. Much of the world's raw data—from electronic medical records to customer transaction histories—lives in organized collections of tables called relational databases. To be an effective data scientist, you must know how to wrangle and extract data from these databases using a language called SQL . This course teaches syntax in SQL shared by many types of databases, such as PostgreSQL, MySQL, SQL Server, and Oracle. This course teaches you everything you need to know to begin working with databases today!","Welcome to the course!,Onboarding | Tables,Onboarding | Query Result,Onboarding | Errors,Onboarding | Multi-step Exercises,Beginning your SQL journey,SELECTing single columns,SELECTing multiple columns,SELECT DISTINCT,Learning to COUNT,Practice with COUNT","Aggregate functions,Aggregate functions practice,Combining aggregate functions with WHERE,A note on arithmetic,It's AS simple AS aliasing,Even more aliasing","Filtering results,Simple filtering of numeric values,Simple filtering of text,WHERE AND,WHERE AND OR,WHERE AND OR (2),BETWEEN,BETWEEN (2),WHERE IN,Introduction to NULL and IS NULL,NULL and IS NULL,LIKE and NOT LIKE","ORDER BY,Sorting single columns,Sorting single columns (2),Sorting single columns (DESC),Sorting multiple columns,GROUP BY,GROUP BY practice,GROUP BY practice (2),HAVING a great time,All together now,All together now (2),A taste of things to come","Filip Schouwenaars,Colin Ricardo","Data Analyst,SQL Fundamentals,IMDb Film data",,
225,Supervised Learning with scikit-learn,4,15,49,"5,649",4050,"Grow your machine learning skills with scikit-learn and discover how to use this popular Python library to train models using labeled data. In this course, you'll learn how to make powerful predictions, such as whether a customer is will churn from your business, whether an individual has diabetes, and even how to tell classify the genre of a song. Using real-world datasets, you'll find out how to build predictive models, tune their parameters, and determine how well they will perform with unseen data.","Machine learning with scikit-learn,Binary classification,The supervised learning workflow,The classification challenge,k-Nearest Neighbors: Fit,k-Nearest Neighbors: Predict,Measuring model performance,Train/test split + computing accuracy,Overfitting and underfitting,Visualizing model complexity","How good is your model?,Deciding on a primary metric,Assessing a diabetes prediction classifier,Logistic regression and the ROC curve,Building a logistic regression model,The ROC curve,ROC AUC,Hyperparameter tuning,Hyperparameter tuning with GridSearchCV,Hyperparameter tuning with RandomizedSearchCV","Introduction to regression,Creating features,Building a linear regression model,Visualizing a linear regression model,The basics of linear regression,Fit and predict for regression,Regression performance,Cross-validation,Cross-validation for R-squared,Analyzing cross-validation metrics,Regularized regression,Regularized regression: Ridge,Lasso regression for feature importance","Preprocessing data,Creating dummy variables,Regression with categorical features,Handling missing data,Dropping missing data,Pipeline for song genre prediction: I,Pipeline for song genre prediction: II,Centering and scaling,Centering and scaling for regression,Centering and scaling for classification,Evaluating multiple models,Visualizing regression model performance,Predicting on the test set,Visualizing classification model performance,Pipeline for predicting song popularity,Congratulations","James Chapman,Amy Peterson,Izzy Weber","Data Scientist,Machine Learning Fundamentals,Machine Learning Scientist,Advertising and Sales,Diabetes,Telecom Churn,Music,Introduction to Statistics in Python",,
226,Introduction to Network Analysis in Python,4,14,50,"65,255",4100,"From online social networks such as Facebook and Twitter to transportation networks such as bike sharing systems, networks are everywhere—and knowing how to analyze them will open up a new world of possibilities for you as a data scientist. This course will equip you with the skills to analyze, visualize, and make sense of networks. You'll apply the concepts you learn to real-world network data using the powerful NetworkX library. With the knowledge gained in this course, you'll develop your network thinking skills and be able to look at your data with a fresh perspective.","Introduction to Networks,What is a network?,Basics of NetworkX API, using Twitter network,Basic drawing of a network using NetworkX,Queries on a graph,Types of graphs,Checking the un/directed status of a graph,Specifying a weight on edges,Checking whether there are self-loops in the graph,Network visualization,Visualizing using Matrix plots,Visualizing using Circos plots,Visualizing using Arc plots","Communities & cliques,Identifying triangle relationships,Finding nodes involved in triangles,Finding open triangles,Maximal cliques,Finding all maximal cliques of size ""n"",Subgraphs,Subgraphs I,Subgraphs II","Degree centrality,Compute number of neighbors for each node,Compute degree distribution,Degree centrality distribution,Graph algorithms,Shortest Path I,Shortest Path II,Shortest Path III,Betweenness centrality,NetworkX betweenness centrality on a social network,Deep dive - Twitter network,Deep dive - Twitter network part II","Case study!,Characterizing the network (I),Characterizing the network (II),Characterizing the network (III),Case study part II: Visualization,MatrixPlot,ArcPlot,CircosPlot,Case study part III: Cliques,Finding cliques (I),Finding cliques (II),Case Study Part IV: Final Tasks,Finding important collaborators,Characterizing editing communities,Recommending co-editors who have yet to edit together,Final thoughts","Hugo Bowne-Anderson,Yashas Roy","Twitter network,GitHub users,Python Data Science Toolbox (Part 2)",,
227,Visualizing Geospatial Data in R,4,15,58,"23,186",5000,,"Introduction to spatial data,Grabbing a background map,Putting it all together,Insight through aesthetics,Useful get_map() and ggmap() options,Different maps,Leveraging ggplot2's strengths,A quick alternative,Common types of spatial data,Drawing polygons,Choropleth map,Raster data as a heatmap","The raster package,What's a raster object?,Some useful methods,A more complicated object,A package that uses Raster objects,Color scales,Pick the right palette,Adding a custom continuous color palette to ggplot2 plots,Custom palette in tmap,More about color scales,An interval scale example,A diverging scale example,A qualitative example","Introducing sp objects,Let's take a look at a spatial object,What's inside a spatial object?,A more complicated spatial object,sp and S4,Walking the hierarchy,Further down the rabbit hole,More sp classes and methods,Subsetting by index,Accessing data in sp objects,Subsetting based on data attributes,tmap, a package that works with sp objects,Introduction to tmap,Building a plot in layers,Why is Greenland so big?,Saving a tmap plot","Reading in spatial data,Reading in a shapefile,Reading in a raster file,Getting data using a package,Coordinate reference systems,Merging data from different CRS/projections,Converting from one CRS/projection to another,Adding data to spatial objects,The wrong way,Checking data will match,Merging data attributes,A first plot,Polishing a map,Subsetting the neighborhoods,Adding neighborhood labels,Tidying up the legend and some final tweaks,Wrap up","Sumedh Panchadhar,Nick Carchedi,Tom Jeon","Spatial Data,House sales in Corvallis, 2015,Ward sales in Corvallis, 2015,Predicted house prices in Corvallis,Countries (sp object),Countries (spdf object),Population around the Boston and NYC areas,Population around the Boston and NYC areas (Broken into different age groups),Population around the Boston and NYC areas (Proportion by age),Migration,Neighborhood Tabulation Areas,Median Income data,NYC tracts data,Water bodies in NYC,NYC Income data,Introduction to R,Introduction to Data Visualization with ggplot2",,
228,Unsupervised Learning in R,4,16,49,"41,146",3600,"Many times in machine learning, the goal is to find patterns in data without trying to make predictions. This is called unsupervised learning. One common use case of unsupervised learning is grouping consumers based on demographics and purchasing history to deploy targeted marketing campaigns. Another example is wanting to describe the unmeasured factors that most influence crime differences between cities. This course provides a basic introduction to clustering and dimensionality reduction in R from a machine learning perspective, so that you can get from data to insights as quickly as possible.","Welcome to the course!,Identify clustering problems,Introduction to k-means clustering,k-means clustering,Results of kmeans(),Visualizing and interpreting results of kmeans(),How k-means works and practical matters,Handling random algorithms,Selecting number of clusters,Introduction to the Pokemon data,Practical matters: working with real data,Review of k-means clustering","Introduction to PCA,PCA using prcomp(),Results of PCA,Additional results of PCA,Visualizing and interpreting PCA results,Interpreting biplots (1),Interpreting biplots (2),Variance explained,Visualize variance explained,Practical issues with PCA,Practical issues: scaling,Additional uses of PCA and wrap-up","Introduction to hierarchical clustering,Hierarchical clustering with results,Selecting number of clusters,Interpreting dendrogram,Cutting the tree,Clustering linkage and practical matters,Linkage methods,Comparing linkage methods,Practical matters: scaling,Comparing kmeans() and hclust(),Review of hierarchical clustering","Introduction to the case study,Preparing the data,Exploratory data analysis,Performing PCA,Interpreting PCA results,Variance explained,PCA review and next steps,Communicating PCA results,Hierarchical clustering of case data,Results of hierarchical clustering,Selecting number of clusters,k-means clustering and comparing results,Clustering on PCA results,Wrap-up and review","Nick Carchedi,Tom Jeon","Data Engineer,Data Scientist,Machine Learning Fundamentals,Machine Learning Scientist,SQL Fundamentals,Unsupervised Machine Learning,Pokemon data,Wisconsin breast cancer data,Introduction to R",,
229,ARIMA Models in R,4,13,45,"27,450",3600,"In this course, you will become an expert in fitting ARIMA models to time series data using R. First, you will explore the nature of time series data using the tools in the R stats package. Next, you learn how to fit various ARMA models to simulated data (where you will know the correct model) using the R package astsa. Once you have mastered the basics, you will learn how to fit integrated ARMA models, or ARIMA models to various real data sets. You will learn how to check the validity of an ARIMA model and you will learn how to forecast time series data. Finally, you will learn how to fit ARIMA models to seasonal data, including forecasting using the astsa package.","First things first,Data play,Elements of time series,Stationarity and nonstationarity,Differencing,Detrending data,Dealing with trend and heteroscedasticity,Stationary time series: ARMA,Simulating ARMA models","ARIMA - integrated ARMA,ARIMA - plug and play,Simulated ARIMA,Global warming,ARIMA diagnostics,Diagnostics - simulated overfitting,Diagnostics - global temperatures,Forecasting ARIMA,Forecasting simulated ARIMA,Forecasting global temperatures","AR and MA models,Fitting an AR(1) model,Fitting an AR(2) model,Fitting an MA(1) model,AR and MA together,Fitting an ARMA model,Identify an ARMA model,Model choice and residual analysis,Model choice - I,Model choice - II,Residual analysis - I,Residual analysis - II,ARMA get in","Pure seasonal models,P/ACF of pure seasonal models,Fit a pure seasonal model,Mixed seasonal models,Fit a mixed seasonal model,Data analysis - unemployment I,Data analysis - unemployment II,Data analysis - commodity prices,Data analysis - birth rate,Forecasting seasonal ARIMA,Forecasting monthly unemployment,How hard is it to forecast commodity prices?,Congratulations!","Lore Dirick,Matt Isaacs","Quantitative Analyst,Time Series,Time Series Analysis in R",,
230,Introduction to Data in R,4,15,46,"100,888",3200,"Scientists seek to answer questions using rigorous methods and careful observations. These observations—collected from the likes of field notes, surveys, and experiments—form the backbone of a statistical investigation and are called data. Statistics is the study of how best to collect, analyze, and draw conclusions from data. It is helpful to put statistics in the context of a general process of investigation: 1) identify a question or problem; 2) collect relevant data on the topic; 3) analyze the data; and 4) form a conclusion. In this course, you'll focus on the first two steps of the process.","Welcome to the course!,Loading data into R,Types of variables,Identify variable types,Categorical data in R: factors,Filtering based on a factor,Complete filtering based on a factor,Discretize a variable,Discretize a different variable,Combining levels of a different factor,Visualizing numerical data,Visualizing numerical and categorical data","Sampling strategies,Sampling strategies, determine which,Sampling strategies, choose worst,Sampling in R,Simple random sample in R,Stratified sample in R,Compare SRS vs. stratified sample,Principles of experimental design,Identifying components of a study,Experimental design terminology,Connect blocking and stratifying","Observational studies and experiments,Identify type of study: Reading speed and font,Identify type of study: Countries,Random sampling and random assignment,Random sampling or random assignment?,Identify the scope of inference of study,Simpson's paradox,Number of males and females admitted,Proportion of males admitted overall,Proportion of males admitted for each department,Admission rates for males across departments,Recap: Simpson's paradox,Identify type of study: Countries [new]","Beauty in the classroom,Inspect the data,Identify type of study,Sampling / experimental attributes,Variables in the data,Identify variable types,Recode a variable,Create a scatterplot,Create a scatterplot, with an added layer,Congratulations!","Nick Carchedi,Tom Jeon","Course evaluation,UC Berkeley admissions,US state regions,Introduction to the Tidyverse",,
231,Correlation and Regression in R,4,18,58,"84,122",4200,"Ultimately, data analysis is about understanding relationships among variables. Exploring data with multiple variables requires new, more complex tools, but enables a richer set of comparisons. In this course, you will learn how to describe relationships between two numerical quantities. You will characterize these relationships graphically, in the form of summary statistics, and through simple linear regression models.","Visualizing bivariate relationships,Scatterplots,Boxplots as discretized/conditioned scatterplots,Characterizing bivariate relationships,Creating scatterplots,Characterizing scatterplots,Transformations,Outliers,Identifying outliers","Visualization of Linear Models,The ""best fit"" line,Uniqueness of least squares regression line,Understanding Linear Models,Regression model terminology,Regression model output terminology,Fitting a linear model ""by hand"",Regression vs. regression to the mean,Regression to the mean,""Regression"" in the parlance of our time","Assessing Model Fit,RMSE,Standard error of residuals,Comparing model fits,Assessing simple linear model fit,Interpretation of R^2,Linear vs. average,Unusual Points,Leverage,Influence,Dealing with Outliers,Removing outliers,High leverage points,Conclusion","Quantifying the strength of bivariate relationships,Understanding correlation scale,Understanding correlation sign,Computing correlation,The Anscombe dataset,Exploring Anscombe,Perception of correlation,Perception of correlation (2),Interpretation of Correlation,Interpreting correlation in context,Correlation and causation,Spurious correlations,Spurious correlation in random data","Nick Carchedi,Tom Jeon",Exploratory Data Analysis in R,"Interpretation of Regression,Interpretation of coefficients,Interpretation in context,Fitting simple linear models,Units and scale,Your linear model object,The lm summary output,Fitted values and residuals,Tidying your linear model,Using your linear model,Making predictions,Adding a regression line to a plot manually",
232,Exploratory Data Analysis in R,4,15,54,"75,474",3950,"When your dataset is represented as a table or a database, it's difficult to observe much about it beyond its size and the types of variables it contains. In this course, you'll learn how to use graphical and numerical techniques to begin uncovering the structure of your data. Which variables suggest interesting relationships? Which observations are unusual? By the end of the course, you'll be able to answer these questions and more, while generating graphics that are both insightful and beautiful.","Exploring categorical data,Bar chart expectations,Contingency table review,Dropping levels,Side-by-side bar charts,Bar chart interpretation,Counts vs. proportions,Conditional proportions,Counts vs. proportions (2),Distribution of one variable,Marginal bar chart,Conditional bar chart,Improve pie chart","Measures of center,Choice of center measure,Calculate center measures,Measures of variability,Choice of spread measure,Calculate spread measures,Choose measures for center and spread,Shape and transformations,Describe the shape,Transformations,Outliers,Identify outliers","Exploring numerical data,Faceted histogram,Boxplots and density plots,Compare distribution via plots,Distribution of one variable,Marginal and conditional histograms,Marginal and conditional histograms interpretation,Three binwidths,Three binwidths interpretation,Box plots,Box plots for outliers,Plot selection,Visualization in higher dimensions,3 variable plot,Interpret 3 var plot","Introducing the data,Spam and num_char,Spam and num_char interpretation,Spam and !!!,Spam and !!! interpretation,Check-in 1,Collapsing levels,Image and spam interpretation,Data Integrity,Answering questions with chains,Check-in 2,What's in a number?,What's in a number interpretation,Conclusion","Nick Carchedi,Tom Jeon","Data Analyst,Data Scientist,Cars data,Comics data,Immigration data,Raw life expectancy data,Names data,Raw U.S. income data,Introduction to Data in R",,
233,Foundations of Inference,4,17,58,"29,125",4350,"One of the foundational aspects of statistical analysis is inference, or the process of drawing conclusions about a larger population from a sample of data. Although counter intuitive, the standard practice is to attempt to disprove a research claim that is not of interest. For example, to show that one medical treatment is better than another, we can assume that the two treatments lead to equal survival rates only to then be disproved by the data. Additionally, we introduce the idea of a p-value, or the degree of disagreement between the data and the hypothesis. We also dive into confidence intervals, which measure the magnitude of the effect of interest (e.g. how much better one treatment is than another).","Welcome to the course!,Hypotheses (1),Hypotheses (2),Randomized distributions,Working with the NHANES data,Calculating statistic of interest,Randomized data under null model of independence,Randomized statistics and dotplot,Randomization density,Using the randomization distribution,Do the data come from the population?,What can you conclude?,Study conclusions","Example: opportunity cost,Summarizing opportunity cost (1),Plotting opportunity cost,Randomizing opportunity cost,Summarizing opportunity cost (2),Opportunity cost conclusion,Errors and their consequences,Different choice of error rate,Errors for two-sided hypotheses,p-value for two-sided hypotheses: opportunity costs,Summary of opportunity costs","Example: gender discrimination,Gender discrimination hypotheses,Summarizing gender discrimination,Step-by-step through the permutation,Randomizing gender discrimination,Distribution of statistics,Reflecting on analysis,Critical region,Two-sided critical region,Why 0.05?,How does sample size affect results?,Sample size in randomization distribution,Sample size for critical region,What is a p-value?,Calculating the p-values,Practice calculating p-values,Calculating two-sided p-values,Summary of gender discrimination","Parameters and confidence intervals,What is the parameter?,Hypothesis test or confidence interval?,Bootstrapping,Resampling from a sample,Visualizing the variability of p-hat,Always resample the original number of observations,Variability in p-hat,Empirical Rule,Bootstrap t-confidence interval,Bootstrap percentile interval,Interpreting CIs and technical conditions,Sample size effects on bootstrap CIs,Sample proportion value effects on bootstrap CIs,Percentile effects on bootstrap CIs,Summary of statistical inference","Nick Carchedi,Tom Jeon","Statistical Inference,Statistician,All polls,Polling data,Big discrimination dataset,New discrimination dataset,Small discrimination dataset,Introduction to Regression in R,Hypothesis Testing in R",,
234,Bond Valuation and Analysis in R,4,13,43,"11,818",3350,,"Introduction,Price vs. value,Time value of money,Computing a bond's future value,Computing a bond's present value,Bond valuation,Laying out the bond's cash flows,Discounting bond cash flows with a known yield,Convert your code into a function,Convert your code into a bond valuation function","Bond price volatility and the price value of a basis point,Price value of a basis point,Calculate PV01 of a 10% bond,Duration,Duration of a zero-coupon bond,Calculate approximate duration for a bond,Estimating effect on bond price using duration,Convexity,Calculate approximate convexity for a bond,Estimating effect of convexity on bond price,Estimating the bond price using duration and convexity","Price-yield relationship,Credit ratings,The yield on the Moody's Baa index,Value the 5% bond using the Baa yield you found,Plotting the price/yield relationship,Components of yield,Risk-free yield,Plotting US Treasury yields,Plotting the investment grade spread,Estimating the yield of a bond,Finding a bond's yield,Use uniroot function to find YTM","Summarizing the main lessons,Find AAA bond yields as of September 30, 2016,Bond valuation,Alternative cash flow vector code,Duration and convexity,Direction of price change,Calculate duration,Calculate convexity measure,The estimated price change using duration and convexity,Congratulations!",Lore Dirick,"Applied Finance,Quantitative Analyst,Importing and Managing Financial Data in R",,
235,Introduction to Importing Data in Python,3,15,54,"229,302",4150,"As a data scientist, you will need to clean data, wrangle and munge it, visualize it, build predictive models, and interpret these models. Before you can do so, however, you will need to know how to get data into Python. In this course, you'll learn the many ways to import data into Python: from flat files such as .txt and .csv; from files native to other software such as Excel spreadsheets, Stata, SAS, and MATLAB files; and from relational databases such as SQLite and PostgreSQL.","Welcome to the course!,Exploring your working directory,Importing entire text files,Importing text files line by line,The importance of flat files in data science,Pop quiz: examples of flat files,Pop quiz: what exactly are flat files?,Why we like flat files and the Zen of Python,Importing flat files using NumPy,Using NumPy to import flat files,Customizing your NumPy import,Importing different datatypes,Working with mixed datatypes (1),Working with mixed datatypes (2),Importing flat files using pandas,Using pandas to import flat files as DataFrames (1),Using pandas to import flat files as DataFrames (2),Customizing your pandas import,Final thoughts on data import","Introduction to relational databases,Pop quiz: The relational model,Creating a database engine in Python,Creating a database engine,What are the tables in the database?,Querying relational databases in Python,The Hello World of SQL Queries!,Customizing the Hello World of SQL Queries,Filtering your database records using SQL's WHERE,Ordering your SQL records with ORDER BY,Querying relational databases directly with pandas,Pandas and The Hello World of SQL Queries!,Pandas for more complex querying,Advanced querying: exploiting table relationships,The power of SQL lies in relationships between tables: INNER JOIN,Filtering your INNER JOIN,Final Thoughts","Introduction to other file types,Not so flat any more,Loading a pickled file,Listing sheets in Excel files,Importing sheets from Excel files,Customizing your spreadsheet import,Importing SAS/Stata files using pandas,How to import SAS7BDAT,Importing SAS files,Using read_stata to import Stata files,Importing Stata files,Importing HDF5 files,Using File to import HDF5 files,Using h5py to import HDF5 files,Extracting data from your HDF5 file,Importing MATLAB files,Loading .mat files,The structure of .mat in Python",,Francisco Castro,"Data Scientist,Importing & Cleaning Data,Chinook (SQLite),LIGO (HDF5),Battledeath (XLSX),Extent of infectious diseases (DTA),Gene expressions (MATLAB),MNIST,Sales (SAS7BDAT),Seaslugs,Titanic,Intermediate Python",,
236,Intermediate Importing Data in Python,2,7,28,"138,453",2300,"As a data scientist, you will need to clean data, wrangle and munge it, visualize it, build predictive models and interpret these models. Before you can do so, however, you will need to know how to get data into Python. In the prequel to this course, you learned many ways to import data into Python: from flat files such as .txt and .csv; from files native to other software such as Excel spreadsheets, Stata, SAS, and MATLAB files; and from relational databases such as SQLite and PostgreSQL. In this course, you'll extend this knowledge base by learning to import data from the web and by pulling data from Application Programming Interfaces— APIs—such as the Twitter streaming API, which allows us to stream real-time tweets.","Importing flat files from the web,Importing flat files from the web: your turn!,Opening and reading flat files from the web,Importing non-flat files from the web,HTTP requests to import files from the web,Performing HTTP requests in Python using urllib,Printing HTTP request results in Python using urllib,Performing HTTP requests in Python using requests,Scraping the web in Python,Parsing HTML with BeautifulSoup,Turning a webpage into data using BeautifulSoup: getting the text,Turning a webpage into data using BeautifulSoup: getting the hyperlinks","The Twitter API and Authentication,Streaming tweets,Load and explore your Twitter data,Twitter data to DataFrame,A little bit of Twitter text analysis,Plotting your Twitter data,Final Thoughts","Introduction to APIs and JSONs,Pop quiz: What exactly is a JSON?,Loading and exploring a JSON,Pop quiz: Exploring your JSON,APIs and interacting with the world wide web,Pop quiz: What's an API?,API requests,JSON–from the web to Python,Checking out the Wikipedia API",,Francisco Castro,"Data Scientist,Importing & Cleaning Data,Latitudes (XLS),Tweets,Red wine quality,Introduction to Importing Data in Python",,
237,Intermediate Portfolio Analysis in R,5,12,42,"9,719",3250,"This course builds on the fundamental concepts from Introduction to Portfolio Analysis in R and explores advanced concepts in the portfolio optimization process. It is critical for an analyst or portfolio manager to understand all aspects of the portfolio optimization problem to make informed decisions. In this course, you will learn a quantitative approach to apply the principles of modern portfolio theory to specify a portfolio, define constraints and objectives, solve the problem, and analyze the results. This course will use the R package PortfolioAnalytics to solve portfolio optimization problems with complex constraints and objectives that mirror real world problems.","Welcome to the course!,Load the PortfolioAnalytics package,Solve a simple portfolio optimization problem,Visualize results,Modern Portfolio Theory objective,Defining risk,Challenges of portfolio optimization,Quadratic utility,Maximize quadratic utility function,Introduction to PortfolioAnalytics,Key design goals","Introduction to moments,Sample moment estimates,Advanced moment estimates,Method for estimating moments,Custom moment functions,Define a custom moment function,Optimization with custom moment function,Objective functions,Custom objective function,Optimization with custom objective function","Portfolio specification, constraints, and objectives,Create a portfolio specification,Add constraints,Add objectives,Running optimizations,Single-Period optimization,Optimization with periodic rebalancing,Global solvers,Analyzing optimization results,Objective measure values,Optimal weights","Application,Compute benchmark returns,Define the portfolio optimization problem,Benchmark,Optimization backtest,Backtest with periodic rebalancing,Refine constraints and objectives,Do improved estimates lead to improved performance?,Analyze results and compare to benchmark,Congratulations!","Davis Vaughan,Lore Dirick","Finance Fundamentals,Quantitative Analyst,Portfolio specifications object I,Portfolio specifications object II,Set of random portfolios I,Set of random portfolios II,Introduction to Portfolio Analysis in R",,
238,Intermediate Statistical Modeling in R,4,10,41,"7,884",3300,"Statistical Modeling in R is a multi-part course designed to get you up to speed with the most important and powerful methodologies in statistics. In this intermediate course 2, we'll take a look at effect size and interaction, the concepts of total and partial change, sampling variability and mathematical transforms, and the implications of something called collinearity. This course has been written from scratch, specifically for DataCamp users. As you'll see, by using computing and concepts from machine learning, we'll be able to leapfrog many of the marginal and esoteric topics encountered in traditional 'regression' courses.","Multiple explanatory variables,Graphing a model of house prices,Body-mass index (BMI),Categorical response variables,Eager runners,Who are the mellow runners?,Smoking and survival,Interactions among explanatory variables,With and without an interaction term,Working together,Mileage and age interacting,Interactions and effect size,Optimal temperature","Bootstrapping and precision,A bootstrap trial,From a bootstrap ensemble to the standard error,Example: fireplaces,Scales and transformations,Typical values of data,Exponential growth,Prediction with log transforms,Confidence intervals on log-transformed models","Total and partial change,Another bedroom?,Calculating total change,Car prices,R-squared,Calculating R-squared,Warming in Minneapolis?,R-squared goes up,Degrees of freedom,Rules for counting,Is bigger R-squared better? (1),Is bigger R-squared better? (2),Accidental ""perfection""","Confidence and collinearity,Collinearity and inflation (1),Collinearity and inflation (2),Inflation and interaction,Modeling SAT scores,Start modeling!","Nick Carchedi,Tom Jeon","Used Fords,Introduction to Statistical Modeling in R",,
239,Introduction to Statistical Modeling in R,4,10,43,"28,010",3250,,"Welcome to statistical modeling!,A mathematical model,Running experiments on the toy model,From experimental results to a prediction,R objects for statistical modeling,Accessing data,Starting with formulas,Graphics with formulas","Choosing explanatory variables,Conceptual warm-up,Running experience,Prediction performance,Where's the statistics?,Cross validation,Tidying up,Testing and training datasets,Repeating random trials,To add or not to add (an explanatory variable)?","Covariates,House prices,Crime and poverty,Equal pay?,Effect size,Sex and death,Comparing effect sizes,How do GPAs compare?,Housing units","Designing and training models,Modeling running times,Using the recursive partitioning model architecture,Will they run again?,Evaluating models,From inputs to outputs,Extrapolation,Typical values of data","Nick Carchedi,Tom Jeon","Ran twice,100 Runners,Introduction to R,Introduction to the Tidyverse","Prediction error for categorical response variables,The maximum error rate,A non-null model,A better model?,Exploring data for relationships,Evaluating a recursive partitioning model,Exploring birth-weight data,Exploring more broadly",
240,Statistical Thinking in Python (Part 2),4,15,66,"82,066",5350,"After completing Statistical Thinking in Python (Part 1), you have the probabilistic mindset and foundational hacker stats skills to dive into data sets and extract useful information from them. In this course, you will do just that, expanding and honing your hacker stats toolbox to perform the two key tasks in statistical inference, parameter estimation and hypothesis testing. You will work with real data sets as you learn, culminating with analysis of measurements of the beaks of the Darwin's famous finches. You will emerge from this course with new knowledge and lots of practice under your belt, ready to attack your own inference problems out in the world.","Optimal parameters,How often do we get no-hitters?,Do the data follow our story?,How is this parameter optimal?,Linear regression by least squares,EDA of literacy/fertility data,Linear regression,How is it optimal?,The importance of EDA: Anscombe's quartet,The importance of EDA,Linear regression on appropriate Anscombe data,Linear regression on all Anscombe data","Formulating and simulating a hypothesis,Generating a permutation sample,Visualizing permutation sampling,Test statistics and p-values,Test statistics,What is a p-value?,Generating permutation replicates,Look before you leap: EDA before hypothesis testing,Permutation test on frog data,Bootstrap hypothesis tests,A one-sample bootstrap hypothesis test,A two-sample bootstrap hypothesis test for difference of means","Finch beaks and the need for statistics,EDA of beak depths of Darwin's finches,ECDFs of beak depths,Parameter estimates of beak depths,Hypothesis test: Are beaks deeper in 2012?,Variation in beak shapes,EDA of beak length and depth,Linear regressions,Displaying the linear regression results,Beak length to depth ratio,How different is the ratio?,Calculation of heritability,EDA of heritability,Correlation of offspring and parental data,Pearson correlation of offspring and parental data,Measuring heritability,Is beak depth heritable at all in G. scandens?,Final thoughts","Generating bootstrap replicates,Getting the terminology down,Bootstrapping by hand,Visualizing bootstrap samples,Bootstrap confidence intervals,Generating many bootstrap replicates,Bootstrap replicates of the mean and the SEM,Confidence intervals of rainfall data,Bootstrap replicates of other statistics,Confidence interval on the rate of no-hitters,Pairs bootstrap,A function to do pairs bootstrap,Pairs bootstrap of literacy/fertility data,Plotting bootstrap regressions","Hugo Bowne-Anderson,Yashas Roy","Anscombe data,Bee sperm counts,Female literacy and fertility,Finch beaks (1975),Finch beaks (2012),Fortis beak depth heredity,Frog tongue data,Major League Baseball no-hitters,Scandens beak depth heredity,Sheffield Weather Station,Statistical Thinking in Python (Part 1)","A/B testing,The vote for the Civil Rights Act in 1964,What is equivalent?,A time-on-website analog,What should you have done first?,Test of correlation,Simulating a null hypothesis concerning correlation,Hypothesis test on Pearson correlation,Do neonicotinoid insecticides have unintended consequences?,Bootstrap hypothesis test on bee sperm counts",
241,Statistical Thinking in Python (Part 1),3,18,61,"163,507",4550,"After all of the hard work of acquiring data and getting them into a form you can work with, you ultimately want to make clear, succinct conclusions from them. This crucial last step of a data analysis pipeline hinges on the principles of statistical inference. In this course, you will start building the foundation you need to think statistically, speak the language of your data, and understand what your data is telling you. The foundations of statistical thinking took decades to build, but can be grasped much faster today with the help of computers. With the power of Python-based tools, you will rapidly get up-to-speed and begin thinking statistically by the end of this course.","Introduction to Exploratory Data Analysis,Tukey's comments on EDA,Advantages of graphical EDA,Plotting a histogram,Plotting a histogram of iris data,Axis labels!,Adjusting the number of bins in a histogram,Plot all of your data: Bee swarm plots,Bee swarm plot,Interpreting a bee swarm plot,Plot all of your data: ECDFs,Computing the ECDF,Plotting the ECDF,Comparison of ECDFs,Onward toward the whole story!","Probabilistic logic and statistical inference,What is the goal of statistical inference?,Why do we use the language of probability?,Random number generators and hacker statistics,Generating random numbers using the np.random module,The np.random module and Bernoulli trials,How many defaults might we expect?,Will the bank fail?,Probability distributions and stories: The Binomial distribution,Sampling out of the Binomial distribution,Plotting the Binomial PMF,Poisson processes and the Poisson distribution,Relationship between Binomial and Poisson distributions,How many no-hitters in a season?,Was 2015 anomalous?","Introduction to summary statistics: The sample mean and median,Means and medians,Computing means,Percentiles, outliers, and box plots,Computing percentiles,Comparing percentiles to ECDF,Box-and-whisker plot,Variance and standard deviation,Computing the variance,The standard deviation and the variance,Covariance and the Pearson correlation coefficient,Scatter plots,Variance and covariance by looking,Computing the covariance,Computing the Pearson correlation coefficient","Probability density functions,Interpreting PDFs,Interpreting CDFs,Introduction to the Normal distribution,The Normal PDF,The Normal CDF,The Normal distribution: Properties and warnings,Gauss and the 10 Deutschmark banknote,Are the Belmont Stakes results Normally distributed?,What are the chances of a horse matching or beating Secretariat's record?,The Exponential distribution,Matching a story and a distribution,Waiting for the next Secretariat,If you have a story, you can simulate it!,Distribution of no-hitters and cycles,Final thoughts","Hugo Bowne-Anderson,Yashas Roy","2008 election results (all states),2008 election results (swing states),Belmont Stakes,Speed of light,Python Data Science Toolbox (Part 2)",,
242,Python Data Science Toolbox (Part 1),3,12,46,"320,449",3650,"It's time to push forward and develop your Python chops even further. There are tons of fantastic functions in Python and its library ecosystem. However, as a data scientist, you'll constantly need to write your own functions to solve problems that are dictated by your data. You will learn the art of function writing in this first Python Data Science Toolbox course. You'll come out of this course being able to write your very own custom functions, complete with multiple parameters and multiple return values, along with default arguments and variable-length arguments. You'll gain insight into scoping in Python and be able to write lambda functions and handle errors in your function writing practice. And you'll wrap up each chapter by using your new skills to write functions that analyze Twitter DataFrames.","User-defined functions,Strings in Python,Recapping built-in functions,Write a simple function,Single-parameter functions,Functions that return single values,Multiple parameters and return values,Functions with multiple parameters,A brief introduction to tuples,Functions that return multiple values,Bringing it all together,Bringing it all together (1),Bringing it all together (2),Congratulations!","Lambda functions,Pop quiz on lambda functions,Writing a lambda function you already know,Map() and lambda functions,Filter() and lambda functions,Reduce() and lambda functions,Introduction to error handling,Pop quiz about errors,Error handling with try-except,Error handling by raising an error,Bringing it all together,Bringing it all together (1),Bringing it all together (2),Bringing it all together (3),Bringing it all together: testing your error handling skills,Congratulations!","Scope and user-defined functions,Pop quiz on understanding scope,The keyword global,Python's built-in scope,Nested functions,Nested Functions I,Nested Functions II,The keyword nonlocal and nested functions,Default and flexible arguments,Functions with one default argument,Functions with multiple default arguments,Functions with variable-length arguments (*args),Functions with variable-length keyword arguments (**kwargs),Bringing it all together,Bringing it all together (1),Bringing it all together (2)",,Francisco Castro,"Data Scientist,Python Fundamentals,Python Programmer,Tweets,Intermediate Python",,
243,Python Data Science Toolbox (Part 2),4,12,46,"209,860",3800,"In this second Python Data Science Toolbox course, you'll continue to build your Python data science skills. First, you'll learn about iterators, objects you have already encountered in the context of for loops. You'll then learn about list comprehensions, which are extremely handy tools for all data scientists working in Python. You'll end the course by working through a case study in which you'll apply all the techniques you learned in both parts of this course.","Introduction to iterators,Iterators vs. Iterables,Iterating over iterables (1),Iterating over iterables (2),Iterators as function arguments,Playing with iterators,Using enumerate,Using zip,Using * and zip to 'unzip',Using iterators to load large files into memory,Processing large amounts of Twitter data,Extracting information for large amounts of Twitter data,Congratulations!","Welcome to the case study!,Dictionaries for data science,Writing a function to help you,Using a list comprehension,Turning this all into a DataFrame,Using Python generators for streaming data,Processing data in chunks (1),Writing a generator to load data in chunks (2),Writing a generator to load data in chunks (3),Using pandas' read_csv iterator for streaming data,Writing an iterator to load data in chunks (1),Writing an iterator to load data in chunks (2),Writing an iterator to load data in chunks (3),Writing an iterator to load data in chunks (4),Writing an iterator to load data in chunks (5),Final thoughts","List comprehensions,Write a basic list comprehension,List comprehension over iterables,Writing list comprehensions,Nested list comprehensions,Advanced comprehensions,Using conditionals in comprehensions (1),Using conditionals in comprehensions (2),Dict comprehensions,Introduction to generator expressions,List comprehensions vs. generators,Write your own generator expressions,Changing the output in generator expressions,Build a generator,Wrapping up comprehensions and generators.,List comprehensions for time-stamped data,Conditional list comprehensions for time-stamped data",,"Francisco Castro,Yashas Roy","Data Scientist,Python Fundamentals,Python Programmer,Tweets,World Bank World Development Indicators,Python Data Science Toolbox (Part 1)",,
244,Data Visualization in R,4,15,60,"57,923",5250,,"The world of data visualization,Creating an exploratory plot array,Creating an explanatory scatterplot,The plot() function is generic,A preview of some more and less useful techniques,Adding details to a plot using point shapes, color, and reference lines,Creating multiple plot arrays,Avoid pie charts","The plot() function and its options,Introduction to the par() function,Exploring the type option,The surprising utility of the type ""n"" option,Adding lines and points to plots,The lines() function and line types,The points() function and point types,Adding trend lines from linear regression models,Adding text to plots,Using the text() function to label plot features,Adjusting text position, size, and font,Rotating text with the srt argument,Adding or modifying other plot details,Using the legend() function,Adding custom axes with the axis() function,Using the supsmu() function to add smooth trend curves","Creating and saving more complex plots,Some plot functions also return useful information,Using the symbols() function to display relations between more than two variables,Saving plot results as files,Using color effectively,Iliinsky and Steele's 12 recommended colors,Using color to enhance a bubbleplot,Using color to enhance stacked barplots,Other graphics systems in R,The tabplot package and grid graphics,A lattice graphics example,A ggplot2 graphics example","Characterizing a single variable,The hist() and truehist() functions,Density plots as smoothed histograms,Using the qqPlot() function to see many details in data,Visualizing relations between two variables,The sunflowerplot() function for repeated numerical data,Useful options for the boxplot() function,Using the mosaicplot() function,Showing more complex relations between variables,Using the bagplot() function,Plotting correlation matrices with the corrplot() function,Building and plotting rpart() models","Nick Carchedi,Tom Jeon",Introduction to R,"Managing visual complexity,Too much is too much,Deciding how many scatterplots is too many,How many words is too many?,Creating plot arrays with the mfrow parameter,The Anscombe quartet,The utility of common scaling and individual titles,Using multiple plots to give multiple views of a dataset,Creating plot arrays with the layout() function,Constructing and displaying layout matrices,Creating a triangular array of plots,Creating arrays with different sized plots",
245,Intermediate Importing Data in R,3,10,48,"71,543",3950,"In this course, you will take a deeper dive into the wide range of data formats out there. More specifically, you'll learn how to import data from relational databases and how to import and work with data coming from the web. Finally, you'll get hands-on experience with importing data from statistical software packages such as SAS, STATA, and SPSS.","Connect to a database,Establish a connection,Inspect the connection,Import table data,List the database tables,Import users,Import all tables,How do the tables relate?","HTTP,Import flat files from the web,Secure importing,Downloading files,Import Excel files from the web,Downloading any file, secure or not,Reading a text file from the web,HTTP? httr! (1),HTTP? httr! (2)","haven,Import SAS data with haven,Import STATA data with haven,What does the graphic tell?,Import SPSS data with haven,Factorize, round two,foreign,Import STATA data with foreign (1),Import STATA data with foreign (2),Do you know your data?,Import SPSS data with foreign (1),Excursion: Correlation,Import SPSS data with foreign (2)","SQL Queries from inside R,Query tweater (1),Query tweater (2),Query tweater (3),Query tweater (4),Join the query madness!,DBI internals,Send - Fetch - Clear,Be polite and ...",,"Data Scientist,Importing & Cleaning Data,Education equality data,Employee data,Florida election data,International socio-economic data,Latitude (XLS),Latitude (XLSX),Big Five data,Potatoes,Sales data,Swimming pools,Sugar import data,Water data,Wine data,Introduction to Importing Data in R","APIs & JSON,From JSON to R,Quandl API,OMDb API,JSON & jsonlite,JSON practice (1),JSON practice (2),toJSON(),Minify and prettify",
246,Introduction to Importing Data in R,3,11,42,"161,499",3550,"Importing data into R should be the easiest step in your analysis. Unfortunately, that is almost never the case. Data can come in many formats, ranging from .csv and text files, to statistical software files, to databases and HTML data. Knowing which approach to use is key to getting started with the actual analysis. In this course, you’ll start by learning how to read .csv and text files in R. You will then cover the readr and data.table packages to easily and efficiently import flat file data. After that, you will learn how to read .xls files in R using readxl and gdata.","Introduction & read.csv,read.csv,stringsAsFactors,Any changes?,read.delim & read.table,read.delim,read.table,Arguments,Column classes,Final Thoughts","readxl (1),List the sheets of an Excel file,Import an Excel sheet,Reading a workbook,readxl (2),The col_names argument,The skip argument,gdata,Import a local file,read.xls() wraps around read.table(),Work that Excel data!","readr: read_csv & read_tsv,read_csv,read_tsv,readr: read_delim,read_delim,skip and n_max,col_types,col_types with collectors,data.table: fread,fread,fread: more advanced use,Dedicated classes","Reading sheets,Connect to a workbook,List and read Excel sheets,Customize readWorksheet,Adapting sheets,Add worksheet,Populate worksheet,Renaming sheets,Removing sheets",,"Data Scientist,Importing & Cleaning Data,Hotdogs,Potatoes (CSV),Potatoes (TSV),Swimming pools,Urban population (XLS),Urban population (XLSX),Introduction to R",,
247,Case Study: Exploratory Data Analysis in R,4,15,58,"46,145",4800,"Once you've started learning tools for data manipulation and visualization like dplyr and ggplot2, this course gives you a chance to use them in action on a real dataset. You'll explore the historical voting of the United Nations General Assembly, including analyzing differences in voting between countries, across time, and among international issues. In the process you'll gain more practice with the dplyr and ggplot2 packages, learn about the broom package for tidying model output, and experience the kind of start-to-finish exploratory analysis common in data science.","The United Nations Voting Dataset,Filtering rows,Adding a year column,Adding a country column,Grouping and summarizing,Summarizing the full dataset,Summarizing by year,Summarizing by country,Sorting and filtering summarized data,Sorting by percentage of ""yes"" votes,Filtering summarized output","Linear regression,Linear regression on the United States,Finding the slope of a linear regression,Finding the p-value of a linear regression,Tidying models with broom,Tidying a linear regression model,Combining models for multiple countries,Nesting for multiple models,Nesting a data frame,List columns,Unnesting,Fitting multiple models,Performing linear regression on each nested dataset,Tidy each linear regression model,Unnesting a data frame,Working with many tidy models,Filtering model terms,Filtering for significant countries,Sorting by slope","Visualization with ggplot2,Choosing an aesthetic,Plotting a line over time,Other ggplot2 layers,Visualizing by country,Summarizing by year and country,Plotting just the UK over time,Plotting multiple countries,Faceting by country,Faceting the time series,Faceting with free y-axis,Choose your own countries","Joining datasets,Joining datasets with inner_join,Filtering the joined dataset,Visualizing colonialism votes,Tidy data,Tidy data observations,Using gather to tidy a dataset,Recoding the topics,Summarize by country, year, and topic,Visualizing trends in topics for one country,Tidy modeling by topic and country,Nesting by topic and country,Interpreting tidy models,Steepest trends by topic,Checking models visually,Conclusion","Nick Carchedi,Tom Jeon","Data Manipulation,Data Scientist,United Nations voting dataset,Topic information for each country (Descriptions),Introduction to Data Visualization with ggplot2",,
248,Interactive Data Visualization with Bokeh,4,15,53,,4500,"Bokeh is a powerful Python package for interactive data visualization, enabling you to go beyond static plots and allow stakeholders to modify your visualizations! In this interactive data visualization with Bokeh course, you'll work with a range of datasets, including stock prices, basketball player statistics, and Australian real-estate sales data. Through hands-on exercises, you’ll build and customize a range of plots, including scatter, bar, line, and grouped bar plots. You'll also get to grips with configuration tools to change how viewers interact with your plot, discover Bokeh's custom themes, learn how to generate subplots, and even how to add widgets to your plots!","Introduction to Bokeh,When to use a scatter plot,Blocks vs. rebounds,Kevin Durant's performance across seasons,Shooting ability by position,Configuration tools,The best tools for the job,Setting tools,Adding LassoSelectTool,The HoverTool,Adding a HoverTool,Formatting the HoverTool","Customizing glyph settings,Shooting guards versus small forwards,Big shooters,Evolution of the point guard,Highlighting and contrasting,Highlighting by glyph size,Steals vs. assists,Adding a color bar,Free throw percentage by position,Communicating with text,Sales by time and type of day,Products sold by the time of day,Adding annotations,Box annotations for sales performance,Setting up a polygon annotation,Annotating Netflix stock price growth","Adding style,Colors, legend, and theme,Customizing glyphs,Customizing axes,Average building size,Sales over time,Subplots,Categorical column subplots,Size, location, and price,Using gridplot,Changing size,Visualizing categorical data,High to low prices by region,Creating nested categories,Visualizing sales by period","Introduction to widgets,Adding a Div,Modifying glyph size with a widget,Slider widgets,Automotive stocks analysis,Tech stock performance over time,Select widgets,Travel analysis,Changing line plots with Select,Congratulations!","James Chapman,Amy Peterson","Bakery Sales,Stocks,NBA Player Statistics,Australia Property Market,Data Manipulation with pandas",,
249,Importing and Managing Financial Data in R,5,15,57,"16,788",4850,"If you've ever done anything with financial or economic time series, you know the data come in various shapes, sizes, and periodicities. Getting the data into R can be stressful and time-consuming, especially when you need to merge data from several different sources into one data set. This course will cover importing data from local files as well as from internet sources.","Welcome to the course!,Introducing getSymbols(),Data sources,Make getSymbols() return the data it retrieves,Introduction to Quandl,Introducing Quandl(),Return data type,Finding data from internet sources,Find stock ticker from Yahoo Finance,Download exchange rate data from Oanda,Find and import Unemployment Rate data from FRED","Setting default arguments for getSymbols(),Set a default data source,Set default arguments for a getSymbols source,Setting per-instrument default arguments,Set default data source for one symbol,Save and load symbol lookup table,How *not* to specify the getSymbols() source,Handling instrument symbols that clash or are not valid R names,Access the object using get() or backticks,Create valid name for one instrument,Create valid names for multiple instruments","Importing text files,Import well-formatted daily OHLC data,Import text files in other formats,Handle date and time in separate columns,Read text file containing multiple instruments,Checking for weirdness,Handle missing values,Visualize imported data,Cross reference sources,Adjusting for corporate actions,Adjust for stock splits and dividends,Download split and dividend data,Adjust univariate data for splits and dividends,When to adjust data,Congratulations!","Extracting columns from financial time series,Extract one column from one instrument,Extract multiple columns from one instrument,Use getPrice to extract other columns,Importing and transforming multiple instruments,Use Quandl to download quarterly returns data,Combine many instruments into one object,Extract the Close column from many instruments","Davis Vaughan,Lore Dirick","Finance Fundamentals,Quantitative Analyst,Amazon CSV file,DC data,UNE CSV file,two_symbols CSV file,Manipulating Time Series Data with xts and zoo in R","Making irregular data regular,Create a zero-width and regular xts object,Use merge to make an irregular index regular,Aggregating to lower frequency,Aggregate daily data and merge with monthly data,Align series to first and last day of month,Aggregate to weekly, ending on Wednesdays,Aggregating and combining intraday data,Combine data that have timezones,Make irregular intra-day data regular,Fill missing values by trading day,Aggregate irregular intra-day data",
250,Financial Trading in R,5,20,65,"20,247",5050,"This course will cover the basics on financial trading and will give you an overview of how to use quantstrat to build signal-based trading strategies in R. It will teach you how to set up a quantstrat strategy, apply transformations of market data called indicators, create signals based on the interactions of those indicators, and even simulate orders. Lastly, it will explain how to analyze your results both from statistical and visual perspectives.","Why do people trade?,Identifying types of trading philosophies - I,Identifying types of trading philosophies - II,Identifying types of trading philosophies - III,Pitfalls of various trading systems,How to prevent overfitting,Getting financial data,Plotting financial data,Adding indicators to financial data,Adding a moving average to financial data","Introduction to indicators,The SMA and RSI functions,Visualize an indicator and guess its purpose - I,Visualize an indicator and guess its purpose - II,Indicator mechanics,Implementing an indicator - I,Implementing an indicator - II,Implementing an indicator - III,Indicator structure review,Code your own indicator - I,Code your own indicator - II,Apply your own indicator","Introduction to rules,Using add.rule() to implement an exit rule,Specifying sigcol in add.rule(),Specifying sigval in add.rule(),More rule mechanics,Specifying orderqty in add.rule(),Specifying ordertype in add.rule(),Specifying orderside in add.rule(),More rule mechanics II,Specifying replace in add.rule(),Specifying prefer in add.rule(),Using add.rule() to implement an entry rule,Order sizing functions,Implementing a rule with an order sizing function","Setting up a strategy I,Understanding initialization settings - I,Understanding initialization settings - II,Setting up a strategy II,Understanding initialization settings - III,Understanding initialization settings - IV",Lore Dirick,"Applied Finance,Quantitative Analyst,SPY data from 2000 through 2016,Intermediate R for Finance","Introduction to signals,Signal or not? - I,Signal or not? - II,sigComparison and sigCrossover,Using sigComparison,Using sigCrossover,sigThreshold,Using sigThreshold - I,Using sigThreshold() - II,sigFormula,Using sigFormula(),Combining signals - I,Combining signals - II","Analyzing your strategy,Running your strategy,Profit factor,Percent positive,Visualizing your strategy,Using chart.Posn(),Adding an indicator to a chart.Posn() chart,Additional analytics,Cash Sharpe ratio,Returns Sharpe ratio in quantstrat"
251,Time Series Analysis in R,4,16,58,"49,866",4600,"Many phenomena in our day-to-day lives, such as the movement of stock prices, are measured in intervals over a period of time. Time series analysis methods are extremely useful for analyzing these special data types. In this course, you will be introduced to some core time series analysis concepts and techniques.","Welcome to the course!,Exploring raw time series,Basic time series plots,What does the time index tell us?,Sampling frequency,Identifying the sampling frequency,When is the sampling frequency exact?,Missing values,Basic time series objects,Creating a time series object with ts(),Testing whether an object is a time series,Plotting a time series object","Scatterplots,Asset prices vs. asset returns,Characteristics of financial time series,Plotting pairs of data,Covariance and correlation,Calculating sample covariances and correlations,Guess the correlation coefficient,Autocorrelation,Calculating autocorrelations,The autocorrelation function,Visualizing the autocorrelation function","The simple moving average model,Simulate the simple moving average model,Estimate the autocorrelation function (ACF) for a moving average,MA model estimation and forecasting,Estimate the simple moving average model,Simple forecasts from an estimated MA model,Compare AR and MA models,AR vs MA models,Name that model by time series plot,Name that model by ACF plot,Congratulations!","Trend spotting!,Random or not random?,Name that trend,Removing trends in variability via the logarithmic transformation,Removing trends in level by differencing,Removing seasonal trends with seasonal differencing,The white noise (WN) model,Simulate the white noise model,Estimate the white noise model,The random walk (RW) model,Simulate the random walk model,Simulate the random walk model with a drift,Estimate the random walk model,Stationary processes,Stationary or not?,Are the white noise model or the random walk model stationary?","Lore Dirick,Matt Isaacs","Quantitative Analyst,Time Series,Intermediate R","The autoregressive model,Simulate the autoregressive model,Estimate the autocorrelation function (ACF) for an autoregression,Persistence and anti-persistence,Compare the random walk (RW) and autoregressive (AR) models,AR model estimation and forecasting,Estimate the autoregressive (AR) model,Simple forecasts from an estimated AR model",
252,Manipulating Time Series Data with xts and zoo in R,4,15,55,"41,301",4500,"Time series are all around us, from server logs to high frequency financial data. Managing and manipulating ordered observations is central to all time series analysis. The xts and zoo packages provide a set of powerful tools to make this task fast and mistake free. In this course, you will learn everything from the basics of xts to advanced tips and tricks for working with time series data in R.","Introducing xts and zoo objects,What is an xts object?,More than a matrix,Your first xts object,Deconstructing xts,Time based indices,Importing, exporting and converting time series,Converting xts objects,Importing data,Exporting xts objects","Merging time series,Combining xts by column with merge,Combining xts by row with rbind,What types of data can be combined using merge?,Handling missingness,Fill missing values using last or previous observation,NA interpolation using na.approx(),Lags and differences,Combine a leading and lagging time series,Calculate a difference of a series using diff(),What is the key difference in lag between xts and zoo","Index, attributes, and time zones,Time via index(),Class attributes - tclass, tzone, and tformat,Time Zones (and why you should care!),Periods, periodicity and timestamps,Determining periodicity,Find the number of periods in your data,Secret index tools,Modifying timestamps,Congratulations!","Introducing time based queries,The ISO-8601 standard,Querying for dates,Extracting recurring intraday intervals,Alternative extraction techniques,Row selection with time objects,Update and replace elements,Methods to find periods in your data,Find the first or last period of time,Combining first and last,Math operations using xts,Matrix arithmetic - add, subtract, multiply, and divide in time!,Math with non-overlapping indexes",Lore Dirick,"Finance Fundamentals,Quantitative Analyst,Time Series,Chicago summer temperature data,Daily USD/EUR exchange rate,Intermediate R for Finance","Apply functions by time,Find intervals by time in xts,Apply a function by time period(s),Using lapply() and split() to apply functions on intervals,Selection by endpoints vs. split-lapply-rbind,Converting periodicity,Convert univariate series to OHLC data,Convert a series to a lower frequency,Rolling functions,Calculate basic rolling value of series by month,Calculate the rolling standard deviation of a time series",
253,Network Analysis in the Tidyverse,4,12,47,"5,422",3950,"If you've ever wanted to understand more about social networks, information networks, or even the neural networks of our brains, then you need to know network science! It will demonstrate network analysis using several R packages, including dplyr, ggplot2, igraph, ggraph as well as visNetwork. You will take on the role of Interpol Analyst and investigate the terrorist network behind the Madrid train bombing in 2004. Following the course, you will be able to analyse any network with basic centrality and similarity measures and create beautiful and interactive network visualizations.","Network Science,Explore the dataset,Build and explore the network (part 1),Build and explore the network (part 2),Visualizing networks,Visualize the network (part 1),Visualize the network (part 2),Centrality measures,Find the most connected terrorists,Find the most strongly connected terrorists,More on centrality","Connection patterns,Visualizing connection patterns,The adjacency matrix (part 1),The adjacency matrix (part 2),Pearson correlation coefficient,Computing Pearson similarity,Negative and positive similarity,Explore correlation between degree and strength,Most similar and most dissimilar terrorists,Transforming the similarity matrix,Join similarity and nodes data frames,Find most similar and dissimilar pairs,Visualize similarity","Tie betweenness,Betweenness of ties,Find ties with high betweenness,Visualizing centrality measures,Visualize node centrality,Visualize tie centrality,Filter important ties,The strength of weak ties,How many weak ties are there?,Visualize the network highlighting weak ties,Visualize the sub-network of weak ties,More on betweenness","Hierarchical clustering,Cluster the similarity network,Cut the dendrogram,Analyze clusters,Visualize the clusters,Interactive visualizations,Basic visualization,Change the layout,Highlight nearest nodes and ties,Select nodes and groups of nodes,Congratulations!","Chester Ismay,Becca Robins","Network Analysis,Nodes of the network,Ties of the network,Introduction to the Tidyverse",,
254,Mixture Models in R,4,14,47,"4,174",3600,"Mixture modeling is a way of representing populations when we are interested in their heterogeneity. Mixture models use familiar probability distributions (e.g. Gaussian, Poisson, Binomial) to provide a convenient yet formal statistical framework for clustering and classification. Unlike standard clustering approaches, we can estimate the probability of belonging to a cluster and make inference about the sub-populations. For example, in the context of marketing, you may want to cluster different customer groups and find their respective probabilities of purchasing specific products to better target them with custom promotions. When applying natural language processing to a large set of documents, you may want to cluster documents into different topics and understand how important each topic is across each document. In this course, you will learn what Mixture Models are, how they are estimated, and when it is appropriate to apply them!","Introduction to model-based clustering,Clustering approaches,Explore gender data,Gaussian distribution,Sampling a Gaussian distribution,(not so good) Estimations of the mean and sd,Gaussian mixture models (GMM),Simulate a mixture of two Gaussian distributions,Plot histogram of Gaussian Mixture,Mixture of three Gaussian distributions","Univariate Gaussian Mixture Models,Number of clusters,Number of parameters,Univariate Gaussian Mixture Models with flexmix,Univariate case with flexmix,Extracting Parameters for Univariate Case,Visualizing Univariate Gaussian Mixture Model,Compare the results,Bivariate Gaussian Mixture Models,Cross-term from covariance matrix,Parameters in the bivariate case,Bivariate Gaussian Mixture Models with flexmix,Fit the model with cross-terms,Get the components,Create the ellipses,Visualize the clusters","Structure of mixture models,Which probability distribution?,Handwritten digits dataset,Parameters estimation,Estimation given the probabilities,Calculating the probabilities,EM algorithm,Expectation function,Maximization function,Apply the two steps,Plot the estimated clusters","Bernoulli Mixture Models,Binary images,How many values?,Bernoulli Mixture Models with flexmix,Handwritten digits with `flexmix`,Poisson Mixture Models,Discover the lambda,Sample from Poisson distribution,Poisson Mixture Models with flexmix,Crimes data with `flexmix`","David Campos,Chester Ismay,Victor Medina,Shon Inouye,Benjamin Feder","Chicago Crimes dataset,Digits dataset,Gender dataset,Intermediate R,Introduction to the Tidyverse,Foundations of Probability in R",,
255,Analyzing Survey Data in R,4,14,49,"8,682",3950,"You've taken a survey (or 1000) before, right? Have you ever wondered what goes into designing a survey and how survey responses are turned into actionable insights? Of course you have! In Analyzing Survey Data in R, you will work with surveys from A to Z, starting with common survey design structures, such as clustering and stratification, and will continue through to visualizing and analyzing survey results. You will model survey data from the National Health and Nutrition Examination Survey using R's survey and tidyverse packages. Following the course, you will be able to successfully interpret survey results and finally find the answers to life's burning questions!","What are survey weights?,Survey weights,Visualizing the weights,Specifying elements of the design in R,Designs in R,Stratified designs in R,Cluster designs in R,Comparing survey weights of different designs,Visualizing the impact of survey weights,NHANES weights,Tying it all together!","Summarizing quantitative data,Survey statistics,Estimating quantiles,Visualizing quantitative data,Bar plots of survey-weighted means,Output of svyby(),Bar plots with error,Survey-weighted histograms,Survey-weighted density plots,Inference for quantitative data,Survey-weighted t-test,Tying it all together!","Visualizing a categorical variable,Summarizing a categorical variable,Interpreting frequency tables,Graphing a categorical variable,Exploring two categorical variables,Creating contingency tables,Building segments bar graphs,Summarizing with svytotal(),Interpreting svymean(),Inference for categorical variables,Running a chi squared test,Tying it all together!","Visualization with scatter plots,Bubble plots,Survey-weighted scatter plots,Use of color in scatter plots,Visualizing trends,Line of best fit,Trend lines,Modeling survey data,Regression model,Regression inference,More complex modeling,Multiple linear regression,Tying it all together,Wrap-up","Chester Ismay,Eunkyung Park,Becca Robins","Statistician,Quarter 4 of the 2016 BLS Consumer Expenditure Survey,Introduction to the Tidyverse,Foundations of Inference",,
256,Introduction to Python for Finance,4,14,55,"47,041",4650,"The financial industry is increasingly adopting Python for general-purpose programming and quantitative analysis, ranging from understanding trading dynamics to risk management systems. This course focuses specifically on introducing Python for financial analysis. Using practical examples, you will learn the fundamentals of Python data structures such as lists and arrays and learn powerful ways to store and manipulate financial data to identify trends.","Welcome to Python for Finance!,Why might you use Python in finance?,Run code vs. submit answer,Comments and variables,Printing output,Finding the average revenue,Data types,Creating variables,Determining types,Booleans in Python,Combining data types","Arrays,Create an array,Elementwise operations on arrays,Subsetting elements from an array,2D arrays and functions,Creating a 2D array,Subsetting 2D arrays,Calculating array stats,Generating a sequence of numbers,Using arrays for analysis,Who's above average?,Who's in health care?","Introducing the dataset,Lists,Arrays and NumPy,A closer look at the sectors,Filtering arrays,Summarizing sector data,Plot P/E ratios,Visualizing trends,Histogram of P/E ratios,Identify the outlier,Name the outlier","Lists,Creating lists in Python,Indexing list items,Slicing multiple list elements,Nested lists,Stock up a nested list,Subset a nested list,List methods and functions,Exploring list methods and functions,Using list methods to add data,Finding stock with maximum price","Sumedh Panchadhar,Lore Dirick,Eunkyung Park","Finance Fundamentals,Stocks data (I),Stocks data (II),S&P 100 data","Visualization in Python,Importing matplotlib and pyplot,Adding axis labels and titles,Multiple lines on the same plot,Scatterplots,Histograms,What are applications of histograms in finance?,Is data normally distributed?,Comparing two histograms,Adding a legend",
257,Intermediate Functional Programming with purrr,4,17,49,"4,344",3850,"Have you ever been wondering what the purrr description (“A functional programming toolkit for R”) refers to? Then, you’ve come to the right place! This course will walk you through the functional programming part of purrr - in other words, you will learn how to take full advantage of the flexibility offered by the .f in map(.x, .f) to iterate other lists, vectors and data.frame with a robust, clean, and easy to maintain code. During this course, you will learn how to write your own mappers (or lambda functions), and how to use predicates and adverbs. Finally, this new knowledge will be applied to a use case, so that you’ll be able to see how you can use this newly acquired knowledge on a concrete example of a simple nested list, how to extract, keep or discard elements, how to compose functions to manipulate and parse results from this list, how to integrate purrr workflow inside other functions, how to avoid copy and pasting with purrr functional tools.","purrr basics - a refresher,Refreshing your purrr memory,Another purrr refresher,Introduction to mappers,Creating lambda functions,Lambda functions,Using mappers to clean up your data,Clean up your data with keep,Split up with keep() and discard(),Predicates,What is a predicate?,Exploring data with predicates","Why cleaner code?,How to write compose(),Back to the office,Building functions with compose() and negate(),Build a function,Count the NA,Prefilling functions,A content extractor,Another extractor,List columns,About list-columns,Create a list-column data.frame","Functional programming in R,Everything that happens is a function call,Identifying pure functions,Tools for functional programming in purrr,Safe iterations,Create a function,Using possibly(),A possibly() version of read_lines(),Everything in one call,Handling adverb results,Purrrfecting our function,Extracting status codes with GET()","Discovering the dataset,Playing with tweets, round 1,Identify profiles,Extracting information from the dataset,Counting favorites,Extracting mentions,Manipulating URLs,Analyzing URLs,Playing with URLs,Identifying influencers,Splitting the dataset,We have a winner!,Congratulations!","Chester Ismay,Becca Robins","Intermediate Tidyverse Toolbox,Foundations of Functional Programming with purrr",,
258,Bayesian Regression Modeling with rstanarm,4,15,45,"5,306",3400,"Bayesian estimation offers a flexible alternative to modeling techniques where the inferences depend on p-values. In this course, you’ll learn how to estimate linear regression models using Bayesian methods and the rstanarm package. You’ll be introduced to prior distributions, posterior predictive model checking, and model comparisons within the Bayesian framework. You’ll also learn how to use your estimated model to make predictions for new data.","Non-Bayesian Linear Regression,Exploring the data,Fitting a frequentist linear regression,Bayesian Linear Regression,Fitting a Bayesian linear regression,Convergence criteria,Assessing model convergence,Comparing frequentist and Bayesian methods,Difference between frequentists and Bayesians,Creating credible intervals","Using the R Squared statistic,Calculating Frequentist R-squared,R-squared for a Bayesian Model,Posterior predictive model checks,Predicted score distributions,Distributions for a single observation,Model fit with posterior predictive model checks,R-squared Posterior,Posterior Predictive Testing,Bayesian model comparisons,Calculating the LOO estimate,Comparing models","What's in a Bayesian Model?,Altering chains,Do I have enough iterations?,Prior distributions,Determine Prior Distributions,Calculate Adjusted Scales,Unadjusted Priors,User Specified Priors,Changing Priors,Specifying informative priors,Consequences of informative priors,Altering the estimation process,Altering the Estimation","Visualizing a Bayesian model,Plotting a Bayesian model,Plotting Model Uncertainty,Making predictions,Popularity for Observed Songs,Popularity for New Songs,Visualizing predictions,Format prediction posteriors,Visualize New Predictions,Conclusion","David Campos,Chester Ismay,Shon Inouye","Machine Learning Scientist,Spotify dataset,Bayesian Modeling with RJAGS,Introduction to Data Visualization with ggplot2,Intermediate Regression in R",,
259,Building Response Models in R,4,13,53,"2,321",4600,"Almost every company collects digital information as part of their marketing campaigns and uses it to improve their marketing tactics. Data scientists are often tasked with using this information to develop statistical models that enable marketing professionals to see if their actions are paying off. In this course, you will learn how to uncover patterns of marketing actions and customer reactions by building simple models of market response. In particular, you will learn how to quantify the impact of marketing variables, such as price and different promotional tactics, using aggregate sales and individual-level choice data.","Fundamentals of market response models,Retail sales,Understanding sales,Linear response models,A linear response model for sales,Making predictions,Predictive performance,Nonlinear response models,Linearizing nonlinear functions,What 's the value added?","Models for individual demand,Customer purchases,Summarizing the data,Competition,A linear probability model for beer demand,Logistic response models,A logistic model for beer demand,Bounded predictions,Average marginal effects,Effect plots,Probit response models,A probit model for beer demand,Logistic vs. probit,Model comparison","Model extension part 1: Dummy variables,Understanding dummy variables,The effect of display on sales,The effect of multiple dummies on sales,What about price?,Model extensions part 2: Dynamic variables,How to lag?,Adding lagged price effects,More lags,What's the value added?,How many extensions are needed?,Summarizing the model,Unnecessary predictors,Dropping predictors,Eliminating predictors","Model selection,Extending the logistic response model,Summarizing the model,The deviance principle,Eliminating predictors,Predictive performance,Classifications,Model confusion,ROC curves,Model validation,Subsetting,Model training,Out-of-sample testing,Wrapping it up","David Campos,Chester Ismay,Shon Inouye","Marketing Analytics,Beer sales dataset,Beer choice dataset,Introduction to Regression in R",,
260,Machine Learning for Finance in Python,4,15,59,"21,945",5150,"Time series data is all around us; some examples are the weather, human behavioral patterns as consumers and members of society, and financial data. In this course, you'll learn how to calculate technical indicators from historical stock data, and how to create features and targets out of the historical stock data. You'll understand how to prepare our features for linear models, xgboost models, and neural network models. We will then use linear models, decision trees, random forests, and neural networks to predict the future price of stocks in the US markets. You will also learn how to evaluate the performance of the various models we train in order to optimize them, so our predictions have enough accuracy to make a stock trading strategy profitable.","Machine learning for finance,Explore the data with some EDA,Correlations,Data transforms, features, and targets,Create moving average and RSI features,Create features and targets,Check the correlations,Linear modeling,Create train and test features,Fit a linear model,Evaluate our results","Scaling data and KNN Regression,Standardizing data,Optimize n_neighbors,Evaluate KNN performance,Neural Networks,Build and fit a simple neural net,Plot losses,Measure performance,Custom loss functions,Custom loss function,Fit neural net with custom loss function,Visualize the results,Overfitting and ensembling,Combatting overfitting with dropout,Ensembling models,See how the ensemble performed","Engineering more features,Feature engineering from volume,Create day-of-week features,Examine correlations of the new features,Decision trees,Fit a decision tree,Try different max depths,Check our results,Random forests,Fit a random forest,Tune random forest hyperparameters,Evaluate performance,Feature importances and gradient boosting,Random forest feature importances,A gradient boosting model,Gradient boosting feature importances","Modern portfolio theory (MPT); efficient frontiers,Join stock DataFrames and calculate returns,Calculate covariances for volatility,Calculate portfolios,Plot efficient frontier,Sharpe ratios; features and targets,Get best Sharpe ratios,Calculate EWMAs,Make features and targets,Plot efficient frontier with best Sharpe ratio,Machine learning for MPT,Make predictions with a random forest,Get predictions and first evaluation,Evaluate returns,Plot returns,Closing remarks and advice","David Campos,Chester Ismay,Shon Inouye","NASDAQ: AAPL,NASDAQ: AMD,QQQ ETF,SPY,LNG,SMLV,Supervised Learning with scikit-learn",,
261,Preprocessing for Machine Learning in Python,4,20,62,"29,637",4700,"This course covers the basics of how and when to perform data preprocessing. This essential step in any machine learning project is when you get your data ready for modeling. Between importing and cleaning your data and fitting your machine learning model is when preprocessing comes into play. You'll learn how to standardize your data so that it's in the right form for your model, create new features to best leverage the information in your dataset, and select the best features to improve your model fit. Finally, you'll have some practice preprocessing by getting a dataset on UFO sightings ready for modeling.","What is data preprocessing?,Missing data - columns,Missing data - rows,Working with data types,Exploring data types,Converting a column type,Class distribution,Class imbalance,Stratified sampling","Feature engineering,Feature engineering knowledge test,Identifying areas for feature engineering,Encoding categorical variables,Encoding categorical variables - binary,Encoding categorical variables - one-hot,Engineering numerical features,Engineering numerical features - taking an average,Engineering numerical features - datetime,Text classification,Engineering features from strings - extraction,Engineering features from strings - tf/idf,Text classification using tf/idf vectors","UFOs and preprocessing,Checking column types,Dropping missing data,Categorical variables and standardization,Extracting numbers from strings,Identifying features for standardization,Engineering new features,Encoding categorical variables,Features from dates,Text vectorization,Feature selection and modeling,Selecting the ideal dataset,Modeling the UFO dataset, part 1,Modeling the UFO dataset, part 2,Congratulations!","Standardizing Data,When to standardize,Modeling without normalizing,Log normalization,Checking the variance,Log normalization in Python,Scaling data for feature comparison,Scaling data - investigating columns,Scaling data - standardizing columns,Standardized data and modeling,KNN on non-scaled data,KNN on scaled data","Nick Solomon,Kara Woo","Machine Learning Scientist,Hiking data,Wine data,UFO sightings data,Volunteering data,Cleaning Data in Python,Supervised Learning with scikit-learn","Feature selection,When to use feature selection,Identifying areas for feature selection,Removing redundant features,Selecting relevant features,Checking for correlated features,Selecting features using text vectors,Exploring text vectors, part 1,Exploring text vectors, part 2,Training Naive Bayes with feature selection,Dimensionality reduction,Using PCA,Training a model with PCA",
262,Experimental Design in R,4,12,52,"11,927",4400,"Experimental design is a crucial part of data analysis in any field, whether you work in business, health or tech. If you want to use data to answer a question, you need to design an experiment! In this course you will learn about basic experimental design, including block and factorial designs, and commonly used statistical tests, such as the t-tests and ANOVAs. You will use built-in R data and real world datasets including the CDC NHANES survey, SAT Scores from NY Public Schools, and Lending Club Loan Data. Following the course, you will be able to design and analyze your own experiments!","Intro to experimental design,A basic experiment,Randomization,Replication,Blocking,Hypothesis testing,One sided vs. Two-sided tests,pwr package Help Docs exploration,Power & Sample Size Calculations","Intro to NHANES and sampling,NHANES dataset construction,NHANES EDA,NHANES Data Cleaning,Resampling NHANES data,Randomized Complete Block Designs (RCBD),Which is NOT a good blocking factor?,Drawing RCBDs with Agricolae,NHANES RCBD,RCBD Model Validation,Balanced Incomplete Block Designs (BIBD),Is a BIBD even possible?,Drawing BIBDs with agricolae,BIBD - cat's kidney function,NHANES BIBD","ANOVA, single and multiple factor experiments,Exploratory Data Analysis (EDA) Lending Club,How does loan purpose affect amount funded?,Which loan purpose mean is different?,Multiple Factor Experiments,Model validation,Pre-modeling EDA,Post-modeling validation plots + variance,Kruskal-Wallis rank sum test,A/B testing,Which post-A/B test test?,Sample size for A/B test,Basic A/B test,A/B tests vs. multivariable experiments","Latin squares,NYC SAT Scores EDA,Dealing with Missing Test Scores,Drawing Latin Squares with agricolae,Latin Square with NYC SAT Scores,Graeco-Latin squares,NYC SAT Scores Data Viz,Drawing Graeco-Latin Squares with agricolae,Graeco-Latin Square with NYC SAT Scores,Factorial experiments,NYC SAT Scores Factorial EDA,Factorial Experiment with NYC SAT Scores,Evaluating the NYC SAT Scores Factorial Model,What's next in experimental design","Richie Cotton,Becca Robins","Statistician,sample of Lending Club data,NHANES Body Measures,NHANES Demographics,NHANES final combined dataset,NHANES Medical Conditions,NYC SAT Scores,Introduction to the Tidyverse,Introduction to Statistics in R",,
263,Advanced Deep Learning with Keras,4,13,46,"24,075",3950,"This course shows you how to solve a variety of problems using the versatile Keras functional API. You will start with simple, multi-layer dense networks (also known as multi-layer perceptrons), and continue on to more complicated architectures. The course will cover how to build models with multiple inputs and a single output, as well as how to share weights between layers in a model. We will also cover advanced topics such as category embeddings and multiple-output networks. If you've ever wanted to train a network that does both classification and regression, then this course is for you!","Keras input and dense layers,Input layers,Dense layers,Output layers,Build and compile a model,Build a model,Compile a model,Visualize a model,Fit and evaluate a model,Fit the model to the tournament basketball data,Evaluate the model on a test set","Three-input models,Make an input layer for home vs. away,Make a model and compile it,Fit the model and evaluate,Summarizing and plotting models,Model summaries,Plotting models,Stacking models,Add the model predictions to the tournament data,Create an input layer with multiple columns,Fit the model,Evaluate the model","Category embeddings,Define team lookup,Define team model,Shared layers,Defining two inputs,Lookup both inputs in the same model,Merge layers,Output layer using shared layer,Model using two inputs and one output,Predict from your model,Fit the model to the regular season training data,Evaluate the model on the tournament test data","Two-output models,Simple two-output model,Fit a model with two outputs,Inspect the model (I),Evaluate the model,Single model for classification and regression,Classification and regression in one model,Compile and fit the model,Inspect the model (II),Evaluate on new data with two metrics,Wrap-up",Sumedh Panchadhar,"Deep Learning,Machine Learning Scientist,Basketball data,Basketball models,Introduction to Deep Learning in Python",,
264,Multivariate Probability Distributions in R,4,15,51,"6,798",4000,"When working with data that contains many variables, we are often interested in studying the relationship between these variables using multivariate statistics. In this course, you'll learn ways to analyze these datasets. You will also learn about common multivariate probability distributions, including the multivariate normal, the multivariate-t, and some multivariate skew distributions. You will then be introduced to techniques for representing high dimensional data in fewer dimensions, including principal component analysis (PCA) and multidimensional scaling (MDS).","Reading multivariate data,Reading multivariate data using read.table,Specifying datatypes for columns,Mean vector and variance-covariance matrix,Calculating the mean vector,Calculating the variance-covariance matrix,Calculating the correlation matrix,Plotting multivariate data,Pairs plot using base graphics and lattice,Plotting multivariate data using ggplot,3D plotting techniques","Other common Multivariate distributions,Generate samples from multivariate t-distribution,Identify the distribution,Density and cumulative density for multivariate-t,Density of multivariate t-distribution,Cumulative distributions and quantiles of t,Comparing normal and t probabilities,Multivariate skewed distributions,Drawing samples from skew distributions,Plotting and testing of skewed-densities,Examine skewness from contour plot,Parameter estimation for multivariate skew-normals","Multivariate normal distribution,Samples from multivariate normal distributions,Identify the distribution of a normal sample,Density of a multivariate normal distribution,Calculating the density of multivariate normal,Calculating dmvnorm over a grid,Cumulative Distribution and Inverse CDF,Using the pmvnorm function,Calculating probability contours using qmvnorm,Checking normality of multivariate data,Graphical tests for multivariate normality,Numerical tests for multivariate normality,Test multivariate normality by wine type","Principal Component Analysis,Number of PCs for the state.x77 dataset,Using the princomp function,Choosing the number of components,Calculating the proportion of variation explained,Choosing the number of PCs,Number of components explaining 95% variation,Number of PCs using scree plot,Interpreting PCA attributes,Loadings and scores for the PCs,Visualizing PCA using the factoextra library,Multi-dimensional scaling,Multidimensional scaling in two dimensions,Multidimensional scaling in three dimensions,Congratulations","Nick Solomon,Chester Ismay,Amy Peterson","Iris,Wine,Birthweight,Foundations of Probability in R",,
265,Categorical Data in the Tidyverse,4,13,44,"11,853",3600,"As a data scientist, you will often find yourself working with non-numerical data, such as job titles, survey responses, or demographic information. R has a special way of representing them, called factors, and this course will help you master working with them using the tidyverse package forcats. We’ll also work with other tidyverse packages, including ggplot2, dplyr, stringr, and tidyr and use real world datasets, such as the fivethirtyeight flight dataset and Kaggle’s State of Data Science and ML Survey. Following this course, you’ll be able to identify and manipulate factor variables, quickly and efficiently visualize your data, and effectively communicate your results. Get ready to categorize!","Introduction to qualitative variables,Recognizing factor variables,Qualitative variables in theory,Understanding your qualitative variables,Getting number of levels,Examining number of levels,Examining levels,Making better plots,Reordering a variable by its frequency,Ordering one variable by another","Examining common themed variables,Grouping and reshaping similar columns,Summarizing data,Creating an initial plot,Tricks of ggplot2,Editing plot text,Reordering graphs,Changing and creating variables with case_when(),case_when() with single variable,case_when() from multiple columns","Reordering factors,Changing the order of factor levels,Tricks of fct_relevel(),Renaming factor levels,Distinguishing between forcats functions,Renaming a few levels,When you have a typo,Collapsing factor levels,Manually collapsing levels,Lumping variables by proportion,Preserving the most common levels","Case study introduction,Changing characters to factors,Tidying data,Data preparation and regex,Cleaning up strings,Dichotomizing variables,Summarizing data,Recreating the plot,Creating an initial plot,Fixing labels,Flipping things around,Finalizing the chart,End of course recap","Chester Ismay,Becca Robins","Tidyverse Fundamentals,538 Flying Etiquette survey,Kaggle multiple choice responses,Working with Data in the Tidyverse",,
266,Choice Modeling for Marketing in R,4,17,54,"5,165",4100,"People make choices everyday. They choose products like orange juice or a car, decide who to vote for, and choose how to get to work. Marketers, retailers, product designers, political scientists, transportation planners, sociologists, and many others want to understand what drives these choices. Choice models predict what people will choose as a function of the features of the options available and can be used to make important product design decisions. This course will teach you how to organize choice data, estimate choice models in R and present findings. This course covers both analyses of observed real-world choices and the survey-based approach called conjoint analysis.","Why choice?,Choice data,Inspecting choice data,Finding the levels of a factor,Inspecting a choice observation,What did people choose?,Fitting and interpreting a choice model,Fitting a choice model,Interpreting parameters,Using choice models to make decisions,Predicting choice shares,Plotting choice shares","Choice models - under the hood,Create mlogit.data object,Fit a choice model,Remove the intercept,Interpreting choice model parameters,Which chocolate brand is most preferred?,Computing willingness-to-pay,Price as a factor,Likelihood-ratio test,Intercepts and interactions,Interaction between brand and type,Interaction between price and trial,Predicting shares,Predicting shares for the racer segment,Predict shares for chocolate bars,Plot shares for chocolate bars","Assembling choice data,How many choices do we have?,Attributes and levels,Inspect a single choice,Converting from wide to long,Convert from wide to long,Sort the long data,Change the Selection variable,Choice data in two files,Inspect a choice in two files,Merging two files,Visualizing choice data,What types of chocolate do people choose?,Do people choose lower prices?,Designing a conjoint survey","What is a hierarchical choice model?,How many people answered the chocolate suvey?,Chocolate model with random price coefficient,Heterogeneity in preferences for other features,Setting effects codes,Chocolate model with all coefficients random,Interpreting hierarchical model parameters,How do people value white chocolate?,Predicting shares with hierarchical models,Predicting shares for chocolates,Goodbye and good luck!","David Campos,Chester Ismay,Shon Inouye","Marketing Analytics,Sportscar choice dataset,Chocolate choice dataset,Intermediate Regression in R",,
267,Introduction to Predictive Analytics in Python,4,14,52,"13,743",4100,"In this course, you will learn how to build a logistic regression model with meaningful variables. You will also learn how to use this model to make predictions and how to present it and its performance to business stakeholders.","Introduction and base table structure,Structure of the base table,Exploring the base table,Exploring the predictive variables,Logistic regression,Interpretation of coefficients,Building a logistic regression model,Showing the coefficients and intercept,Using the logistic regression model,Making predictions,Donor that is most likely to donate","The cumulative gains curve,Interpreting the cumulative gains curve,Constructing the cumulative gains curve,A random model,The lift curve,Interpreting the lift curve,Constructing the lift curve,A perfect model,Guiding business to better decisions,Targeting using cumulative gains curve,Business case using lift curve,Business case using cumulative gains curve","Motivation for variable selection,Which model is best?,Calculating AUC,Using different sets of variables,Forward stepwise variable selection,Selecting the next best variable,Finding the order of variables,Correlated variables,Deciding on the number of variables,Partitioning,Evaluating a model on test and train,Building the AUC curves,Deciding the cut-off","Predictor insight graphs,Interpretation of predictor insight graphs,Retrieving information from the predictor insight table,Discretization of continuous variables,Discretization of a certain variable,Discretizing all variables,Making clean cuts,Preparing the predictor insight graph table,Calculating average incidences,Constructing the predictor insight graph table,Grouping all predictor insight graph tables,Plotting the predictor insight graph,Plotting the incidences,Plotting the group sizes,Putting it all together,Summary","Lore Dirick,Nick Solomon,Hadrien Lacroix","Example basetable,Intermediate Python",,
268,Factor Analysis in R,4,13,45,"7,779",3600,"The world is full of unobservable variables that can't be directly measured. You might be interested in a construct such as math ability, personality traits, or workplace climate. When investigating constructs like these, it's critically important to have a model that matches your theories and data. This course will help you understand dimensionality and show you how to conduct exploratory and confirmatory factor analyses. With these statistical techniques in your toolkit, you'll be able to develop, refine, and share your measures. These analyses are foundational for diverse fields including psychology, education, political science, economics, and linguistics.","Introduction to Exploratory Factor Analysis (EFA),Starting out with a unidimensional EFA,Viewing and visualizing the factor loadings,Interpreting individuals' factor scores,Overview of the measure development process,Descriptive statistics of your dataset,Splitting your dataset,Comparing the halves of your dataset,Measure features: correlations and reliability,Viewing and testing correlations,Internal reliability,When to use EFA","Setting up a CFA,Creating CFA syntax from EFA results,Creating CFA syntax from theory,Understanding the sem() syntax,Components of sem() syntax,Run a CFA and interpret loadings,Examine item loadings,Investigating model fit,Absolute fit statistics,Relative fit statistics","Determining dimensionality,Splitting the BFI dataset,Calculating eigenvalues,Creating a scree plot,Interpreting the scree plot,Understanding multidimensional data,Conducting a multidimensional EFA,Interpreting the results,Investigating model fit,Interpret absolute model fit statistics,Selecting the best model","EFA vs. CFA revisited,Differences in estimated factor loadings,Plotting differences in persons' factor scores,Adding loadings to improve fit,Add loadings to improve fit,Compare original model to model with added loadings,Evaluate added loadings with relative fit stats,Improving fit by removing loadings,Remove loadings to improve fit,Compare original model to model with deleted loadings,Evaluate deleted loadings with relative fit stats,Wrap-Up Video","Chester Ismay,Becca Robins","Statistician,Unsupervised Machine Learning,Generic Conspiracist Beliefs Scale (GCBS) dataset,Intermediate R,Foundations of Inference",,
269,Differential Expression Analysis with limma in R,4,15,47,"5,143",3900,"Functional genomic technologies like microarrays, sequencing, and mass spectrometry enable scientists to gather unbiased measurements of gene expression levels on a genome-wide scale. Whether you are generating your own data or want to explore the large number of publicly available data sets, you will first need to learn how to analyze these types of experiments. In this course, you will be taught how to use the versatile R/Bioconductor package limma to perform a differential expression analysis on the most common experimental designs. Furthermore, you will learn how to pre-process the data, identify and correct for batch effects, visually assess the results, and perform enrichment testing. After completing this course, you will have general analysis strategies for gaining insight from any functional genomics study.","Differential expression analysis,Applications of differential expression analysis,Differential expression data,Create a boxplot,The ExpressionSet class,Create an ExpressionSet object,Create a boxplot with an ExpressionSet object,The limma package,Specify a linear model to compare 2 groups,Test for differential expression between 2 groups","Normalizing and filtering,Normalize,Filter genes,Accounting for technical batch effects,Visualize batch effects,Remove batch effects,Visualizing the results,Histogram of p-values,Volcano plot,Enrichment testing,KEGG pathways,Gene ontology categories","Flexible linear models,Design matrix for group-means model,Contrasts matrix for group-means,Test for differential expression for group-means,Studies with more than two groups,Design matrix for 3 groups,Contrasts matrix for 3 groups,Test for differential expression for 3 groups,Factorial experimental design,Design matrix for 2x2 factorial,Contrasts matrix for 2x2 factorial,Test for differential expression for 2x2 factorial","Pre-process the data,Pre-process features,Boxplot of Top2b,Check sources of variation,Model the data,Design matrix,Contrasts matrix,Test for differential expression,Inspect the results,Histogram of p-values,Volcano plot,Pathway enrichment,Conclusion","David Campos,Richie Cotton,Shon Inouye","Analyzing Genomic Data,Doxorubicin dataset,Leukemia dataset,Hypoxia dataset,Introduction to Statistics in R",,
270,Structural Equation Modeling with lavaan in R,4,14,45,"6,857",3750,"When working with data, we often want to create models to predict future events, but we also want an even deeper understanding of how our data is connected or structured. In this course, you will explore the connectedness of data using using structural equation modeling (SEM) with the R programming language using the lavaan package. SEM will introduce you to latent and manifest variables and how to create measurement models, assess measurement model accuracy, and fix poor fitting models. During the course, you will explore classic SEM datasets, such as the Holzinger and Swineford (1939) and Bollen (1989) datasets. You will also work through a multi-factor model case study using the Wechsler Adult Intelligence Scale. Following this course, you will be able to dive into your data and gain a much deeper understanding of how it all fits together.","Model Specification,Build Text Speed Model,Build Political Democracy Model,Model Analysis,Analyze Text Speed Model,Summarize Political Democracy,Model Assessment,Examine Standardized Loadings,Explore Fit Indices,Examine Political Democracy","Heywood Cases on the Latent Variable,Analyze a Latent Heywood Case,Fix the Latent Heywood Model,Heywood Cases on the Manifest Variables,Analyze a Manifest Heywood Case,Fix the Manifest Heywood Model,Create Diagrams with semPaths(),Basic SEM Diagram,Edit the Layout,Edit the Labels","Multifactor Specification,Create a Zero df Model,Fix the Zero df Model,Build a Multi-Factor Model,Summarize the Multi-Factor Model,Model Structure,Three-Factor Model with Zero Correlation,Create a Direct Path,Modification Indices,Check Model Variance,Examine Modification Indices,Model Comparison,Compare Two Models,Select Specific Fit Indices","Model the WAIS-III IQ Scale,Create a Four-Factor Model,Update the Model,Diagram the Final Model,Update the WAIS-III Model,Add Paths to Improve Fit,Compare Models,A Hierarchical Model of IQ,Create a Hierarchical Model,Diagram the Hierarchical Model,Course Wrap Up","Chester Ismay,Becca Robins","WAIS-III IQ Data for Hierarchical Model,Latent Variable Heywood Case Data,Negative Variance Heywood Case Data,Intermediate Regression in R",,
271,Bayesian Modeling with RJAGS,4,15,58,"6,261",4650,"The Bayesian approach to statistics and machine learning is logical, flexible, and intuitive. In this course, you will engineer and analyze a family of foundational, generalizable Bayesian models. These range in scope from fundamental one-parameter models to intermediate multivariate & generalized linear regression models. The popularity of such Bayesian models has grown along with the availability of computing resources required for their implementation. You will utilize one of these resources - the rjags package in R. Combining the power of R with the JAGS (Just Another Gibbs Sampler) engine, rjags provides a framework for Bayesian modeling, inference, and prediction.","The prior model,Simulating a Beta prior,Comparing & contrasting Beta priors,Which prior?,Data & the likelihood,Simulating the dependence of X on p,Approximating the likelihood function,Interpreting the likelihood function,The posterior model,Define, compile, and simulate,Updating the posterior,Influence of the prior & data on the posterior","A simple Bayesian regression model,Regression priors,Visualizing the regression priors,Weight & height data,Bayesian regression in RJAGS,Define, compile, & simulate the regression model,Regression Markov chains,Posterior estimation & inference,Posterior point estimates,Posterior credible intervals,Posterior probabilities,Posterior prediction,Inference for the posterior trend,Calculating posterior predictions,Posterior predictive distribution","The Normal-Normal model,Normal-Normal priors,Sleep study data,Insights from the prior and data,Simulating the Normal-Normal in RJAGS,Define, compile, & simulate the Normal-Normal,Posterior insights on sleep deprivation,Markov chains,Storing Markov chains,Markov chain trace plots,Markov chain density plots,Markov chain diagnostics & reproducibility,Multiple chains,Naive standard errors,Reproducibility","Bayesian regression with a categorical predictor,RailTrail sample data,RJAGS simulation with categorical variables,Interpreting categorical coefficients,Inference for volume by weekday,Multivariate Bayesian regression,Re-examining the RailTrail data,RJAGS simulation for multivariate regression,Interpreting multivariate regression parameters,Posterior inference for multivariate regression,Bayesian Poisson regression,RJAGS simulation for Poisson regression,Plotting the Poisson regression model,Inference for the Poisson rate parameter,Poisson posterior prediction,Conclusion","Nick Solomon,Chester Ismay,Eunkyung Park","Sleep study data,Fundamentals of Bayesian Data Analysis in R,Introduction to the Tidyverse",,
272,Nonlinear Modeling in R with GAMs,4,15,50,"6,059",4050,"Generalized Additive Models are a powerful tool for both prediction and inference. More flexible than linear models, and more understandable than black-box methods, GAMs model relationships in data as nonlinear functions that are highly adaptable to different types of data and data science problems. In this course, you'll learn how GAMs work and how to construct them with the popular mgcv package. You'll learn how to interpret, explain and visualize your model results, and how to diagnose and fix model problems. You'll work with data sets that will show you how to apply GAMs to a variety of situations: automobile performance data for building mixed linear and nonlinear models, soil pollution data for building geospatial models, and consumer purchasing data for classification and prediction. By the end of this course, you'll have a toolbox for solving many data science problems.","Introduction,Motorcycle crash data: linear approach,Motorcycle crash data: non-linear approach,Parts of non-linear function,Basis functions and smoothing,Setting complexity of the motorcycle model,Using smoothing parameters to avoid overfitting,Complexity and smoothing together,Multivariate GAMs,Multivariate GAMs of auto performance,Adding categorical to the auto performance model,Category-level smooths for different auto types","Two-dimensional smooths and spatial data,Modeling soil pollution in the Netherlands,Adding more variables to predict soil pollution,Plotting and interpreting GAM interactions,Plotting the model surface,Customizing 3D plots,Extrapolation in surface plots,Visualizing categorical-continuous interactions,Soil pollution in different land uses,Plotting pollution in different land uses,Interactions with different scales: Tensors,Pollution models with multi-scale interactions,Teasing apart multi-scale interactions","Interpreting GAM outputs,Significance and linearity (I),Significance and linearity (II),Visualizing GAMs,Plotting the motorcycle crash model and data,Plotting multiple auto performance variables,Visualizing auto performance uncertainty,Model checking with gam.check(),Reading model diagnostics,Fixing problems with model diagnostics,Checking concurvity,Examining overall concurvity in auto data,Examining concurvity between auto variables","Types of model outcomes,Classifying purchasing behavior,Purchase behavior with multiple smooths,Visualizing logistic GAMs,Visualizing influences on purchase probability,Interpreting purchase effect plots (I),Interpreting purchase effect plots (II),Interpreting purchase effect plots (III),Making predictions,Predicting purchase behavior and uncertainty,Explaining individual behaviors,Doing more with GAMs","Sumedh Panchadhar,Rasmus Bååth,Chester Ismay,Eunkyung Park","Insurance (csale) data,Introduction to Regression in R",,
273,Data Privacy and Anonymization in R,4,13,45,"3,696",3650,"With social media and big data everywhere, data privacy has been a growing, public concern. Recognizing this issue, entities such as Google, Apple, and the US Census Bureau are promoting better privacy techniques; specifically differential privacy, a mathematical condition that quantifies privacy risk. In this course, you will learn to code basic data privacy methods and a differentially private algorithm based on various differentially private properties. With these tools in hand, you will learn how to generate a basic synthetic (fake) data set with the differential privacy guarantee for public data release.","Intro to anonymization (I),Removing Names,Rounding Salaries,Intro to anonymization (II),Generalization,Bottom Coding,summarize_at(),count(),Data synthesis,Binomial Distribution,Normal Distribution","Sequential composition,Value of Epsilon per the Sequential Composition,Sequential Composition and Laplace mechanism,Parallel composition,Value of Epsilon per the Parallel Composition,Parallel Composition and Laplace mechanism,Post-processing,Setting Epsilon and Global Sensitivity,Post-processing and Laplace mechanism,Impossible and inconsistent answers,Inconsistent answers,Normalizing noise","Differential privacy,Zero Privacy Budget,Changing the Privacy Budget,Less Privacy Protection,Less Information Leakage,Global sensitivity,Sensitivity of Counting and Proportion Queries,Sensitivity of Mean and Variance Queries,Laplace mechanism,Counting Query,Proportion Query,Mean and Variance Queries","Laplace sanitizer,Prepping for the Laplace sanitizer,Applying the Laplace sanitizer,Normalizing Noise and Generating Synthetic Data,Differential privacy (DP) parametric approaches,Prepping for the DP Binomial Distribution,Generating Binomial Synthetic Data,Prepping for the DP Normal Distribution,Generating Normal Synthetic Data,Wrap-up","Sumedh Panchadhar,Chester Ismay","Data sets,Intermediate R,Foundations of Probability in R,Introduction to the Tidyverse",,
274,Marketing Analytics: Predicting Customer Churn in Python,4,13,45,"12,585",3550,"Churn is when a customer stops doing business or ends a relationship with a company. It’s a common problem across a variety of industries, from telecommunications to cable TV to SaaS, and a company that can predict churn can take proactive action to retain valuable customers and get ahead of the competition. This course will provide you a roadmap to create your own customer churn models. You’ll learn how to explore and visualize your data, prepare it for modeling, make predictions using machine learning, and communicate important, actionable insights to stakeholders. By the end of the course, you’ll become comfortable using the pandas library for data analysis and the scikit-learn library for machine learning.","Welcome to the course,Defining customer churn,Exploring customer churn,Grouping and summarizing data,Summary statistics for both classes,Churn by State,Exploring your data using visualizations,Exploring feature distributions,Customer service calls and churn","Making Predictions,Predicting whether a new customer will churn,Training another scikit-learn model,Evaluating Model Performance,Creating training and test sets,Check each sets length,Computing accuracy,Model Metrics,Confusion matrix,Varying training set size,Computing precision and recall,Other model metrics,ROC curve,Area under the curve,Precision-recall curve,F1 score","Data preprocessing,Identifying features to convert,Encoding binary features,One hot encoding,Feature scaling,Feature selection and engineering,Dropping unnecessary features,Engineering a new column","Tuning your model,Tuning the number of features,Tuning other hyperparameters,Randomized search,Feature importances,Visualizing feature importances,Improving the plot,Interpreting feature importances,Adding new features,Does model performance improve?,Computing other metrics,Final thoughts","Lore Dirick,Yashas Roy","Marketing Analytics,Telco Churn Dataset,Data Manipulation with pandas",,
275,Human Resources Analytics: Predicting Employee Churn in R,4,14,50,"3,695",4000,"Organizational growth largely depends on staff retention. Losing employees frequently impacts the morale of the organization and hiring new employees is more expensive than retaining existing ones. Good news is that organizations can increase employee retention using data-driven intervention strategies. This course focuses on data acquisition from multiple HR sources, exploring and deriving new features, building and validating a logistic regression model, and finally, show how to calculate ROI for a potential retention strategy.","What is turnover?,Objectives of employee turnover prediction,Importing headcount and turnover data,Exploring the data,What proportion of employees have left?,Which levels have high turnover rate?,Is turnover rate different across locations?,HR data architecture,Filtering the dataset,Combining HR datasets (I),Combining HR datasets (II),Master data overview","Data splitting,Split the data,Corroborate the splits,Introduction to logistic regression,Build your first logistic regression model,Build a multiple logistic regression model,Interpreting significance levels,Multicollinearity,Detecting multicollinearity,Dealing with multicollinearity,Building your final model,Building final logistic regression model,Understanding the model predictions,Interpret the results","Feature engineering,Derive age difference,Derive job hop index,Derive employee tenure,Compensation,Exploring compensation,Pay Gap,Deriving Compa-ratio,Deriving Compa-level,Information value,Calculating Information Value,Which variables are important?","Validating logistic regression results,Create a confusion matrix,Accuracy of your model,Designing retention strategy,Calculate turnover risk probability,Creating turnover risk buckets,What would you do?,Return on investment,Create salary hike range,Calculate turnover rate across salary hike range,Calculate ROI,Wrap-up","Sumedh Panchadhar,Sascha Mayr","Employee data,Human Resources Analytics: Exploring Employee Data in R",,
276,Introduction to Bioconductor in R,4,14,54,"9,397",4050,"Much of the biological research, from medicine to biotech, is moving toward sequence analysis. We are now generating targeted and whole genome big data, which needs to be analyzed to answer biological questions. To help you get started, you will be introduced to The Bioconductor project. Bioconductor is and builds the infrastructure to share software tools (packages), workflows and datasets for the analysis and comprehension of genomic data. Bioconductor is a great platform accessible to you, and it is a community developed open software resource. By the end of this course, you will be able to use essential Bioconductor packages and get a grasp of its infrastructure and some built-in datasets. Using BSgenome, Biostrings, IRanges, GenomicRanges, TxDB, ShortRead and Rqc with real datasets from different species is going to be an exceptional experience!","Introduction to the Bioconductor Project,Bioconductor version,BiocLite to install packages,The role of S4 in Bioconductor,S4 class definition,Interaction with classes,Introducing biology of genomic datasets,Discovering the yeast genome,Partitioning the yeast genome,Available genomes","IRanges and Genomic Structures,IRanges,Constructing IRanges,Interacting with IRanges,Gene of interest,From tabular data to Genomic Ranges,GenomicRanges accessors,ABCD1 mutation,Human genome chromosome X,Manipulating collections of GRanges,A sequence window,Is it there?,More about ABCD1,How many transcripts?,From GRangesList object into a GRanges object","Introduction to Biostrings,Exploring the Zika virus sequence,Biostrings containers,Manipulating Biostrings,Sequence handling,From a set to a single sequence,Subsetting a set,Common sequence manipulation functions,Why are we interested in patterns?,Searching for a pattern,Finding Palindromes,Finding a conserved region within six frames,Looking for a match","Sequence files,Why fastq?,Reading in files,Exploring a fastq file,Extract a sample from a fastq file,Sequence quality,Exploring sequence quality,Base quality plot,Try your own nucleotide frequency plot,Match and filter,Filtering reads on the go!,Removing duplicates,More filtering!,Multiple assessment,Plotting cycle average quality,Introduction to Bioconductor","David Campos,Richie Cotton,Shon Inouye","Analyzing Genomic Data,Zika Genomic DNA dataset,A. Thaliana Short Reads with Quality dataset,Human Gene & Transcript ID dataset,Yeast Genome dataset,Introduction to R,Introduction to the Tidyverse",,
277,Machine Learning with Tree-Based Models in Python,5,15,57,"59,352",4650,"Decision trees are supervised learning models used for problems involving classification and regression. Tree models present a high flexibility that comes at a price: on one hand, trees are able to capture complex non-linear relationships; on the other hand, they are prone to memorizing the noise present in a dataset. By aggregating the predictions of trees that are trained differently, ensemble methods take advantage of the flexibility of trees while reducing their tendency to memorize noise. Ensemble methods are used across a variety of fields and have a proven track record of winning many machine learning competitions. In this course, you'll learn how to use Python to train decision trees and tree-based models with the user-friendly scikit-learn machine learning library. You'll understand the advantages and shortcomings of trees and demonstrate how ensembling can alleviate these shortcomings, all while practicing on real-world datasets. Finally, you'll also understand how to tune the most influential hyperparameters in order to get the most out of your models.","Decision tree for classification,Train your first classification tree,Evaluate the classification tree,Logistic regression vs classification tree,Classification tree Learning,Growing a classification tree,Using entropy as a criterion,Entropy vs Gini index,Decision tree for regression,Train your first regression tree,Evaluate the regression tree,Linear regression vs regression tree","Bagging,Define the bagging classifier,Evaluate Bagging performance,Out of Bag Evaluation,Prepare the ground,OOB Score vs Test Set Score,Random Forests (RF),Train an RF regressor,Evaluate the RF regressor,Visualizing features importances","Tuning a CART's Hyperparameters,Tree hyperparameters,Set the tree's hyperparameter grid,Search for the optimal tree,Evaluate the optimal tree,Tuning a RF's Hyperparameters,Random forests hyperparameters,Set the hyperparameter grid of RF,Search for the optimal forest,Evaluate the optimal forest,Congratulations!","Generalization Error,Complexity, bias and variance,Overfitting and underfitting,Diagnose bias and variance problems,Instantiate the model,Evaluate the 10-fold CV error,Evaluate the training error,High bias or high variance?,Ensemble Learning,Define the ensemble,Evaluate individual classifiers,Better performance with a Voting Classifier","Sumedh Panchadhar,Kara Woo,Eunkyung Park","Data Scientist,Machine Learning Scientist,Auto-mpg,Bike Sharing Demand,Wisconsin Breast Cancer,Indian Liver Patient,Supervised Learning with scikit-learn","Adaboost,Define the AdaBoost classifier,Train the AdaBoost classifier,Evaluate the AdaBoost classifier,Gradient Boosting (GB),Define the GB regressor,Train the GB regressor,Evaluate the GB regressor,Stochastic Gradient Boosting (SGB),Regression with SGB,Train the SGB regressor,Evaluate the SGB regressor",
278,Feature Engineering with PySpark,4,16,60,"10,011",5000,"The real world is messy and your job is to make sense of it. Toy datasets like MTCars and Iris are the result of careful curation and cleaning, even so the data needs to be transformed for it to be useful for powerful machine learning algorithms to extract meaning, forecast, classify or cluster. This course will cover the gritty details that data scientists are spending 70-80% of their time on; data wrangling and feature engineering. With size of datasets now becoming ever larger, let's use PySpark to cut this Big Data problem down to size!","Where to Begin,Where to begin?,Check Version,Load in the data,Defining A Problem,What are we predicting?,Verifying Data Load,Verifying DataTypes,Visually Inspecting Data / EDA,Using Corr(),Using Visualizations: distplot,Using Visualizations: lmplot","Feature Generation,Differences,Ratios,Deeper Features,Time Features,Time Components,Joining On Time Components,Date Math,Extracting Features,Extracting Text to New Features,Splitting & Exploding,Pivot & Join,Binarizing, Bucketing  & Encoding,Binarizing Day of Week,Bucketing,One Hot Encoding","Dropping data,Dropping a list of columns,Using text filters to remove records,Filtering numeric fields conditionally,Adjusting Data,Custom Percentage Scaling,Scaling your scalers,Correcting Right Skew Data,Working with Missing Data,Visualizing Missing Data,Imputing Missing Data,Calculate Missing Percents,Getting More Data,A Dangerous Join,Spark SQL Join,Checking for Bad Joins","Choosing the Algorithm,Which MLlib Module?,Creating Time Splits,Adjusting Time Features,Feature Engineering Assumptions for RFR,Feature Engineering For Random Forests,Dropping Columns with Low Observations,Naively Handling Missing and Categorical Values,Building a Model,Building a Regression Model,Evaluating & Comparing Algorithms,Understanding Metrics,Interpreting, Saving & Loading,Interpreting Results,Saving & Loading Models,Final Thoughts","Nick Solomon,Adrián Soto","Big Data with PySpark,2017 St Paul MN Real Estate Dataset,Introduction to PySpark,Supervised Learning with scikit-learn",,
279,Parallel Programming in R,4,15,53,"9,710",4250,"With an increasing amount of data and more complex algorithms available to scientists and practitioners today, parallel processing is almost always a must, and in fact, is expected in packages implementing time-consuming methods. This course introduces you to concepts and tools available in R for parallel computing and provides solutions to a few important non-trivial issues in parallel processing like reproducibility, generating random numbers and load balancing.","Partitioning problems into independent pieces,Partitioning demographic model,Partitioning probabilistic demographic model,Find the most frequent words in a text,Models of parallel computing,A simple embarrassingly parallel application,Probabilistic projection of migration (setup),Probabilistic projection of migration,R packages for parallel computing,Passing arguments via clusterApply(),Sum in parallel,More tasks than workers","foreach,Combining results,Word frequency with foreach,Multiple iterators in word frequency,foreach and parallel backends,Using doParallel,Word frequency with doParallel,Word frequency with doFuture and benchmarking,future and future.apply,Word frequency with future.apply,Planning future,Benchmark future,Load balancing and scheduling,Load balancing,Scheduling","Cluster basics,Exploring the cluster object,Socket vs. Fork,The core of parallel,Benchmarking setup,Task size matters,Initialization of nodes,Loading package on nodes,Setting global variables,Exporting global objects,Subsetting data,Passing data as arguments,Chunking migration application on worker's side,Alternative chunking","Are my results reproducible?,Reproducibility (I),SOCK vs. FORK,SOCK vs. FORK & random numbers,Parallel random number generators,Setting an RNG,Reproducible results in parallel,Non-reproducible results in parallel,Reproducibility in foreach and future.apply,Reproducibility (II),Reproducing migration app with foreach,Reproducing migration app with future.apply,Next steps",Benjamin Feder,"Words (Jane Austen's 6 books),US migration,SOTU (2016),Writing Efficient R Code",,
280,Human Resources Analytics: Predicting Employee Churn in Python,4,14,44,"6,752",3500,"Among all of the business domains, HR is still the least disrupted. However, the latest developments in data collection and analysis tools and technologies allow for data driven decision-making in all dimensions, including HR. This course will provide a solid basis for dealing with employee data and developing a predictive model to analyze employee turnover.","Introduction and overview,Finding categorical variables,Observing categoricals,Transforming categorical variables,Encoding categories,Getting dummies,Dummy trap,Descriptive statistics,Correlations in the employee data,Percentage of employees who churn","Tuning employee turnover classifier,Pruning the tree,Limiting the sample size,Evaluating the model,Interpreting accuracy metrics,Calculating accuracy metrics: precision,Calculating accuracy metrics: recall,Targeting both leavers and stayers,Calculating the ROC/AUC score,Class imbalance,Balancing classes,Comparison of Employee attrition models","Splitting the data,Separating Target and Features,Spliting employee data,Introduction to Decision Tree classification,Computing Gini index,Splitting the tree,Predicting employee churn using decision trees,Fitting the tree to employee data,Checking the accuracy of prediction,Interpretation of the decision tree,Exporting the tree,Interpretation of results","Hyperparameter tuning,Cross-validation using sklearn,Setting up GridSearch parameters,Implementing GridSearch,Important features for predicting attrition,Interpreting importance,Sorting important features,Selecting important features,Develop and test the best model,Final thoughts","Lore Dirick,Nick Solomon","Employee turnover data,Intermediate Python",,
281,Linear Classifiers in Python,4,13,44,"39,208",3200,"In this course you'll learn all about using linear classifiers, specifically logistic regression and support vector machines, with scikit-learn. Once you've learned how to apply these methods, you'll dive into the ideas behind them and find out what really makes them tick. At the end of this course you'll know how to train, test, and tune these linear classifiers in Python. You'll also have a conceptual foundation for understanding many other machine learning algorithms.","scikit-learn refresher,KNN classification,Comparing models,Overfitting,Applying logistic regression and SVM,Running LogisticRegression and SVC,Sentiment analysis for movie reviews,Linear classifiers,Which decision boundary is linear?,Visualizing decision boundaries","Logistic regression and regularization,Regularized logistic regression,Logistic regression and feature selection,Identifying the most positive and negative words,Logistic regression and probabilities,Getting class probabilities,Regularization and probabilities,Visualizing easy and difficult examples,Multi-class logistic regression,Counting the coefficients,Fitting multi-class logistic regression,Visualizing multi-class logistic regression,One-vs-rest SVM","Linear classifiers: the coefficients,How models make predictions,Changing the model coefficients,What is a loss function?,The 0-1 loss,Minimizing a loss function,Loss function diagrams,Classification loss functions,Comparing the logistic and hinge losses,Implementing logistic regression","Support vectors,Support vector definition,Effect of removing examples,Kernel SVMs,GridSearchCV warm-up,Jointly tuning gamma and C with GridSearchCV,Comparing logistic regression and SVM (and beyond),An advantage of SVMs,An advantage of logistic regression,Using SGDClassifier,Conclusion","Nick Solomon,Kara Woo","Machine Learning Fundamentals,Machine Learning Scientist,Supervised Learning with scikit-learn",,
282,Customer Analytics and A/B Testing in Python,4,16,49,"17,658",3750,"The most successful companies today are the ones that know their customers so well that they can anticipate their needs. Customer analytics and in particular A/B Testing are crucial parts of leveraging quantitative know-how to help make business decisions that generate value. This course covers the ins and outs of how to use Python to analyze customer behavior and business trends as well as how to create, run, and analyze A/B tests to make proactive, data-driven business decisions.","Course introduction and overview,Understanding the key components of an A/B test,Defining meaningful KPIs,Identifying and understanding KPIs,Loading & examining our data,Merging on different sets of fields,Exploratory analysis of KPIs,Practicing aggregations,Grouping & aggregating,Calculating KPIs - a practical example,Calculating KPIs,Average purchase price by cohort","Introduction to A/B testing,Good applications of A/B testing,General properties of an A/B Test,A/B test generalizability,Initial A/B test design,Experimental units: Revenue per user day,Preparing to run an A/B test,Conversion rate sensitivities,Sensitivity,Standard error,Calculating sample size,Exploring the power calculation,Calculating the sample size","Working with time series data in pandas,Parsing dates,Creating time series graphs with matplotlib,Plotting time series data,Pivoting our data,Examining the different cohorts,Understanding and visualizing trends,Seasonality and moving averages,Exponential rolling average & over/under smoothing,Events and releases,Visualizing user spending,Looking more closely at revenue","Analyzing the A/B test results,Confirming our test results,Thinking critically about p-values,Understanding statistical significance,Intuition behind statistical significance,Checking for statistical significance,Understanding confidence intervals,Calculating confidence intervals,Interpreting your test results,Plotting the distribution,Plotting the difference distribution,Finale","Lore Dirick,Yashas Roy,Eunkyung Park","Marketing Analytics,Customer dataset,In-App Purchases dataset,Daily Revenue dataset,User Demographics Paywall dataset,AB Testing Results,Data Manipulation with pandas,Python Data Science Toolbox (Part 1)",,
283,Machine Learning for Time Series Data in Python,4,13,53,"31,344",4550,"Time series data is ubiquitous. Whether it be stock market fluctuations, sensor data recording climate change, or activity in the brain, any signal that changes over time can be described as a time series. Machine learning has emerged as a powerful method for leveraging complexity in data in order to generate predictions and insights into the problem one is trying to solve. This course is an intersection between these two worlds of machine learning and time series data, and covers feature engineering, spectograms, and other advanced techniques in order to classify heartbeat sounds and predict stock prices.","Timeseries kinds and applications,Identifying a time series,Plotting a time series (I),Plotting a time series (II),Machine learning basics,Fitting a simple model: classification,Predicting using a classification model,Fitting a simple model: regression,Predicting using a regression model,Machine learning and time series data,Inspecting the classification data,Inspecting the regression data","Predicting data over time,Introducing the dataset,Fitting a simple regression model,Visualizing predicted values,Advanced time series prediction,Visualizing messy data,Imputing missing values,Transforming raw data,Handling outliers,Creating features over time,Engineering multiple rolling features at once,Percentiles and partial functions,Using ""date"" information","Classifying a time series,Many repetitions of sounds,Invariance in time,Build a classification model,Improving features for classification,Calculating the envelope of sound,Calculating features from the envelope,Derivative features: The tempogram,The spectrogram,Spectrograms of heartbeat audio,Engineering spectral features,Combining many features in a classifier","Creating features from the past,Creating time-shifted features,Special case: Auto-regressive models,Visualize regression coefficients,Auto-regression with a smoother time series,Cross-validating time series data,Cross-validation with shuffling,Cross-validation without shuffling,Time-based cross-validation,Stationarity and stability,Stationarity,Bootstrapping a confidence interval,Calculating variability in model coefficients,Visualizing model score variability over time,Accounting for non-stationarity,Wrap-up","Sumedh Panchadhar,Lore Dirick,Eunkyung Park","Machine Learning Scientist,Time Series,Prices,Audio,Manipulating Time Series Data in Python,Visualizing Time Series Data in Python,Machine Learning with scikit-learn",,
284,Hierarchical and Mixed Effects Models in R,4,13,55,"14,472",4750,"This course begins by reviewing slopes and intercepts in linear regressions before moving on to random-effects. You'll learn what a random effect is and how to use one to model your data. Next, the course covers linear mixed-effect regressions. These powerful models will allow you to explore data with a more complicated structure than a standard linear regression. The course then teaches generalized linear mixed-effect regressions. Generalized linear mixed-effects models allow you to model more kinds of data, including binary responses and count data. Lastly, the course goes over repeated-measures analysis as a special case of mixed-effect modeling. This kind of data appears when subjects are followed over time and measurements are collected at intervals. Throughout the course you'll work with real data to answer interesting questions using mixed-effects models.","What is a hierarchical model?,Examples of hierarchical datasets,Multi-level student data,Exploring multiple-levels: Classrooms and schools,Parts of a regression,Intercepts,Slopes and multiple regression,Random-effects in regressions with school data,Random-effect intercepts,Random-effect slopes,Building the school model,Interpreting the school model","Crash course on GLMs,Logistic regression,Poisson Regression,Plotting GLMs,Binomial data,Toxicology data,Marketing example,Calculating odds-ratios,Count data,Internet click-throughs,Chlamydia by age-group and county,Displaying chlamydia results","Linear mixed effect model- Birth rates data,Building a lmer model with random effects,Including a fixed effect,Random-effect slopes,Uncorrelated random-effect slope,Fixed- and random-effect predictor,Understanding and reporting the outputs of a lmer,Comparing print and summary output,Extracting coefficients,Displaying the results from a lmer model,Statistical inference with Maryland crime data,Visualizing Maryland crime data,Rescaling slopes,Null hypothesis testing,Controversies around P-values,Model comparison with ANOVA","An introduction to repeated measures,Paired t-test,Repeated measures ANOVA,Sleep study,Exploring the data,Building models,Comparing regressions and ANOVAs,Plotting results,Hate in NY state?,Exploring NY hate data,Building the model,Interpreting model results,Displaying the results,Hierarchical models in R review,Conclusion","Nick Solomon,Chester Ismay","Statistician,Illinois chlamydia data,Maryland crime data,Classroom data,Birth rate data,New York hate crime data,Generalized Linear Models in R",,
285,Case Studies: Network Analysis in R,4,11,47,"2,750",4150,"Now that you're familiar with the basics of network analysis it's time to see how to apply those concepts to large real-world data sets. You'll work through three different case studies, each building on your previous work. These case studies are working with the kinds of data you'll see in both academic and industry settings. We'll explore some of the computational and visualization challenges you'll face and how to overcome them. Your knowledge of igraph will continue to grow, but we'll also leverage other visualization libraries that will help you bring your visualizations to the web.","Exploring your data set,Finding Dyads and Triads,Clustering and Reciprocity,Important Products,What Makes an Important Product?,Exploring temporal structure,Metrics through time,Plotting Metrics Over Time","Creating our graph from raw data,Making Graphs of Different User Types,Compare Graphs of Different User Types,Compare graph distance vs. geographic distance,Compare Subscriber vs. Non-Subscriber Distances,Most Traveled To and From Stations,Most Traveled To and From Stations with Weights,Visualize central vertices,Weighted Measures of Centrality,Connectivity,Find the minimum cut 1,Find the minimum cut 2,Unweighted Clustering Randomizations,Weighted Clustering Randomizations","Creating your retweet graph,Visualize the graph,Visualize nodes by degree,What's the distribution of centrality?,Who is important in the conversation?,Plotting important vertices,Building a mentions graph,Comparing mention and retweet graph,Assortativity and reciprocity,Finding who is talking to whom,Finding communities,Comparing community algorithms,Visualizing the communities","Other packages for plotting graphs!,ggnet Basics,ggnetwork Basics,More ggnet Plotting Options,More ggnetwork Plotting Options,Interactive visualizations,Interactive plots with ggiraph,Interactive javascript plots,Alternative visualizations,Alternative ways to visualize a graph: Hive plots,BioFabric as an HTML widget,Plotting graphs on a map","Nick Solomon,Chester Ismay,Benjamin Feder","Network Analysis,Amazon graph,Amazon purchase graph over time,Twitter retweet graph,Twitter mention graph,Bike sharing data,Network Analysis in R",,
286,Machine Learning for Marketing Analytics in R,4,17,60,"11,193",4200,"This is your chance to dive into the worlds of marketing and business analytics using R. Day by day, there are a multitude of decisions that companies have to face. With the help of statistical models, you're going to be able to support the business decision-making process based on data, not your gut feeling. Let us show you what a great impact statistical modeling can have on the performance of businesses. You're going to learn about and apply strategies to communicate your results and help them make a difference.","Customer lifetime value in CRM,Benefits of knowing CLV,Looking at data,Simple linear regression,Understanding residuals,Estimating simple linear regression,Multiple linear regression,Avoiding multicollinearity,Interpretation of coefficients,Model validation, model fit, and prediction,Interpretation of model fit,Future predictions of sales","Survival analysis: introduction,Applications of survival analysis,Data for survival analysis,Characteristics of survival analysis,Survival curve analysis by Kaplan Meier,Survival function, hazard function and hazard rate,The survival object,Kaplan-Meier Analysis,Cox PH model with constant covariates,Proportional hazard assumption,Cox Proportional Hazard Model,Interpretation of coefficients,Checking model assumptions and making predictions,Violation of the PH assumption,Model assumptions,Predictions","Churn prevention in online marketing,Application churn prevention,Data discovery,Peculiarities of the dependent variable,Modeling and model selection,Model specification and estimation,Statistical significance,Model specification,In-sample model fit and thresholding,In-sample fit full model,In-sample fit restricted model,Finding the optimal threshold,Danger of overfitting,Out-of-sample validation and cross validation,Assessing out-of-sample model fit,Cross validation","PCA for CRM data,Purposes of PCA,Getting to know the data,Exploring the correlation structure,PCA computation,Standardization of data,Compute a PCA,The result object of a PCA,Choosing the right number of principal components,How many components are relevant?,Interpretation of components,Visualization with a biplot,Principal components in a regression analysis,Regression analysis with many variables,Linear regression with principal components,Closing","Nick Solomon,Chester Ismay","Marketing Analytics,Churn data,Sales data,Sales data, months 2-4,Survival data,Default data,News data,First CLV dataset,Second CLV dataset,Customer data,Introduction to Regression in R",,
287,Forecasting Product Demand in R,4,13,50,"7,485",4200,"Accurately predicting demand for products allows a company to stay ahead of the market. By knowing what things shape demand, you can drive behaviors around your products better. This course unlocks the process of predicting product demand through the use of R. You will learn how to identify important drivers of demand, look at seasonal effects, and predict demand for a hierarchy of products from a real world example. By the end of the course you will be able to predict demand for multiple products across a region of a state in the US. Then you will roll up these predictions across many different regions of the same state to form a complete hierarchical forecasting system.","Loading data into xts object,Importing data,Plotting / visualizing data,ARIMA Time Series 101,auto.arima() function,Interpret auto.arima,Forecasting and Evaluating,Forecast function,Calculating MAPE and MAE,Visualizing Forecast,Confidence Intervals for Forecast","Residuals from regression model,Calculating residuals from regression,Visualizing residuals,Forecasting residuals,auto.arima function,Forecasting residuals with time series,Visualizing residual forecasts,Transfer functions & ensembling,Combining residuals from regression & time series,Visualizing transfer function forecast,Calculating transfer function MAPE and MAE,ARIMA Forecasting,Ensembling of Forecasts","Price elasticity,Calculating price elasticity,Interpret results from elasticity,Seasonal / holiday / promotional effects,Visualize holiday / promotion effects,Create holiday / promotional effect variables,Regression for holiday / promotional effects,Significant holiday or promotional effects?,Forecasting with regression,Create future predictor variables,Forecast future values of demand,Visualizing forecasts of regression","Bottom-Up Hierarchical Forecasting,Build time series forecast for new product,Build regression forecast for new product,Ensemble forecast for new product,Calculate bottom-up forecast for whole region,Top-Down Hierarchical Forecasting,Build time series forecast at regional level,Using average historical proportions,Using proportion of historical averages,Middle-Out Hierarchical Forecasting,Build time series forecast for new region,Top-down forecast for new region,Bottom-up forecast for whole state,Congratulations!",Yashas Roy,"Beverage producer sales,Case Studies: Manipulating Time Series Data in R",,
288,Working with Data in the Tidyverse,4,17,56,"27,375",4500,"In this course, you'll learn to work with data using tools from the tidyverse in R. By data, we mean your own data, other people's data, messy data, big data, small data - any data with rows and columns that comes your way! By work, we mean doing most of the things that sound hard to do with R, and that need to happen before you can analyze or visualize your data. But work doesn't mean that it is not fun - you will see why so many people love working in the tidyverse as you learn how to explore, tame, tidy, and transform your data. Throughout this course, you'll work with data from a popular television baking competition called ""The Great British Bake Off.""","Import your data,Read a CSV file,Assign missing values,Know your data,Arrange and glimpse,Summarize your data,Know your variable types,Count with your data,Distinct and count,Count episodes,Count bakers,Plot counts","Introduction to Tidy Data,Tidy line-up,Plot untidy data,Gather,Gather by hand,Gather & plot,Gather & plot non-sequential columns,separate(),Separate a column,Unite columns,spread(),Spread rows into columns,Tidy multiple sets of columns,Masterclass: Tidy I,Masterclass: Tidy II,Masterclass: Tidy III","Cast column types,Cast a column to a date,Cast a column to a number,Cast a column as a factor,Recode values,Recode a character variable,Recode a numeric variable,Select variables,Combine functions with select,Recode factor to plot,Select and reorder variables,Tame variable names,Reformat variables,Rename and subset variables,Rename and reorder variables","Complex recoding with case_when,Combine two variables,Add another bin,Factors,Cast a factor and examine levels,Plot factor counts,Dates,Cast characters as dates,Calculate timespans,Strings,Wrangle a character variable,Detect a string pattern,Final thoughts","Yashas Roy,Chester Ismay,Benjamin Feder","Bakeoff,Bakers,Desserts,Ratings,Introduction to Data Visualization with ggplot2",,
289,Modeling with Data in the Tidyverse,4,17,49,"17,804",3900,"In this course, you will learn to model with data. Models attempt to capture the relationship between an outcome variable of interest and a series of explanatory/predictor variables. Such models can be used for both explanatory purposes, e.g. ""Does knowing professors' ages help explain their teaching evaluation scores?"", and predictive purposes, e.g., ""How well can we predict a house's price based on its size and condition?"" You will leverage your tidyverse skills to construct and interpret such models. This course centers around the use of linear regression, one of the most commonly-used and easy to understand approaches to modeling. Such modeling and thinking is used in a wide variety of fields, including statistics, causal inference, machine learning, and artificial intelligence.","Background on modeling for explanation,Exploratory visualization of age,Numerical summaries of age,Background on modeling for prediction,Exploratory visualization of house size,Log10 transformation of house size,The modeling problem for explanation,EDA of relationship of teaching & ""beauty"" scores,Correlation between teaching and ""beauty"" scores,The modeling problem for prediction,EDA of relationship of house price and waterfront,Predicting house price with waterfront","Explaining house price with year & size,EDA of relationship,Fitting a regression,Predicting house price using year & size,Making predictions using size and bedrooms,Interpreting residuals,Explaining house price with size & condition,Parallel slopes model,Interpreting the parallel slopes model,Predicting house price using size & condition,Making predictions using size and waterfront,Automating predictions on ""new"" houses","Explaining teaching score with age,Plotting a ""best-fitting"" regression line,Fitting a regression with a numerical x,Predicting teaching score using age,Making predictions using ""beauty score"",Computing fitted/predicted values & residuals,Explaining teaching score with gender,EDA of relationship of score and rank,Fitting a regression with a categorical x,Predicting teaching score using gender,Making predictions using rank,Visualizing the distribution of residuals","Model selection and assessment,Refresher: sum of squared residuals,Which model to select?,Assessing model fit with R-squared,Computing the R-squared of a model,Comparing the R-squared of two models,Assessing predictions with RMSE,Computing the MSE & RMSE of a model,Comparing the RMSE of two models,Validation set prediction framework,Fitting model to training data,Predicting on test data,Conclusion - Where to go from here?","Sumedh Panchadhar,Chester Ismay,Benjamin Feder","Tidyverse Fundamentals,Working with Data in the Tidyverse",,
290,Building Dashboards with shinydashboard,4,13,45,"21,764",3750,"Once you've started learning tools for building interactive web applications with shiny, this course will translate this knowledge into building dashboards. Dashboards, a common data science deliverable, are pages that collate information, often tracking metrics from a live-updating data source. You'll gain more expertise using shiny while learning to build and design these dynamic dashboards. In the process, you'll pick up tips to optimize performance as well as best practices to create a visually appealing product.","Dashboard structure overview,Create empty Header, Sidebar, and Body,Create an empty Shiny Dashboard,Dashboard Header overview,Create message menus,Create notification menus,Create task menus,Dashboard Sidebar and Body overview,Create Sidebar tabs,Create Body tabs,Create tab boxes","Bootstrap explanation,Create body with row-based layout,Create body with column-based layout,Create body with mixed layout,Customizing the appearance,Change the appearance of the dashboard,Customize the body with CSS,Icons, statuses, colors,Incorporate icons,Add some life to your layouts","Reactive expression refresher,Review selectInput and sliderInput,Reactive expression practice,Server-side dynamic how-to,Read in real-time data,View real-time data,Optimizing performance,How many times will this code run? (1),How many times will this code run? (2),Optimize this,UI dynamic how-to,Create reactive menu items,Create reactive boxes","Introduction to the NASA fireball data set,Examine the variables in the data set,Create a value box for the maximum velocity,Create a value box for the maximum impact,Create a value box for the maximum energy,Dynamic refresher,Make the value boxes dynamic,Allow the user to input an alert threshold,Create a dynamic plot of the location of fireballs,Update the look of your new application,Thank you!","Nick Solomon,Chester Ismay","Shiny Fundamentals,NASA fireball dataset,Starwars dataset,Building Web Applications with Shiny in R",,
291,Visualization Best Practices in R,4,13,49,"12,888",4200,"This course will help you take your data visualization skills beyond the basics and hone them into a powerful member of your data science toolkit. Over the lessons we will use two interesting open datasets to cover different types of data (proportions, point-data, single distributions, and multiple distributions) and discuss the pros and cons of the most common visualizations. In addition, we will cover some less common alternatives visualizations for the data types and how to tweak default ggplot settings to most efficiently and effectively get your message across.","Grammar of Graphics intro,Familiarizing with disease data,Warming up data-wrangling,The pie chart and its friends,The infamous P-I-E,Cleaning up the pie,How about a waffle?,When to use bars,Basic stacked bars,Ordering stack for readability,Categorical x-axis","Importance of distributions,Orienting with the data,Looking at all data,Changing y-axis to density,Histogram nuances,Adjusting the bin numbers,More bars,Bin width by context,The kernel density estimator,Histogram to KDE,Putting a rug down,KDE with lots of data","Bars and dots: point data,Are bars appropriate?,Working with geom_col,Wrangling geom_bar,Point charts,Ordered point chart,Adding visual anchors,Faceting to show structure.,Tuning your charts,Let's flip some axes,Cleaning up the bars,Converting to point chart","Intro to comparing distributions,A simple boxplot,Adding some jitter,Faceting to show all colors,Beeswarms and violins,Your first beeswarm,Fiddling with a violin plot,Violins with boxplots,Comparing lots of distributions,Comparing spatially-related distributions,A basic ridgeline plot,Cleaning up your ridgelines,Making it rain (data points),Wrap-up","David Campos,Chester Ismay,Shon Inouye","Data Visualization,World Health Organization Disease Dataset,Introduction to Data Visualization with ggplot2",,
292,Foundations of Functional Programming with purrr,4,13,44,"8,310",3750,"Lists can be difficult to both understand and manipulate, but they can pack a ton of information and are very powerful. In this course, you will learn to easily extract, summarize, and manipulate lists and how to export the data to your desired object, be it another list, a vector, or even something else! Throughout the course, you will work with the purrr package and a variety of datasets from the repurrrsive package, including data from Star Wars and Wes Anderson films and data collected about GitHub users and GitHub repos. Following this course, your list skills will be purrrfect!","The power of iteration,Introduction to iteration,Iteration with purrr,More iteration with for loops,More iteration with purrr,Subsetting lists; it's not that hard!,Subsetting lists,Subsetting list elements,The many flavors of map(),map() argument alternatives,map_*","How to purrr safely(),safely() replace with NA,Convert data to numeric with purrr,Finding the problem areas,Another way to possibly() purrr,Replace safely() with possibly(),Convert values with possibly(),purrr is a walk() in the park,Comparing walk() vs no walk() outputs,walk() for printing cleaner list outputs","Working with unnamed lists,Names & pipe refresher,Setting names,Pipes in map(),More map(),Simulating Data with Purrr,Run a linear model,map_chr(),map_dbl() and map_int(),map2() and pmap(),Simulating data with multiple inputs using map2(),Simulating data 3+ inputs with pmap()","Using purrr in your workflow,Name review,Setting names,Asking questions from a list,Even more complex problems,Questions about gh_repos,Graphs in purrr,ggplot() refresher,purrr and scatterplots,purrr and histograms,Wrap Up","Chester Ismay,Becca Robins","Intermediate Tidyverse Toolbox,Simulated data 1990-2005,Introduction to the Tidyverse",,
293,Joining Data with data.table in R,4,13,47,"12,643",3950,"In the real world, data sets typically come split across many tables while most data analysis functions in R are designed to work with single tables of data. In this course, you'll learn how to effectively combine data sets into single tables using data.table. You'll learn how to add columns from one table to another table, how to filter a table based on observations in another table, and how to identify records across multiple tables matching complex criteria. Along the way, you'll learn how to troubleshoot failed join operations and best practices for working with complex data sets. After completing this course you'll be well on your way to be a data.table master!","Welcome to the course,Exploring data.tables,Identifying join keys,Multiple data.tables, multiple keys,The merge function,Inner join,Full join,Left and right joins,Left join,Right join,Mastering simple joins","Complex keys,Keys with different names,Multi-column keys,Multi-key, single-key,Tricky columns,Column name suffixes,Joining a data.frame,Duplicate matches,Joining with missing values,Filtering duplicates,Joining and filtering duplicates","Joins using data.table syntax,Right join with the data.table syntax,Inner join with the data.table syntax,Anti-joins,Setting and viewing data.table keys,Setting keys,Getting keys,Incorporating joins into your data.table workflow,Exploring the Australian population,Finding multiple matches,Exploring world life expectancy","Concatenating two or more data.tables,Concatenating data.table variables,Concatenating a list of data.tables,Set operations,Identifying observations shared by multiple tables,Removing duplicates while combining tables,Identifying observations unique to a table,Melting data.tables,Melting a wide table,More melts,Casting data.tables,Casting a long table,Casting multiple columns,Splitting by multiple groups","Sumedh Panchadhar,Richie Cotton,Eunkyung Park","Data Manipulation,IMDB,Netflix,Australia Population,Life Expectancy,School Database,Heart Disease,Ebola Cases,GDP,Data Manipulation with data.table in R",,
294,ChIP-seq with Bioconductor in R,4,13,46,"3,302",3650,"ChIP-seq analysis is an important branch of bioinformatics. It provides a window into the machinery that makes the cells in our bodies tick. Whether it is a brain cell helping you to read this web page or an immune cell patrolling your body for microorganisms that would make you sick, they all carry the same genome. What differentiates them are the genes that are active at any given time. Which genes these are is determined by a complex system of proteins that can activate and deactivate genes. When this regulatory machinery gets out of control, it can lead to cancer and other debilitating diseases. ChIP-seq analysis allows us to understand the function of regulatory proteins, how they can contribute to disease and can provide insights into how we may be able to intervene to prevent cells from spinning out of control. In this course, you will explore a real dataset while learning how to process and analyze ChIP-seq data in R.","What is ChIP-seq?,ChIP-seq recap,Sequencing data,Peak calls,ChIP-seq Workflow,Heat map,Genes that make a difference,ChIP-seq results summary,Understanding ChIP-seq data","Introduction to differential binding,Do these samples look the same to you?,Clustering samples,Visualising differences in protein binding,Testing for differential binding,Loading Read Counts,Setting-up the model,Fitting the model,Revisiting PCA and Heat map,A closer look at differential binding,MA plot,Volcano plot,Summarising differences in protein binding","Importing data,Reading BAM files,Reading BED files,Taking a closer look at peaks,Plotting a region in detail,Adding Annotations,Cleaning ChIP-seq data,Removing blacklisted regions,Filtering reads,Compare filtered data to raw reads,Assessing enrichment,Computing coverage,Peaks vs background","Interpreting ChIP-seq peaks,Consolidating peaks,Using Annotations,Annotating peaks,Which peaks are different?,Interpreting Gene lists,Associating peaks with genes,Finding common themes,Understanding the impact on pathways,A closer look at pathways,Advanced ChIP-seq analyses","David Campos,Richie Cotton,Shon Inouye","Analyzing Genomic Data,Androgen Receptor ChIP-seq Peaks dataset,Chromosome 20 dataset,Intermediate R,Introduction to Bioconductor in R",,
295,Introduction to Linear Modeling in Python,4,16,59,"18,117",5050,"One of the primary goals of any scientist is to find patterns in data and build models to describe, predict, and extract insight from those patterns. The most fundamental of these patterns is a linear relationship between two variables. This course provides an introduction to exploring, quantifying, and modeling linear relationships in data, by demonstrating techniques such as least-squares, linear regression, estimatation, and bootstrap resampling. Here you will apply the most powerful modeling tools in the python data science ecosystem, including scipy, statsmodels, and scikit-learn, to build and evaluate linear models. By exploring the concepts and applications of linear models with python, this course serves as both a practical introduction to modeling, and as a foundation for learning more advanced modeling techniques and tools in statistics and machine learning.","Introduction to Modeling Data,Reasons for Modeling: Interpolation,Reasons for Modeling: Extrapolation,Reasons for Modeling: Estimating Relationships,Visualizing Linear Relationships,Plotting the Data,Plotting the Model on the Data,Visually Estimating the Slope & Intercept,Quantifying Linear Relationships,Mean, Deviation, & Standard Deviation,Covariance vs Correlation,Correlation Strength","Modeling Real Data,Linear Model in Anthropology,Linear Model in Oceanography,Linear Model in Cosmology,The Limits of Prediction,Interpolation: Inbetween Times,Extrapolation: Going Over the Edge,Goodness-of-Fit,RMSE Step-by-step,R-Squared,Standard Error,Variation Around the Trend,Variation in Two Parts","What makes a model linear,Terms in a Model,Model Components,Model Parameters,Interpreting Slope and Intercept,Linear Proportionality,Slope and Rates-of-Change,Intercept and Starting Points,Model Optimization,Residual Sum of the Squares,Minimizing the Residuals,Visualizing the RSS Minima,Least-Squares Optimization,Least-Squares with `numpy`,Optimization with Scipy,Least-Squares with `statsmodels`","Inferential Statistics Concepts,Sample Statistics versus Population,Variation in Sample Statistics,Visualizing Variation of a Statistic,Model Estimation and Likelihood,Estimation of Population Parameters,Maximizing Likelihood, Part 1,Maximizing Likelihood, Part 2,Model Uncertainty and Sample Distributions,Bootstrap and Standard Error,Estimating Speed and Confidence,Visualize the Bootstrap,Model Errors and Randomness,Test Statistics and Effect Size,Null Hypothesis,Visualizing Test Statistics,Visualizing the P-Value,Course Conclusion","Nick Solomon,Adrián Soto","Femur length versus body height,Distance hiked versus hike duration,Galaxy distances versus recession velocities,Sea surface height versus year,Mass versus volume of solution,Introduction to Regression with statsmodels in Python",,
296,Communicating with Data in the Tidyverse,4,15,53,"23,348",4350,"They say that a picture is worth a thousand words. Indeed, successfully promoting your data analysis is not only a matter of accurate and effective graphics, but also of aesthetics and uniqueness. This course teaches you how to leverage the power of ggplot2 themes for producing publication-quality graphics that stick out from the mass of boilerplate plots out there. It shows you how to tweak and get the most out of ggplot2 in order to produce unconventional plots that draw attention on social media. In the end, you will combine that knowledge to produce a slick and custom-styled report with RMarkdown and CSS – all of that within the powerful tidyverse.","Introduction to the data,Join the two data sets together,Change variable types,Filtering and plotting the data,Filter the data for plotting,Some summary statistics,A basic scatter plot,Add labels to the plot,Custom ggplot2 themes,Apply a default theme,Change the appearance of titles,Alter background color and add margins","What is RMarkdown?,When is a document reproducible?,Introduction to the RMarkdown exercise interface,Formatting with Markdown,Give your document a structure,Change formatting of text snippets,R code in RMarkdown documents,Specify packages in the first code chunk,R code chunk options,Inline code statements,Images in RMarkdown files,Adjusting figure options, optimizing them for mobile devices.,Add auxiliary images","Visualizing aspects of data with facets,Prepare the data set for the faceted plot,Add facets to the plot,Define your own theme function,Apply the new theme function to the plot,A custom plot to emphasize change,A basic dot plot,Add arrows to the lines in the plot,Add some labels to each country,Polishing the dot plot,The fct_reorder function,Reordering elements in the plot,Correct ugly label positions,Finalizing the plot for different audiences and devices,Change the viewport so labels don't overlap with plot border,Optimizing the plot for mobile devices","Advanced YAML settings,Change the overall appearance of your report,Add a table of contents,More YAML hacks,Custom stylesheets,CSS selectors,Change style attributes of text elements,Reference the style sheet,Beautiful tables,Beautify a table with kable,Repetition: CSS,Summary","Yashas Roy,Chester Ismay","Tidyverse Fundamentals,Hourly Compensation (ILO),Weekly Working Hours (ILO),Introduction to the Tidyverse",,
297,Building Dashboards with flexdashboard,4,14,50,"8,682",4150,"Communication is a key part of the data science process. Dashboards are a popular way to present data in a cohesive visual display. In this course you'll learn how to assemble your results into a polished dashboard using the flexdashboard package. This can be as simple as adding a few lines of R Markdown to your existing code, or as rich as a fully interactive Shiny-powered experience. You will learn about the spectrum of dashboard creation tools available in R and complete this course with the ability to produce a professional quality dashboard.","Welcome to the course!,Components of a dashboard,Anatomy of a flexdashboard,Generating a dashboard,Adding charts,Layout basics,Column widths,Row orientation,Advanced layouts,Tabsets,Pages,Menus","Highlighting single values,Create value box,Create gauge,Color indicators,Linking,Dashboard Tables,Static table,Web-friendly table,DT::datatable,Text for Dashboards,Captions,Captions with Inline Code,Storyboards,Storyboard Commentary","Graphs,Static Graph,Graph Sizing,Web-friendly visualizations,Static vs. web-friendly,Make a plot web-friendly,Explore web-friendly features,htmlwidgets,Add a leaflet map,Add a leaflet map directly from dataframe","Incorporating Shiny into Dashboards,What adding Shiny to a flexdashboard means,Converting our flexdashboard to use Shiny,The reactive dataframe pattern,Adding Sidebar,Adding User Input,Making the Dataframe Reactive,Making a Chart React to Inputs,Making All Charts React to Inputs,Customized inputs for charts,Apply Input to Single Chart,Move Input to Chart Box,Create Global Input Sidebar,Course Recap","Nick Solomon,Chester Ismay","Shiny Fundamentals,San Francisco bike share data,San Francisco bike share station data,Building Web Applications with Shiny in R",,
298,Visualizing Big Data with Trelliscope in R,4,16,46,"4,465",3450,"Having honed your visualization skills by learning ggplot2, it's now time to tackle larger datasets. In this course, you will learn several techniques for visualizing big data, with particular focus on the scalable visualization technique of faceting. You will learn how to put this technique into action using the Trelliscope approach as implemented in the trelliscopejs R package. Trelliscope plugs seamlessly into standard R workflows and produces interactive visualizations that allow you to visually explore your data in detail. By the end of this course, you will be able to easily create interactive exploratory displays of large datasets that will help you and your colleagues gain new insights into your data.","Visualizing summaries,Daily ride counts,Distribution of cab fare amount,Distribution of payment type,Adding more detail to summaries,Relationship between trip duration and total fare,Faceting daily rides,Tip amount distribution faceted by payment type,Visualizing subsets,Comparing fare distribution by payment type,Visualizing all subsets","Trelliscope in the tidyverse,Grouping and nesting,Stock price display,Exploring the display,Cognostics,Adding cognostics,Cognostics from nested data frames,Navigating stock plots with new cognostics,Trelliscope options,Customizing the stock display,Visualizing databases of images,Visualizing Pokemon,The most powerful Pokemon","Faceting with TrelliscopeJS,Trelliscope faceting gapminder by country,Interacting with the TrelliscopeJS displays,Interacting with the display,Additional TrelliscopeJS features,Customizing the gapminder display,Examining the new cognostics,Adding your own cognostics,Adding custom cognostics,Interpreting custom cognostics","Montreal BIXI bike data,Number of daily rides,Examining time-of-day,Effect of membership and weekday,Summary visualization recap,Daily plots,Looking at all days,Top 100 routes dataset,Augmenting the data: Route summary statistics,Visualizing the data: Counts by hour-of-day,Evaluating the visualization,Au revoir","Richie Cotton,Yashas Roy,Benjamin Feder","Big Data,Interactive Data Visualization,Bikes,Pokémon,Top 100 routes,Stocks,Taxi rides,Introduction to the Tidyverse",,
299,Interactive Data Visualization with plotly in R,4,15,54,"8,161",4600,"Interactive graphics allow you to manipulate plotted data to gain further insight. As an example, an interactive graphic would allow you to zoom in on a subset of your data without the need to create a new plot. In this course, you will learn how to create and customize interactive graphics in plotly using the R programming language. Along the way, you will review data visualization best practices and be introduced to new plot types such as scatterplot matrices and binned scatterplots.","What is plotly?,A follow-up on the course intro,Converting a ggplot2 scatterplot,Univariate graphics,Histograms,Bar charts,Bivariate graphics,A first scatterplot,A first stacked bar chart,Boxplots","Layering traces,Adding a linear smoother,Overlayed density plots,Subplots,Manual faceting,Automated faceting,Plot and axis titles,Polishing axis titles,Scatterplot matrices,Your first SPLOM,Customizing color,Tweaking the appearance,Binned scatterplots,Binning a scatterplot","Customize your traces,Color and opacity,Alternative color formats,Size and symbol,Thoughtful use of color,Adding a third variable,Beyond color: Symbols,Transforming a color scale,Hover info,Removing a piece of hover info,Adding to hoverinfo,Custom hoverinfo,Customizing your layout,Polishing a scatterplot,Matching a theme","Introduction to the 2018 election data,Did voters turn out?,Adding a reference line,Which state had the highest turnout?,How much was spent on Senate races?,Which candidate spent the most?,Choropleth maps,Mapping change in voter turnout,Mapping Senate winners,Adding points to a map,Geo layout,From polygons to maps,Mapping Senate winners, redux,A county-level choropleth map,Wrap-up","David Campos,Chester Ismay,Shon Inouye","Interactive Data Visualization,Video game sales and ratings dataset,Wine datasets,Midterm election datasets,Introduction to the Tidyverse",,
300,Inference for Categorical Data in R,4,14,53,"7,023",4000,"Categorical data is all around us. It's in the latest opinion polling numbers, in the data that lead to new breakthroughs in genomics, and in the troves of data that internet companies collect to sell products to you. In this course you'll learn techniques for parsing the signal from the noise; tools for identifying when structure in this data represents interesting phenomena and when it is just random noise.","The General Social Survey,Exploring consci,Generating via bootstrap,Constructing a CI,Why more bootstraps?,Interpreting a Confidence Interval,CIs and confidence level,SE with less data,SE with different p,The approximation shortcut,CI via approximation,Methods compared","Contingency tables,Politics and Space,Understanding contingency tables,From tidy to table to tidy,Chi-squared test statistic,A single permuted Chi-sq,Building two null distributions,Is the data consistent with the model?,Alternate method: the chi-squared distribution,Checking conditions,The geography of happiness,A p-value two ways,Intervals for the chi-squared distribution","Hypothesis test for a proportion,Life after death,Generating from H0,Testing a claim,Making a decision,Intervals for differences,Death penalty and sex,Hypothesis test on the difference in proportions,Interpreting the test,Hypothesis tests and confidence intervals,Statistical errors,When the null is true,When the null is true: decision","Case study: election fraud,Getting to know the Iran data,Who won?,Breaking it down by province,Extracting the first digit I,Goodness of fit,Goodness of fit test,A p-value, two ways,Is this evidence of fraud?,And now to US,Getting to know the Iowa data,Extracting the first digit II,Testing Iowa,Fraud in Iowa?,Election fraud in Iran and Iowa: debrief","Nick Solomon,Benjamin Feder,Jonathan Ng","Statistical Inference,GSS data,Iowa election data,Iran election data,Foundations of Inference",,
301,Introduction to Portfolio Risk Management in Python,4,13,51,"16,682",4250,"This course will teach you how to evaluate basic portfolio risk and returns like a quantitative analyst on Wall Street. This is the most critical step towards being able to fully automate your portfolio construction and management processes. Discover what factors are driving your portfolio returns, construct market-cap weighted equity portfolios, and learn how to forecast and hedge market risk via scenario generation.","Financial returns,Financial timeseries data,Calculating financial returns,Return distributions,Mean, variance, and normal distribution,First moment: Mu,Second moment: Variance,Annualizing variance,Skewness and kurtosis,Third moment: Skewness,Fourth moment: Kurtosis,Statistical tests for normality","The Capital Asset Pricing model,Excess returns,Calculating beta using co-variance,Calculating beta with CAPM,Adjusted R-squared,Alpha and multi-factor models,The Fama French 3-factor model,p-values and coefficients,Economic intuition in factor modeling,The efficient market and alpha,Expanding the 3-factor model,The 5-factor model,Alpha vs R-squared","Portfolio composition and backtesting,Calculating portfolio returns,Equal weighted portfolios,Market-cap weighted portfolios,Correlation and co-variance,The correlation matrix,The co-variance matrix,Portfolio standard deviation,Markowitz portfolios,The efficient frontier,Sharpe ratios,The MSR portfolio,The GMV portfolio","Estimating tail risk,Historical drawdown,Historical value at risk,Historical expected shortfall,VaR extensions,Changing VaR and CVaR quantiles,Parametric VaR,Scaling risk estimates,Random walks,A random walk simulation,Monte Carlo simulations,Monte Carlo VaR,Understanding risk","Sumedh Panchadhar,Lore Dirick,Eunkyung Park","Applied Finance,All returns (2017),Efficient Frontier Portfolios,Fama-French factors,Microsoft prices,ETF of oil prices (UFO),Introduction to Financial Concepts in Python,Manipulating Time Series Data in Python",,
302,Introduction to Financial Concepts in Python,4,13,50,"17,336",4200,"Understanding the basic principles of finance is essential for making important financial decisions ranging from taking out a student loan to constructing an investment portfolio. Combining basic financial knowledge with Python will allow you to construct some very powerful tools. You'll come out of this course understanding the time value of money, how to compare potential projects and how to make rational, data-driven financial decisions.","Fundamental financial concepts,Growth and rate of return,Compound interest,Discount factors and depreciation,Present and future value,Present value,Future value,Adjusting future values for inflation,Net present value and cash flows,Discounting cash flows,Initial project costs,Diminishing cash flows","Mortgage basics,Taking out a mortgage loan,Calculating the monthly mortgage payment,Amortization, interest and principal,Calculating interest and principal payments,Simulating periodic payments (I),Simulating periodic payments (II),Home ownership, equity and forecasting,Cumulative payments and home equity,Rising housing prices,Falling housing prices and underwater mortgages","A tale of two project proposals,Project proposals and cash flows projections,Internal Rate of Return,Make a decision based on IRR,The Weighted Average Cost of Capital,Debt and equity financing,Calculating WACC,Comparing project NPV with IRR,Comparing two projects of different life spans,Two project with different lifespans,Calculating IRR and NPV with different project lifespans,Using the equivalent annual annuity approach,Making a data-driven decision on projects of different lifespans","Budgeting project proposal,Salary and taxes,Monthly expenses and savings,Forecast salary growth and cost of living,Forecast growing expenses due to inflation,Net worth and valuation in your personal financial life,Calculate your net worth,So you want to be a millionaire?,Investing a percentage of your income (I),Investing a percentage of your income (II),The power of time and compound interest,Investing over time,Inflation-adjusted net worth,Financial concepts in your daily life","Sumedh Panchadhar,Lore Dirick","Finance Fundamentals,Introduction to Python for Finance",,
303,Cluster Analysis in R,4,16,52,"35,522",3800,"Cluster analysis is a powerful toolkit in the data science workbench. It is used to find groups of observations (clusters) that share similar characteristics. These similarities can inform all kinds of business decisions; for example, in marketing, it is used to identify distinct groups of customers for which advertisements can be tailored. In this course, you will learn about two commonly used clustering methods - hierarchical clustering and k-means clustering. You won't just learn how to use these methods, you'll build a strong intuition for how they work and how to interpret their results. You'll develop this intuition by exploring three different datasets: soccer player positions, wholesale customer spending data, and longitudinal occupational wage data.","What is cluster analysis?,When to cluster?,Distance between two observations,Calculate & plot the distance between two players,Using the dist() function,Who are the closest players?,The importance of scale,Effects of scale,When to scale data?,Measuring distance for categorical data,Calculating distance between categorical variables,The closest observation to a pair","Introduction to K-means,K-means on a soccer field,K-means on a soccer field (part 2),Evaluating different values of K by eye,Many K's many models,Elbow (Scree) plot,Interpreting the elbow plot,Silhouette analysis: observation level performance,Silhouette analysis,Making sense of the K-means clusters,Revisiting wholesale data: ""Best"" k,Revisiting wholesale data: Exploration","Comparing more than two observations,Calculating linkage,Revisited: The closest observation to a pair,Capturing K clusters,Assign cluster membership,Exploring the clusters,Validating the clusters,Visualizing the dendrogram,Comparing average, single & complete linkage,Height of the tree,Cutting the tree,Clusters based on height,Exploring the branches cut from the tree,What do we know about our clusters?,Making sense of the clusters,Segment wholesale customers,Explore wholesale customer clusters,Interpreting the wholesale customer clusters","Occupational wage data,Initial exploration of the data,Hierarchical clustering: Occupation trees,Hierarchical clustering: Preparing for exploration,Hierarchical clustering: Plotting occupational clusters,Reviewing the HC results,K-means: Elbow analysis,K-means: Average Silhouette Widths,The ""best"" number of clusters,Review K-means results","Richie Cotton,Yashas Roy","Data Scientist,Machine Learning Scientist,Unsupervised Machine Learning,Soccer player positions,Occupational Employment Statistics (OES),Wholesale customer spending,Intermediate R",,
304,Python for R Users,5,15,57,"11,714",4950,"Python and R have seen immense growth in popularity in the ""Machine Learning Age"". They both are high-level languages that are easy to learn and write. The language you use will depend on your background and field of study and work. R is a language made by and for statisticians, whereas Python is a more general purpose programming language. Regardless of the background, there will be times when a particular algorithm is implemented in one language and not the other, a feature is better documented, or simply, the tutorial you found online uses Python instead of R. In either case, this would require the R user to work in Python to get his/her work done, or try to understand how something is implemented in Python for it to be translated into R. This course helps you cross the R-Python language barrier.","Introduction,Assignment and data types,Arithmetic with strings,Containers - lists and dictionaries,Lists,Dictionaries,Functions, methods, and libraries,Methods,NumPy arrays,Pandas DataFrames","Selecting data in pandas,Selecting columns,Selecting rows,Selecting rows and columns,Data types,Integers and floats,Strings,Category,Dates (I),Dates (II),Advanced Pandas,Missing values,Groupby,Tidy data","NYC flights data,Load multiple data files,Explore,Visualize,Manipulating data,Recode dates,Groupby aggregates,Plots,Dummy variables,Wrap-up","Control flow and loops,Control flow,Loops,Functions,Individual binge drinking function,General binge drinking function,Lambda functions,Comprehensions,Mapping functions,List comprehension,Dictionary comprehension","Sumedh Panchadhar,Hugo Bowne-Anderson,Eunkyung Park","Air quality,Country timeseries,Flights (sample),Inflammation,NYC Flights 2013,Tips,Introduction to Writing Functions in R","Plotting directly using pandas,Univariate plots in pandas,Bivariate plots in pandas,Seaborn,Univariate plots in seaborn,Bivariate plots in seaborn,Facet plots in seaborn,Matplotlib,Univariate and bivariate plots in matplotlib,Subfigures in matplotlib,Working with axes,Polishing up a figure",
305,Working with Dates and Times in R,4,14,48,"27,362",4000,"Dates and times are abundant in data and essential for answering questions that start with when, how long, or how often. However, they can be tricky, as they come in a variety of formats and can behave in unintuitive ways. This course teaches you the essentials of parsing, manipulating, and computing with dates and times in R. By the end, you'll have mastered the lubridate package, a member of the tidyverse, specifically designed to handle dates and times. You'll also have applied your new skills to explore how often R versions are released, when the weather is good in Auckland (the birthplace of R), and how long monarchs ruled in Britain.","Introduction to dates,Recognizing ISO 8601 dates,Specifying dates,Automatic import,Why use dates?,Plotting,Arithmetic and logical operators,What about times?,Getting datetimes into R,Datetimes behave nicely too,Why lubridate?","Taking differences of datetimes,How long has it been?,How many seconds are in a day?,Time spans.,Adding or subtracting a time span to a datetime,Duration or Period?,Arithmetic with timespans,Generating sequences of datetimes,The tricky thing about months,Intervals,Examining intervals. Reigns of kings and queens,Comparing intervals and datetimes,Converting to durations and periods","Parsing dates with lubridate,Selecting the right parsing function,Specifying an order with `parse_date_time()`,Weather in Auckland,Import daily weather data,Import hourly weather data,Extracting parts of a datetime,What can you extract?,Adding useful labels,Extracting for plotting,Extracting for filtering and summarizing,Rounding datetimes,Practice rounding,Rounding with the weather data","Time zones,Setting the timezone,Viewing in a timezone,Timezones in the weather data,Times without dates,More on importing and exporting datetimes,Fast parsing with fasttime,Fast parsing with lubridate::fast_strptime,Outputting pretty dates and times,Wrap-up","Richie Cotton,Yashas Roy","Data Scientist,R Programmer,Auckland daily weather,Auckland hourly weather,R releases,Cran logs,Intermediate R",,
306,Fundamentals of Bayesian Data Analysis in R,4,23,58,"18,798",4450,"Bayesian data analysis is an approach to statistical modeling and machine learning that is becoming more and more popular. It provides a uniform framework to build problem specific models that can be used for both statistical inference and for prediction. This course will introduce you to Bayesian data analysis: What it is, how it works, and why it is a useful tool to have in your data science toolbox.","A first taste of Bayes,Unknowns and ice creams,Let's try some Bayesian data analysis,Coin flips with prop_model,Zombie drugs with prop_model,Samples and posterior summaries,Looking at samples from prop_model,Summarizing the zombie drug experiment,You've done some Bayesian data analysis!","Four good things with Bayes,Explore using the Beta distribution as a prior,Pick the prior that best captures the information,Change the model to use an informative prior,Contrasts and comparisons,Fit the model using another dataset,Calculating the posterior difference,Decision analysis,A small decision analysis 1,A small decision analysis 2,Change anything and everything,The Poisson distribution,Clicks per day instead of clicks per ad,Bayes is optimal, kind of...","The temperature in a Normal lake,rnorm, dnorm, and the weight of newborns,A Bayesian model of water temperature,A Bayesian model of Zombie IQ,Eyeballing the mean IQ of zombies?,Answering the question: Should I have a beach party?,Sampling from the zombie posterior,But how smart will the next zombie be?,A practical tool: BEST,The BEST models and zombies on a diet,BEST is robust,What have you learned? What did we miss?","The parts needed for Bayesian inference,Take a generative model for a spin,Take the binomial distribution for a spin,Using a generative model,How many visitors could your site get (1)?,Representing uncertainty with priors,Adding a prior to the model,Bayesian models and conditioning,Update a Bayesian model with data,How many visitors could your site get (3)?,What have we done?","Nick Solomon,Chester Ismay","Machine Learning Scientist,Statistician,Introduction to R","Probability rules,Cards and the sum rule,Cards and the product rule,Calculating likelihoods,From rbinom to dbinom,Calculating probabilities with dbinom,Bayesian calculation,Calculating a joint distribution,Conditioning on the data (again),A conditional shortcut,Bayes' theorem,A Poisson model description",
307,Data Manipulation with data.table in R,4,15,59,"19,913",5050,"The data.table package provides a high-performance version of base R's data.frame with syntax and feature enhancements for ease of use, convenience and programming speed. This course shows you how to create, subset, and manipulate data.tables. You'll also learn about the database-inspired features of data.tables, including built-in groupwise operations. The course concludes with fast methods of importing and exporting tabular text data such as CSV files. Upon completion of the course, you will be able to use data.table in R for a more efficient manipulation and analysis process. Throughout the course you'll explore the San Francisco Bay Area bike share trip dataset from 2014.","Welcome to the course!,data.table pop quiz,Creating a data.table,Introducing bikes data,Filtering rows in a data.table,Filtering rows using positive integers,Filtering rows using negative integers,Filtering rows using logical vectors,Helpers for filtering,I %like% data.tables,Filtering with %in%,Filtering with %between% and %chin%","Computations by groups,Computing stats by groups (I),Computing stats by groups (II),Computing multiple stats,Chaining data.table expressions,Ordering rows,What are the top 5 destinations?,What is the most popular destination from each start station?,Combining i, j, and by (I),Computations in j using .SD,Using .SD (I),Using .SD (II)","Fast data reading with fread(),Fast reading from disk,Importing a CSV file,Importing selected columns,Importing selected rows,Advanced file reading,Reading large integers,Specifying column classes,Dealing with empty and incomplete lines,Dealing with missing values,Fast data writing with fwrite(),Writing files to disk,Writing date and time columns,Fast writing to disk","Selecting columns from a data.table,Selecting a single column,Selecting columns by name,Deselecting specific columns,Computing on columns the data.table way,Computing in j (I),Computing in j (II),Advanced computations in j,Computing in j (III),Combining i and j","Sumedh Panchadhar,Richie Cotton,Eunkyung Park,Benjamin Feder","Data Manipulation,Intermediate R","Adding and updating columns by reference,Adding a new column,Updating an existing column (I),Updating an existing column (II),Grouped aggregations,Adding columns by group,Updating columns by group,Advanced aggregations,Adding multiple columns (I),Adding multiple columns (II),Combining i, j, and by (II)",
308,Visualizing Time Series Data in Python,4,17,59,"17,310",4850,"Time series data is omnipresent in the field of Data Science. Whether it is analyzing business trends, forecasting company revenue or exploring customer behavior, every data scientist is likely to encounter time series data at some point during their work. To get you started on working with time series data, this course will provide practical knowledge on visualizing time series data using Python.","Welcome to the course!,Load your time series data,Test whether your data is of the correct type,Plot your first time series,Your first plot!,Specify plot styles,Display and label plots,Customize your time series plot,Subset time series data,Add vertical and horizontal markers,Add shaded regions to your plot","Autocorrelation and Partial autocorrelation,Autocorrelation in time series data,Interpret autocorrelation plots,Partial autocorrelation in time series data,Interpret partial autocorrelation plots,Seasonality, trend and noise in time series data,Time series decomposition,Plot individual components,A quick review,Visualize the airline dataset,Analyze the airline dataset,Time series decomposition of the airline dataset","Apply your knowledge to a new dataset,Explore the Jobs dataset,Describe time series data with boxplots,Beyond summary statistics,Plot all the time series in your dataset,Annotate significant events in time series data,Plot monthly and yearly trends,Decompose time series data,Apply time series decomposition to your dataset,Visualize the seasonality of multiple time series,Compute correlations between time series,Correlations between multiple time series,Interpret correlations,Congratulations!","Clean your time series data,Find missing values,Handle missing values,Plot aggregates of your data,Display rolling averages,Display aggregated values,Summarize the values in your time series data,Compute numerical summaries,Boxplots and Histograms,Density plots","Sumedh Panchadhar,Lore Dirick","Time Series,Inventions and Scientific Discoveries,CO2 levels in Mauai Hawaii,Airline passengers,Production of meat in USA,Unemployment rate in USA,Introduction to Data Visualization with Matplotlib,Manipulating Time Series Data in Python","Working with more than one time series,Load multiple time series,Visualize multiple time series,Statistical summaries of multiple time series,Plot multiple time series,Define the color palette of your plots,Add summary statistics to your time series plot,Plot your time series on individual plots,Find relationships between multiple time series,Compute correlations between time series,Visualize correlation matrices,Clustered heatmaps",
309,Inference for Numerical Data in R,4,15,49,"9,960",3650,"In this course, you'll learn how to use statistical techniques to make inferences and estimations using numerical data. This course uses two approaches to these common tasks. The first makes use of bootstrapping and permutation to create resample based tests and confidence intervals. The second uses theoretical results and the t-distribution to achieve the same result. You'll learn how (and when) to perform a t-test, create a confidence interval, and do an ANOVA!","Welcome to the course!,Generate bootstrap distribution for median,Review percentile and standard error methods,Calculate bootstrap interval using both methods,Which method more appropriate: percentile or SE?,Doctor visits during pregnancy,Average number of doctor's visits,SD of number of doctor's visits,Re-centering a bootstrap distribution,Test for median price of 1 BR apartments in Manhattan,Conclude the hypothesis test on median,Test for average weight of babies","Hypothesis testing for comparing two means,Evaluating the effectiveness of stem cell treatment,Evaluating the effectiveness of stem cell treatment (cont.),Conclusion of the hypothesis test,Evaluating the relationship between smoking during pregnancy and birth weight,Bootstrap CI for difference in two means,Quantifying the relationship between smoking during pregnancy and birth weight,Median lengths of pregnancies for smoking and non-smoking mothers,Comparing means with a t-test,Hourly pay vs. citizenship status,Estimating the difference of two means using a t-interval","t-distribution,When to t?,Probabilities under the t-distribution,Cutoffs under the t-distribution,Estimating a mean with a t-interval,Average commute time of Americans,Average number of hours worked,t-interval for paired data,t-interval at various levels,Understanding confidence intervals,Testing a mean with a t-test,Estimate the median difference in textbook prices,Test for a difference in median test scores,Interpret the p-value","Vocabulary score vary between vs. (self identified) social class,EDA for vocabulary score vs. social class,Comparing many means, visually,ANOVA,ANOVA for vocabulary score vs. (self identified) social class,Conditions for ANOVA,Checking the normality condition,Checking the constant variance condition,Post-hoc testing,Calculate alpha*,Compare pairwise means,Congratulations!","Nick Carchedi,Nick Solomon","Statistical Inference,Chp1-vid1-boot-dist-noaxes-parantheses,Chp1-vid1-bootsamp-bootpop.001,Chp1-vid1-manhattan-rents,Chp1-vid2-boot-dist-withaxes,Chp1-vid2-perc-method.001,Chp1-vid2-perc-method.002,Chp1-vid3-boot-test.001,Chp3-vid3-hrly-rate-citizen-smaller,Chp3-vid3-hrly-rate-citizen,Chp4-vid1-class-bar,Chp4-vid1-wodrsum-hist,Gss moredays,GSS data,Manhattan rent data,Runners.001,Tdistcomparetonormaldist,Foundations of Inference",,
310,Developing R Packages,4,16,56,"5,888",4200,"In this course, you will learn the end-to-end process for creating an R package from scratch. You will start off by creating the basic structure for your package, and adding in important details like functions and metadata. Once the basic components of your package are in place, you will learn about how to document your package, and why this is important for creating quality packages that other people - as well as your future self - can use with ease. Once you have created the components of your package, you will learn how to test they work properly, by creating tests, running checks, and building your package. By the end of this course you can expect to have all the necessary skills to create and share your own R packages.","Introduction to package building,The structure of an R package,Contents of an R package,Writing a simple function,Including functions in a package,DESCRIPTION and NAMESPACE files,Package names,Writing a DESCRIPTION file,Detailing authors, maintainers and contributors,Optional directories,The use_* functions,Best practice for structuring code","Why check an R package?,What does a ""check"" check?,Running a check,Errors, warnings and notes,Undocumented parameters,Undefined global variables,Differences in package dependencies,Depends or imports?,Adding a dependency,Adding the import to the description,Building packages with continuous integration,Building an R package,Setting a package up for using Travis","Introduction to roxygen2,A simple function header,Documenting function arguments,Importing other packages,How to export functions?,Export best practice,Exporting functions,Documenting other elements,Adding examples,Documenting function return values,Additional documentation,Minimum level of documentation,Documenting a package,Adding package documentation,Documenting data objects,Creating man files","What are unit tests and why write them?,Setting up the test structure,Writing an individual test,Testing for equality,Testing errors and warnings,Testing errors,Testing warnings,Testing specific output and non-exported functions,Testing non-exported functions,Testing specific output,Grouping tests and execution output,Grouping tests,Executing unit tests,Understanding a test failure,Wrap-up","Sumedh Panchadhar,Richie Cotton,Eunkyung Park","R Programmer,Introduction to Writing Functions in R",,
311,Introduction to Shell,4,,55,"95,626",4650,"The Unix command line has survived and thrived for almost 50 years because it lets people do complex things with just a few keystrokes. Sometimes called ""the universal glue of programming,"" it helps users combine existing programs in new ways, automate repetitive tasks, and run programs on clusters and clouds that may be halfway around the world. This course will introduce its key elements and show you how to use them efficiently.","How does the shell compare to a desktop interface?,Where am I?,How can I identify files and directories?,How else can I identify files and directories?,How can I move to another directory?,How can I move up a directory?,How can I copy files?,How can I move a file?,How can I rename files?,How can I delete files?,How can I create and delete directories?,Wrapping up","How can I store a command's output in a file?,How can I use a command's output as an input?,What's a better way to combine commands?,How can I combine many commands?,How can I count the records in a file?,How can I specify many files at once?,What other wildcards can I use?,How can I sort lines of text?,How can I remove duplicate lines?,How can I save the output of a pipe?,How can I stop a running program?,Wrapping up","How can I edit a file?,How can I record what I just did?,How can I save commands to re-run later?,How can I re-use pipes?,How can I pass filenames to scripts?,How can I process a single argument?,How can one shell script do many things?,How can I write loops in a shell script?,What happens when I don't provide filenames?","How can I view a file's contents?,How can I view a file's contents piece by piece?,How can I look at the start of a file?,How can I type less?,How can I control what commands do?,How can I list everything below a directory?,How can I get help for a command?,How can I select columns from a file?,What can't cut do?,How can I repeat commands?,How can I select lines containing specific values?,Why isn't it always safe to treat data as text?",Filip Schouwenaars,"Data Engineer,Python Programmer,R Programmer","How does the shell store information?,How can I print a variable's value?,How else does the shell store information?,How can I repeat a command many times?,How can I repeat a command once for each file?,How can I record the names of a set of files?,A variable's name versus its value,How can I run many commands in a single loop?,Why shouldn't I use spaces in filenames?,How can I do many things in a single loop?",
312,Introduction to the Tidyverse,4,16,50,"240,449",4150,"This is an introduction to the programming language R, focused on a powerful set of tools known as the Tidyverse. You'll learn the intertwined processes of data manipulation and visualization using the tools dplyr and ggplot2. You'll learn to manipulate data by filtering, sorting, and summarizing a real dataset of historical country data in order to answer exploratory questions. You'll then learn to turn this processed data into informative line plots, bar plots, histograms, and more with the ggplot2 package. You’ll get a taste of the value of exploratory data analysis and the power of Tidyverse tools. This is a suitable introduction for those who have no previous experience in R and are interested in performing data analysis.","The gapminder dataset,Loading the gapminder and dplyr packages,Understanding a data frame,The filter verb,Filtering for one year,Filtering for one country and one year,The arrange verb,Arranging observations by life expectancy,Filtering and arranging,The mutate verb,Using mutate to change or create a column,Combining filter, mutate, and arrange","The summarize verb,Summarizing the median life expectancy,Summarizing the median life expectancy in 1957,Summarizing multiple variables in 1957,The group_by verb,Summarizing by year,Summarizing by continent,Summarizing by continent and year,Visualizing summarized data,Visualizing median life expectancy over time,Visualizing median GDP per capita per continent over time,Comparing median life expectancy and median GDP per continent in 2007","Visualizing with ggplot2,Variable assignment,Comparing population and GDP per capita,Comparing population and life expectancy,Log scales,Putting the x-axis on a log scale,Putting the x- and y- axes on a log scale,Additional aesthetics,Adding color to a scatter plot,Adding size and color to a plot,Faceting,Creating a subgraph for each continent,Faceting by year","Line plots,Visualizing median GDP per capita over time,Visualizing median GDP per capita by continent over time,Bar plots,Visualizing median GDP per capita by continent,Visualizing GDP per capita by country in Oceania,Histograms,Visualizing population,Visualizing population with x-axis on a log scale,Boxplots,Comparing GDP per capita across continents,Adding a title to your graph,Conclusion","Yashas Roy,Chester Ismay","Data Analyst,Data Scientist,R Programmer,Tidyverse Fundamentals,Gapminder",,
313,Case Studies in Statistical Thinking,4,16,61,"13,321",4850,"Mastery requires practice. Having completed Statistical Thinking I and II, you developed your probabilistic mindset and the hacker stats skills to extract actionable insights from your data. Your foundation is in place, and now it is time practice your craft. In this course, you will apply your statistical thinking skills, exploratory data analysis, parameter estimation, and hypothesis testing, to two new real-world data sets. First, you will explore data from the 2013 and 2015 FINA World Aquatics Championships, where you will quantify the relative speeds and variability among swimmers. You will then perform a statistical analysis to assess the ""current controversy"" of the 2013 Worlds in which swimmers claimed that a slight current in the pool was affecting result. Second, you will study the frequency and magnitudes of earthquakes around the world. Finally, you will analyze the changes in seismicity in the US state of Oklahoma after the practice of high pressure waste water injection at oil extraction sites became commonplace in the last decade. As you work with these data sets, you will take vital steps toward mastery as you cement your existing knowledge and broaden your abilities to use statistics and Python to make sense of your data.","Activity of zebrafish and melatonin,EDA: Plot ECDFs of active bout length,Interpreting ECDFs and the story,Bootstrap confidence intervals,Parameter estimation: active bout length,Permutation and bootstrap hypothesis tests,Permutation test: wild type versus heterozygote,Bootstrap hypothesis test,Linear regressions and pairs bootstrap,Assessing the growth rate,Plotting the growth curve","Introduction to the current controversy,A metric for improvement,ECDF of improvement from low to high lanes,Estimation of mean improvement,How should we test the hypothesis?,Hypothesis test: Does lane assignment affect performance?,Did the 2015 event have this problem?,The zigzag effect,Which splits should we consider?,EDA: mean differences between odd and even splits,How does the current effect depend on lane position?,Hypothesis test: can this be by chance?,Recap of swimming analysis","Variations in earthquake frequency and seismicity,EDA: Plotting earthquakes over time,Estimates of the mean interearthquake times,Hypothesis test: did earthquake frequency change?,How to display your analysis,Earthquake magnitudes in Oklahoma,EDA: Comparing magnitudes before and after 2010,Quantification of the b-values,How should we do a hypothesis test on differences of the b-value?,Hypothesis test: are the b-values different?,What can you conclude from this analysis?,Closing comments","Introduction to swimming data,Graphical EDA of men's 200 free heats,200 m free time with confidence interval,Do swimmers go faster in the finals?,EDA: finals versus semifinals,Parameter estimates of difference between finals and semifinals,How to do the permutation test,Generating permutation samples,Hypothesis test: Do women swim the same way in semis and finals?,How does the performance of swimmers decline over long events?,EDA: Plot all your data,Linear regression of average split time,Hypothesis test: are they slowing down?","Hugo Bowne-Anderson,Yashas Roy","Swimming results, 2013 World Aquatics Championships,Swimming results, 2015 World Aquatics Championships,Zebrafish active bout lengths,Oklahoma earthquakes (1950 to mid-2017),Bacterial growth,Parkfield earthquakes (1950 to mid-2017),Statistical Thinking in Python (Part 1),Statistical Thinking in Python (Part 2)","Introduction to statistical seismology and the Parkfield experiment,Parkfield earthquake magnitudes,Computing the b-value,The b-value for Parkfield,Timing of major earthquakes and the Parkfield sequence,Interearthquake time estimates for Parkfield,When will the next big Parkfield quake be?,How are the Parkfield interearthquake times distributed?,Computing the value of a formal ECDF,Computing the K-S statistic,Drawing K-S replicates,The K-S test for Exponentiality",
314,Network Analysis in R,4,12,50,"15,624",4000,"In this course you'll learn how to work with and visualize network data. You'll use the igraph package to create networks from edgelists and adjacency matrices. You'll also learn how to plot networks and their attributes. Then, you'll learn how to identify important vertices using measures like betweenness and degree. Next, this course covers network structures, including triangles and cliques. Next, you'll learn how to identify special relationships between vertices, using metrics like assortativity. Finally, you'll see how to create interactive network plots using threejs.","What are social networks?,Creating an igraph object,Counting vertices and edges,Network attributes,Node attributes and subsetting,Edge attributes and subsetting,Visualizing attributes,Quiz on attributes,Network visualization,igraph network layouts,Visualizing edges,Quiz on igraph objects","Introduction,Forrest Gump network,Network density and average path length,Graph density quiz,Understanding network structures,Random graphs,Network randomizations,Randomization quiz,Network substructures,Triangles and transitivity,Transitivity randomizations,Cliques,Visualize largest cliques","Directed networks,Directed igraph objects,Identifying edges for each vertex,Relationships between vertices,Neighbors,Distances between vertices,Finding longest path between two vertices,Important and influential vertices,Identifying key vertices,Betweenness,Visualizing important nodes and edges,Important vertices quiz","Close relationships: assortativity & reciprocity,Assortativity,Using randomizations to assess assortativity,Reciprocity,Assortativity quiz,Community detection,Fast-greedy community detection,Edge-betweenness community detection,Community quiz,Interactive network visualizations,Interactive networks with threejs,Sizing vertices in threejs,3D community network graph","Richie Cotton,Nick Solomon","Network Analysis,Friendship network data,Friendship network edge data,Friendship network node data,Forrest Gump network data,Measles network data,Intermediate R",,
315,Introduction to PySpark,4,,45,"99,252",3850,"In this course, you'll learn how to use Spark from Python! Spark is a tool for doing parallel computation with large datasets and it integrates well with Python. PySpark is the Python package that makes the magic happen. You'll use this package to work with data about flights from Portland and Seattle. You'll learn to wrangle this data and build a whole machine learning pipeline to predict whether or not flights will be delayed. Get ready to put some Spark in your Python code and dive into the world of high-performance machine learning!","What is Spark, anyway?,Using Spark in Python,Examining The SparkContext,Using DataFrames,Creating a SparkSession,Viewing tables,Are you query-ious?,Pandafy a Spark DataFrame,Put some Spark in your data,Dropping the middle man","Machine Learning Pipelines,Join the DataFrames,Data types,String to integer,Create a new column,Making a Boolean,Strings and factors,Carrier,Destination,Assemble a vector,Create the pipeline,Test vs. Train,Transform the data,Split the data","Creating columns,SQL in a nutshell,SQL in a nutshell (2),Filtering Data,Selecting,Selecting II,Aggregating,Aggregating II,Grouping and Aggregating I,Grouping and Aggregating II,Joining,Joining II","What is logistic regression?,Create the modeler,Cross validation,Create the evaluator,Make a grid,Make the validator,Fit the model(s),Evaluating binary classifiers,Evaluate the model",Colin Ricardo,"Big Data with PySpark,Data Engineer,Machine Learning Scientist,Airports,Flights,Planes,Introduction to Python",,
316,Spatial Analysis with sf and raster in R,4,15,53,"10,297",4550,"There has never been a better time to use R for spatial analysis! The sf package has made working with vector data in R a breeze and the raster package provides a set of powerful and intuitive tools to work gridded data like satellite imagery. Instead of the painful process of performing your spatial analysis in GIS systems like ArcGIS or QGIS and then shuffling your results into another system for analysis, you can move your entire spatial analysis workflow into R. In this course you will learn why the sf package is rapidly taking over spatial analysis in R. You will read in spatial data, manipulate vectors using the dplyr package and learn how to work with coordinate reference systems. You'll also learn how to perform geoprocessing of vectors including buffering, spatial joins, computing intersections, simplifying and measuring distance. With rasters, you will aggregate, reclassify, crop, mask, and extract. The last chapter of the course is devoted to showing you how to make maps in R with the ggplot2 and tmap packages and performing a fun mini-analysis that brings together all your new skills.","Reading vector and raster data into R,Reading vector data,Reading raster data,Getting to know your vector data,sf objects are data frames,Geometry is stored in list-columns,Extracting geometric information from your vector layers,First look at plotting vector spatial objects,Getting to know your raster data,Learning about your raster objects,Accessing raster data values,Plot your raster object","Buffers and centroids,Buffer layers,Compute polygon centroids,Bounding boxes, dissolve features and create a convex hull,Create a bounding box around vector data,Dissolve multiple features into one,Compute a convex hull around vectors,Multi-layer geoprocessing and relationships,Spatial joins,Spatial relationships,Measuring distance between features,Geoprocessing with rasters,Limit rasters to focus areas,Crop a raster based on another spatial object,Extract raster values by location,Raster math with overlay","A quick refresher on the coordinate reference system,Vector and raster coordinate systems,Transform your layers to a common CRS,Plot vector and raster together,Manipulating vector layers with dplyr,Dropping geometry from a data frame,Join spatial and non-spatial data,Simplify the neighborhood boundaries,Converting sf objects into sp objects and coordinates,Converting sf objects to sp objects,Converting to and from coordinates,Manipulating raster layers,Change the raster grid cell size using aggregate,Change values and handle missing values in rasters","Compute tree density and average tree canopy by neighborhood,Compute tree density by neighborhood (I),Compute tree density by neighborhood (II),Compute average tree canopy by neighborhood,First look at results with ggplot2,Create plots using ggplot2,Create a map using ggplot2,Create final, polished maps with tmap,Create a map using tmap,Use tmap to create a final pretty map,Wrap-up video",Richie Cotton,"Spatial Data,Canopy,Impervious,Landcover,Manhattan,Neighborhoods,Parks,Trees,Visualizing Geospatial Data in R",,
317,Introduction to Airflow in Python,4,16,55,"19,810",4050,"Delivering data on a schedule can be a manual process. You write scripts, add complex cron tasks, and try various ways to meet an ever-changing set of requirements—and it’s even trickier to manage everything when working with teammates. Airflow can remove this headache by adding scheduling, error handling, and reporting to your workflows. In this course, you’ll master the basics of Airflow and learn how to implement complex data engineering pipelines in production. You'll also learn how to use Directed Acyclic Graphs (DAGs), automate data engineering workflows, and implement data engineering tasks in an easy and repeatable fashion—helping you to maintain your sanity.","Introduction to Airflow,Running a task in Airflow,Examining Airflow commands,Airflow DAGs,Defining a simple DAG,Working with DAGs and the Airflow shell,Troubleshooting DAG creation,Airflow web interface,Starting the Airflow webserver,Navigating the Airflow UI,Examining DAGs with the Airflow UI","Airflow sensors,Sensors vs operators,Sensory deprivation,Airflow executors,Determining the executor,Executor implications,Debugging and troubleshooting in Airflow,DAGs in the bag,Missing DAG,SLAs and reporting in Airflow,Defining an SLA,Defining a task SLA,Generate and email a report,Adding status emails","Airflow operators,Defining a BashOperator task,Multiple BashOperators,Airflow tasks,Define order of BashOperators,Determining the order of tasks,Troubleshooting DAG dependencies,Additional operators,Using the PythonOperator,More PythonOperators,EmailOperator and dependencies,Airflow scheduling,Schedule a DAG via Python,Deciphering Airflow schedules,Troubleshooting DAG runs","Working with templates,Creating a templated BashOperator,Templates with multiple arguments,More templates,Using lists with templates,Understanding parameter options,Sending templated emails,Branching,Define a BranchPythonOperator,Branch troubleshooting,Creating a production pipeline,Creating a production pipeline #1,Creating a production pipeline #2,Adding the final changes to your pipeline,Congratulations!","Hadrien Lacroix,Lis Sulmont","Data Engineer,Intermediate Python,Introduction to Shell",,
318,Joining Data with pandas,4,15,52,"73,228",4150,"Being able to combine and work with multiple datasets is an essential skill for any aspiring Data Scientist. pandas is a crucial cornerstone of the Python data science ecosystem, with Stack Overflow recording 5 million views for pandas questions. Learn to handle multiple DataFrames by combining, organizing, joining, and reshaping them using pandas. You'll work with datasets from the World Bank and the City Of Chicago. You will finish the course with a solid skillset for data-joining in pandas.","Inner join,What column to merge on?,Your first inner join,Inner joins and number of rows returned,One-to-many relationships,One-to-many classification,One-to-many merge,Merging multiple DataFrames,Total riders in a month,Three table merge,One-to-many merge with multiple tables","Filtering joins,Steps of a semi join,Performing an anti join,Performing a semi join,Concatenate DataFrames together vertically,Concatenation basics,Concatenating with keys,Using the append method,Verifying integrity,Validating a merge,Concatenate and merge to find common songs","Left join,Counting missing rows with left join,Enriching a dataset,How many rows with a left join?,Other joins,Right join to find unique movies,Popular genres with right join,Using outer join to select actors,Merging a table to itself,Self join,How does pandas handle self joins?,Merging on indexes,Index merge for movie ratings,Do sequels earn more?","Using merge_ordered(),Correlation between GDP and S&P500,Phillips curve using merge_ordered(),merge_ordered() caution, multiple columns,Using merge_asof(),Using merge_asof() to study stocks,Using merge_asof() to create dataset,merge_asof() and merge_ordered() differences,Selecting data with .query(),Explore financials with .query(),Subsetting rows with .query(),Reshaping data with .melt(),Select the right .melt() arguments,Using .melt() to reshape government data,Using .melt() for stocks vs bond performance,Course wrap-up","Maggie Matsui,Amy Peterson","Data Analyst,Data Manipulation,Data Scientist,Chicago Wards,Chicago Business Licenses,Chicago Census,Chicago Demographics by Zip Code,Chicago Business Owners,Chicago Land Use,Chicago Taxi Vehicles,Chicago Taxi Owners,CTA Ridership,CTA Calendar,CTA Stations,Movies,Movie Actors,Movie Ratings,Movie Casts,Movie Crews,Movie Genres,Movie Sequels,Movie Financial Data,Movie Tag Lines,S&P 500,World Bank GDP,World Bank Population,Data Manipulation with pandas",,
319,GARCH Models in Python,4,15,54,"5,381",3950,"Volatility is an essential concept in finance, which is why GARCH models in Python are a popular choice for forecasting changes in variance, specifically when working with time-series data that are time-dependant. This course will show you how and when to implement GARCH models, how to specify model assumptions, and how to make volatility forecasts and evaluate model performance. Using real-world data, including historical Tesla stock prices, you’ll gain hands-on experience of how to better quantify portfolio risks, through calculations of Value-at-Risk, covariance, and stock Beta. You’ll also apply what you’ve learned to a wide range of assets, including stocks, indices, cryptocurrencies, and foreign exchange, preparing you to go forth and use GARCH models.","Why do we need GARCH models,Understand volatility,Observe volatility clustering,Calculate volatility,What are ARCH and GARCH,Review GARCH model basics,Simulate ARCH and GARCH series,Observe the impact of model parameters,How to implement GARCH models in Python,Review ""arch"" documentation,Implement a basic GARCH model,Make forecast with GARCH models","Significance testing of model parameters,Keep it simple stupid,Simplify the model with p-values,Simplify the model with t-statistics,Validation of GARCH model assumptions,Detect autocorrelations,ACF plot,Ljung-Box test,Goodness of fit measures,Goodness of fit basics,Pick a winner based on log-likelihood,Pick a winner based on AIC/BIC,GARCH model backtesting,Backtesting basics,Backtesting with MAE, MSE","Distribution assumptions,Fat tails and skewness,Plot distribution of standardized residuals,Fit a GARCH with skewed t-distribution,Mean model specifications,Check mean model assumptions,Effect of mean model on volatility predictions,Volatility models for asymmetric shocks,Modeling of asymmetric responses of volatility,Fit GARCH models to cryptocurrency,Compare GJR-GARCH with EGARCH,GARCH rolling window forecast,Why use rolling window forecast,Fixed rolling window forecast,Compare forecast results","VaR in financial risk management,VaR concept,Compute parametric VaR,Compute empirical VaR,Dynamic covariance in portfolio optimization,Covariance concept,Compute GARCH covariance,Compute dynamic portfolio variance,Dynamic Beta in portfolio management,Beta concept,Compute dynamic stock Beta,Congratulations!","Adel Nehme,Amy Peterson","Applied Finance,SP500,Tesla stock price,Bitcoin price,Foreign exchange data,Time Series Analysis in Python",,
320,Data Manipulation with pandas,4,15,56,"203,483",4850,"pandas is the world's most popular Python library, used for everything from data manipulation to data analysis. In this course, you'll learn how to manipulate DataFrames, as you extract, filter, and transform real-world datasets for analysis. Using pandas you’ll explore all the core data science concepts. Using real-world data, including Walmart sales figures and global temperature time series, you’ll learn how to import, clean, calculate statistics, and create visualizations—using pandas to add to the power of Python!","Introducing DataFrames,Inspecting a DataFrame,Parts of a DataFrame,Sorting and subsetting,Sorting rows,Subsetting columns,Subsetting rows,Subsetting rows by categorical variables,New columns,Adding new columns,Combo-attack!","Explicit indexes,Setting and removing indexes,Subsetting with .loc[],Setting multi-level indexes,Sorting by index values,Slicing and subsetting with .loc and .iloc,Slicing index values,Slicing in both directions,Slicing time series,Subsetting by row/column number,Working with pivot tables,Pivot temperature by city and year,Subsetting pivot tables,Calculating on a pivot table","Summary statistics,Mean and median,Summarizing dates,Efficient summaries,Cumulative statistics,Counting,Dropping duplicates,Counting categorical variables,Grouped summary statistics,What percent of sales occurred at each store type?,Calculations with .groupby(),Multiple grouped summaries,Pivot tables,Pivoting on one variable,Fill in missing values and sum values with pivot tables","Visualizing your data,Which avocado size is most popular?,Changes in sales over time,Avocado supply and demand,Price of conventional vs. organic avocados,Missing values,Finding missing values,Removing missing values,Replacing missing values,Creating DataFrames,List of dictionaries,Dictionary of lists,Reading and writing CSVs,CSV to DataFrame,DataFrame to CSV,Wrap-up","Alex Yarosh,Adel Nehme,Amy Peterson,Justin Saddlemyer","Data Analyst,Data Manipulation,Data Scientist,Python Programmer,Avocado prices,Walmart sales,Homelessness data,Temperatures,Intermediate Python",,
321,Introduction to Bash Scripting,4,13,43,"18,476",3350,"Bash is a concise, superfast, and robust scripting language for data and file manipulation. It’s a vital skill for building analytics pipelines in the cloud, favored by Linux users to work with data stored across multiple files. In this course, we’ll guide you through the basics of Bash scripting. We begin with an introduction to Bash script structures, including inputting arguments and outputting results. You’ll then work through data structures, such as variables and arrays, and control statements, including loops and conditionals. You’ll then put what you’ve learned into practice, by creating your own Bash functions and scheduling automated scripts to run like clockwork with cron.","Introduction and refresher,Extracting scores with shell,Searching a book with shell,Your first Bash script,A simple Bash script,Shell pipelines to Bash scripts,Extract and edit using Bash scripts,Standard streams & arguments,Using arguments in Bash scripts,Using arguments with HR data","IF statements,Sorting model results,Moving relevant files,FOR loops & WHILE statements,A simple FOR loop,Correcting a WHILE statement,Cleaning up a directory,CASE statements,Days of the week with CASE,Moving model results with CASE,Finishing a CASE statement","Basic variables in Bash,Using variables in Bash,Shell within a shell,Numeric variables in Bash,Converting Fahrenheit to Celsius,Extracting data from files,Arrays in Bash,Creating an array,Creating associative arrays,Climate calculations in Bash","Basic functions in Bash,Uploading model results to the cloud,Get the current day,Arguments, return values, and scope,A percentage calculator,Sports analytics function,Summing an array,Scheduling your scripts with Cron,Analyzing a crontab schedule,Creating cronjobs,Scheduling cronjobs with crontab,Thanks and wrap up","Maggie Matsui,Lis Sulmont","Data Engineer,New Hires,Soccer Scores,Hire Data,Model Results,Rob's Files,Model Output,Inherited Folder,Introduction to Shell",,
322,Intermediate Regular Expressions in R,4,14,48,"2,884",3650,"Analyzing data that comes in tables is fun. But what if the things that we find most interesting are not available as a neatly organized dataset but in plain text? Do not despair: In this course, you'll learn everything you need to know to create powerful regular expressions that will help you find all the information you need for your analyses from just a blob of text. But not only that. Using the concept of string distances you will learn to work even with text that contains typos or scanning errors, as you will be able to match them to their correct counterparts from other data sources (record linkage). As a learning material, we will analyze real documents about box office figures in Swiss cinemas.","Welcome,Starts with, ends with,If you don't know what you're looking for,Character classes and repetitions,Digits, words and spaces,Match repetitions,Which special character did what again?,The pipe and the question mark,This or that,The question mark and its two meanings,You can now read this!","Capturing groups,Match all capturing groups,Search and replace,Can you nest capturing groups?,Tidyr's extract,Creating a regex that matches your needs,Why does this fail?,Extracting an advanced regular expression,Extracting matches and surroundings from a text,Extract names with context,So many special characters","Getting to know glue,Stop pasting, start gluing,Gluing data frames,How many arguments can glue take?,Collapsing multiple elements into a string,Formulating a question from a list,Collapsing data frames,Glue and Collapse, what's the difference?,Gluing regular expressions,Construct ""or patterns"" with glue,Using the ""or pattern"" with a larger dataset,Make advanced patterns more readable","Understanding string distances,Calculating a string distance,Finding a match to a search typo,Methods of string distances,Edit distances vs. q-gram methods,Trying out different methods,Is one distance better than the other?,Fuzzy joins,Performing a string distance join,String distances of short strings,Custom Fuzzy Matching,Finding matches based on two conditions,Why join on multiple columns?,Congratulations","Adel Nehme,Amy Peterson","Introduction to R,Introduction to the Tidyverse,String Manipulation with stringr in R",,
323,Introduction to Oracle SQL,4,15,54,"5,683",4500,"Oracle SQL is one of the most widely used database management system around the world. It's well suited to power primarily commercial and enterprise applications, and is particularly popular at large companies with mission-critical databases. Mastering Oracle SQL is therefore guaranteed to open exciting opportunities.

In this course, you will get a complete introduction to Oracle SQL solving business problems for a digital media store. You will first learn how to access, retrieve and restrict data. You will then perform aggregation and combine tables. The last chapter will have you handle missing values and convert data. By the end of this course, you will understand how Oracle processes SQL queries and will have a solid foundation in Oracle SQL.","What is an Oracle database?,Writing your first query,Relational databases,Retrieving data,Removing duplicates,Working with strings,Arithmetic expressions,Ordering,Restricting data,Comparison operators,Logical operators,Comparison keywords","Using joins,Inner joins,Using USING,Joining multiple tables,Outer joins,Picking an outer join type,Left outer join,Right outer join,More joins,Cross joins,Self joins,Set operators,I want it all,Under pressure,Another one bites the dust","Group functions,Getting started with group functions,Counting,Data types,Creating groups of data,Grouping,Advanced grouping,Restricting group results,Restricting groups,More restricting,Combining WHERE and HAVING","Query processing order,Order of execution of a query,Mistakes against query processing order,Customizing output,Rounding numbers,Working with the modulo,Manipulating strings,Replacing letters,Working with NULL values,Testing if a value is NULL,Replacing NULL values,Comparing values,Using conversion functions,Implicit and explicit conversion,Conversion functions,Congratulations!",Lis Sulmont,Chinook data,,
324,Database Design,4,13,52,"33,612",4150,"A good database design is crucial for a high-performance application. Just like you wouldn't start building a house without the benefit of a blueprint, you need to think about how your data will be stored beforehand. Taking the time to design a database saves time and frustration later on, and a well-designed database ensures ease of access and retrieval of information. While choosing a design, a lot of considerations have to be accounted for. In this course, you'll learn how to process, store, and organize data in an efficient way. You'll see how to structure data through normalization and present your data with views. Finally, you'll learn how to manage your database and all of this will be done on a variety of datasets from book sales, car rentals, to music reviews.","OLTP and OLAP,OLAP vs. OLTP,Which is better?,Storing data,Name that data type!,Ordering ETL Tasks,Recommend a storage solution,Database design,Classifying data models,Deciding fact and dimension tables,Querying the dimensional model","Database views,Tables vs. views,Viewing views,Creating and querying a view,Managing views,Creating a view from other views,Granting and revoking access,Updatable views,Redefining a view,Materialized views,Materialized versus non-materialized,Creating and refreshing a materialized view,Managing materialized views","Star and snowflake schema,Running from star to snowflake,Adding foreign keys,Extending the book dimension,Normalized and denormalized databases,Querying the star schema,Querying the snowflake schema,Updating countries,Extending the snowflake schema,Normal forms,Converting to 1NF,Converting to 2NF,Converting to 3NF","Database roles and access control,Create a role,GRANT privileges and ALTER attributes,Add a user role to a group role,Table partitioning,Reasons to partition,Partitioning and normalization,Creating vertical partitions,Creating horizontal partitions,Data integration,Data integration do's and dont's,Analyzing a data integration plan,Picking a Database Management System (DBMS),SQL versus NoSQL,Choosing the right DBMS","Vincent Vankrunkelsven,Ruanne Van Der Walt,Hervé Eerebout,Hadrien Lacroix,David Venturi,Sara Billen,Jeroen Hermans,Tim Sangster","Data Engineer,SQL for Database Administrators,SQL Server Developer,SQL Server for Database Administrators,Chicago 311 Service Requests,Pitchfork Reviews,Introduction to Relational Databases in SQL",,
325,Predicting CTR with Machine Learning in Python,4,15,57,"2,510",4700,"Have you ever wondered how companies like Facebook and Google are able to serve you surprisingly targeted ads that you occasionally click? Well, behind the scenes, they are running sophisticated machine learning models and using rich user data to predict the click-through rate (CTR) for every user who sees those ads. This course will teach you how to implement basic models in Python so that you can see how to better optimize ads with machine learning. Using real-life ad data you’ll learn how to engineer features, build machine learning models using those features, and evaluate your models in the context of CTR prediction. By the end of this course, you’ll have a strong understanding of how you can apply machine learning to make your ads more effective.","Introduction to click-through rates,Beginning steps,Feature exploration,First evaluation of data,Overview of machine learning models,Logistic regression for breast cancer,Logistic regression for images,A second toy model,CTR prediction using decision trees,Model implementation,A first CTR model,Beyond only accuracy","Applications of metric evaluation,Four categories of outcomes,Evaluating four categories,ROI on ad spend,Model evaluation,Precision and recall,Baseline,Classifier comparison,Tuning models,Regularization,Cross validation,Model selection,Ensembles and hyperparameter tuning,Understanding hyperparameter tuning,Random forests,Grid search","Exploratory data analysis,A first look,Checking for missing values,Distributions by CTR,Feature engineering,Analyzing datetime columns,Converting categorical variables,Creating new features,Standardizing features,Log normalization,Understanding standardization,Standard scaling","Introduction to deep learning,Understanding MLPs,Beginning model,MLPs for CTR,Hyperparameter tuning in deep learning,Hyperparameter tuning in MLPs,Varying hyperparameters,MLP Grid Search,Model evaluation,F-beta score,Low precision and high AUC,Precision, ROI, and AUC,Model review and comparison,Model comparison warmup,Evaluating precision and ROI,Total scoring,Wrap-up video","Maggie Matsui,Lis Sulmont","Avazu,Data Manipulation with pandas",,
326,Natural Language Generation in Python,4,13,52,"3,635",4550,"Have you ever wondered how Gmail autocompletes your sentences, or, what powers the WhatsApp suggestions when you’re typing a message? The technology behind these helpful writing hints is machine learning. In this course, you'll build and train machine learning models for different natural language generation tasks. For example, you'll train a model on the literary works of Shakespeare and generate text in the style of his writing. You'll also learn how to create a neural translation model to translate English sentences into French. Finally, you'll train a seq2seq model to generate your own natural language autocomplete sentences, just like Gmail!","Handling sequential data,Preprocess names dataset,Preprocessing names dataset (cont'd),Introduction to recurrent neural network,Create input and target tensors,Initialize input and target vectors with values,Build and compile RNN network,Inference using recurrent neural network,Train RNN model and start predictions,Generate baby names","Introduction to sequence to sequence models,Create the eng-fra the dataset,Getting the vocabularies,Mapping characters to integers and vice-versa,Neural machine translation,Define the input and target vectors,Initialize the input and target vectors,Building the encoder and the decoder,Train the encoder decoder network,Inference model for encoder and decoder,Build inference models for encoder and decoder,Predict the first character,Predict the second character,Generate a fully translated sentence","Limitations of recurrent neural networks,Vanishing and exploding gradients,Simple network using Keras,Vanishing gradients,Introduction to long short term memory,Vocabulary and character to integer mapping,Input and target dataset,Create and initialize the input and target vectors,Create LSTM model in keras,Inference using long short term memory,Train LSTM model,Predict next character given a sequence,Generate text imitating Shakespeare","Convert email data to seq2seq,Divide the sentences into prefixes and suffixes,Create the vocabulary and the mappings,Define the input and target vectors,Initialize the input and target vectors,Sentence autocompletion using Encoder-Decoder,Building the encoder,Building the decoder,Train the encoder and decoder,Autocomplete sentences using inference models,Building the inference models,Predict the first character using inference models,Predict the second character,Autocomplete sentences,Congratulations","Adel Nehme,Lis Sulmont","Deep Learning for NLP,Shakespear text,Names,Introduction to Natural Language Processing in Python,Advanced Deep Learning with Keras",,
327,Joining Data with dplyr,4,13,49,"41,546",4200,"Often in data science, you'll encounter fascinating data that is spread across multiple tables. This course will teach you the skills you'll need to join multiple tables together to analyze them in combination. You'll practice your skills using a fun dataset about LEGOs from the Rebrickable website. The dataset contains information about the sets, parts, themes, and colors of LEGOs, but is spread across many tables. You'll work with the data throughout the course as you learn a total of six different joins! You'll learn four mutating joins: inner join, left join, right join, and full join, and two filtering joins: semi join and anti join. In the final chapter, you'll apply your new skills to Stack Overflow data, containing each of the almost 300,000 Stack Oveflow questions that are tagged with R, including information about their answers, the date they were asked, and their score. Get ready to take your dplyr skills to the next level!","The inner_join verb,What columns would you join on?,Joining parts and part categories,Joining with a one-to-many relationship,Joining parts and inventories,Joining in either direction,Joining three or more tables,Joining three tables,What's the most common color?","The full_join verb,Differences between Batman and Star Wars,Aggregating each theme,Full joining Batman and Star Wars LEGO parts,Comparing Batman and Star Wars LEGO parts,The semi_join and anti_join verbs,Select the join,Something within one set but not another,What colors are included in at least one set?,Which set is missing version 1?,Visualizing set differences,Aggregating sets to look at their differences,Combining sets,Visualizing the difference: Batman and Star Wars","The left_join verb,Left joining two sets by part and color,Left joining two sets by color,Finding an observation that doesn't have a match,The right_join verb,Which join is best?,Counting part colors,Cleaning up your count,Joining tables to themselves,Joining themes to their children,Joining themes to their grandchildren,Left joining a table to itself","Stack Overflow questions,Left joining questions and tags,Comparing scores across tags,What tags never appear on R questions?,Joining questions and answers,Finding gaps between questions and answers,Joining question and answer counts,Joining questions, answers, and tags,Average answers by question,The bind_rows verb,Joining questions and answers with tags,Binding and counting posts with tags,Visualizing questions and answers in tags,Congratulations!",Amy Peterson,"Data Analyst,Data Manipulation,Data Scientist,sets,themes,parts,part_categories,inventories,inventory_parts,colors,questions,tags,question_tags,answers,Data Manipulation with dplyr",,
328,Intermediate Python for Finance,4,15,52,"11,870",4150,"Are you a financial or business analyst, or simply looking for an easier way to manage your stock portfolio? If so learning Python can automate financial tasks such as calculating risk, mapping market health, and visualizing a stock's price trends, saving you time and money. In this course, you’ll learn how to use Python data structures, execution control statements, and DataFrames to manipulate financial data. You will then work with pandas, using data from the Federal Reserve Bank, to explore national economic trends—an essential part of understanding investment strategies. You will also calculate risk based on stock price data, and display this data in easy to read plots. By the end of this course, you’ll be the new Python of Wall Street.","Representing time with datetimes,Creating datetimes for dates,Datetimes from strings,Converting format with datetimes,Working with datetimes,Accessing datetime attributes,Comparing datetimes,Making relative datetimes,Dictionaries,Creating and accessing dictionaries,Accessing safely and deleting","Creating a DataFrame,Creating DataFrames,Reading market history,Accessing Data,Accessing using names,Accessing using indexes,Aggregating and summarizing,Mean prices,Median prices,Extending and manipulating data,Creating new columns,Dropping columns from DataFrame,Manipulating data with Pandas","Comparison operators,Equality across types,Assignment and equality,Comparing dividends,Boolean operators,Decisions with Boolean operations,Assigning variables with Boolean operators,Negating with Boolean operators,If statements,Control statements,Comparing sales and purchases,Branching with elif and else,For and while loops,Breaking out of a for loop,Controlling loop execution","Peeking at data with head, tail, and describe,Why use describe,Peek at top and bottom,Describing data,Filtering data,Why filter data,Filtering stock data.,Selecting data from data range,Plotting data,Identifying plot type,Making a line plot,Choose kind of plot,Wrapping up",Adel Nehme,"Finance Fundamentals,Alphabet stock,Introduction to Python for Finance",,
329,Practicing Statistics Interview Questions in R,4,16,50,"2,582",4200,"Are you job interview ready? You may know everything there is to know about your target company, but have you practiced the classic R statistical interview questions? If not, we have you covered. In this course, you'll prepare for the most frequently covered statistical topics from distributions to hypothesis testing, regression models, and much more. You’ll sharpen your skills using datasets including Parkinson’s disease data and gas prices. This course is purposely more challenging than a typical DataCamp course to make sure that when it comes to interviewing time you’re ready to confidently tackle any statistics interview question in R.","Discrete distributions,Probability functions,Bernoulli trials,Binomial distribution,Continuous distributions,Uniform distribution,Shape of normal distribution,Sample from normal distribution,Central limit theorem,Law of large numbers,Simulating central limit theorem","Normality tests,Shapiro-Wilk test,Q-Q plot,Inference for a mean,Confidence interval,One-sample t-test,Comparing two means,Two-sample t-test,Paired test,ANOVA,Comparing groups,ANOVA for plant growth","Descriptive statistics,Centrality measures,Variability measures,Categorical data,Survey analysis,Data encoding,Time series,Time series object,Wrangling time series,Principal Component Analysis,PCA - rotation,PCA - dimension reduction","Covariance and correlation,Covariance by hand,Linear relationship,Nonlinear relationship,Linear regression model,Fitting linear models,Predicting with linear models,Logistic regression model,Fitting logistic models,Predicting with logistic models,Model evaluation,Validation set approach,Regression evaluation,Classification evaluation,Wrapping up","Maggie Matsui,Anneleen Beckers","Natural Gas,Gold monthly,Parkinson's Data,Letter Recognition,Intermediate R,Foundations of Inference,Foundations of Probability in R",,
330,Creating PostgreSQL Databases,4,16,51,"6,938",4100,"You have experience working with databases or, perhaps, you have heard how useful databases can be for organizing your data. Have you ever wanted to create and manage your own databases but thought such knowledge is reserved for database administrators? Well, it is not! This course teaches you the skills and knowledge necessary to create and manage your own PostgreSQL databases. Topics that will be covered include the structure of PostgreSQL databases, PostgreSQL datatypes, and normalization of databases to efficiently store data and avoid data loss. These topics will be taught using data from the U.S. Small Business Administration (SBA) to guide the lessons and provide context for the concepts covered in the course.","Creating a database,New database creation,Motivation for a new database,Creating tables,Name that table,Two tables and a foreign key connection,Creating schemas,User-level schemas,The public schema,Creating tables in existing schemas","The importance of data normalization,Reasons for normalizing databases,Reducing data redundancy,Improving object-to-data mapping,1st Normal Form,Simplifying database records,Too much normalization,2nd Normal Form,Designing a course table,Streamlining meal options,3rd Normal Form,Identifying transitive dependencies,Table definitions for 3rd Normal Form,Working through the normalization process","Introduction to PostgreSQL data types,Matching data representations and categories,Choosing data types at table creation,Defining text columns,Matching text types,SBA appeals table,Defining numeric data columns,Using integer types,Supporting an SBA marketing campaign,Defining boolean and temporal data columns,Revisiting the appeals table,Boolean defaults,Choosing data types representations","Introduction to access control,Creating a new user,Updating user passwords,PostgreSQL access privileges,Granting user privileges,Using the granted privileges,Hierarchical access control,Working with users and groups,Schema privileges,Removing access,Removing user privileges,Rescinding group membership,Implementing access control for teams,Course wrap-up","Maggie Matsui,David Venturi","SQL for Database Administrators,Introduction to SQL",,
331,Time Series Analysis in Python,4,17,59,"46,834",4850,"From stock prices to climate data, time series data are found in a wide variety of domains, and being able to effectively work with such data is an increasingly important skill for data scientists. This course will introduce you to time series analysis in Python. After learning about what a time series is, you'll learn about several time series models ranging from autoregressive and moving average models to cointegration models. Along the way, you'll learn how to estimate, forecast, and simulate these models using statistical libraries in Python. You'll see numerous examples of how these models are used, with a particular emphasis on applications in finance.","Introduction to Course,A ""Thin"" Application of Time Series,Merging Time Series With Different Dates,Correlation of Two Time Series,Correlation of Stocks and Bonds,Flying Saucers Aren't Correlated to Flying Markets,Simple Linear Regression,Looking at a Regression's R-Squared,Match Correlation with Regression Output,Autocorrelation,A Popular Strategy Using Autocorrelation,Are Interest Rates Autocorrelated?","Describe AR Model,Simulate AR(1) Time Series,Compare the ACF for Several AR Time Series,Match AR Model with ACF,Estimating and Forecasting AR Model,Estimating an AR Model,Forecasting with an AR Model,Let's Forecast Interest Rates,Compare AR Model with Random Walk,Choosing the Right Model,Estimate Order of Model: PACF,Estimate Order of Model: Information Criteria","Cointegration Models,A Dog on a Leash? (Part 1),A Dog on a Leash? (Part 2),Are Bitcoin and Ethereum Cointegrated?,Case Study: Climate Change,Is Temperature a Random Walk (with Drift)?,Getting ""Warmed"" Up: Look at Autocorrelations,Which ARMA Model is Best?,Don't Throw Out That Winter Coat Yet,Congratulations","Autocorrelation Function,Taxing Exercise: Compute the ACF,Are We Confident This Stock is Mean Reverting?,White Noise,Can't Forecast White Noise,Random Walk,Generate a Random Walk,Get the Drift,Are Stock Prices a Random Walk?,How About Stock Returns?,Stationarity,Is it Stationary?,Seasonal Adjustment During Tax Season","Lore Dirick,Nick Solomon","Time Series,Financial time series datasets,UFO sightings,New York temperature data,Manipulating Time Series Data in Python","Describe Model,Simulate MA(1) Time Series,Compute the ACF for Several MA Time Series,Match ACF with MA Model,Estimation and Forecasting an MA Model,Estimating an MA Model,Forecasting with MA Model,ARMA  models,High Frequency Stock Prices,More Data Cleaning: Missing Data,Applying an MA Model,Equivalence of AR(1) and MA(infinity)",
332,Manipulating Time Series Data in Python,4,16,55,"39,126",4700,"In this course you'll learn the basics of manipulating time series data. Time series data are data that are indexed by a sequence of dates or times. You'll learn how to use methods built into Pandas to work with this index. You'll also learn how resample time series to change the frequency. This course will also show you how to calculate rolling and cumulative values for times series. Finally, you'll use all your new skills to build a value-weighted stock index from actual stock data.","How to use dates & times with pandas,Your first time series,Indexing & resampling time series,Create a time series of air quality data,Compare annual stock price trends,Set and change time series frequency,Lags, changes, and returns for stock price series,Shifting stock prices across time,Calculating stock price changes,Plotting multi-period returns","Rolling window functions with pandas,Rolling average air quality since 2010 for new york city,Rolling 360-day median & std. deviation for nyc ozone data since 2000,Rolling quantiles for daily air quality in nyc,Expanding window functions with pandas,Cumulative sum vs .diff(),Cumulative return on $1,000 invested in google vs apple I,Cumulative return on $1,000 invested in google vs apple II,Case study: S&P500 price simulation,Random walk I,Random walk II,Random walk III,Relationships between time series: correlation,Annual return correlations among several stocks","Compare time series growth rates,Compare the performance of several asset classes,Comparing stock prices with a benchmark,Plot performance difference vs benchmark index,Changing the time series frequency: resampling,Convert monthly to weekly data,Create weekly from monthly unemployment data,Upsampling & interpolation with .resample(),Use interpolation to create weekly employment data,Interpolate debt/GDP and compare to unemployment,Downsampling & aggregation,Compare weekly, monthly and annual ozone trends for NYC & LA,Compare monthly average stock prices for Facebook and Google,Compare quarterly GDP growth rate and stock returns,Visualize monthly mean, median and standard deviation of S&P500 returns","Select index components & import data,Explore and clean company listing information,Select and inspect index components,Import index component price information,Build a market-cap weighted index,Calculate number of shares outstanding,Create time series of market value,Calculate & plot the composite index,Evaluate index performance,Calculate the contribution of each stock to the index,Compare index performance against benchmark I,Compare index performance against benchmark II,Index correlation & exporting to Excel,Visualize your index constituent correlations,Save your analysis to multiple excel worksheets,Congratulations!","Lore Dirick,Nick Solomon","Finance Fundamentals,Time Series,Air quality data,Stock data,Data Manipulation with pandas",,
333,Introduction to Data Science in Python,4,13,44,"343,607",3700,"Begin your journey into Data Science! Even if you've never written a line of code in your life, you'll be able to follow this course and witness the power of Python to perform Data Science. You'll use data to solve the mystery of Bayes, the kidnapped Golden Retriever, and along the way you'll become familiar with basic Python syntax and popular Data Science modules like Matplotlib (for charts and graphs) and pandas (for tabular data).","Dive into Python,Importing Python modules,Correcting a broken import,Creating variables,Creating a float,Creating strings,Correcting string errors,Valid variable names,Fun with functions,Load a DataFrame,Correcting a function error,Snooping for suspects","Creating line plots,Working hard,Or hardly working?,Adding text to plots,Adding a legend,Adding labels,Adding floating text,Styling graphs,Tracking crime statistics,Playing with styles,Identifying Bayes' kidnapper","What is pandas?,Loading a DataFrame,Inspecting a DataFrame,Selecting columns,Two methods for selecting columns,Correcting column selection errors,More column selection mistakes,Selecting rows with logic,Logical testing,Selecting missing puppies,Narrowing the list of suspects","Making a scatter plot,Charting cellphone data,Modifying a scatterplot,Making a bar chart,Build a simple bar chart,Where did the time go?,Making a histogram,Modifying histograms,Heroes with histograms,Recap of the rescue",Mona Khalil,"Data Analyst,Data Skills for Business,Python Programmer",,
334,Writing Efficient Python Code,4,15,53,"73,683",4050,"As a Data Scientist, the majority of your time should be spent gleaning actionable insights from data -- not waiting for your code to finish running. Writing efficient Python code can help reduce runtime and save computational resources, ultimately freeing you up to do the things you love as a Data Scientist. In this course, you'll learn how to use Python's built-in data structures, functions, and modules to write cleaner, faster, and more efficient code. We'll explore how to time and profile code in order to find bottlenecks. Then, you'll practice eliminating these bottlenecks, and other bad design patterns, using Python's Standard Library, NumPy, and pandas. After completing this course, you'll have the necessary tools to start writing efficient Python code!","Welcome!,Pop quiz: what is efficient,A taste of things to come,Zen of Python,Building with built-ins,Built-in practice: range(),Built-in practice: enumerate(),Built-in practice: map(),The power of NumPy arrays,Practice with NumPy arrays,Bringing it all together: Festivus!","Efficiently combining, counting, and iterating,Combining Pokémon names and types,Counting Pokémon from a sample,Combinations of Pokémon,Set theory,Comparing Pokédexes,Searching for Pokémon,Gathering unique Pokémon,Eliminating loops,Gathering Pokémon without a loop,Pokémon totals and averages without a loop,Writing better loops,One-time calculation loop,Holistic conversion loop,Bringing it all together: Pokémon z-scores","Examining runtime,Using %timeit: your turn!,Using %timeit: specifying number of runs and loops,Using %timeit: formal name or literal syntax,Using cell magic mode (%%timeit),Code profiling for runtime,Pop quiz: steps for using %lprun,Using %lprun: spot bottlenecks,Using %lprun: fix the bottleneck,Code profiling for memory usage,Pop quiz: steps for using %mprun,Using %mprun: Hero BMI,Using %mprun: Hero BMI 2.0,Bringing it all together: Star Wars profiling","Intro to pandas DataFrame iteration,Iterating with .iterrows(),Run differentials with .iterrows(),Another iterator method: .itertuples(),Iterating with .itertuples(),Run differentials with .itertuples(),pandas alternative to looping,Analyzing baseball stats with .apply(),Settle a debate with .apply(),Optimal pandas iterating,Replacing .iloc with underlying arrays,Bringing it all together: Predict win percentage,Congratulations!","Chester Ismay,Becca Robins","Data Engineer,Python Programmer,Python Programming,Python Toolbox,Baseball statistics,Data Types for Data Science in Python,Python Data Science Toolbox (Part 2)",,
335,Intermediate SQL,4,15,55,"131,195",4700,"So you've learned how to aggregate and join data from tables in your database—now what? How do you manipulate, transform, and make the most sense of your data? This intermediate-level course will teach you several key functions necessary to wrangle, filter, and categorize information in a relational database, expand your SQL toolkit, and answer complex questions. You will learn the robust use of CASE statements, subqueries, and window functions—all while discovering some interesting facts about soccer using the European Soccer Database.","We'll take the CASE,Basic CASE statements,CASE statements comparing column values,CASE statements comparing two column values part 2,In CASE things get more complex,In CASE of rivalry,Filtering your CASE statement,CASE WHEN with aggregate functions,COUNT using CASE WHEN,COUNT and CASE WHEN with multiple conditions,Calculating percent with CASE and AVG","Correlated subqueries,Basic Correlated Subqueries,Correlated subquery with multiple conditions,Nested subqueries,Nested simple subqueries,Nest a subquery in FROM,Common Table Expressions,Clean up with CTEs,Organizing with CTEs,CTEs with nested subqueries,Deciding on techniques to use,Get team names with a subquery,Get team names with correlated subqueries,Get team names with CTEs,Which technique to use?","WHERE are the Subqueries?,Filtering using scalar subqueries,Filtering using a subquery with a list,Filtering with more complex subquery conditions,Subqueries in FROM,Joining Subqueries in FROM,Building on Subqueries in FROM,Subqueries in SELECT,Add a subquery to the SELECT clause,Subqueries in Select for Calculations,Subqueries everywhere! And best practices!,ALL the subqueries EVERYWHERE,Add a subquery in FROM,Add a subquery in SELECT","It's OVER,The match is OVER,What's OVER here?,Flip OVER your results,OVER with a PARTITION,PARTITION BY a column,PARTITION BY multiple columns,Sliding windows,Slide to the left,Slide to the right,Bringing it all together,Setting up the home team CTE,Setting up the away team CTE,Putting the CTEs together,Add a window function","Sumedh Panchadhar,Hillary Green-Lerman","Data Analyst,SQL Fundamentals,Joining Data in SQL",,
336,Exploratory Data Analysis in SQL,4,16,58,"56,153",4750,"You have access to a database. Now what do you do? Building on your existing skills joining tables, using basic functions, grouping data, and using subqueries, the next step in your SQL journey is learning how to explore a database and the data in it. Using data from Stack Overflow, Fortune 500 companies, and 311 help requests from Evanston, IL, you'll get familiar with numeric, character, and date/time data types. You'll use functions to aggregate, summarize, and analyze data without leaving the database. Errors and inconsistencies in the data won't stop you! You'll learn common problems to look for and strategies to clean up messy data. By the end of this course, you'll be ready to start exploring your own PostgreSQL databases and analyzing the data in them.","What's in the database?,Explore table sizes,Count missing values,Join tables,The keys to the database,Foreign keys,Read an entity relationship diagram,Coalesce,Coalesce with a self-join,Column types and constraints,Effects of casting,Summarize the distribution of numeric values","Character data types and common issues,Count the categories,Spotting character data problems,Cases and spaces,Trimming,Exploring unstructured text,Splitting and concatenating text,Concatenate strings,Split strings on a delimiter,Shorten long strings,Strategies for multiple transformations,Create an ""other"" category,Group and recode values,Create a table with indicator variables","Numeric data types and summary functions,Division,Explore with division,Summarize numeric columns,Summarize group statistics,Exploring distributions,Truncate,Generate series,More summary functions,Correlation,Mean and Median,Creating temporary tables,Create a temp table,Create a temp table to simplify a query,Insert into a temp table","Date/time types and formats,ISO 8601,Date comparisons,Date arithmetic,Completion time by category,Date/time components and aggregation,Date parts,Variation by day of week,Date truncation,Aggregating with date/time series,Find missing dates,Custom aggregation periods,Monthly average with missing dates,Time between events,Longest gap,Rats!,Wrap-up","Chester Ismay,Adrián Soto,Mona Khalil","Data Analyst,SQL for Business Analysts,Stack Overflow Question Counts,Fortune 500 Companies,Evanston 311 Help Requests,Course Database Creation Code,Course Database Entity Relationship Diagram,Intermediate SQL",,
337,Software Engineering for Data Scientists in Python,4,15,51,"27,931",4100,"Data scientists can experience huge benefits by learning concepts from the field of software engineering, allowing them to more easily reutilize their code and share it with collaborators. In this course, you'll learn all about the important ideas of modularity, documentation, & automated testing, and you'll see how they can help you solve Data Science problems quicker and in a way that will make future you happy. You'll even get to use your acquired software engineering chops to write your very own Python package for performing text analytics.","Python, data science, & software engineering,The big ideas,Python modularity in the wild,Introduction to packages & documentation,Installing packages with pip,Leveraging documentation,Conventions and PEP 8,Using pycodestyle,Conforming to PEP 8,PEP 8 in documentation","Adding classes to a package,Writing a class for your package,Using your package's class,Adding functionality to classes,Writing a non-public method,Using your class's functionality,Classes and the DRY principle,Using inheritance to create a class,Adding functionality to a child class,Using your child class,Multilevel inheritance,Exploring with dir and help,Creating a grandchild class,Using inherited methods","Writing your first package,Minimal package requirements,Naming packages,Recognizing packages,Adding functionality to packages,Adding functionality to your package,Using your package's new functionality,Making your package portable,Writing requirements.txt,Installing package requirements,Creating setup.py,Listing requirements in setup.py","Documentation,Identifying good comments,Identifying proper docstrings,Writing docstrings,Readability counts,Using good function names,Using good variable names,Refactoring for readability,Unit testing,Using doctest,Using pytest,Documentation & testing in practice,Documenting classes for Sphinx,Identifying tools,Final Thoughts","Chester Ismay,Adrián Soto","Python Programmer,Python Programming,Python Data Science Toolbox (Part 1),Introduction to Shell",,
338,Designing Machine Learning Workflows in Python,4,16,51,"7,764",4200,"Deploying machine learning models in production seems easy with modern tools, but often ends in disappointment as the model performs worse in production than in development. This course will give you four superpowers that will make you stand out from the data science crowd and build pipelines that stand the test of time: how to exhaustively tune every aspect of your model in development; how to make the best possible use of available domain expertise; how to monitor your model in performance and deal with any performance deterioration; and finally how to deal with poorly or scarcely labelled data. Digging deep into the cutting edge of sklearn, and dealing with real-life datasets from hot areas like personalized healthcare and cybersecurity, this course reveals a view of machine learning from the frontline.","Supervised learning pipelines,Feature engineering,Your first pipeline,Model complexity and overfitting,Grid search CV for model complexity,Number of trees and estimators,Feature engineering and overfitting,Categorical encodings,Feature transformations,Bringing it all together","From workflows to pipelines,Your first pipeline - again!,Custom scorers in pipelines,Model deployment,Pickles,Custom function transformers in pipelines,Iterating without overfitting,Challenge the champion,Cross-validation statistics,Dataset shift,Tuning the window size,Bringing it all together","Data fusion,Is the source or the destination bad?,Feature engineering on grouped data,Imperfect labels,Turning a heuristic into a classifier,Combining heuristics,Dealing with label noise,Loss functions Part I,Reminder of performance metrics,Real-world cost analysis,Confusion matrix calculations,Loss functions Part II,Default thresholding,Optimizing the threshold,Bringing it all together","Anomaly detection,A simple outlier,LoF contamination,Novelty detection,A simple novelty,Three novelty detectors,Contamination revisited,Distance-based learning,Find the neighbor,Not all metrics agree,Unstructured data,Restricted Levenshtein,Bringing it all together,Concluding remarks","Chester Ismay,Sara Billen","Credit,Flows,Attacks,Hepatitis,Proteins,Arrhythmia,Python Data Science Toolbox (Part 2),Unsupervised Learning in Python,Supervised Learning with scikit-learn",,
339,Business Process Analytics in R,4,16,58,"4,291",4550,"Although you might not have realized, processes take up an indispensable role in our daily lives. Your actions and those of others generate an extensive amount of data. Whether you are ordering a book, a train crosses a red light, or your thermostat heats your bathroom, every second millions of events are taking place which are stored in data centers around the world. These enormous sets of event data can be used to gain insight into processes in a virtually unlimited range of fields. However, the analysis of this data requires its own set of specific formats and techniques. This course will introduce you to process mining with R and demonstrate the different steps needed to analyze business processes.","Introduction to process analytics,Identify process elements,Process Analysis Workflow,Activities as cornerstones of processes,Retrieve basic process information,Explore activities,The happy path,Create process maps,Components of process data,Event data identifiers,Constructing event data objects,Inspecting event data objects","Filtering cases,The path well traveled,The downside of rejections,The downside of refusals,Filtering events,The vicious disapproval circle,Working with high-paid R&D candidates,Aggreggating events,Disapprovals are disapprovals,Zooming out,Admiring the view,Enriching events,Everything has a cost,Cost versus urgency","Organizational analysis,Specialization of resources,Detecting roles and specializations,Involvement of resources,Structuredness,Process variants,Rework,Precedence matrix,Performance analysis,Eating habits,Eating habits - Dotted chart,Eat, sleep, repeat,Linking perspectives,The right person on the job I,The right person on the job II,The right person on the job faster","Preparing the event data,Transforming Sales Data (1/3),Transforming Sales Data (2/3),Transforming Sales Data (3/3),Putting the process together,Creating the event log,Getting to know the process,Examining Traces,Zooming Out,Roles and Rules,Resource Roles,The 4-Eye Principle,Control-flow deviations,Fast Production, Fast Delivery,Throughput time analysis,Course Recap","Richie Cotton,Yashas Roy","Eating patterns,Order-to-cash process,Working with Data in the Tidyverse",,
340,Human Resources Analytics: Exploring Employee Data in R,5,16,60,"8,635",4750,"HR analytics, people analytics, workforce analytics -- whatever you call it, businesses are increasingly counting on their human resources departments to answer questions, provide insights, and make recommendations using data about their employees. In this course, you'll learn how to manipulate, visualize, and perform statistical tests on HR data through a series of HR analytics case studies.","Welcome to the course!,Applications of human resources (HR) analytics,Looking at the recruiting data,Recruiting and quality of hire,Identifying groups in data,Sales numbers by recruiting source,Attrition rates by recruiting source,Visualizing the recruiting data,Visualizing the sales performance differences,Visualizing the attrition differences,Drawing conclusions","Paying new hires fairly,Importing the pay data,Is the difference significant?,Omitted variable bias,Omitted variable bias examples,What other differences exist?,What does the pay difference look like now?,Are hourly hires paid more?,Linear regression,New hire pay: a simple regression,New hire pay: accounting for job levels,Drawing conclusions from the tests","Employee safety,Importing and joining the accident data,Where is the highest accident rate?,Where did the accident rate increase most?,Focusing on the location of interest,Focusing on the problem location,Bringing in more data,Checking for omitted variables,Is that change isolated to the problem location?,Explaining the increase in accidents,Using regression to identify change drivers,What can you conclude?,Conclusion","Analyzing employee engagement,Importing the survey data,Which department has the lowest engagement?,Comparing other factors by department,Visualizing the engagement data,Visualizing several variables at once,Visualizing several variables at once with facets,Drawing conclusions from graphs,Is that difference meaningful?,Statistical significance - disengaged employees,Statistical significance - vacation days,Drawing conclusions from the tests","Sumedh Panchadhar,Richie Cotton","Recruitment data,Survey data,Fair pay data,Performance data,HR data,Accident data,HR data (2),Survey data (2),Introduction to Regression in R","Joining HR data,Importing the two datasets,Joining performance data,Performance ratings and fairness,Focus on high performers,Comparing distributions of high performers,Checking for omitted variable bias,Logistic regression,Linear and logistic regression,Performance ratings: a simple logistic regression,Performance ratings: accounting for job levels,Conclusions and recommendations",
341,Introduction to Databases in Python,4,20,66,"88,191",5550,"In this course, you'll learn the basics of using SQL with Python. This will be useful because databases are ubiquitous and data scientists, analysts, and engineers must interact with them constantly. The Python SQL toolkit SQLAlchemy provides an accessible and intuitive way to query, build, and write to essential databases, including SQLite, MySQL, and PostgreSQL.","Introduction to Databases,Relational model,Connecting to your database,Engines and connection strings,Autoloading Tables from a database,Viewing Table details,Introduction to SQL queries,Selecting data from a Table: raw SQL,Selecting data from a Table with SQLAlchemy,Handling a ResultSet,Congratulations!","Calculating values in a query,Connecting to a MySQL database,Calculating a difference between two columns,Determining the overall percentage of women,SQL relationships,Automatic joins with an established relationship,Joins,More practice with joins,Working with hierarchical tables,Using alias to handle same table joined queries,Leveraging functions and group_bys with hierarchical data,Handling large ResultSets,Working on blocks of records","Census case study,Setup the engine and metadata,Create the table to the database,Populating the database,Reading the data from the CSV,Load data from a list into the Table,Querying the database,Determine the average age by population,Determine the percentage of population by gender and state,Determine the difference by state from the 2000 and 2008 censuses,Congratulations!","Filtering and targeting data,Connecting to a PostgreSQL database,Filter data selected from a Table - Simple,Filter data selected from a Table - Expressions,Filter data selected from a Table - Advanced,Ordering query results,Ordering by a single column,Ordering in descending order by a single column,Ordering by multiple columns,Counting, summing, and grouping data,Counting distinct data,Count of records by state,Determining the population sum by state,SQLAlchemy and pandas for visualization,ResultsSets and pandas DataFrames,From SQLAlchemy results to a plot",Hugo Bowne-Anderson,"Data Manipulation,Census (CSV),Census (SQLite),Employees (SQLite),Intermediate Python","Creating databases and tables,Creating tables with SQLAlchemy,Constraints and data defaults,Inserting data into a table,Inserting a single row,Inserting multiple records at once,Loading a CSV into a table,Updating data in a table,Updating individual records,Updating multiple records,Correlated updates,Deleting data from a database,Deleting all the records from a table,Deleting specific records,Deleting a table completely",
342,Machine Learning with caret in R,4,24,88,"50,787",6200,"Machine learning is the study and application of algorithms that learn from and make predictions on data. From search results to self-driving cars, it has manifested itself in all areas of our lives and is one of the most exciting and fast growing fields of research in the world of data science. This course teaches the big ideas in machine learning: how to build and evaluate predictive models, how to tune them for optimal performance, how to preprocess data for better results, and much more. The popular caret R package, which provides a consistent interface to all of R's most powerful machine learning facilities, is used throughout the course.","Welcome to the Toolbox,In-sample RMSE for linear regression,In-sample RMSE for linear regression on diamonds,Out-of-sample error measures,Out-of-sample RMSE for linear regression,Randomly order the data frame,Try an 80/20 split,Predict on test set,Calculate test set RMSE by hand,Comparing out-of-sample RMSE to in-sample RMSE,Cross-validation,Advantage of cross-validation,10-fold cross-validation,5-fold cross-validation,5 x 5-fold cross-validation,Making predictions on new data","Random forests and wine,Random forests vs. linear models,Fit a random forest,Explore a wider model space,Advantage of a longer tune length,Try a longer tune length,Custom tuning grids,Advantages of a custom tuning grid,Fit a random forest with custom tuning,Introducing glmnet,Advantage of glmnet,Make a custom trainControl,Fit glmnet with custom trainControl,glmnet with custom tuning grid,Why a custom tuning grid?,glmnet with custom trainControl and tuning,Interpreting glmnet plots","Reusing a trainControl,Why reuse a trainControl?,Make custom train/test indices,Reintroducing glmnet,glmnet as a baseline model,Fit the baseline model,Reintroducing random forest,Random forest drawback,Random forest with custom trainControl,Comparing models,Matching train/test indices,Create a resamples object,More on resamples,Create a box-and-whisker plot,Create a scatterplot,Ensembling models,Summary","Logistic regression on sonar,Why a train/test split?,Try a 60/40 split,Fit a logistic regression model,Confusion matrix,Confusion matrix takeaways,Calculate a confusion matrix,Calculating accuracy,Calculating true positive rate,Calculating true negative rate,Class probabilities and predictions,Probabilities and classes,Try another threshold,From probabilites to confusion matrix,Introducing the ROC curve,What's the value of a ROC curve?,Plot an ROC curve,Area under the curve (AUC),Model, ROC, and AUC,Customizing trainControl,Using custom trainControl","Nick Carchedi,Tom Jeon","Machine Learning Fundamentals,Machine Learning Scientist,Diamonds,Sonar,Wine,Overfit data,Breast Cancer,Blood-brain,Churn,Introduction to Regression in R","Median imputation,Median imputation vs. omitting rows,Apply median imputation,KNN imputation,Comparing KNN imputation to median imputation,Use KNN imputation,Compare KNN and median imputation,Multiple preprocessing methods,Order of operations,Combining preprocessing methods,Handling low-information predictors,Why remove near zero variance predictors?,Remove near zero variance predictors,preProcess() and nearZeroVar(),Fit model on reduced blood-brain data,Principle components analysis (PCA),Using PCA as an alternative to nearZeroVar()",
343,Credit Risk Modeling in R,4,16,52,"43,162",4000,,"Introduction and data structure,Exploring the credit data,Interpreting a CrossTable(),Histograms and outliers,Histograms,Outliers,Missing data and coarse classification,Deleting missing data,Replacing missing data,Keeping missing data,Data splitting and confusion matrices,Splitting the data set,Creating a confusion matrix","What is a decision tree?,Computing the gain for a tree,Changing one Gini...,Building decision trees using the rpart()-package,Undersampling the training set,Changing the prior probabilities,Including a loss matrix,Pruning the decision tree,Pruning the tree with changed prior probabilities,Pruning the tree with the loss matrix,Other tree options and  the construction of confusion matrices,One final tree using more options,Confusion matrices and accuracy of our final trees,Optimizing the accuracy","Logistic regression: introduction,Basic logistic regression,Interpreting the odds for a categorical variable,Multiple variables in a logistic regression model,Interpreting significance levels,Logistic regression:  predicting the probability of default,Predicting the probability of default,Making more discriminative models,Evaluating the logistic regression model result,Specifying a cut-off,Comparing two cut-offs,Wrap-up and remarks,Comparing link functions for a given cut-off","Finding the right cut-off: the strategy curve,Computing a bad rate given a fixed acceptance rate,The strategy table and strategy curve,To tree or not to tree?,The ROC-curve,ROC-curves for comparison of logistic regression models,ROC-curves for comparison of tree-based models,Input selection based on the AUC,Another round of pruning based on AUC,Best of four,Further model reduction?,Course wrap-up",,"Applied Finance,Quantitative Analyst,Loan Data Chapter 1,Loan Data Chapter 2, 3 and 4,Intermediate R for Finance",,
344,Intermediate Python,4,18,87,"805,026",7400,"Learning Python is crucial for any aspiring data science practitioner. Learn to visualize real data with Matplotlib's functions and get acquainted with data structures such as the dictionary and the pandas DataFrame. After covering key concepts such as boolean logic, control flow, and loops in Python, you'll be ready to blend together everything you've learned to solve a case study using hacker statistics.","Basic plots with Matplotlib,Line plot (1),Line Plot (2): Interpretation,Line plot (3),Scatter Plot (1),Scatter plot (2),Histogram,Build a histogram (1),Build a histogram (2): bins,Build a histogram (3): compare,Choose the right plot (1),Choose the right plot (2),Customization,Labels,Ticks,Sizes,Colors,Additional Customizations,Interpretation","Comparison Operators,Equality,Greater and less than,Compare arrays,Boolean Operators,and, or, not (1),and, or, not (2),Boolean operators with NumPy,if, elif, else,Warmup,if,Add else,Customize further: elif,Filtering pandas DataFrames,Driving right (1),Driving right (2),Cars per capita (1),Cars per capita (2)","Random Numbers,Random float,Roll the dice,Determine your next move,Random Walk,The next step,How low can you go?,Visualize the walk,Distribution,Simulate multiple walks,Visualize all walks,Implement clumsiness,Plot the distribution,Calculate the odds","Dictionaries, Part 1,Motivation for dictionaries,Create dictionary,Access dictionary,Dictionaries, Part 2,Dictionary Manipulation (1),Dictionary Manipulation (2),Dictionariception,Pandas, Part 1,Dictionary to DataFrame (1),Dictionary to DataFrame (2),CSV to DataFrame (1),CSV to DataFrame (2),Pandas, Part 2,Square Brackets (1),Square Brackets (2),loc and iloc (1),loc and iloc (2),loc and iloc (3)","Vincent Vankrunkelsven,Filip Schouwenaars","Data Analyst,Data Scientist,Python Fundamentals,Gapminder,Cars,BRICS,Introduction to Python","while loop,while: warming up,Basic while loop,Add conditionals,for loop,Loop over a list,Indexes and values (1),Indexes and values (2),Loop over list of lists,Loop Data Structures Part 1,Loop over dictionary,Loop over NumPy array,Loop Data Structures Part 2,Loop over DataFrame (1),Loop over DataFrame (2),Add column (1),Add column (2)",
345,Building Recommendation Engines in Python,4,16,60,"5,208",4850,"We’ve come to expect personalized experiences online—whether it’s Netflix recommending a show or an online retailer suggesting items you might also like to purchase. But how are these suggestions generated? In this course, you’ll learn everything you need to know to create your own recommendation engine. Through hands-on exercises, you’ll get to grips with the two most common systems, collaborative filtering and content-based filtering. Next, you’ll learn how to measure similarities like the Jaccard distance and cosine similarity, and how to evaluate the quality of recommendations on test data using the root mean square error (RMSE). By the end of this course, you’ll have built your very own movie recommendation engine and be able to apply your Python skills to create these systems for any industry.","What are recommendation engines?,Recommendation engines vs. predictions,Identifying the correct data for recommendation engines,Implicit vs. explicit data,Non-personalized recommendations,Introduction to non-personalized recommendations,Improved non-personalized recommendations,Combining popularity and reviews,Non-personalized suggestions,Finding all pairs of movies,Counting up the pairs,Making your first movie recommendations","Collaborative filtering,Pivoting your data,Finding similar users,Challenges with missing values,Compensating for incomplete data,Finding similarities,User-based to item-based,Similar and different movie ratings,Finding similarly liked movies,Using K-nearest neighbors,Stepping through K-nearest neighbors,Getting KNN data in shape,KNN predictions,Item-based or user-based,Comparing item-based and user-based models,Which should you choose?","Intro to content-based recommendations,Why use content-based models?,Creating content-based data,Understanding the content-based data,Making content-based recommendations,Comparing individual movies with Jaccard similarity,Comparing all your movies at once,Making recommendations based on movie genres,Text-based similarities,Instantiate the TF-IDF model,Creating the TF-IDF DataFrame,Comparing all your movies with TF-IDF,Making  recommendations with TF-IDF,User profile recommendations,Build the user profiles,User profile based recommendations","Dealing with sparsity,Matrix sparsity,Limited data in your rows,Matrix multiplication,Matrix factorization,Identifying latent features,Information loss in factorization,Singular value decomposition (SVD),Normalize your data,Decomposing your matrix,Recalculating the matrix,Making recommendations with SVD,Validating your predictions,Calculating RMSE,Comparing recommendation methods,Wrap up","Maggie Matsui,Amy Peterson","User ratings,Movies,Supervised Learning with scikit-learn",,
346,Interactive Data Visualization with Bokeh,4,15,53,,4500,"Bokeh is a powerful Python package for interactive data visualization, enabling you to go beyond static plots and allow stakeholders to modify your visualizations! In this interactive data visualization with Bokeh course, you'll work with a range of datasets, including stock prices, basketball player statistics, and Australian real-estate sales data. Through hands-on exercises, you’ll build and customize a range of plots, including scatter, bar, line, and grouped bar plots. You'll also get to grips with configuration tools to change how viewers interact with your plot, discover Bokeh's custom themes, learn how to generate subplots, and even how to add widgets to your plots!","Introduction to Bokeh,When to use a scatter plot,Blocks vs. rebounds,Kevin Durant's performance across seasons,Shooting ability by position,Configuration tools,The best tools for the job,Setting tools,Adding LassoSelectTool,The HoverTool,Adding a HoverTool,Formatting the HoverTool","Customizing glyph settings,Shooting guards versus small forwards,Big shooters,Evolution of the point guard,Highlighting and contrasting,Highlighting by glyph size,Steals vs. assists,Adding a color bar,Free throw percentage by position,Communicating with text,Sales by time and type of day,Products sold by the time of day,Adding annotations,Box annotations for sales performance,Setting up a polygon annotation,Annotating Netflix stock price growth","Adding style,Colors, legend, and theme,Customizing glyphs,Customizing axes,Average building size,Sales over time,Subplots,Categorical column subplots,Size, location, and price,Using gridplot,Changing size,Visualizing categorical data,High to low prices by region,Creating nested categories,Visualizing sales by period","Introduction to widgets,Adding a Div,Modifying glyph size with a widget,Slider widgets,Automotive stocks analysis,Tech stock performance over time,Select widgets,Travel analysis,Changing line plots with Select,Congratulations!","James Chapman,Amy Peterson","Bakery Sales,Stocks,NBA Player Statistics,Australia Property Market,Data Manipulation with pandas",,
347,Interactive Data Visualization with Bokeh,4,15,53,,4500,"Bokeh is a powerful Python package for interactive data visualization, enabling you to go beyond static plots and allow stakeholders to modify your visualizations! In this interactive data visualization with Bokeh course, you'll work with a range of datasets, including stock prices, basketball player statistics, and Australian real-estate sales data. Through hands-on exercises, you’ll build and customize a range of plots, including scatter, bar, line, and grouped bar plots. You'll also get to grips with configuration tools to change how viewers interact with your plot, discover Bokeh's custom themes, learn how to generate subplots, and even how to add widgets to your plots!","Introduction to Bokeh,When to use a scatter plot,Blocks vs. rebounds,Kevin Durant's performance across seasons,Shooting ability by position,Configuration tools,The best tools for the job,Setting tools,Adding LassoSelectTool,The HoverTool,Adding a HoverTool,Formatting the HoverTool","Customizing glyph settings,Shooting guards versus small forwards,Big shooters,Evolution of the point guard,Highlighting and contrasting,Highlighting by glyph size,Steals vs. assists,Adding a color bar,Free throw percentage by position,Communicating with text,Sales by time and type of day,Products sold by the time of day,Adding annotations,Box annotations for sales performance,Setting up a polygon annotation,Annotating Netflix stock price growth","Adding style,Colors, legend, and theme,Customizing glyphs,Customizing axes,Average building size,Sales over time,Subplots,Categorical column subplots,Size, location, and price,Using gridplot,Changing size,Visualizing categorical data,High to low prices by region,Creating nested categories,Visualizing sales by period","Introduction to widgets,Adding a Div,Modifying glyph size with a widget,Slider widgets,Automotive stocks analysis,Tech stock performance over time,Select widgets,Travel analysis,Changing line plots with Select,Congratulations!","James Chapman,Amy Peterson","Bakery Sales,Stocks,NBA Player Statistics,Australia Property Market,Data Manipulation with pandas",,
348,Joining Data in SQL,5,13,53,"321,322",4400,"Now that you've learned the basics of SQL in our Introduction to SQL course, it's time to supercharge your queries using joins and relational set theory. In this course, you'll learn all about the power of joining tables while exploring interesting features of countries and their cities throughout the world. You will master inner and outer joins, as well as self joins, semi joins, anti joins and cross joins—fundamental tools in any PostgreSQL wizard's toolbox. Never fear set theory again after learning all about unions, intersections, and except clauses through easy-to-understand diagrams and examples. Lastly, you'll be introduced to the challenging topic of subqueries. You will be able to visually grasp these ideas by using Venn diagrams and other linking illustrations.","Introduction to INNER JOIN,Inner join,Inner join (2),Inner join (3),INNER JOIN via USING,Review inner join using on,Inner join with using,Self-ish joins, just in CASE,Self-join,Case when and then,Inner challenge","State of the UNION,Union,Union (2),Union all,INTERSECTional data science,Intersect,Intersect (2),Review union and intersect,EXCEPTional,Except,Except (2),Semi-joins and Anti-joins,Semi-join,Relating semi-join to a tweaked inner join,Diagnosing problems using anti-join,Set theory challenge","LEFT and RIGHT JOINs,Left Join,Left join (2),Left join (3),Right join,FULL JOINs,Full join,Full join (2),Full join (3),Review outer joins,CROSSing the rubicon,A table of two cities,Outer challenge","Subqueries inside WHERE and SELECT clauses,Subquery inside where,Subquery inside where (2),Subquery inside select,Subquery inside FROM clause,Subquery inside from,Advanced subquery,Subquery challenge,Subquery review,Course review,Final challenge,Final challenge (2),Final challenge (3)","Filip Schouwenaars,Colin Ricardo","Data Analyst,SQL Fundamentals,SQL Server Fundamentals,Countries,Leaders,Diagrams,Introduction to SQL",,
349,Intermediate SQL Server,4,14,47,"42,255",3850,"A majority of data is stored in databases and knowing the necessary tools needed to analyze and clean data directly in databases is indispensable. This course focuses on T-SQL, the version of SQL used in Microsoft SQL Server, needed for data analysis. You will learn several concepts in this course such as dealing with missing data, working with dates, and calculating summary statistics using advanced queries. After completing this course, you will have the skills needed to analyze data and provide insights quickly and easily.","Data analysis with aggregations,Creating aggregations,Creating grouped aggregations,Dealing with missing data,Removing missing values,Imputing missing values (I),Imputing missing values (II),Binning data with CASE,Using CASE statements,Creating several groups with CASE","WHILE loops,Creating and using variables,Creating a WHILE loop,Derived tables,Queries with derived tables (I),Queries with derived tables (II),Common Table Expressions,CTE syntax,Creating CTEs (I),Creating CTEs (II)","Counting and totals,Calculating the total,Counting the number of rows,Dates,Which date function should you use?,Counting the number of days between dates,Adding days to a date,Rounding and truncating,Rounding numbers,Truncating numbers,More math functions,Calculating the absolute value,Calculating squares and square roots","Window functions in T-SQL,Window functions with aggregations (I),Window functions with aggregations (II),Common window functions,Do you know window functions?,First value in a window,Previous and next values,Increasing window complexity,Creating running totals,Assigning row numbers,Using windows for statistical functions,Calculating standard deviation,Calculating mode (I),Calculating mode (II)","Sumedh Panchadhar,Richie Cotton","SQL Server Developer,SQL Server Fundamentals,Incidents,Shipments,Kidney,Orders,Introduction to SQL Server",,
350,Parallel Programming with Dask in Python,4,15,51,,4150,"When working with big data, you’ll face two common obstacles: using too much memory and long runtimes. The Dask library can lower your memory use by loading chunks of data only when needed. It can lower runtimes by using all your available computing cores in parallel. Best of all, it requires very few changes to your existing Python code. In this course, you use Dask to analyze Spotify song data, process images of sign language gestures, calculate trends in weather data, analyze audio recordings, and train machine learning models on big data.","Introduction to Dask,Lazy evaluation,Delaying functions,Task graphs and scheduling methods,What are the different schedulers?,Plotting the task graph,Building delayed pipelines,Analyzing songs on Spotify,How danceable are songs these days?,Most popular songs","Introduction to Dask bags,Creating a Dask bag,Creating a bag from saved text,String operations,Dask bag operations,Loading JSON data,Filtering Dask bags,Chaining operations,Converting unstructured data to a DataFrame,Restructuring a dictionary,Converting to DataFrame,Using any data in Dask bags,Loading wav data,Constructing custom Dask bags,Processing unstructured audio","Dask arrays,Dask array chunksizes,Loading and processing photos,An image processing pipeline,Dask DataFrames,Creating Dask dataframes from CSVs,Read Dask DataFrames from Parquet,Summertime grooves,Multidimensional arrays,Exploring HDF5 files,Dask arrays from HDF5 datasets,Dask arrays from Zarr datasets,Xarray,Exploratory data analysis with xarray,Monthly mean temperatures,Calculating the trend in European temperatures","Using processes and threads,Which scheduler will be used?,Clusters and clients,Training machine learning models on big datasets,Using Dask to train a linear model,Making lazy predictions,Preprocessing big datasets,Lazily transforming training data,Lazy train-test split,Wrap-up","James Chapman,Amy Peterson","Spotify Songs - CSV,Spotify Songs - Parquet,European Rainfall - HDF5,European Rainfall - Zarr,Tripadvisor Hotel Reviews,Politicians,Data Manipulation with pandas,Python Data Science Toolbox (Part 2)",,
351,Introduction to Portfolio Analysis in R,5,14,57,"29,587",4400,"A golden rule in investing is to always test the portfolio strategy on historical data, and, once you are trading the strategy, to constantly monitor its performance. In this course, you will learn this by critically analyzing portfolio returns using the package PerformanceAnalytics. The course also shows how to estimate the portfolio weights that optimally balance risk and return. This is a data-driven course that combines portfolio theory with the practice in R, illustrated on real-life examples of equity portfolios and asset allocation problems. If you'd like to continue exploring the data after you've finished this course, the data used in the first three chapters can be obtained using the tseries-package. The code to get them can be found here. The data used in chapter 4 can be downloaded here.","Welcome to the course,Getting a grasp of the basics,Get a feel for the data,The portfolio weights,Calculating portfolio weights when component values are given,The weights of an equally weighted portfolio,The weights of a market capitalization-weighted portfolio,The portfolio return,Calculation of portfolio returns,From simple to gross and multi-period returns,The asymmetric impact of gains and losses,PerformanceAnalytics,Buy-and-hold versus (daily) rebalancing,The time series of asset returns,The time series of portfolio returns,The time series of weights","Drivers in the case of two assets,Driver 1: The assets' individual performance,Driver 2: The choice of portfolio weights,Driver 3: The correlation between the asset returns,Interpreting correlation,Using matrix notation,Making a risk-reward scatter diagram,The covariance matrix,Matrix-based calculation of portfolio mean and variance,Portfolio risk budget,Who did it?","Dimensions of portfolio performance,Exploring the monthly S&P 500 returns,The monthly mean and volatility,The (annualized) Sharpe ratio,Excess returns and the portfolio's Sharpe ratio,Annualized mean and volatility,Time-variation in portfolio performance,Effect of window length choice,Rolling annualized mean and volatility,Subperiod performance analysis and the function window,Non-normality of the return distribution,Balancing risk and reward,Detecting non-normality using skewness and kurtosis,Downside risk measures,Drawdowns due to buying high, selling low","Modern portfolio theory of Harry Markowitz,Mean-variance based investing in DJIA stocks,Exploring monthly returns of the 30 DJIA stocks,Finding the mean-variance efficient portfolio,Effect of the return target,Imposing weight constraints,The efficient frontier,Computing the efficient frontier using a grid of target returns,Interpreting the efficient frontier,Properties of the efficient frontier,The minimum variance and maximum Sharpe ratio portfolio,In-sample vs. out-of-sample evaluation,Split-sample evaluation,Out of sample performance evaluation,It ain't over",Lore Dirick,"Finance Fundamentals,Quantitative Analyst,Stock prices for Apple and Microsoft,Bonds prices,Commodities prices,Equities prices,Stock prices for DIJA,Real estate prices,Daily prices in S&P 500,Intermediate R for Finance",,
352,Text Mining with Bag-of-Words in R,4,15,69,"40,393",5700,"It is estimated that over 70% of potentially usable business information is unstructured, often in the form of text data. Text mining provides a collection of techniques that allows us to derive actionable insights from unstructured data. In this course, we explore the basics of text mining using the bag of words method. The first three chapters introduce a variety of essential topics for analyzing and visualizing text data. The final chapter allows you to apply everything you've learned in a real-world case study to extract insights from employee reviews of two major tech companies.","What is text mining?,Understanding text mining,Quick taste of text mining,Getting started,Load some text,Make the vector a VCorpus object (1),Make the vector a VCorpus object (2),Make a VCorpus from a data frame,Cleaning and preprocessing text,Common cleaning functions from tm,Cleaning with qdap,All about stop words,Intro to word stemming and stem completion,Word stemming and stem completion on a sentence,Apply preprocessing steps to a corpus,The TDM & DTM,Understanding TDM and DTM,Make a document-term matrix,Make a term-document matrix","Simple word clustering,Test your understanding of text mining,Distance matrix and dendrogram,Make a dendrogram friendly TDM,Put it all together: a text-based dendrogram,Dendrogram aesthetics,Using word association,Getting past single words,N-gram tokenization,Changing n-grams,How do bigrams affect word clouds?,Different frequency criteria,Changing frequency weights,Capturing metadata in tm","Common text mining visuals,Test your understanding of text mining,Frequent terms with tm,Frequent terms with qdap,Intro to word clouds,A simple word cloud,Stop words and word clouds,Plot the better word cloud,Improve word cloud colors,Use prebuilt color palettes,Other word clouds and word networks,Find common words,Visualize common words,Visualize dissimilar words,Polarized tag cloud,Visualize word networks,Teaser: simple word clustering","Amazon vs. Google,Organizing a text mining project,Step 1: Problem definition,Step 2: Identifying the text sources,Step 3: Text organization,Text organization,Working with Google reviews,Steps 4 & 5: Feature extraction & analysis,Feature extraction & analysis: amzn_pros,Feature extraction & analysis: amzn_cons,amzn_cons dendrogram,Word association,Quick review of Google reviews,Cage match! Amazon vs. Google pro reviews,Cage match, part 2! Negative reviews,Step 6: Reach a conclusion,Draw conclusions, insights, or recommendations,Draw another conclusion, insight, or recommendation,Finished!","Nick Carchedi,Tom Jeon","Text Mining,Coffee tweets,Chardonnay tweets,Anonymous online reviews: Amazon,Anonymous online reviews: Google,Intermediate R",,
353,Introduction to Python,4,11,57,"4,291,144",4700,"Python is a general-purpose programming language that is becoming ever more popular for data science. Companies worldwide are using Python to harvest insights from their data and gain a competitive edge. Unlike other Python tutorials, this course focuses on Python specifically for data science. In our Introduction to Python course, you’ll learn about powerful ways to store and manipulate data, and helpful data science tools to begin conducting your own analyses. Start DataCamp’s online Python curriculum now.","Hello Python!,The Python Interface,When to use Python?,Any comments?,Python as a calculator,Variables and Types,Variable Assignment,Calculations with variables,Other variable types,Guess the type,Operations with other types,Type conversion,Can Python handle everything?","Functions,Familiar functions,Help!,Multiple arguments,Methods,String Methods,List Methods,List Methods (2),Packages,Import package,Selective import,Different ways of importing","Python Lists,Create a list,Create list with different types,Select the valid list,List of lists,Subsetting Lists,Subset and conquer,Subset and calculate,Slicing and dicing,Slicing and dicing (2),Subsetting lists of lists,Manipulating Lists,Replace list elements,Extend a list,Delete list elements,Inner workings of lists","NumPy,Your First NumPy Array,Baseball players' height,Baseball player's BMI,Lightweight baseball players,NumPy Side Effects,Subsetting NumPy Arrays,2D NumPy Arrays,Your First 2D NumPy Array,Baseball data in 2D form,Subsetting 2D NumPy Arrays,2D Arithmetic,NumPy: Basic Statistics,Average versus median,Explore the baseball data,Blend it all together","Vincent Vankrunkelsven,Filip Schouwenaars","Data Scientist,Python Fundamentals,MLB (baseball),FIFA (soccer)",,
354,Intermediate R,6,14,81,"505,413",6950,"Intermediate R is the next stop on your journey in mastering the R programming language. In this R training, you will learn about conditional statements, loops, and functions to power your own R scripts. Next, make your R code more efficient and readable using the apply functions. Finally, the utilities chapter gets you up to speed with regular expressions in R, data structure manipulations, and times and dates. This course will allow you to take the next step in advancing your overall knowledge and capabilities while programming in R.","Relational Operators,Equality,Greater and less than,Compare vectors,Compare matrices,Logical Operators,& and |,& and | (2),Reverse the result: !,Blend it all together,Conditional Statements,The if statement,Add an else,Customize further: else if,Else if 2.0,Take control!","Introduction to Functions,Function documentation,Use a function,Use a function (2),Use a function (3),Functions inside functions,Required, or optional?,Writing Functions,Write your own function,Write your own function (2),Write your own function (3),Function scoping,R passes arguments by value,R you functional?,R you functional? (2),R Packages,Load an R Package,Different ways to load a package","Useful Functions,Mathematical utilities,Find the error,Data Utilities,Find the error (2),Beat Gauss using R,Regular Expressions,grepl & grep,grepl & grep (2),sub & gsub,sub & gsub (2),Times & Dates,Right here, right now,Create and format dates,Create and format times,Calculations with Dates,Calculations with Times,Time is of the essence","While loop,Write a while loop,Throw in more conditionals,Stop the while loop: break,Build a while loop from scratch,For loop,Loop over a vector,Loop over a list,Loop over a matrix,Mix it up with control flow,Next, you break it,Build a for loop from scratch",,"Data Scientist,R Programming,Introduction to R","lapply,Use lapply with a built-in R function,Use lapply with your own function,lapply and anonymous functions,Use lapply with additional arguments,Apply functions that return NULL,sapply,How to use sapply,sapply with your own function,sapply with function returning vector,sapply can't simplify, now what?,sapply with functions that return NULL,Reverse engineering sapply,vapply,Use vapply,Use vapply (2),From sapply to vapply",
355,Introduction to R,4,,62,"2,274,368",6200,"In this introduction to R course, you'll master the basics of this widely used open source language—including vectors, factors, lists, and data frames. With the coding skills you'll gain in this course, you'll be ready to undertake your own data analysis in R. There are millions of R users worldwide, cementing it as a leading programming language in statistics and data science. More and more organizations are using R, so begin your coding journey in one of DataCamp's most popular courses today!","How it works,Arithmetic with R,Variable assignment,Variable assignment (2),Variable assignment (3),Apples and oranges,Basic data types in R,What's that data type?","What's a matrix?,Analyze matrices, you shall,Naming a matrix,Calculating the worldwide box office,Adding a column for the Worldwide box office,Adding a row,The total box office revenue for the entire saga,Selection of matrix elements,A little arithmetic with matrices,A little arithmetic with matrices (2)","What's a data frame?,Quick, have a look at your dataset,Have a look at the structure,Creating a data frame,Creating a data frame (2),Selection of data frame elements,Selection of data frame elements (2),Only planets with rings,Only planets with rings (2),Only planets with rings but shorter,Sorting,Sorting your data frame","Create a vector,Create a vector (2),Create a vector (3),Naming a vector,Naming a vector (2),Calculating total winnings,Calculating total winnings (2),Calculating total winnings (3),Comparing total winnings,Vector selection: the good times,Vector selection: the good times (2),Vector selection: the good times (3),Vector selection: the good times (4),Selection by comparison - Step 1,Selection by comparison - Step 2,Advanced selection",,"Data Analyst,Data Scientist,R Programming","What's a factor and why would you use it?,What's a factor and why would you use it? (2),What's a factor and why would you use it? (3),Factor levels,Summarizing a factor,Battle of the sexes,Ordered factors,Ordered factors (2),Comparing ordered factors","Lists, why would you need them?,Lists, why would you need them? (2),Creating a list,Creating a named list,Creating a named list (2),Selecting elements from a list,Creating a new list for another movie"
356,Joining Data in SQL,5,13,53,"321,322",4400,"Now that you've learned the basics of SQL in our Introduction to SQL course, it's time to supercharge your queries using joins and relational set theory. In this course, you'll learn all about the power of joining tables while exploring interesting features of countries and their cities throughout the world. You will master inner and outer joins, as well as self joins, semi joins, anti joins and cross joins—fundamental tools in any PostgreSQL wizard's toolbox. Never fear set theory again after learning all about unions, intersections, and except clauses through easy-to-understand diagrams and examples. Lastly, you'll be introduced to the challenging topic of subqueries. You will be able to visually grasp these ideas by using Venn diagrams and other linking illustrations.","Introduction to INNER JOIN,Inner join,Inner join (2),Inner join (3),INNER JOIN via USING,Review inner join using on,Inner join with using,Self-ish joins, just in CASE,Self-join,Case when and then,Inner challenge","State of the UNION,Union,Union (2),Union all,INTERSECTional data science,Intersect,Intersect (2),Review union and intersect,EXCEPTional,Except,Except (2),Semi-joins and Anti-joins,Semi-join,Relating semi-join to a tweaked inner join,Diagnosing problems using anti-join,Set theory challenge","LEFT and RIGHT JOINs,Left Join,Left join (2),Left join (3),Right join,FULL JOINs,Full join,Full join (2),Full join (3),Review outer joins,CROSSing the rubicon,A table of two cities,Outer challenge","Subqueries inside WHERE and SELECT clauses,Subquery inside where,Subquery inside where (2),Subquery inside select,Subquery inside FROM clause,Subquery inside from,Advanced subquery,Subquery challenge,Subquery review,Course review,Final challenge,Final challenge (2),Final challenge (3)","Filip Schouwenaars,Colin Ricardo","Data Analyst,SQL Fundamentals,SQL Server Fundamentals,Countries,Leaders,Diagrams,Introduction to SQL",,
357,Data Visualization in Power BI,3,9,27,"8,365",2250,"Power BI has extraordinary visuals that can be used in reports and dashboards. In this Power BI course, you’ll learn to create insightful visualizations through built-in and customized charts and conditional formatting. You’ll discover how to create a plethora of visualizations such as scatter plots, tornado charts, gauges, and how to visualize everything without overwhelming your audience.","Know your audience,Dashboard or report?,Tables and scatter charts,Add a table and slicer,Create a scatter plot,Create a bubble chart","Reduce cognitive load,Reducing cognitive load,Combination charts and custom visuals,Line and area charts,Combo charts,Tornado charts","Getting an emotional response,Factors for evoking emotion,Bar charts and small multiples,Create a bar chart,Format a visual,Stacking errors by position,Using small multiples","Less is more,Why not do this?,Shares, gauges, and KPIs,Shares of the whole,Gauges and cards,Key performance indicators,Conditional formatting,Congratulations!","Maarten Van den Broeck,Carl Rosseel,Danny Tello","Data Analyst,Power BI Fundamentals,Exercises and Datasets,Metadata sheet - Lahman's Baseball Dataset,DataCamp vs. Local Experience,Introduction to Power BI",,
358,ETL in Python,4,16,48,"5,913",3850,"Want to grow your data engineering skills and more efficiently process big data? Well, it’s time to develop your ETL skills. In this course, you’ll learn the foundations of creating pipelines to efficiently extract, transform, and load data into the systems your company commonly uses. You’ll get hands-on experience by helping a fictional private equity firm process the sales data they need to make informed business decisions when buying real estate. Jump in, learn how to create ETL pipelines, and develop one of the most in-demand engineering skills needed in the market.","Introduction to ETL in Python,The ETL process,Downloading a ZIP file,Exploring a ZIP file,Ask the right questions,Reading from a CSV file,Writing to CSV,Extracting,Downloading the new dataset file from web,Project folder structure,Extract 'em all!","Unique key definition and clean table,Date data type definition,Unique key definition,Insert and delete operations,Querying,Insert and delete,Put load operations together,Insert operation,Delete operation,Load 'em all!","Let's talk with the database,SQLAlchemy core components,Engines and sessions,Database tables,Table class definition,Columns definition,Data cleaning,Lower string and date format,Price and description,Put transform operations together,Setup base script,Create tables,Transform 'em all!","Operators,Sales for Dublin and Cork,First month 2021 sales,Sqlalchemy func,Aggregate functions,Average, max and min functions,Create the insights,Creating the insights view,How many counties?,Working with Excel files,Create a simple Excel file,Add a table into Excel file,Export monthly insights,Wrap-up",Hadrien Lacroix,"Property price register 2021,Data Engineering for Everyone,Introduction to Data Engineering,Python Data Science Toolbox (Part 2)",,
359,ETL in Python,4,16,48,"5,913",3850,"Want to grow your data engineering skills and more efficiently process big data? Well, it’s time to develop your ETL skills. In this course, you’ll learn the foundations of creating pipelines to efficiently extract, transform, and load data into the systems your company commonly uses. You’ll get hands-on experience by helping a fictional private equity firm process the sales data they need to make informed business decisions when buying real estate. Jump in, learn how to create ETL pipelines, and develop one of the most in-demand engineering skills needed in the market.","Introduction to ETL in Python,The ETL process,Downloading a ZIP file,Exploring a ZIP file,Ask the right questions,Reading from a CSV file,Writing to CSV,Extracting,Downloading the new dataset file from web,Project folder structure,Extract 'em all!","Unique key definition and clean table,Date data type definition,Unique key definition,Insert and delete operations,Querying,Insert and delete,Put load operations together,Insert operation,Delete operation,Load 'em all!","Let's talk with the database,SQLAlchemy core components,Engines and sessions,Database tables,Table class definition,Columns definition,Data cleaning,Lower string and date format,Price and description,Put transform operations together,Setup base script,Create tables,Transform 'em all!","Operators,Sales for Dublin and Cork,First month 2021 sales,Sqlalchemy func,Aggregate functions,Average, max and min functions,Create the insights,Creating the insights view,How many counties?,Working with Excel files,Create a simple Excel file,Add a table into Excel file,Export monthly insights,Wrap-up",Hadrien Lacroix,"Property price register 2021,Data Engineering for Everyone,Introduction to Data Engineering,Python Data Science Toolbox (Part 2)",,
360,Intermediate SQL Server,4,14,47,"42,255",3850,"A majority of data is stored in databases and knowing the necessary tools needed to analyze and clean data directly in databases is indispensable. This course focuses on T-SQL, the version of SQL used in Microsoft SQL Server, needed for data analysis. You will learn several concepts in this course such as dealing with missing data, working with dates, and calculating summary statistics using advanced queries. After completing this course, you will have the skills needed to analyze data and provide insights quickly and easily.","Data analysis with aggregations,Creating aggregations,Creating grouped aggregations,Dealing with missing data,Removing missing values,Imputing missing values (I),Imputing missing values (II),Binning data with CASE,Using CASE statements,Creating several groups with CASE","WHILE loops,Creating and using variables,Creating a WHILE loop,Derived tables,Queries with derived tables (I),Queries with derived tables (II),Common Table Expressions,CTE syntax,Creating CTEs (I),Creating CTEs (II)","Counting and totals,Calculating the total,Counting the number of rows,Dates,Which date function should you use?,Counting the number of days between dates,Adding days to a date,Rounding and truncating,Rounding numbers,Truncating numbers,More math functions,Calculating the absolute value,Calculating squares and square roots","Window functions in T-SQL,Window functions with aggregations (I),Window functions with aggregations (II),Common window functions,Do you know window functions?,First value in a window,Previous and next values,Increasing window complexity,Creating running totals,Assigning row numbers,Using windows for statistical functions,Calculating standard deviation,Calculating mode (I),Calculating mode (II)","Sumedh Panchadhar,Richie Cotton","SQL Server Developer,SQL Server Fundamentals,Incidents,Shipments,Kidney,Orders,Introduction to SQL Server",,
361,Parallel Programming with Dask in Python,4,15,51,,4150,"When working with big data, you’ll face two common obstacles: using too much memory and long runtimes. The Dask library can lower your memory use by loading chunks of data only when needed. It can lower runtimes by using all your available computing cores in parallel. Best of all, it requires very few changes to your existing Python code. In this course, you use Dask to analyze Spotify song data, process images of sign language gestures, calculate trends in weather data, analyze audio recordings, and train machine learning models on big data.","Introduction to Dask,Lazy evaluation,Delaying functions,Task graphs and scheduling methods,What are the different schedulers?,Plotting the task graph,Building delayed pipelines,Analyzing songs on Spotify,How danceable are songs these days?,Most popular songs","Introduction to Dask bags,Creating a Dask bag,Creating a bag from saved text,String operations,Dask bag operations,Loading JSON data,Filtering Dask bags,Chaining operations,Converting unstructured data to a DataFrame,Restructuring a dictionary,Converting to DataFrame,Using any data in Dask bags,Loading wav data,Constructing custom Dask bags,Processing unstructured audio","Dask arrays,Dask array chunksizes,Loading and processing photos,An image processing pipeline,Dask DataFrames,Creating Dask dataframes from CSVs,Read Dask DataFrames from Parquet,Summertime grooves,Multidimensional arrays,Exploring HDF5 files,Dask arrays from HDF5 datasets,Dask arrays from Zarr datasets,Xarray,Exploratory data analysis with xarray,Monthly mean temperatures,Calculating the trend in European temperatures","Using processes and threads,Which scheduler will be used?,Clusters and clients,Training machine learning models on big datasets,Using Dask to train a linear model,Making lazy predictions,Preprocessing big datasets,Lazily transforming training data,Lazy train-test split,Wrap-up","James Chapman,Amy Peterson","Spotify Songs - CSV,Spotify Songs - Parquet,European Rainfall - HDF5,European Rainfall - Zarr,Tripadvisor Hotel Reviews,Politicians,Data Manipulation with pandas,Python Data Science Toolbox (Part 2)",,
362,Parallel Programming with Dask in Python,4,15,51,,4150,"When working with big data, you’ll face two common obstacles: using too much memory and long runtimes. The Dask library can lower your memory use by loading chunks of data only when needed. It can lower runtimes by using all your available computing cores in parallel. Best of all, it requires very few changes to your existing Python code. In this course, you use Dask to analyze Spotify song data, process images of sign language gestures, calculate trends in weather data, analyze audio recordings, and train machine learning models on big data.","Introduction to Dask,Lazy evaluation,Delaying functions,Task graphs and scheduling methods,What are the different schedulers?,Plotting the task graph,Building delayed pipelines,Analyzing songs on Spotify,How danceable are songs these days?,Most popular songs","Introduction to Dask bags,Creating a Dask bag,Creating a bag from saved text,String operations,Dask bag operations,Loading JSON data,Filtering Dask bags,Chaining operations,Converting unstructured data to a DataFrame,Restructuring a dictionary,Converting to DataFrame,Using any data in Dask bags,Loading wav data,Constructing custom Dask bags,Processing unstructured audio","Dask arrays,Dask array chunksizes,Loading and processing photos,An image processing pipeline,Dask DataFrames,Creating Dask dataframes from CSVs,Read Dask DataFrames from Parquet,Summertime grooves,Multidimensional arrays,Exploring HDF5 files,Dask arrays from HDF5 datasets,Dask arrays from Zarr datasets,Xarray,Exploratory data analysis with xarray,Monthly mean temperatures,Calculating the trend in European temperatures","Using processes and threads,Which scheduler will be used?,Clusters and clients,Training machine learning models on big datasets,Using Dask to train a linear model,Making lazy predictions,Preprocessing big datasets,Lazily transforming training data,Lazy train-test split,Wrap-up","James Chapman,Amy Peterson","Spotify Songs - CSV,Spotify Songs - Parquet,European Rainfall - HDF5,European Rainfall - Zarr,Tripadvisor Hotel Reviews,Politicians,Data Manipulation with pandas,Python Data Science Toolbox (Part 2)",,
363,Interactive Data Visualization with Bokeh,4,15,53,,4500,"Bokeh is a powerful Python package for interactive data visualization, enabling you to go beyond static plots and allow stakeholders to modify your visualizations! In this interactive data visualization with Bokeh course, you'll work with a range of datasets, including stock prices, basketball player statistics, and Australian real-estate sales data. Through hands-on exercises, you’ll build and customize a range of plots, including scatter, bar, line, and grouped bar plots. You'll also get to grips with configuration tools to change how viewers interact with your plot, discover Bokeh's custom themes, learn how to generate subplots, and even how to add widgets to your plots!","Introduction to Bokeh,When to use a scatter plot,Blocks vs. rebounds,Kevin Durant's performance across seasons,Shooting ability by position,Configuration tools,The best tools for the job,Setting tools,Adding LassoSelectTool,The HoverTool,Adding a HoverTool,Formatting the HoverTool","Customizing glyph settings,Shooting guards versus small forwards,Big shooters,Evolution of the point guard,Highlighting and contrasting,Highlighting by glyph size,Steals vs. assists,Adding a color bar,Free throw percentage by position,Communicating with text,Sales by time and type of day,Products sold by the time of day,Adding annotations,Box annotations for sales performance,Setting up a polygon annotation,Annotating Netflix stock price growth","Adding style,Colors, legend, and theme,Customizing glyphs,Customizing axes,Average building size,Sales over time,Subplots,Categorical column subplots,Size, location, and price,Using gridplot,Changing size,Visualizing categorical data,High to low prices by region,Creating nested categories,Visualizing sales by period","Introduction to widgets,Adding a Div,Modifying glyph size with a widget,Slider widgets,Automotive stocks analysis,Tech stock performance over time,Select widgets,Travel analysis,Changing line plots with Select,Congratulations!","James Chapman,Amy Peterson","Bakery Sales,Stocks,NBA Player Statistics,Australia Property Market,Data Manipulation with pandas",,
364,Parallel Programming with Dask in Python,4,15,51,,4150,"When working with big data, you’ll face two common obstacles: using too much memory and long runtimes. The Dask library can lower your memory use by loading chunks of data only when needed. It can lower runtimes by using all your available computing cores in parallel. Best of all, it requires very few changes to your existing Python code. In this course, you use Dask to analyze Spotify song data, process images of sign language gestures, calculate trends in weather data, analyze audio recordings, and train machine learning models on big data.","Introduction to Dask,Lazy evaluation,Delaying functions,Task graphs and scheduling methods,What are the different schedulers?,Plotting the task graph,Building delayed pipelines,Analyzing songs on Spotify,How danceable are songs these days?,Most popular songs","Introduction to Dask bags,Creating a Dask bag,Creating a bag from saved text,String operations,Dask bag operations,Loading JSON data,Filtering Dask bags,Chaining operations,Converting unstructured data to a DataFrame,Restructuring a dictionary,Converting to DataFrame,Using any data in Dask bags,Loading wav data,Constructing custom Dask bags,Processing unstructured audio","Dask arrays,Dask array chunksizes,Loading and processing photos,An image processing pipeline,Dask DataFrames,Creating Dask dataframes from CSVs,Read Dask DataFrames from Parquet,Summertime grooves,Multidimensional arrays,Exploring HDF5 files,Dask arrays from HDF5 datasets,Dask arrays from Zarr datasets,Xarray,Exploratory data analysis with xarray,Monthly mean temperatures,Calculating the trend in European temperatures","Using processes and threads,Which scheduler will be used?,Clusters and clients,Training machine learning models on big datasets,Using Dask to train a linear model,Making lazy predictions,Preprocessing big datasets,Lazily transforming training data,Lazy train-test split,Wrap-up","James Chapman,Amy Peterson","Spotify Songs - CSV,Spotify Songs - Parquet,European Rainfall - HDF5,European Rainfall - Zarr,Tripadvisor Hotel Reviews,Politicians,Data Manipulation with pandas,Python Data Science Toolbox (Part 2)",,
365,Interactive Data Visualization with Bokeh,4,15,53,,4500,"Bokeh is a powerful Python package for interactive data visualization, enabling you to go beyond static plots and allow stakeholders to modify your visualizations! In this interactive data visualization with Bokeh course, you'll work with a range of datasets, including stock prices, basketball player statistics, and Australian real-estate sales data. Through hands-on exercises, you’ll build and customize a range of plots, including scatter, bar, line, and grouped bar plots. You'll also get to grips with configuration tools to change how viewers interact with your plot, discover Bokeh's custom themes, learn how to generate subplots, and even how to add widgets to your plots!","Introduction to Bokeh,When to use a scatter plot,Blocks vs. rebounds,Kevin Durant's performance across seasons,Shooting ability by position,Configuration tools,The best tools for the job,Setting tools,Adding LassoSelectTool,The HoverTool,Adding a HoverTool,Formatting the HoverTool","Customizing glyph settings,Shooting guards versus small forwards,Big shooters,Evolution of the point guard,Highlighting and contrasting,Highlighting by glyph size,Steals vs. assists,Adding a color bar,Free throw percentage by position,Communicating with text,Sales by time and type of day,Products sold by the time of day,Adding annotations,Box annotations for sales performance,Setting up a polygon annotation,Annotating Netflix stock price growth","Adding style,Colors, legend, and theme,Customizing glyphs,Customizing axes,Average building size,Sales over time,Subplots,Categorical column subplots,Size, location, and price,Using gridplot,Changing size,Visualizing categorical data,High to low prices by region,Creating nested categories,Visualizing sales by period","Introduction to widgets,Adding a Div,Modifying glyph size with a widget,Slider widgets,Automotive stocks analysis,Tech stock performance over time,Select widgets,Travel analysis,Changing line plots with Select,Congratulations!","James Chapman,Amy Peterson","Bakery Sales,Stocks,NBA Player Statistics,Australia Property Market,Data Manipulation with pandas",,
366,Interactive Data Visualization with rbokeh,4,12,47,"3,525",4000,"Data visualization is an integral part of the data analysis process. This course will get you introduced to rbokeh: a visualization library for interactive web-based plots. You will learn how to use rbokeh layers and options to create effective visualizations that carry your message and emphasize your ideas. We will focus on the two main pieces of data visualization: wrangling data in the appropriate format as well as employing the appropriate visualization tools, charts and options from rbokeh.","Getting started with rbokeh,Hello rbokeh!,Tidyverse Refresher (Filter),Tidyverse Refresher (Mutate),Constructing rbokeh layers (Part 1),Specifying Data in rbokeh Layers (Part 1),Specifying Data in rbokeh Layers (Part 2),Specifying Data in rbokeh Layers 3,Constructing rbokeh layers (Part 2),One-Layer Plot (Scatter Plot),Multi-Layer Plot 1 (Scatter + Line Plot),Multi-Layer Plot 2 (Scatter + Line Plot)","Data formats,Wide and Long Data 1,Wide and long Data 2,Wide and Long Data 3,More rbokeh layers,Scatter Plot + Regression Line (Reshaping Data),Scatter Plot + Regression Line (Scatter Plot),Scatter Plot + Regression Line (Regression Line),Interaction tools,Toolbar Location,Interaction Tools (Hide/View)","Plot and mapped attributes (Part 1),Line and Fill Color 1,Line and Fill Color 2,Color Palette,Plot and mapped attributes (Part 2),Size & Alpha (Scatter Plot) 1,Size & Alpha (Scatter Plot) 2,Line Width,Hover info and figure options,Hover Info (Part 1),Hover Info (Part 2),Figure Options","rbokeh grid plots,Grid Plots,Grid Plots (Axes),Grid Plot (Layout),Facets with grid plots,Facets 1,Facets 2,Facets 3,rbokeh maps,Initializing Maps,Adding Points Layer to Maps,Multiple Maps in a Grid Plot","David Campos,Shon Inouye","Human Development Index dataset,Corruption Perception Index dataset,Tuberculosis Cases dataset,New York Citi Bike Trips dataset,Introduction to the Tidyverse",,
367,Biomedical Image Analysis in Python,4,15,54,"13,936",4400,"The field of biomedical imaging has exploded in recent years - but for the uninitiated, even loading data can be a challenge! In this introductory course, you'll learn the fundamentals of image analysis using NumPy, SciPy, and Matplotlib. You'll navigate through a whole-body CT scan, segment a cardiac MRI time series, and determine whether Alzheimer’s disease changes brain structure. Even if you have never worked with images before, you will finish the course with a solid toolkit for entering this dynamic field.","Image data,Load images,Metadata,Plot images,N-dimensional images,Stack images,Load volumes,Field of view,Advanced plotting,Generate subplots,Slice 3D images,Plot other views","Objects and labels,Segment the heart,Select objects,Extract objects,Measuring intensity,Measure variance,Separate histograms,Measuring morphology,Calculate volume,Calculate distance,Pinpoint center of mass,Measuring in time,Summarize the time series,Measure ejection fraction","Image intensities,Intensity,Histograms,Masks,Create a mask,Apply a mask,Tune a mask,Filters,Filter convolutions,Filter functions,Smoothing,Feature detection,Detect edges (1),Detect edges (2)","Spatial transformations,Translations,Rotations,Affine transform,Resampling and interpolation,Resampling,Interpolation,Comparing images,Mean absolute error,Intersection of the union,Normalizing measurements,Identifying potential confounds,Testing group differences,Normalizing metrics","Lore Dirick,Becca Robins,Sara Snell","Image Processing,RSNA Hand Radiograph,OASIS Brain Measurements,Sunnybrook Cardiac MRI,TCIA Chest CT (Sample),Intermediate Python",,
368,Dealing With Missing Data in R,4,14,52,"10,948",4350,"Missing data is part of any real world data analysis. It can crop up in unexpected places, making analyses challenging to understand. In this course, you will learn how to use tidyverse tools and the naniar R package to visualize missing values. You'll tidy missing values so they can be used in analysis and explore missing values to find bias in the data. Lastly, you'll reveal other underlying patterns of missingness. You will also learn how to ""fill in the blanks"" of missing values with imputation models, and how to visualize, assess, and make decisions based on these imputed datasets.","Introduction to missing data,Using and finding missing values,How many missing values are there?,Working with missing values,Why care about missing values?,Summarizing missingness,Tabulating Missingness,Other summaries of missingness,How do we visualize missing values?,Your first missing data visualizations,Visualizing missing cases and variables,Visualizing missingness patterns","Tools to explore missing data dependence,Creating shadow matrix data,Performing grouped summaries of missingness,Further exploring more combinations of missingness,Visualizing missingness across one variable,Nabular data and filling by missingness,Nabular data and summarising by missingness,Explore variation by missingness: box plots,Visualizing missingness across two variables,Exploring missing data with scatter plots,Using facets to explore missingness,Faceting to explore missingness (multiple plots)","Searching for and replacing missing values,Using miss_scan_count,Using replace_with_na,Using replace_with_na scoped variants,Filling down missing values,Fix implicit missings using complete(),Fix explicit missings using fill(),Using complete() and fill() together,Missing Data dependence,Differences between MCAR and MAR,Exploring missingness dependence,Further exploring missingness dependence","Filling in the blanks,Impute data below range with nabular data,Visualize imputed values in a scatter plot,Create histogram of imputed data,What makes a good imputation,Evaluating bad imputations,Evaluating imputations: The scale,Evaluating imputations: Across many variables,Performing imputations,Using simputation to impute data,Evaluating and comparing imputations,Evaluating imputations (many models & variables),Evaluating imputations and models,Combining and comparing many imputation models,Evaluating the different parameters in the model,Final Lesson","David Campos,Chester Ismay,Shon Inouye","Intermediate Tidyverse Toolbox,Introduction to R,Introduction to the Tidyverse",,
369,Financial Forecasting in Python,4,12,49,"8,922",4050,"In Financial Forecasting in Python, you will step into the role of CFO and learn how to advise a board of directors on key metrics while building a financial forecast, the basics of income statements and balance sheets, and cleaning messy financial data. During the course, you will examine real-life datasets from Netflix, Tesla, and Ford, using the pandas package. Following the course, you will be able to calculate financial metrics, work with assumptions and variances, and build your own forecast in Python!","Introduction to financial statements,Calculating gross profit,Calculating net profit,Elements within net profit & gross profit,Calculating sales & Cost of Goods Sold (COGS),Calculating sales,Forecasting sales with a discount,Calculating COGS,Calculating the break-even point,Working with raw forecast datasets,Tesla income statement,Forecasting profit for Tesla","Financial periods and how to work with them,Converting quarters into months,Merging months into quarters,The datetime library,Working with the datetime library,Converting date formats - simple,Converting date formats - explicit,Tips and tricks when working with datasets,Working with datasets - month totals,Working with datasets - combining datasets,Working with datasets - exporting data","Introduction to the balance sheet,Calculating accounts receivable (debtors),Bad debts,Calculating accounts payable (creditors),Understanding accounts payable and receivable,Balance sheet efficiency ratios - Part 1,Debtor days ratio,Days payable outstanding,Balance sheet efficiency ratios - Part 2,Days in inventory and asset turnover ratio,Understanding ratios,Calculating balance sheet ratios for Ford,Forecasting the balance sheet for Ford","Building sensitive forecast models,Weighted probability,Market sentiment,Dependencies and sensitivity,Assigning dependencies for sales and COGS,Building a sensitivity analysis for gross profit,Assigning dependencies for expenses,Build a sensitivity analysis for the net profit,Working with variances in the forecast,Building an alternate forecast,Building a gap analysis between forecasts,Setting dependencies for Netflix,Calculating an alternative forecast for Netflix","Becca Robins,Sara Snell","Ford Balance Sheet,Netflix Forecast,Tesla Income Statement,Introduction to Python,Intermediate Python",,
370,Hypothesis Testing in Python,4,15,50,"2,145",3750,"Hypothesis testing lets you answer questions about your datasets in a statistically rigorous way. In this course, you'll grow your Python analytical skills as you learn how and when to use common tests like t-tests, proportion tests, and chi-square tests. Working with real-world data, including Stack Overflow user feedback, you'll gain a deep understanding of how these tests work, and the key assumptions that underpin them. You'll also discover how different tests are related using the “there is only one test"" framework, before learning how to use non-parametric tests to go beyond the limitations of side-step the requirements of hypothesis tests.","To the lab for testing,Uses of A/B testing,Calculating the sample mean,Calculating a z-score,A tail of two z's,Criminal trials and hypothesis tests,Left tail, right tail, two tails,Calculating p-values,Statistically significant other,Decisions from p-values,Calculating a confidence interval,Type I and type II errors","Difference strokes for proportions, folks,t for proportions?,Test for single proportions,A sense of proportion,Test for two proportions,proportions_ztest() for two samples,Declaration of independence,The chi-square distribution,How many tails for chi-square tests?,Chi-square test of independence,Does this dress make my fit look good?,Visualizing goodness of fit,Chi-square test of goodness of fit","Is this some kind of test statistic?,Hypothesis testing workflow,Two sample mean test statistic,Time for t,Why is t needed?,The t-distribution,From t to p,Pairing is caring,Is pairing needed?,Visualizing the difference,Using ttest(),P-hacked to pieces,Visualizing many categories,ANOVA,Pairwise t-tests","What do you assume?,Common assumptions of hypothesis tests,Testing sample size,Assumptions not met,Which parametric test?,Wilcoxon signed-rank test,Look ma! Still no parameters!,Wilcoxon-Mann-Whitney,Kruskal-Wallis,Congratulations!","Dr. Chester Ismay,Amy Peterson,Izzy Weber","Data Analyst,Data Scientist,Statistics Fundamentals,Late Shipments,Stack Overflow,U.S. Democrat Votes 2012/2016,U.S. Republican Votes 2008/2012,Sampling in Python",,
371,Introduction to DAX in Power BI,2,7,20,"6,805",1650,"Start your journey to becoming a DAX master with this introductory course on DAX. You’ll learn fundamental concepts and best practices for implementing DAX in your reports. You’ll learn to write DAX code to generate calculated columns, measures, and tables while learning supporting knowledge around ‘context’ in Power BI. Finally, we’ll round off the course by introducing time-intelligence functions and show you how to use Quick Measures to create complex DAX code. Let’s take the first step in your DAX mastery journey!","Introduction to DAX in Power BI,Calculated columns vs. measures,Creating calculated columns and measures,Profit column,Sales count,Profit margin ratio","The Date Table,Creating a calculated table,Dates and Quick Measures,Expanding the Date table,DATEDIFF,Your first quick measure,Year-over-year change,Congratulations!","Context in DAX Formulas,Context 101,Creating DAX Measures,Using Variables,Iterator Functions,Sales by Category and Year",,"Maarten Van den Broeck,Carl Rosseel","Data Analyst,Power BI Fundamentals,Exercises and Datasets,DataCamp vs. Local Experience,Introduction to Power BI",,
372,Data Connections in Power BI,2,9,24,,1750,"Data connections are an essential part of Power BI. In this course, you will be introduced to the many different options for connecting to data. You’ll learn the differences between Power BI Desktop and Power BI Service when it comes to data connections. You’ll also learn about the different ways that Power BI stores data when connecting to a source, and how you are able to amend connections after they have been made. Finally, you’ll learn how you can use parameters and M Language in Power BI Desktop to level up your handling of data import processes.","Data connections in Power BI,The data flow process,Power BI Desktop connections,Which connection?,Welcome to Power BI Service,Desktop vs. Service,First connections,Desktop or Service data connections?,Add a database connection","Data source settings,Incremental refresh,Parameters and incremental refresh,Parameters: true or false?,Query parameters,Discovering M Language,M Language examined,Using M Language on connections,Congratulations","Database connections,Storage modes,Exploring connections,Power BI languages,Controlling the import process,Changing data source settings",,"Maarten Van den Broeck,Carl Rosseel","Data Analyst,Exercises and Datasets,Introduction to Power BI",,
373,Data Preparation in Power BI,3,9,26,"2,078",2050,"In this interactive Power BI course, you’ll learn how to use Power Query Editor to transform and shape your data to be ready for analysis. You’ll also get to grips with advanced Power BI topics, including how to use M language and the Advanced Editor, to help you be even more efficient in data preparation.","Introduction to Power Query,What is clean data?,Introduction to Power Query demo,Load data and promote headers,Rename and reorder columns,Changing data types","Transforming text in Power Query,Universally-applicable transformations,Text transformation,Trim & clean,Merge & extract length,Split & add prefix","Data preview features in Power Query,Data preview differences,Data preview features,Column distribution and duplicates,Column quality and missing values,Column profile,Profiling to find anomalies","Numerical transformations in Power Query,Numerical vs. Date transformations,Numerical transformations,Absolute value and rounding,Multiplication, addition, and square root,Date transformations,Congratulations!",Carl Rosseel,"Data Analyst,Power BI Fundamentals,Exercises and Datasets,Introduction to Power BI",,
374,Data Transformation in Power BI,3,9,28,,2150,"In this course, you’ll learn all about table transformations in Power BI. You’ll learn how to (un)pivot, transpose, and append tables. You’ll also get introduced to joins and discover when it makes sense to use them. Finally, you’ll gain power with custom columns, including how to use M language and the Advanced Editor, to help you be even more efficient in data preparation.","Reshaping & aggregating  data,Which shape after transformation?,Reshaping & aggregating tables in Power Query,Unpivoting & transposing,Pivoting,Grouping & aggregating","Custom columns in Power Query,Custom conditional columns,Custom columns demo,Stock ranking,Stock values,Grouped stock ranking","Combining data in Power Query,What causes null values?,Merging & appending queries in Power Query,Appending queries,Merging queries: left join,Merging queries: right join,Transforming sales data for analysis","Introduction to Advanced Editor,Using the Advanced Editor,DAX vs M Language,M Language & Advanced Editor demo,Calculate stock deviation,Rename steps & add comments,Variables and custom functions,Calculate Z scores,Congratulations!",Carl Rosseel,"Data Analyst,Exercises and Datasets,Data Preparation in Power BI",,
375,Exploratory Data Analysis in Power BI,3,9,26,,2050,"Enhance your reports with Power BI's Exploratory Data Analysis (EDA). You'll start by using descriptive statistics to spot outliers, identify missing data, and apply imputation techniques to fill gaps in your dataset. You’ll then learn how EDA in Power BI can help you discover the relationships between variables—both categorical and continuous— by using basic statistical measures and box and scatter plots.","What is exploratory data analysis?,Steps to EDA,Initial EDA of AirBnB listings,Identify missing data,Descriptive statistics for a variable,Imputation for missing data","EDA with categorical variables,Histograms vs. box plots,Exploring categorical variables with AirBnB data,Analyzing a categorical variable,Proportions with categorical variables,Analyzing multiple categorical variables,Creating a box plot","Distributions and outliers,Choices for finding outliers,Histograms and outliers in AirBnB listings,Create your first histogram,Identify outliers,Addressing outliers in the data","Relationships between continuous variables,Practice interpreting a scatter plot,Exploring AirBnB listings with scatter plots,Analyzing relationships with scatter plots,Adding context to scatter plots,Correlation coefficient,Congratulations!",Carl Rosseel,"Data Analyst,Exercises and Datasets,DataCamp vs. Local Experience,Introduction to DAX in Power BI",,
376,Trend Analysis in Power BI,3,9,25,,1950,"In this course, you’ll learn how to analyze time series, visualize your data, and spot trends. You’ll build new date variables, discover run charts, and get into calculating rolling averages. Finally, you’ll find out how to identify which variables exhibit the most influence on the target variable using Power BI's decomposition trees and key influencers.","Starting to explore time series data,Statements about time series analysis,Exploring AirBnB time series,Generating a new date variable,Analyzing trends by day of week,Calculating year-over-year change","Introduction to decomposition trees,Statements about decomposition trees,Using decomposition trees in Power BI,Getting started with decomposition trees,Diving deeper into decomposition trees,Decomposing attrition rates","Time series run chart,Cyclical vs. Seasonal,Analyzing Glassdoor reviews over time,Building your first time series chart,Calculating rolling averages,Finding anomalies in time series data","Introduction to key influencers,Decomposition trees vs. key influencers,Using key influencers in Power BI,Key influencers for average listing price,Segments from key influencers,Key influencers for super hosts,Congratulations!",Carl Rosseel,"Data Analyst,Exercises and Datasets,DataCamp vs. Local Experience,Exploratory Data Analysis in Power BI",,
377,User-Oriented Design in Power BI,3,9,26,,2100,"In this course you learn how to design with users in mind. You’ll also learn to use R and Python to create unique visualizations, adding custom chart types that would otherwise not be available in Power BI. You’ll get introduced to some best practices in data visualization and optimize your visualizations to be more accessible to visually impaired individuals. This course also teaches you how to create paginated reports, a prerequisite for the official PL-300 exam!","Tracking focal points,Why focal points,Maps and external scripts,Creating a map,Scripting with Python,Using focal points","Readying for production,Choosing a SKU,Q&A and decomposition trees,Adding a Q&A visual,Adding a decomposition tree,Configuring the report","Designing for accessibility,Reviewing accessibility options,Accessibility in practice,Limiting color use,Enhancing labels,Fonts and contrast,Using smart narratives","Paginated reports,Choosing a report type,Creating paginated reports,Create a paginated report,Make it a matrix,Add a line chart,Congratulations!","Kevin Feasel,Carl Rosseel,Azat Saskal","Data Analyst,Exercises and Datasets,DataCamp vs. Local Experience,Data Visualization in Power BI",,
378,DAX Functions in Power BI,3,9,26,"3,665",2150,"DAX, or Data Analysis eXpressions, is a formula language used in Microsoft Power BI to create calculated columns, measures, and custom tables. Once mastered, DAX gives you powerful control over visuals and reports, allowing for better performance and more flexibility. This course covers the core concepts such as row query and filter context, with exercises focusing on filtering, counting, ranking, and iterating functions.","DAX for creating tables and columns,Row vs. query vs. filter context,DAX for calculated tables and columns,Creating a date table,Calculated column for costs,Data cleaning with DAX,Connecting data from different tables","Filtering and counting with DAX,Understanding different filter functions,Using different filters with DAX,Filter ALL the data,Calculating with a filter,Analyzing across dimensional tables","Methods to create DAX measures,Advantages of explicit measures,DAX and Measures,Using variables,Basic statistical measures,Quick measures","Iterating functions,DIY iterating functions,Iterating functions in Power BI,Practice with iterating functions,More iterating functions,Use of RANKX(),Congratulations!","Luke Barousse,Serkan Atalay","Data Analyst,Exercises and Datasets,DAX Cheatsheet,DataCamp vs. Local Experience,Introduction to DAX in Power BI,Data Modeling in Power BI",,
379,Intermediate DAX in Power BI,3,9,25,"2,811",1900,"This course introduces you to new DAX functions and its many use cases. First of all, you expand your core DAX knowledge by learning how to write logical functions. Secondly, you’ll discover how you can write DAX functions for row-level security (RLS) purposes and how to use DAX to manipulate tables and create nested functions. Those time-intelligence quick measures will be building themselves before you know it!","Logical functions,Interpreting SWITCH(),Logical functions in Power BI,IF() for formatting tables,Exploring SWITCH(),Grouping","Table manipulation functions,Summary of SUMMARIZE(),Table manipulations using DAX,SUMMARIZE() the facts,ADDCOLUMNS()? No problem!","Row-level security,Applying row-level security,Managed roles in Power BI,Creating an email list,Implementing RLS,Security filtering","Time intelligence functions,Time intelligence functions output,Time intelligence in Power BI,Use of TOTALYTD(),Use of SAMEPERIODLASTYEAR(),Build your own YoY quick measure,DAX vs Q&A,Congratulations!","Luke Barousse,Serkan Atalay","Data Analyst,Exercises and Datasets,DAX Cheatsheet,DataCamp vs. Local Experience,Introduction to DAX in Power BI,Data Modeling in Power BI",,
380,Intermediate Data Modeling in Power BI,3,9,24,"3,668",1850,"In this course, you’ll extend your knowledge about facts, dimensions, and their relationships. You learn about the cardinality of relationships and how you can use bi-directional cross-filtering in your model. You’ll also explore the use of quick measures and hierarchies and write DAX to fully customize your data model. Finally, you’ll get introduced to Power BI reporting best practices to improve the performance of your reports.","Date dimensions and relationships,Cardinality,Date dimensions and relationships in Power BI,Create a year dimension,Extend the year dimension,Composite key relationships","Working with relationships,Bi-directional relationships,Cross-filtering and role-playing Dimensions,Bi-directional cross-filtering,Role-playing dimensions","Granularity, measures, and hierarchies,Hidden hierarchies,Hierarchies and measures in Power BI,Build a hierarchy,Change the granularity of a query,Measures and quick measures","Identifying performance problems,Optimizing performance,Performance tips in Power BI,Data types and calculations,Calculated versus computed columns,An alternative to bi-directional filtering,Congratulations!","Kevin Feasel,Carl Rosseel,Nina Spreitzer","Data Analyst,Exercises and Datasets,DataCamp vs. Local Experience,Data Modeling in Power BI",,
381,Report Design in Power BI,3,9,26,,2150,"Continue your data visualization journey with this course on designing reports in Power BI. You'll learn practical techniques for incorporating DAX measures and calculations in your reports—empowering users to filter, highlight values, and group data effectively. Through hands-on exercises, you'll also be introduced to progressive disclosure, a user experience (UX) technique to make reporting easier before discovering how to change report themes and optimize them for mobile users.","Enhance visuals with DAX,Highlight the median value,Improve engagement with DAX,Perform filtered calculations,Review the filter context,Highlight the smallest value,Bucket by department","Create a custom theme,Guidance on themes,Modifying a theme,Change default font sizes,Modify color choices,Alter the filter pane","Progressive disclosure,Progressive disclosure requirements,Progressive disclosure in Power BI,Budgets vs expenditures over time,Show and hide departments,Choose between visuals","Design for mobile devices,Mobile layout capabilities,Creating a mobile design,Create a mobile layout,Progressive disclosure on mobile,Make it mobile-friendly,Congratulations!",Carl Rosseel,"Data Analyst,Exercises and Datasets,DataCamp vs. Local Experience,Reports in Power BI,Intermediate DAX in Power BI",,
382,Reports in Power BI,3,9,28,,2350,"In this advanced course, take your Power BI visualizations up a level with the skills you already have. You’ll learn complex alternative data storytelling techniques to simply building dashboards, including buttons and bookmarks to create more interactive visualizations. Customize the user experience by drillthrough filters and emoji, and learn how to tweak the Q&A feature for personalized reports.","Reports vs. dashboards,Report or dashboard?,Increasing report interaction,Extend the Over Budget report,Create drill-through filters,Use scatterplots over time","Customize look and feel,Button format options,Mouse actions and Unicode,Add a button animation,Visual header tooltips,Table look and feel,Edit interactions","Bookmarks and buttons,What can bookmarks do?,Create and display bookmarks,Create bookmarks,Tell a story with bookmarks,Create buttons,Bookmarks and button navigation","Customize a report with Q&A,Create a Q&A statement,The Q&A visual,Add the Q&A visual,Working with the Q&A visual,Add synonyms for fields,Teach Q&A new terms,Congratulations!",Carl Rosseel,"Data Analyst,Exercises and Datasets,DataCamp vs. Local Experience,Data Visualization in Power BI,Intermediate DAX in Power BI",,
383,Deploying and Maintaining Assets in Power BI,2,8,26,,1850,"Learn how to deploy and maintain assets in Power BI. Through hands-on exercises, you’ll get to grips with the Power BI Service interface and key elements in it like workspaces. You’ll learn how to securely report access by managing access to datasets, implementing row-level security, or applying sensitivity labels to prevent unauthorized data re-use or exfiltration. You’ll also discover how to promote and certify content in Power BI before learning how to save time by subscribing to reports and setting up data alerts—making it easy to keep on top of changes to data in your reports.","Workspaces and applications,Bringing your own data,Template vs organizational apps,Creating workspaces and apps,Workspace defaults,Steps to publish an app,Ways to get an app","Enabling report discovery,Promote or certify?,Personalize a report,Personalizing a visual,Certify content,Subscriptions and data alerts,Subscribing to a report,Congratulations!","Securing datasets in Power BI Service,Sensitivity labels,Row-level security's benefit,Manage dataset permissions,Matching permissions with activities,Granting permissions on datasets,Row-level security and permissions,Configure row-level security,Apply sensitivity labels,Step by step sensitivity labels,Setting sensitivity labels",,"Maarten Van den Broeck,Carl Rosseel","Data Analyst,Exercises and Datasets,Data Connections in Power BI,Introduction to DAX in Power BI",,
384,Case Study: Analyzing Customer Churn in Power BI,3,4,25,,2150,"Are you ready to apply your Power BI skills to a real-world dataset? For subscription-based businesses, reducing customer churn is a top priority. In this Power BI case study, you'll investigate a dataset from an example telecom company called Databel and analyze their churn rates. Analyzing churn doesn’t just mean knowing what the churn rate is: it’s also about figuring out why customers are churning at the rate they are, and how to reduce churn. You'll answer these questions by creating measures and calculated columns, while simultaneously creating eye-catching report pages.","Analyzing customer churn in Power BI,Analysis process,Data check time,Understanding churn,Calculating churn,Investigating churn reasons,Digging deeper into churn categories,Use maps to your advantage","Creating a cohesive story,Dashboarding best practices,Overview page,Age brackets & groups,Payment method and contract category,International and data plan,More insights,Wrap-up","Zooming out,Analyzing demographics,Age groups,Inspecting groups,Multiple fields to investigate,Unlimited plan,International calls,Advice to Databel,Contract type",,"Carl Rosseel,Azat Saskal","Data Analyst,Exercises and Datasets,Metadata sheet,DataCamp vs. Local Experience,Introduction to DAX in Power BI,Data Visualization in Power BI",,
385,Introduction to Git,4,,46,"118,340",3650,"Version control is one of the power tools of programming. It allows you to keep track of what you did when, undo any changes you decide you don't want, and collaborate at scale with other people. This course will introduce you to Git, a modern version control tool that is very popular with data scientists and software developers, and show you how to use it to get more done in less time and with less pain.","What is version control?,Where does Git store information?,How can I check the state of a repository?,How can I tell what I have changed?,What is in a diff?,What's the first step in saving changes?,How can I tell what's going to be committed?,Interlude: how can I edit a file?,How do I commit changes?,How can I view a repository's history?,How can I view a specific file's history?,How do I write a better log message","How can I commit changes selectively?,How do I re-stage files?,How can I undo changes to unstaged files?,How can I undo changes to staged files?,How do I restore an old version of a file?,How can I undo all of the changes I have made?","How can I create a brand new repository?,How can I turn an existing project into a Git repository?,How can I create a copy of an existing repository?,How can I find out where a cloned repository originated?,How can I define remotes?,How can I pull in changes from a remote repository?,What happens if I try to pull when I have unsaved changes?,How can I push my changes to a remote repository?,What happens if my push conflicts with someone else's work?","How does Git store information?,What is a hash?,How can I view a specific commit?,What is Git's equivalent of a relative path?,How can I see who changed what in a file?,How can I see what changed between two commits?,How do I add new files?,How do I tell Git to ignore certain files?,How can I remove unwanted files?,How can I see how Git is configured?,How can I change my Git configuration?",Filip Schouwenaars,,"What is a branch?,How can I see what branches my repository has?,How can I view the differences between branches?,How can I switch from one branch to another?,How can I create a branch?,How can I merge two branches?,What are conflicts?,How can I merge two branches with conflicts?",
386,Introduction to SQL Server,4,13,46,"114,334",3850,"Master the basics of Microsoft SQL Server—one of the world's most popular database systems.

This course covers:
✓ How to use SELECT statements to retrieve data
✓ How to use SQL Server aggregate functions
✓ How to manipulate text fields
✓ How to retrieve data from multiple sources
✓ All of the key aspects of working with data in SQL Server

Each time you're introduced to a new concept or function, you'll have the opportunity to test your knowledge and build your confidence. You'll work with a digital media database to review the sales of various artists and tracks, Eurovision datasets, and review trends in US power outages to explore a number of different data types and scenarios.","Welcome,Simple selections,More selections,Ordering and filtering,Order by,Where,Where again,Working with NULL values,WHERE the wild things are,Exploring classic rock songs,Exploring classic rock songs - AND/OR,Using parentheses in your queries","Joining tables,Inner Joins - a perfect match,Inner Joins (II),Inner Join (III) - Join 3 tables,LEFT & RIGHT JOIN,LEFT join,RIGHT JOIN,UNION & UNION ALL,UNION ALL Check,Join the UNION","Aggregating Data,Summing,Counting,MIN, MAX and AVG,Strings,LEN'gth of a string,Left and right,Stuck in the middle with you,Grouping and Having,GROUP BY,Having,Grouping together","Creator,CRUD operations,Create tables,Insert, Update, Delete,Insert,Update,Delete,Declare yourself,DECLARE and SET a variable,Declare multiple variables,Ultimate Power,Congratulations!","Yashas Roy,Mona Khalil","SQL Server Developer,SQL Server Fundamentals,Eurovision Song Contest,Power outages in USA,Classic rock radio station songs,Chinook Database",,
387,Introduction to Relational Databases in SQL,4,13,45,"97,700",3600,"You’ve already used SQL to query data from databases. But did you know that there's a lot more you can do with databases? You can model different phenomena in your data, as well as the relationships between them. This gives your data structure and consistency, which results in better data quality. In this course, you'll experience this firsthand by working with a real-life dataset that was used to investigate questionable university affiliations. Column by column, table by table, you'll get to unlock and admire the full potential of databases. You'll learn how to create tables and specify their relationships, as well as how to enforce data integrity. You'll also discover other unique features of database systems, such as constraints.","Introduction to relational databases,Attributes of relational databases,Query information_schema with SELECT,Tables: At the core of every database,CREATE your first few TABLEs,ADD a COLUMN with ALTER TABLE,Update your database as the structure changes,RENAME and DROP COLUMNs in affiliations,Migrate data with INSERT INTO SELECT DISTINCT,Delete tables with DROP TABLE","Keys and superkeys,Get to know SELECT COUNT DISTINCT,Identify keys with SELECT COUNT DISTINCT,Primary keys,Identify the primary key,ADD key CONSTRAINTs to the tables,Surrogate keys,Add a SERIAL surrogate key,CONCATenate columns to a surrogate key,Test your knowledge before advancing","Better data quality with constraints,Types of database constraints,Conforming with data types,Type CASTs,Working with data types,Change types with ALTER COLUMN,Convert types USING a function,The not-null and unique constraints,Disallow NULL values with SET NOT NULL,What happens if you try to enter NULLs?,Make your columns UNIQUE with ADD CONSTRAINT","Model 1:N relationships with foreign keys,REFERENCE a table with a FOREIGN KEY,Explore foreign key constraints,JOIN tables linked by a foreign key,Model more complex relationships,Add foreign keys to the ""affiliations"" table,Populate the ""professor_id"" column,Drop ""firstname"" and ""lastname"",Referential integrity,Referential integrity violations,Change the referential integrity behavior of a key,Roundup,Count affiliations per university,Join all the tables together","Sumedh Panchadhar,Chester Ismay,Mona Khalil","Data Engineer,SQL for Database Administrators,SQL Server Developer,SQL Server for Database Administrators,Introduction to SQL",,
388,Introduction to Statistics,4,16,56,"2,351",3450,"Statistics are all around us, from marketing to sales to healthcare. The ability to collect, analyze, and draw conclusions from data is not only extremely valuable, but it is also becoming commonplace to expect roles that are not traditionally analytical to understand the fundamental concepts of statistics. This course will equip you with the necessary skills to feel confident in working with analyzing data to draw insights. You'll be introduced to common methods used for summarizing and describing data, learn how probability can be applied to commercial scenarios, and discover how experiments are conducted to understand relationships and patterns. You'll work with real-world datasets including crime data in London, England, and sales data from an online retail company!","What is statistics?,Using statistics in the real-world,Identifying data types,Descriptive vs. Inferential statistics,Measures of center,Typical number of robberies per London Borough,Choosing a measure,London Boroughs with most frequent crimes,Measures of spread,Defining measures of spread,Box plots for measuring spread,Which crime has the larger standard deviation","The binomial distribution,Recognizing a binomial distribution,How probability affects the binomial distribution,Identifying n and p,The normal distribution,Recognizing the normal distribution,What makes the normal distribution special?,Identifying skewness,Describing distributions using kurtosis,The central limit theorem,Visualizing sampling distributions,The CLT vs. The law of large numbers,When to use the central limit theorem,The Poisson distribution,Identifying Poisson processes,Recognizing lambda in the Poisson distribution","What are the chances?,What is more likely?,Chances of the next sale being more than the mean,Conditional probability,Dependent vs. Independent events,Orders of more than 10 basket products,Discrete distributions,Identifying distributions,Sample mean vs. Theoretical mean,Continuous distributions,Discrete vs. Continuous distributions,Finding the normal distribution,Calculating probability with a uniform distribution","Hypothesis testing,Sunshine and sleep,The hypothesis testing workflow,Independent and dependent variables,Experiments,Recognizing controlled trials,Why use randomization?,Correlation,Identifying correlation between variables,What can correlation tell you?,Confounding variables,Interpreting hypothesis test results,Significance levels vs. p-values,Type I and type II errors,Congratulations!","James Chapman,Izzy Weber",,,
389,Cleaning Data in SQL Server Databases,4,13,48,"6,471",3750,"Did you know that data scientists and data analysts spend a large amount of time cleaning data before they can analyze it? This is because real-world data is messy. To help you navigate messy data this course teaches you how to clean data stored in an SQL Server database. You’ll learn how to solve common problems such as how to clean messy strings, deal with empty values, compare the similarity between strings, and much more. You’ll get hands-on with all these tasks using a wide range of interesting and messy datasets, including monthly airline flights by airport, TV series and paper shop sales. Are you ready to get your hands messy?","Introduction to Cleaning Data,Unifying flight formats I,Unifying flight formats II,Cleaning messy strings,Trimming strings I,Trimming strings II,Unifying strings,Comparing the similarity between strings,SOUNDEX() and DIFFERENCE(),Comparing names with SOUNDEX(),Comparing names with DIFFERENCE()","Out of range values and inaccurate data,Out of range values or inaccurate data?,Detecting out of range values,Excluding out of range values,Detecting and excluding inaccurate data,Converting data with different types,Using CAST() and CONVERT(),The series with most episodes,Pattern matching,Characters to specify a patterns,Matching urls,Checking phone numbers","Dealing with missing data,Removing missing values,Removing blank spaces,Filling missing values using ISNULL(),Filling missing values using COALESCE(),Avoiding duplicate data,Diagnosing duplicates,Treating duplicates,Dealing with different date formats,Using CONVERT(),Using FORMAT(),CONVERT() vs FORMAT()","Combining data of some columns into one column,Combining cities and states using +,Concatenating cities and states,Working with DATEFROMPARTS(),Splitting data of one column into more columns,Using SUBSTRING() and CHARINDEX(),Using RIGHT() , LEFT() and REVERSE(),SUBSTRING() or CHARINDEX()?,Transforming rows into columns and vice versa,PIVOT or UNPIVOT?,Turning rows into columns,Turning columns into rows,Congratulations!",Amy Peterson,"Flight statistics dataset and series ratings dataset,Intermediate SQL Server",,
390,Introduction to Deep Learning in Python,4,17,50,"215,533",3500,"Deep learning is the machine learning technique behind the most exciting capabilities in diverse areas like robotics, natural language processing, image recognition, and artificial intelligence, including the famous AlphaGo. In this course, you'll gain hands-on, practical knowledge of how to use deep learning with Keras 2.0, the latest version of a cutting-edge library for deep learning in Python.","Introduction to deep learning,Comparing neural network models to classical regression models,Forward propagation,Coding the forward propagation algorithm,Activation functions,The Rectified Linear Activation Function,Applying the network to many observations/rows of data,Deeper networks,Forward propagation in a deeper network,Multi-layer neural networks,Representations are learned,Levels of representation","Creating a keras model,Understanding your data,Specifying a model,Compiling and fitting a model,Compiling the model,Fitting the model,Classification models,Understanding your classification data,Last steps in classification models,Using models,Making predictions","The need for optimization,Calculating model errors,Understanding how weights change model accuracy,Coding how weight changes affect accuracy,Scaling up to multiple data points,Gradient descent,Calculating slopes,Improving model weights,Making multiple updates to weights,Backpropagation,The relationship between forward and backward propagation,Thinking about backward propagation,Backpropagation in practice,A round of backpropagation","Understanding model optimization,Diagnosing optimization problems,Changing optimization parameters,Model validation,Evaluating model accuracy on validation dataset,Early stopping: Optimizing the optimization,Experimenting with wider networks,Adding layers to a network,Thinking about model capacity,Experimenting with model structures,Stepping up to images,Building your own digit recognition model,Final thoughts","Hugo Bowne-Anderson,Yashas Roy","Deep Learning,Machine Learning Fundamentals,Machine Learning Scientist,Hourly wages,MNIST,Titanic,Machine Learning with scikit-learn",,
391,Introduction to AWS Boto in Python,4,15,54,"10,613",4550,"What if you were no longer constrained by the capabilities of your laptop? What if you could get an SMS when a city garbage truck camera spots a missing a cat? This is all possible with cloud technology. This course will teach you how to integrate Amazon Web Services (AWS) into your data workflow. You’ll learn how to upload data to S3, AWS cloud storage. You’ll use triggers from your analysis to send text messages with AWS SNS. You will use Rekognition to detect objects in an image. And you will use Comprehend to decide if a piece of feedback is negative. By the time you’re done, you will learn how to build a pipeline, subscribe people to it, and send them text messages when an image contains a cat!","Intro to AWS and Boto3,Your first boto3 client,Multiple clients,Removing repetitive work,Diving into buckets,Creating a bucket,Listing buckets,Deleting a bucket,Deleting multiple buckets,Uploading and retrieving files,Putting files in the cloud,Spring cleaning","SNS Topics,Creating a Topic,Creating multiple topics,Deleting multiple topics,SNS Subscriptions,Subscribing to topics,Creating multiple subscriptions,Deleting multiple subscriptions,Sending messages,Sending an alert,Sending a single SMS message,Case Study: Building a notification system,Creating multi-level topics,Different protocols per topic level,Sending multi-level alerts","Keeping objects secure,Making an object public,Uploading a public report,Making multiple files public,Accessing private objects in S3,Generating a presigned URL,Opening a private file,Sharing files through a website,Generate HTML table from Pandas,Upload an HTML file to S3,Case Study: Generating a Report Repository,Combine daily requests for February,Upload aggregated reports for February,Update index to include February,Upload the new index","Rekognizing patterns,Cat detector,Multiple cat detector,Parking sign reader,Comprehending text,Detecting language,Translating Get It Done requests,Getting request sentiment,Case Study: Scooting Around!,Scooter community sentiment,Scooter dispatch,Wrap up","Adel Nehme,Hillary Green-Lerman","Data Engineer,Get It Done Requests,Python Data Science Toolbox (Part 2),AWS Cloud Concepts",,
